============================= test session starts ==============================
platform linux -- Python 3.11.9, pytest-8.2.0, pluggy-1.6.0
benchmark: 5.1.0 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)
rootdir: /home/pi/hacking
configfile: pytest.ini
plugins: xdist-3.8.0, hypothesis-6.142.1, cov-7.0.0, mock-3.12.0, html-4.1.1, benchmark-5.1.0, Faker-37.11.0, metadata-3.1.1, json-report-1.5.0
collected 360 items

plugins/clustering_advanced/tests/test_clustering_advanced.py ..FFF.F... [  2%]
.....                                                                    [  4%]
plugins/ensemble_models/tests/test_ensemble_models.py ........F.         [  6%]
plugins/example_plugin/tests/test_example_plugin.py ..                   [  7%]
plugins/reinforcement_learning/tests/test_reinforcement_learning.py .... [  8%]
.F......FF....                                                           [ 12%]
plugins/sankey/tests/test_sankey.py ......                               [ 14%]
plugins/umap_plot/tests/test_umap_plot.py .F.FF..F                       [ 16%]
pytest/test_analysis.py ........F.FF...F...FF..F.F                       [ 23%]
pytest/test_app.py ..F...FFF..                                           [ 26%]
pytest/test_capture.py .FF..F....F......F.F.                             [ 32%]
pytest/test_controllers.py .FF..F...FFFFFFFFFF..FF.F                     [ 39%]
pytest/test_error_handling.py ......................F..FFFFFFF..F...     [ 50%]
pytest/test_integration.py FFF.FF..F..FF                                 [ 53%]
pytest/test_performance.py ....FFFFFF.F                                  [ 56%]
pytest/test_presentation.py FF...........F....F.                         [ 62%]
pytest/test_storage.py ......F..F....FF..FF...                           [ 68%]
pytest/test_utils.py F.F......FF..FFFF.FFF.....F.F                       [ 76%]
tests/integration/test_end_to_end.py FFFFFF                              [ 78%]
tests/performance/test_benchmarks.py FFFFFFFFFFFFFF                      [ 82%]
tests/performance/test_memory_profiling.py ..F

=================================== FAILURES ===================================
____________ TestAdvancedClusteringPlugin.test_spectral_clustering _____________

self = <plugins.clustering_advanced.tests.test_clustering_advanced.TestAdvancedClusteringPlugin object at 0x7f92d7fa10>
plugin = <plugins.clustering_advanced.plugin.Plugin object at 0x7f78f47b90>
mock_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f78f47a10>
mock_events = [{'client': 'aa:bb:cc:dd:ee:00', 'ts': 1000.0, 'type': 'probe_req'}, {'client': 'aa:bb:cc:dd:ee:01', 'ts': 1001.0, 'type': 'probe_req'}]

    def test_spectral_clustering(self, plugin, mock_state, mock_events):
        """Test Spectral Clustering."""
        features, client_macs = plugin._extract_features_for_clustering(mock_state, mock_events)
    
        labels, metrics = plugin._run_spectral_clustering(features, n_clusters=3)
    
        assert len(labels) == len(features)
>       assert "algorithm" in metrics
E       assert 'algorithm' in {'error': "name 'calinski_harabasz_score' is not defined"}

plugins/clustering_advanced/tests/test_clustering_advanced.py:88: AssertionError
------------------------------ Captured log call -------------------------------
ERROR    plugins.clustering_advanced.plugin:plugin.py:250 Fehler bei Spectral Clustering: name 'calinski_harabasz_score' is not defined
__________ TestAdvancedClusteringPlugin.test_hierarchical_clustering ___________

self = <plugins.clustering_advanced.tests.test_clustering_advanced.TestAdvancedClusteringPlugin object at 0x7f92d8c090>
plugin = <plugins.clustering_advanced.plugin.Plugin object at 0x7f78f47990>
mock_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f78f98e10>
mock_events = [{'client': 'aa:bb:cc:dd:ee:00', 'ts': 1000.0, 'type': 'probe_req'}, {'client': 'aa:bb:cc:dd:ee:01', 'ts': 1001.0, 'type': 'probe_req'}]

    def test_hierarchical_clustering(self, plugin, mock_state, mock_events):
        """Test Hierarchical Clustering."""
        features, client_macs = plugin._extract_features_for_clustering(mock_state, mock_events)
    
        labels, metrics = plugin._run_hierarchical_clustering(features, n_clusters=3)
    
        assert len(labels) == len(features)
>       assert "algorithm" in metrics
E       assert 'algorithm' in {'error': "name 'calinski_harabasz_score' is not defined"}

plugins/clustering_advanced/tests/test_clustering_advanced.py:100: AssertionError
------------------------------ Captured log call -------------------------------
ERROR    plugins.clustering_advanced.plugin:plugin.py:288 Fehler bei Hierarchical Clustering: name 'calinski_harabasz_score' is not defined
______________ TestAdvancedClusteringPlugin.test_gaussian_mixture ______________

self = <plugins.clustering_advanced.tests.test_clustering_advanced.TestAdvancedClusteringPlugin object at 0x7f92d8c710>
plugin = <plugins.clustering_advanced.plugin.Plugin object at 0x7f74ddb190>
mock_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f74ddb390>
mock_events = [{'client': 'aa:bb:cc:dd:ee:00', 'ts': 1000.0, 'type': 'probe_req'}, {'client': 'aa:bb:cc:dd:ee:01', 'ts': 1001.0, 'type': 'probe_req'}]

    def test_gaussian_mixture(self, plugin, mock_state, mock_events):
        """Test Gaussian Mixture Model."""
        features, client_macs = plugin._extract_features_for_clustering(mock_state, mock_events)
    
        labels, metrics = plugin._run_gaussian_mixture(features, n_clusters=3)
    
        assert len(labels) == len(features)
>       assert "algorithm" in metrics
E       assert 'algorithm' in {'error': "name 'calinski_harabasz_score' is not defined"}

plugins/clustering_advanced/tests/test_clustering_advanced.py:110: AssertionError
------------------------------ Captured log call -------------------------------
ERROR    plugins.clustering_advanced.plugin:plugin.py:333 Fehler bei Gaussian Mixture Model: name 'calinski_harabasz_score' is not defined
_____________ TestAdvancedClusteringPlugin.test_hdbscan_clustering _____________

self = <plugins.clustering_advanced.tests.test_clustering_advanced.TestAdvancedClusteringPlugin object at 0x7f92d8d410>
plugin = <plugins.clustering_advanced.plugin.Plugin object at 0x7f78f64690>
mock_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f78efaa10>
mock_events = [{'client': 'aa:bb:cc:dd:ee:00', 'ts': 1000.0, 'type': 'probe_req'}, {'client': 'aa:bb:cc:dd:ee:01', 'ts': 1001.0, 'type': 'probe_req'}]

    def test_hdbscan_clustering(self, plugin, mock_state, mock_events):
        """Test HDBSCAN Clustering."""
        features, client_macs = plugin._extract_features_for_clustering(mock_state, mock_events)
    
        labels, metrics = plugin._run_hdbscan_clustering(features)
    
        assert len(labels) == len(features)
>       assert "algorithm" in metrics
E       assert 'algorithm' in {'error': "name 'hdbscan' is not defined"}

plugins/clustering_advanced/tests/test_clustering_advanced.py:132: AssertionError
------------------------------ Captured log call -------------------------------
ERROR    plugins.clustering_advanced.plugin:plugin.py:408 Fehler bei HDBSCAN Clustering: name 'hdbscan' is not defined
_______ TestEnsembleModelsPlugin.test_performance_visualization_creation _______

self = <MagicMock name='make_subplots' id='547384373328'>

    def assert_called_once(self):
        """assert that the mock was called only once.
        """
        if not self.call_count == 1:
            msg = ("Expected '%s' to have been called once. Called %s times.%s"
                   % (self._mock_name or 'mock',
                      self.call_count,
                      self._calls_repr()))
>           raise AssertionError(msg)
E           AssertionError: Expected 'make_subplots' to have been called once. Called 0 times.

../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:918: AssertionError

During handling of the above exception, another exception occurred:

self = <plugins.ensemble_models.tests.test_ensemble_models.TestEnsembleModelsPlugin object at 0x7f91bab990>
plugin = <plugins.ensemble_models.plugin.Plugin object at 0x7f7289af10>
temp_outdir = PosixPath('/tmp/pytest-of-pi/pytest-1/test_performance_visualization0/output')

    def test_performance_visualization_creation(self, plugin, temp_outdir):
        """Test Erstellung der Performance-Visualisierung."""
        temp_outdir.mkdir(exist_ok=True)
    
        # Mock Performance-Metriken
        from plugins.ensemble_models.plugin import ModelPerformance
        performance_metrics = [
            ModelPerformance("Model1", 0.8, 0.75, 0.8, 0.77, 0.78, 0.02, 1.0, 0.1),
            ModelPerformance("Model2", 0.85, 0.82, 0.85, 0.83, 0.84, 0.01, 1.5, 0.15),
        ]
    
        with patch('plotly.graph_objects') as mock_go:
            with patch('plotly.subplots.make_subplots') as mock_subplots:
                mock_fig = MagicMock()
                mock_subplots.return_value = mock_fig
    
                plugin._create_performance_visualization(performance_metrics, temp_outdir)
    
                # Überprüfe, dass Plotly-Funktionen aufgerufen wurden
>               mock_subplots.assert_called_once()
E               AssertionError: Expected 'make_subplots' to have been called once. Called 0 times.

plugins/ensemble_models/tests/test_ensemble_models.py:257: AssertionError
_________ TestReinforcementLearningPlugin.test_environment_observation _________

self = <plugins.reinforcement_learning.tests.test_reinforcement_learning.TestReinforcementLearningPlugin object at 0x7f918f1f10>
plugin = <plugins.reinforcement_learning.plugin.Plugin object at 0x7f727e9a50>
mock_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f727e8f50>
mock_events = [{'client': 'aa:bb:cc:dd:ee:00', 'ts': 1000.0, 'type': 'probe_req'}, {'client': 'aa:bb:cc:dd:ee:01', 'ts': 1001.0, 'type': 'probe_req'}]

    def test_environment_observation(self, plugin, mock_state, mock_events):
        """Test Environment Observation."""
        env = plugin._WiFiScanningEnvironment(mock_state, mock_events)
        obs = env._get_observation()
    
        assert len(obs) == 10
        assert all(0 <= val <= 1 for val in obs)  # Normalisierte Werte
>       assert obs[0] == 1.0 / 48.0  # current_channel normalisiert
E       assert 0.020833334 == (1.0 / 48.0)

plugins/reinforcement_learning/tests/test_reinforcement_learning.py:141: AssertionError
_____ TestReinforcementLearningPlugin.test_plugin_run_with_sufficient_data _____

self = <MagicMock name='dump' id='547383027856'>

    def assert_called(self):
        """assert that the mock was called at least once
        """
        if self.call_count == 0:
            msg = ("Expected '%s' to have been called." %
                   (self._mock_name or 'mock'))
>           raise AssertionError(msg)
E           AssertionError: Expected 'dump' to have been called.

../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:908: AssertionError

During handling of the above exception, another exception occurred:

self = <plugins.reinforcement_learning.tests.test_reinforcement_learning.TestReinforcementLearningPlugin object at 0x7f918d9250>
plugin = <plugins.reinforcement_learning.plugin.Plugin object at 0x7f72a61410>
mock_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f72a61a50>
mock_events = [{'client': 'aa:bb:cc:dd:ee:00', 'ts': 1000.0, 'type': 'probe_req'}, {'client': 'aa:bb:cc:dd:ee:01', 'ts': 1001.0, 'type': 'probe_req'}]
mock_console = <MagicMock id='547383022800'>
temp_outdir = PosixPath('/tmp/pytest-of-pi/pytest-1/test_plugin_run_with_sufficien2/output')

    def test_plugin_run_with_sufficient_data(self, plugin, mock_state, mock_events, mock_console, temp_outdir):
        """Test Plugin-Ausführung mit ausreichenden Daten."""
        temp_outdir.mkdir(exist_ok=True)
    
        with patch('joblib.dump') as mock_dump:
            with patch('builtins.open', create=True) as mock_open:
                plugin.run(mock_state, mock_events, mock_console, temp_outdir)
    
        # Überprüfe, dass Console-Ausgaben gemacht wurden
        assert mock_console.print.called
    
        # Überprüfe, dass Ergebnisse gespeichert wurden
>       mock_dump.assert_called()
E       AssertionError: Expected 'dump' to have been called.

plugins/reinforcement_learning/tests/test_reinforcement_learning.py:260: AssertionError
------------------------------ Captured log call -------------------------------
ERROR    plugins.reinforcement_learning.plugin:plugin.py:165 Fehler bei der RL-Optimierung: 'NoneType' object has no attribute 'shape'
Traceback (most recent call last):
  File "/home/pi/hacking/plugins/reinforcement_learning/plugin.py", line 94, in run
    raise ImportError("PyTorch nicht verfügbar")
ImportError: PyTorch nicht verfügbar

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/pi/hacking/plugins/reinforcement_learning/plugin.py", line 97, in run
    state_size=env.observation_space.shape[0],
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
_______ TestReinforcementLearningPlugin.test_plugin_run_without_pytorch ________

self = <plugins.reinforcement_learning.tests.test_reinforcement_learning.TestReinforcementLearningPlugin object at 0x7f918d9850>
plugin = <plugins.reinforcement_learning.plugin.Plugin object at 0x7f7296d510>
mock_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f7296fa10>
mock_events = [{'client': 'aa:bb:cc:dd:ee:00', 'ts': 1000.0, 'type': 'probe_req'}, {'client': 'aa:bb:cc:dd:ee:01', 'ts': 1001.0, 'type': 'probe_req'}]
mock_console = <MagicMock id='547383338512'>
temp_outdir = PosixPath('/tmp/pytest-of-pi/pytest-1/test_plugin_run_without_pytorc0/output')

    def test_plugin_run_without_pytorch(self, plugin, mock_state, mock_events, mock_console, temp_outdir):
        """Test Plugin-Ausführung ohne PyTorch (Fallback zu Simple RL)."""
        temp_outdir.mkdir(exist_ok=True)
    
        with patch('plugins.reinforcement_learning.plugin.torch', None):
            with patch('joblib.dump') as mock_dump:
                with patch('builtins.open', create=True) as mock_open:
                    plugin.run(mock_state, mock_events, mock_console, temp_outdir)
    
        # Überprüfe, dass Console-Ausgaben gemacht wurden
        assert mock_console.print.called
    
        # Überprüfe, dass Simple RL Agent verwendet wurde
        console_calls = [str(call) for call in mock_console.print.call_args_list]
>       assert any("Q-Learning" in call for call in console_calls)
E       assert False
E        +  where False = any(<generator object TestReinforcementLearningPlugin.test_plugin_run_without_pytorch.<locals>.<genexpr> at 0x7f74dc6cf0>)

plugins/reinforcement_learning/tests/test_reinforcement_learning.py:277: AssertionError
------------------------------ Captured log call -------------------------------
ERROR    plugins.reinforcement_learning.plugin:plugin.py:165 Fehler bei der RL-Optimierung: 'NoneType' object has no attribute 'shape'
Traceback (most recent call last):
  File "/home/pi/hacking/plugins/reinforcement_learning/plugin.py", line 94, in run
    raise ImportError("PyTorch nicht verfügbar")
ImportError: PyTorch nicht verfügbar

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/pi/hacking/plugins/reinforcement_learning/plugin.py", line 97, in run
    state_size=env.observation_space.shape[0],
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
______________ TestUMAPPlotPlugin.test_plugin_run_with_valid_data ______________

self = <plugins.umap_plot.tests.test_umap_plot.TestUMAPPlotPlugin object at 0x7f91a2c950>
plugin = <plugins.umap_plot.plugin.Plugin object at 0x7f730dc9d0>
mock_clustered_client_df =                  mac  cluster   vendor
0  aa:bb:cc:dd:ee:00        0    Apple
1  aa:bb:cc:dd:ee:01        1  Samsung
2  aa:bb:cc:dd:ee:02        0    Apple
mock_client_feature_df =    feature1  feature2  feature3      original_macs
0       1.0       4.0       7.0  aa:bb:cc:dd:ee:00
1       2.0       5.0       8.0  aa:bb:cc:dd:ee:01
2       3.0       6.0       9.0  aa:bb:cc:dd:ee:02
mock_console = <MagicMock id='547391134608'>
temp_outdir = PosixPath('/tmp/pytest-of-pi/pytest-1/test_plugin_run_with_valid_dat0/output')

    def test_plugin_run_with_valid_data(self, plugin, mock_clustered_client_df, mock_client_feature_df, mock_console, temp_outdir):
        """Test Plugin-Ausführung mit gültigen Daten."""
        temp_outdir.mkdir(exist_ok=True)
    
>       with patch('umap.UMAP') as mock_umap:

plugins/umap_plot/tests/test_umap_plot.py:66: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1430: in __enter__
    self.target = self.getter()
../.pyenv/versions/3.11.9/lib/python3.11/pkgutil.py:700: in resolve_name
    mod = importlib.import_module(modname)
../.pyenv/versions/3.11.9/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1204: in _gcd_import
    ???
<frozen importlib._bootstrap>:1176: in _find_and_load
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'umap', import_ = <function _gcd_import at 0x7fb2f67d80>

>   ???
E   ModuleNotFoundError: No module named 'umap'

<frozen importlib._bootstrap>:1140: ModuleNotFoundError
__________ TestUMAPPlotPlugin.test_plugin_run_without_clustered_data ___________

self = <plugins.umap_plot.tests.test_umap_plot.TestUMAPPlotPlugin object at 0x7f91a2d690>
plugin = <plugins.umap_plot.plugin.Plugin object at 0x7f72e68090>
mock_console = <MagicMock id='547388556432'>
temp_outdir = PosixPath('/tmp/pytest-of-pi/pytest-1/test_plugin_run_without_cluste0/output')

    def test_plugin_run_without_clustered_data(self, plugin, mock_console, temp_outdir):
        """Test Plugin-Ausführung ohne Cluster-Daten."""
        temp_outdir.mkdir(exist_ok=True)
    
        plugin.run(
            state=None,
            clustered_client_df=None,
            client_feature_df=None,
            outdir=temp_outdir,
            console=mock_console
        )
    
        # Überprüfe Warnung für fehlende Cluster-Daten
        warning_calls = [call for call in mock_console.print.call_args_list
                        if "Keine Cluster-Daten" in str(call)]
>       assert len(warning_calls) > 0
E       assert 0 > 0
E        +  where 0 = len([])

plugins/umap_plot/tests/test_umap_plot.py:129: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  plugins.umap_plot.plugin:plugin.py:38 UMAP/Plotly nicht installiert. Überspringe Client-Map-Visualisierung.
__________ TestUMAPPlotPlugin.test_plugin_run_with_empty_feature_data __________

self = <plugins.umap_plot.tests.test_umap_plot.TestUMAPPlotPlugin object at 0x7f91a2df50>
plugin = <plugins.umap_plot.plugin.Plugin object at 0x7f72f14790>
mock_clustered_client_df =                  mac  cluster   vendor
0  aa:bb:cc:dd:ee:00        0    Apple
1  aa:bb:cc:dd:ee:01        1  Samsung
2  aa:bb:cc:dd:ee:02        0    Apple
mock_console = <MagicMock id='547389272592'>
temp_outdir = PosixPath('/tmp/pytest-of-pi/pytest-1/test_plugin_run_with_empty_fea0/output')

    def test_plugin_run_with_empty_feature_data(self, plugin, mock_clustered_client_df, mock_console, temp_outdir):
        """Test Plugin-Ausführung mit leeren Feature-Daten."""
        temp_outdir.mkdir(exist_ok=True)
    
        empty_feature_df = pd.DataFrame()
    
        plugin.run(
            state=None,
            clustered_client_df=mock_clustered_client_df,
            client_feature_df=empty_feature_df,
            outdir=temp_outdir,
            console=mock_console
        )
    
        # Überprüfe Warnung für leere Feature-Daten
        warning_calls = [call for call in mock_console.print.call_args_list
                        if "Keine Cluster-Daten" in str(call)]
>       assert len(warning_calls) > 0
E       assert 0 > 0
E        +  where 0 = len([])

plugins/umap_plot/tests/test_umap_plot.py:148: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  plugins.umap_plot.plugin:plugin.py:38 UMAP/Plotly nicht installiert. Überspringe Client-Map-Visualisierung.
______________ TestUMAPPlotPlugin.test_plugin_run_with_exception _______________

self = <plugins.umap_plot.tests.test_umap_plot.TestUMAPPlotPlugin object at 0x7f91a2e790>
plugin = <plugins.umap_plot.plugin.Plugin object at 0x7f72f7ea50>
mock_clustered_client_df =                  mac  cluster   vendor
0  aa:bb:cc:dd:ee:00        0    Apple
1  aa:bb:cc:dd:ee:01        1  Samsung
2  aa:bb:cc:dd:ee:02        0    Apple
mock_client_feature_df =    feature1  feature2  feature3      original_macs
0       1.0       4.0       7.0  aa:bb:cc:dd:ee:00
1       2.0       5.0       8.0  aa:bb:cc:dd:ee:01
2       3.0       6.0       9.0  aa:bb:cc:dd:ee:02
mock_console = <MagicMock id='547389690064'>
temp_outdir = PosixPath('/tmp/pytest-of-pi/pytest-1/test_plugin_run_with_exception0/output')

    def test_plugin_run_with_exception(self, plugin, mock_clustered_client_df, mock_client_feature_df, mock_console, temp_outdir):
        """Test Plugin-Ausführung mit Exception."""
        temp_outdir.mkdir(exist_ok=True)
    
>       with patch('umap.UMAP') as mock_umap:

plugins/umap_plot/tests/test_umap_plot.py:192: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1430: in __enter__
    self.target = self.getter()
../.pyenv/versions/3.11.9/lib/python3.11/pkgutil.py:700: in resolve_name
    mod = importlib.import_module(modname)
../.pyenv/versions/3.11.9/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1204: in _gcd_import
    ???
<frozen importlib._bootstrap>:1176: in _find_and_load
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'umap', import_ = <function _gcd_import at 0x7fb2f67d80>

>   ???
E   ModuleNotFoundError: No module named 'umap'

<frozen importlib._bootstrap>:1140: ModuleNotFoundError
___________________ TestAnalysisLogic.test_profile_clusters ____________________

self = <test_analysis.TestAnalysisLogic object at 0x7f7a4d1f10>

    def test_profile_clusters(self):
        """Test Cluster-Profilierung."""
        feature_data = {
            'original_macs': ['mac1', 'mac2', 'mac3'],
            'feature1': [10, 20, 15],
            'feature2': [1, 2, 1.5]
        }
        feature_df = pd.DataFrame(feature_data)
    
        cluster_data = {
            'original_macs': ['mac1', 'mac2', 'mac3'],
            'cluster': [0, 0, 1]
        }
        clustered_df = pd.DataFrame(cluster_data)
    
>       profiles = analysis.profile_clusters(feature_df, clustered_df)

pytest/test_analysis.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/analysis/logic.py:666: in profile_clusters
    profiles["details"] = full_df.set_index("mac").to_dict(orient="index")
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self =   original_macs  feature1  feature2  cluster
0          mac1        10       1.0        0
1          mac2        20       2.0        0
2          mac3        15       1.5        1
keys = ['mac']

    def set_index(
        self,
        keys,
        *,
        drop: bool = True,
        append: bool = False,
        inplace: bool = False,
        verify_integrity: bool = False,
    ) -> DataFrame | None:
        """
        Set the DataFrame index using existing columns.
    
        Set the DataFrame index (row labels) using one or more existing
        columns or arrays (of the correct length). The index can replace the
        existing index or expand on it.
    
        Parameters
        ----------
        keys : label or array-like or list of labels/arrays
            This parameter can be either a single column key, a single array of
            the same length as the calling DataFrame, or a list containing an
            arbitrary combination of column keys and arrays. Here, "array"
            encompasses :class:`Series`, :class:`Index`, ``np.ndarray``, and
            instances of :class:`~collections.abc.Iterator`.
        drop : bool, default True
            Delete columns to be used as the new index.
        append : bool, default False
            Whether to append columns to existing index.
        inplace : bool, default False
            Whether to modify the DataFrame rather than creating a new one.
        verify_integrity : bool, default False
            Check the new index for duplicates. Otherwise defer the check until
            necessary. Setting to False will improve the performance of this
            method.
    
        Returns
        -------
        DataFrame or None
            Changed row labels or None if ``inplace=True``.
    
        See Also
        --------
        DataFrame.reset_index : Opposite of set_index.
        DataFrame.reindex : Change to new indices or expand indices.
        DataFrame.reindex_like : Change to same indices as other DataFrame.
    
        Examples
        --------
        >>> df = pd.DataFrame({'month': [1, 4, 7, 10],
        ...                    'year': [2012, 2014, 2013, 2014],
        ...                    'sale': [55, 40, 84, 31]})
        >>> df
           month  year  sale
        0      1  2012    55
        1      4  2014    40
        2      7  2013    84
        3     10  2014    31
    
        Set the index to become the 'month' column:
    
        >>> df.set_index('month')
               year  sale
        month
        1      2012    55
        4      2014    40
        7      2013    84
        10     2014    31
    
        Create a MultiIndex using columns 'year' and 'month':
    
        >>> df.set_index(['year', 'month'])
                    sale
        year  month
        2012  1     55
        2014  4     40
        2013  7     84
        2014  10    31
    
        Create a MultiIndex using an Index and a column:
    
        >>> df.set_index([pd.Index([1, 2, 3, 4]), 'year'])
                 month  sale
           year
        1  2012  1      55
        2  2014  4      40
        3  2013  7      84
        4  2014  10     31
    
        Create a MultiIndex using two Series:
    
        >>> s = pd.Series([1, 2, 3, 4])
        >>> df.set_index([s, s**2])
              month  year  sale
        1 1       1  2012    55
        2 4       4  2014    40
        3 9       7  2013    84
        4 16     10  2014    31
        """
        inplace = validate_bool_kwarg(inplace, "inplace")
        self._check_inplace_and_allows_duplicate_labels(inplace)
        if not isinstance(keys, list):
            keys = [keys]
    
        err_msg = (
            'The parameter "keys" may be a column key, one-dimensional '
            "array, or a list containing only valid column keys and "
            "one-dimensional arrays."
        )
    
        missing: list[Hashable] = []
        for col in keys:
            if isinstance(col, (Index, Series, np.ndarray, list, abc.Iterator)):
                # arrays are fine as long as they are one-dimensional
                # iterators get converted to list below
                if getattr(col, "ndim", 1) != 1:
                    raise ValueError(err_msg)
            else:
                # everything else gets tried as a key; see GH 24969
                try:
                    found = col in self.columns
                except TypeError as err:
                    raise TypeError(
                        f"{err_msg}. Received column of type {type(col)}"
                    ) from err
                else:
                    if not found:
                        missing.append(col)
    
        if missing:
>           raise KeyError(f"None of {missing} are in the columns")
E           KeyError: "None of ['mac'] are in the columns"

.venv/lib/python3.11/site-packages/pandas/core/frame.py:6106: KeyError
______________________ TestAnalysisLogic.test_cluster_aps ______________________

self = <test_analysis.TestAnalysisLogic object at 0x7f7a4d2d50>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f72ea0cd0>

    def test_cluster_aps(self, populated_state):
        """Test AP-Clustering."""
>       clustered_df = analysis.cluster_aps(populated_state, n_clusters=2)

pytest/test_analysis.py:166: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/analysis/logic.py:736: in cluster_aps
    df["cluster"] = kmeans.fit_predict(X_scaled)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1071: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1351: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1490: in fit
    self._check_params_vs_input(X)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1431: in _check_params_vs_input
    super()._check_params_vs_input(X, default_n_init=10)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = KMeans(n_clusters=2, random_state=42)
X = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])
default_n_init = 10

    def _check_params_vs_input(self, X, default_n_init=None):
        # n_clusters
        if X.shape[0] < self.n_clusters:
>           raise ValueError(
                f"n_samples={X.shape[0]} should be >= n_clusters={self.n_clusters}."
            )
E           ValueError: n_samples=1 should be >= n_clusters=2.

.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:879: ValueError
__________________ TestAnalysisLogic.test_profile_ap_clusters __________________

self = Index(['bssid', 'ssid', 'vendor', 'cluster', 'supports_11k', 'supports_11v',
       'supports_11r'],
      dtype='object')
key = 'channel'

    def get_loc(self, key):
        """
        Get integer location, slice or boolean mask for requested label.
    
        Parameters
        ----------
        key : label
    
        Returns
        -------
        int if unique index, slice if monotonic index, else mask
    
        Examples
        --------
        >>> unique_index = pd.Index(list('abc'))
        >>> unique_index.get_loc('b')
        1
    
        >>> monotonic_index = pd.Index(list('abbc'))
        >>> monotonic_index.get_loc('b')
        slice(1, 3, None)
    
        >>> non_monotonic_index = pd.Index(list('abcb'))
        >>> non_monotonic_index.get_loc('b')
        array([False,  True, False,  True])
        """
        casted_key = self._maybe_cast_indexer(key)
        try:
>           return self._engine.get_loc(casted_key)

.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3802: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
index.pyx:153: in pandas._libs.index.IndexEngine.get_loc
    ???
index.pyx:182: in pandas._libs.index.IndexEngine.get_loc
    ???
pandas/_libs/hashtable_class_helper.pxi:7081: in pandas._libs.hashtable.PyObjectHashTable.get_item
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   KeyError: 'channel'

pandas/_libs/hashtable_class_helper.pxi:7089: KeyError

The above exception was the direct cause of the following exception:

self = <test_analysis.TestAnalysisLogic object at 0x7f7a4d2c10>

    def test_profile_ap_clusters(self):
        """Test AP-Cluster-Profilierung."""
        cluster_data = {
            'bssid': ['ap1', 'ap2'],
            'ssid': ['SSID1', 'SSID2'],
            'vendor': ['Vendor1', 'Vendor2'],
            'cluster': [0, 1],
            'supports_11k': [True, False],
            'supports_11v': [True, False],
            'supports_11r': [False, True]
        }
        clustered_df = pd.DataFrame(cluster_data)
    
>       profiles = analysis.profile_ap_clusters(clustered_df)

pytest/test_analysis.py:187: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/analysis/logic.py:766: in profile_ap_clusters
    "channels": cluster_data["channel"].value_counts().to_dict(),
.venv/lib/python3.11/site-packages/pandas/core/frame.py:4090: in __getitem__
    indexer = self.columns.get_loc(key)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Index(['bssid', 'ssid', 'vendor', 'cluster', 'supports_11k', 'supports_11v',
       'supports_11r'],
      dtype='object')
key = 'channel'

    def get_loc(self, key):
        """
        Get integer location, slice or boolean mask for requested label.
    
        Parameters
        ----------
        key : label
    
        Returns
        -------
        int if unique index, slice if monotonic index, else mask
    
        Examples
        --------
        >>> unique_index = pd.Index(list('abc'))
        >>> unique_index.get_loc('b')
        1
    
        >>> monotonic_index = pd.Index(list('abbc'))
        >>> monotonic_index.get_loc('b')
        slice(1, 3, None)
    
        >>> non_monotonic_index = pd.Index(list('abcb'))
        >>> non_monotonic_index.get_loc('b')
        array([False,  True, False,  True])
        """
        casted_key = self._maybe_cast_indexer(key)
        try:
            return self._engine.get_loc(casted_key)
        except KeyError as err:
            if isinstance(casted_key, slice) or (
                isinstance(casted_key, abc.Iterable)
                and any(isinstance(x, slice) for x in casted_key)
            ):
                raise InvalidIndexError(key)
>           raise KeyError(key) from err
E           KeyError: 'channel'

.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3809: KeyError
________ TestDeviceProfiler.test_create_device_fingerprint_empty_state _________

self = <test_analysis.TestDeviceProfiler object at 0x7f7a4d3d10>

    def test_create_device_fingerprint_empty_state(self):
        """Test Fingerprint mit leerem ClientState."""
        empty_client = ClientState(mac="aa:bb:cc:dd:ee:ff")
        fingerprint = create_device_fingerprint(empty_client)
    
>       assert fingerprint == ""  # Sollte leer sein für leeren State
E       AssertionError: assert 'd41d8cd98f00...00998ecf8427e' == ''
E         
E         + d41d8cd98f00b204e9800998ecf8427e

pytest/test_analysis.py:251: AssertionError
___________________ TestGraphExport.test_build_export_graph ____________________

self = <test_analysis.TestGraphExport object at 0x7f7a4e1810>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f72c739d0>

    def test_build_export_graph(self, populated_state):
        """Test Graph-Aufbau für Export."""
        # Erstelle Test-Daten
        ap_data = {
            'bssid': ['08:96:d7:1a:21:1c'],
            'ssid': ['MyTestWLAN'],
            'vendor': ['TestVendor'],
            'cluster': [0],
            'channel': [6],
            'rssi_mean': [-50.0],
            'supports_11k': [False],
            'supports_11v': [False],
            'supports_11r': [False]
        }
        clustered_ap_df = pd.DataFrame(ap_data)
    
        aps_to_export = {'08:96:d7:1a:21:1c': populated_state.aps['08:96:d7:1a:21:1c']}
        clients_to_export = {}
    
        graph = analysis._build_export_graph(
            populated_state,
            clustered_ap_df,
            aps_to_export,
            clients_to_export,
            include_clients=False,
            clustered_client_df=None
        )
    
        assert graph is not None
        assert graph.number_of_nodes() > 0
>       assert 'start' in graph.graph
E       AssertionError: assert 'start' in {'mode': 'dynamic', 'timeformat': 'datetime'}
E        +  where {'mode': 'dynamic', 'timeformat': 'datetime'} = <networkx.classes.graph.Graph object at 0x7f72c73710>.graph

pytest/test_analysis.py:319: AssertionError
___________________ TestGraphExport.test_discover_attributes ___________________

self = <test_analysis.TestGraphExport object at 0x7f7a4e1e10>

    def test_discover_attributes(self):
        """Test Attribut-Entdeckung für GEXF."""
        import networkx as nx
    
        G = nx.Graph()
        G.add_node("node1", type="AP", activity=10, vendor="Test")
        G.add_edge("node1", "node2", weight=1.5, kind="Association")
    
        node_attrs, edge_attrs = analysis._discover_attributes(G)
    
        assert isinstance(node_attrs, dict)
        assert isinstance(edge_attrs, dict)
        assert 'type' in node_attrs
        assert 'activity' in node_attrs
>       assert 'weight' in edge_attrs
E       AssertionError: assert 'weight' in {}

pytest/test_analysis.py:336: AssertionError
______________ TestAnalysisEdgeCases.test_single_client_analysis _______________

self = <test_analysis.TestAnalysisEdgeCases object at 0x7f7a4e3550>

    def test_single_client_analysis(self):
        """Test Analyse mit nur einem Client."""
        state = WifiAnalysisState()
        client = ClientState(mac="aa:bb:cc:dd:ee:ff")
>       client.all_packet_ts = np.array([time.time(), time.time() + 1])
E       NameError: name 'time' is not defined

pytest/test_analysis.py:379: NameError
_____________ TestAnalysisEdgeCases.test_malformed_event_handling ______________

self = <test_analysis.TestAnalysisEdgeCases object at 0x7f7a4ec250>

    def test_malformed_event_handling(self):
        """Test Behandlung von fehlerhaften Events."""
        state = WifiAnalysisState()
    
        # Teste mit unvollständigem Event
>       malformed_event = {'ts': time.time(), 'type': 'beacon'}  # Fehlt bssid
E       NameError: name 'time' is not defined

pytest/test_analysis.py:406: NameError
________________ TestUtilsModule.test_intelligent_vendor_lookup ________________

self = <test_app.TestUtilsModule object at 0x7f7a4ee5d0>

    def test_intelligent_vendor_lookup(self):
>       assert "Apple" in utils.lookup_vendor("a8:51:ab:0c:b9:e9")
E       TypeError: argument of type 'NoneType' is not iterable

pytest/test_app.py:71: TypeError
_____________ TestAnalysisModule.test_features_for_client_behavior _____________

self = <test_app.TestAnalysisModule object at 0x7f7a4efd50>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f72995750>

    def test_features_for_client_behavior(self, populated_state):
        client = populated_state.clients['a8:51:ab:0c:b9:e9']
>       features = analysis.features_for_client_behavior(client)
E       AttributeError: module 'wlan_tool.analysis' has no attribute 'features_for_client_behavior'

pytest/test_app.py:108: AttributeError
_________________ TestAnalysisModule.test_cluster_clients_runs _________________

self = <test_app.TestAnalysisModule object at 0x7f7a500490>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f73090d10>

    def test_cluster_clients_runs(self, populated_state):
>       clustered_df, feature_df = analysis.cluster_clients(populated_state, algo="kmeans", n_clusters=2)
E       AttributeError: module 'wlan_tool.analysis' has no attribute 'cluster_clients'

pytest/test_app.py:117: AttributeError
___________________ TestAnalysisModule.test_profile_clusters ___________________

self = <test_app.TestAnalysisModule object at 0x7f7a500a90>

    def test_profile_clusters(self):
        feature_data = {'original_macs': ['mac1', 'mac2'], 'feature1': [10, 20], 'feature2': [1, 2]}
        feature_df = pd.DataFrame(feature_data)
        cluster_data = {'original_macs': ['mac1', 'mac2'], 'cluster': [0, 0]}
        clustered_df = pd.DataFrame(cluster_data)
>       profiles = analysis.profile_clusters(feature_df, clustered_df)
E       AttributeError: module 'wlan_tool.analysis' has no attribute 'profile_clusters'

pytest/test_app.py:128: AttributeError
_____________ TestPacketParsing.test_packet_to_event_probe_request _____________

self = <test_capture.TestPacketParsing object at 0x7f7a4619d0>

    def test_packet_to_event_probe_request(self):
        """Test Probe-Request-Paket zu Event-Konvertierung."""
        rt_layer = RadioTap(
            present="Flags+Channel+dBm_AntSignal",
            Flags="",
            ChannelFrequency=2412,
            dBm_AntSignal=-60
        )
        dot11_layer = Dot11(
            type=0, subtype=4,
            addr1='ff:ff:ff:ff:ff:ff',  # Broadcast
            addr2='aa:bb:cc:dd:ee:ff'   # Client
        )
        ssid_ie = Dot11Elt(
            ID=0,
            info=b'TestSSID'
        )
    
        pkt = rt_layer / dot11_layer / ssid_ie
        pkt.time = time.time()
    
        event = capture.packet_to_event(pkt)
    
        assert event is not None
        assert event['type'] == 'probe_req'
        assert event['client'] == 'aa:bb:cc:dd:ee:ff'
        assert event['rssi'] == -60
        # SSID wird als Hex-String gespeichert, dann dekodiert
>       assert 'TestSSID' in event['probes']
E       KeyError: 'probes'

pytest/test_capture.py:63: KeyError
______________ TestPacketParsing.test_packet_to_event_data_frame _______________

self = <test_capture.TestPacketParsing object at 0x7f7a461f10>

    def test_packet_to_event_data_frame(self):
        """Test Data-Frame zu Event-Konvertierung."""
>       rt_layer = RadioTap(
            present="Flags+Channel+dBm_AntSignal+MCS_index",
            Flags="",
            ChannelFrequency=2412,
            dBm_AntSignal=-55,
            MCS_index=7
        )

pytest/test_capture.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.11/site-packages/scapy/base_classes.py:399: in __call__
    i.__init__(*args, **kargs)
.venv/lib/python3.11/site-packages/scapy/packet.py:178: in __init__
    self.get_field(fname).any2i(self, value)
.venv/lib/python3.11/site-packages/scapy/fields.py:3052: in any2i
    return self._fixup_val(super(FlagsField, self).any2i(pkt, x))
.venv/lib/python3.11/site-packages/scapy/fields.py:3048: in _fixup_val
    return FlagValue(x, self.names)
.venv/lib/python3.11/site-packages/scapy/fields.py:2835: in __init__
    self.value = self._fixvalue(value)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'FlagValue' object has no attribute 'value'") raised in repr()] FlagValue object at 0x7f72b0f500>
value = ['Flags', 'Channel', 'dBm_AntSignal', 'MCS_index']

    def _fixvalue(self, value):
        # type: (Any) -> int
        if not value:
            return 0
        if isinstance(value, six.string_types):
            value = value.split('+') if self.multi else list(value)
        if isinstance(value, list):
            y = 0
            for i in value:
>               y |= 1 << self.names.index(i)
E               ValueError: 'MCS_index' is not in list

.venv/lib/python3.11/site-packages/scapy/fields.py:2827: ValueError
_______________ TestPacketParsing.test_packet_to_event_with_dhcp _______________

self = <test_capture.TestPacketParsing object at 0x7f7a4632d0>

    def test_packet_to_event_with_dhcp(self):
        """Test Paket mit DHCP-Informationen."""
        from scapy.layers.dhcp import DHCP, BOOTP
    
        rt_layer = RadioTap(
            present="Flags+Channel+dBm_AntSignal",
            Flags="",
            ChannelFrequency=2412,
            dBm_AntSignal=-50
        )
        dot11_layer = Dot11(
            type=2, subtype=0,
            addr1='aa:bb:cc:dd:ee:ff',
            addr2='11:22:33:44:55:66'
        )
        bootp_layer = BOOTP(chaddr=b'\x11\x22\x33\x44\x55\x66')
        dhcp_layer = DHCP(options=[(53, 3), (12, b'TestHostname')])  # DHCP Request mit Hostname
    
        pkt = rt_layer / dot11_layer / bootp_layer / dhcp_layer
        pkt.time = time.time()
    
        event = capture.packet_to_event(pkt)
    
        assert event is not None
        assert event['type'] == 'data'
>       assert event['hostname'] == 'TestHostname'
E       KeyError: 'hostname'

pytest/test_capture.py:155: KeyError
____________ TestChannelHopper.test_channel_hopper_command_failure _____________

self = <test_capture.TestChannelHopper object at 0x7f7a4699d0>
mock_run = <MagicMock name='run' id='547391477136'>

    @patch('subprocess.run')
    def test_channel_hopper_command_failure(self, mock_run):
        """Test ChannelHopper bei Kommando-Fehlern."""
>       mock_run.side_effect = subprocess.CalledProcessError(1, "iw")
E       NameError: name 'subprocess' is not defined

pytest/test_capture.py:235: NameError
______________________ TestIEExtraction.test_extract_seq _______________________

self = <test_capture.TestIEExtraction object at 0x7f7a46bc10>

    def test_extract_seq(self):
        """Test Sequenznummer-Extraktion."""
        dot11 = Dot11(SC=0x1234)  # SC = 0x1234, >> 4 = 0x123
    
        seq = capture._extract_seq(dot11)
        assert seq == 0x123
    
        # Test mit None
        seq = capture._extract_seq(None)
>       assert seq is None
E       assert 0 is None

pytest/test_capture.py:379: AssertionError
____________ TestErrorHandling.test_packet_to_event_encoding_error _____________

self = <test_capture.TestErrorHandling object at 0x7f7a462e10>

    def test_packet_to_event_encoding_error(self):
        """Test mit Encoding-Fehlern."""
        rt_layer = RadioTap()
        dot11_layer = Dot11(type=0, subtype=8, addr3='aa:bb:cc:dd:ee:ff')
        beacon_layer = Dot11Beacon()
        # Erstelle IE mit ungültigem UTF-8
        ssid_ie = Dot11Elt(ID=0, info=b'\xff\xfe\xfd')
    
        pkt = rt_layer / dot11_layer / beacon_layer / ssid_ie
        pkt.time = time.time()
    
        # Sollte nicht crashen
        event = capture.packet_to_event(pkt)
        if event is not None:
>           assert event['ssid'] == "<binary>"  # Sollte als binary markiert werden
E           AssertionError: assert '<hidden>' == '<binary>'
E             
E             - <binary>
E             + <hidden>

pytest/test_capture.py:412: AssertionError
____________ TestCaptureController.test_select_interface_automatic _____________

self = <test_controllers.TestCaptureController object at 0x7f7a447d50>
mock_find_interfaces = <MagicMock name='find_wlan_interfaces' id='547234560912'>
mock_console = <MagicMock id='547235020752'>

    @patch('wlan_tool.pre_run_checks.find_wlan_interfaces')
    def test_select_interface_automatic(self, mock_find_interfaces, mock_console):
        """Test automatische Interface-Auswahl."""
        mock_find_interfaces.return_value = ["wlan0", "wlan1"]
    
        args = MagicMock()
        args.iface = None
        config_data = {}
    
        controller = CaptureController(args, config_data, mock_console)
    
        with patch('rich.prompt.Prompt.ask', return_value="wlan0"):
>           iface = controller._select_interface()

pytest/test_controllers.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.controllers.CaptureController object at 0x7f72f81890>

    def _select_interface(self) -> Optional[str]:
        """Wählt das zu verwendende physische WLAN-Interface aus."""
        iface = self.args.iface
        if not iface:
            self.console.print(
                "[bold cyan]Kein Interface angegeben. Suche nach geeigneten WLAN-Interfaces...[/bold cyan]"
            )
>           suitable_ifaces = pre_run_checks.find_wlan_interfaces()
E           NameError: name 'pre_run_checks' is not defined

wlan_tool/controllers.py:124: NameError
__________ TestCaptureController.test_select_interface_no_interfaces ___________

self = <test_controllers.TestCaptureController object at 0x7f7a452910>
mock_find_interfaces = <MagicMock name='find_wlan_interfaces' id='547234756240'>
mock_console = <MagicMock id='547234961552'>

    @patch('wlan_tool.pre_run_checks.find_wlan_interfaces')
    def test_select_interface_no_interfaces(self, mock_find_interfaces, mock_console):
        """Test Interface-Auswahl ohne verfügbare Interfaces."""
        mock_find_interfaces.return_value = []
    
        args = MagicMock()
        args.iface = None
        config_data = {}
    
        controller = CaptureController(args, config_data, mock_console)
    
>       iface = controller._select_interface()

pytest/test_controllers.py:57: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.controllers.CaptureController object at 0x7f733bb550>

    def _select_interface(self) -> Optional[str]:
        """Wählt das zu verwendende physische WLAN-Interface aus."""
        iface = self.args.iface
        if not iface:
            self.console.print(
                "[bold cyan]Kein Interface angegeben. Suche nach geeigneten WLAN-Interfaces...[/bold cyan]"
            )
>           suitable_ifaces = pre_run_checks.find_wlan_interfaces()
E           NameError: name 'pre_run_checks' is not defined

wlan_tool/controllers.py:124: NameError
____________ TestCaptureController.test_setup_monitor_mode_failure _____________

self = <test_controllers.TestCaptureController object at 0x7f7a4537d0>
mock_run = <MagicMock name='run' id='547234808848'>
mock_console = <MagicMock id='547235011024'>

    @patch('subprocess.run')
    def test_setup_monitor_mode_failure(self, mock_run, mock_console):
        """Test Monitor-Mode-Setup (Fehler)."""
>       mock_run.side_effect = subprocess.CalledProcessError(1, "airmon-ng")
E       NameError: name 'subprocess' is not defined

pytest/test_controllers.py:89: NameError
________ TestAnalysisController.test_analysis_controller_initialization ________

self = <test_controllers.TestAnalysisController object at 0x7f7a451050>
mock_console = <MagicMock id='547225064720'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f6921af10>

    def test_analysis_controller_initialization(self, mock_console, populated_state):
        """Test AnalysisController-Initialisierung."""
        args = MagicMock()
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
        assert controller.args == args
        assert controller.config_data == config_data
        assert controller.console == mock_console
        assert controller.plugins == plugins
>       assert controller.state == populated_state
E       AttributeError: 'AnalysisController' object has no attribute 'state'

pytest/test_controllers.py:201: AttributeError
__________________ TestAnalysisController.test_run_inference ___________________

self = <test_controllers.TestAnalysisController object at 0x7f7a450890>
mock_score = <MagicMock name='score_pairs_with_recency_and_matching' id='547224732432'>
mock_console = <MagicMock id='547224661072'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f6926ff10>

    @patch('wlan_tool.analysis.logic.score_pairs_with_recency_and_matching')
    def test_run_inference(self, mock_score, mock_console, populated_state):
        """Test Inferenz-Ausführung."""
        mock_score.return_value = []
    
        args = MagicMock()
        args.infer = True
        args.model = None
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       controller.run_inference()
E       AttributeError: 'AnalysisController' object has no attribute 'run_inference'

pytest/test_controllers.py:218: AttributeError
______________ TestAnalysisController.test_run_client_clustering _______________

self = <test_controllers.TestAnalysisController object at 0x7f7a452410>
mock_cluster = <MagicMock name='cluster_clients' id='547224875472'>
mock_console = <MagicMock id='547225495376'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f6924db90>

    @patch('wlan_tool.analysis.logic.cluster_clients')
    def test_run_client_clustering(self, mock_cluster, mock_console, populated_state):
        """Test Client-Clustering."""
        mock_cluster.return_value = (None, None)
    
        args = MagicMock()
        args.cluster_clients = 2
        args.cluster_algo = "kmeans"
        args.no_mac_correlation = False
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       controller.run_client_clustering()
E       AttributeError: 'AnalysisController' object has no attribute 'run_client_clustering'

pytest/test_controllers.py:237: AttributeError
________________ TestAnalysisController.test_run_ap_clustering _________________

self = <test_controllers.TestAnalysisController object at 0x7f7a4512d0>
mock_cluster = <MagicMock name='cluster_aps' id='547224558544'>
mock_console = <MagicMock id='547224718224'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f69201010>

    @patch('wlan_tool.analysis.logic.cluster_aps')
    def test_run_ap_clustering(self, mock_cluster, mock_console, populated_state):
        """Test AP-Clustering."""
        mock_cluster.return_value = None
    
        args = MagicMock()
        args.cluster_aps = 2
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       controller.run_ap_clustering()
E       AttributeError: 'AnalysisController' object has no attribute 'run_ap_clustering'

pytest/test_controllers.py:254: AttributeError
_________________ TestAnalysisController.test_run_graph_export _________________

self = <test_controllers.TestAnalysisController object at 0x7f7a451590>
mock_export = <MagicMock name='export_ap_graph' id='547225039952'>
mock_console = <MagicMock id='547225014544'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f69276e10>

    @patch('wlan_tool.analysis.logic.export_ap_graph')
    def test_run_graph_export(self, mock_export, mock_console, populated_state):
        """Test Graph-Export."""
        mock_export.return_value = True
    
        args = MagicMock()
        args.export_graph = "/tmp/test.gexf"
        args.cluster_aps = 2
        args.graph_include_clients = False
        args.graph_min_activity = 0
        args.graph_min_duration = 0
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       with patch.object(controller, 'run_ap_clustering', return_value=None):

pytest/test_controllers.py:275: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f6929dcd0>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <wlan_tool.controllers.AnalysisController object at 0x7f72a614d0> does not have the attribute 'run_ap_clustering'

../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1419: AttributeError
_________________ TestAnalysisController.test_run_labeling_ui __________________

self = <test_controllers.TestAnalysisController object at 0x7f7a451a50>
mock_label_ui = <MagicMock name='interactive_label_ui' id='547224505872'>
mock_console = <MagicMock id='547225150032'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f691f6090>

    @patch('wlan_tool.presentation.cli.interactive_label_ui')
    def test_run_labeling_ui(self, mock_label_ui, mock_console, populated_state):
        """Test Labeling-UI."""
        args = MagicMock()
        args.label_ui = True
        args.db = "test.db"
        args.label_db = "labels.db"
        args.model = "model.pkl"
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       controller.run_labeling_ui()
E       AttributeError: 'AnalysisController' object has no attribute 'run_labeling_ui'

pytest/test_controllers.py:294: AttributeError
______________ TestAnalysisController.test_run_client_labeling_ui ______________

self = <test_controllers.TestAnalysisController object at 0x7f7a4e0ad0>
mock_client_label_ui = <MagicMock name='interactive_client_label_ui' id='547384291920'>
mock_console = <MagicMock id='547929472336'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f69b50c90>

    @patch('wlan_tool.presentation.cli.interactive_client_label_ui')
    def test_run_client_labeling_ui(self, mock_client_label_ui, mock_console, populated_state):
        """Test Client-Labeling-UI."""
        args = MagicMock()
        args.label_clients = True
        args.label_db = "labels.db"
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       controller.run_client_labeling_ui()
E       AttributeError: 'AnalysisController' object has no attribute 'run_client_labeling_ui'

pytest/test_controllers.py:310: AttributeError
_______________ TestAnalysisController.test_run_mac_correlation ________________

self = <test_controllers.TestAnalysisController object at 0x7f7a4e3710>
mock_correlate = <MagicMock name='correlate_devices_by_fingerprint' id='547382816400'>
mock_console = <MagicMock id='547383410512'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f728ee910>

    @patch('wlan_tool.analysis.device_profiler.correlate_devices_by_fingerprint')
    def test_run_mac_correlation(self, mock_correlate, mock_console, populated_state):
        """Test MAC-Korrelation."""
        mock_correlate.return_value = {}
    
        args = MagicMock()
        args.correlate_macs = True
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       controller.run_mac_correlation()
E       AttributeError: 'AnalysisController' object has no attribute 'run_mac_correlation'

pytest/test_controllers.py:327: AttributeError
_____________ TestAnalysisController.test_run_analysis_no_actions ______________

self = <test_controllers.TestAnalysisController object at 0x7f7a424250>
mock_console = <MagicMock id='547512295056'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f7a447010>

    def test_run_analysis_no_actions(self, mock_console, populated_state):
        """Test Analyse ohne Aktionen."""
        args = MagicMock()
        args.infer = False
        args.cluster_clients = None
        args.cluster_aps = None
        args.export_graph = None
        args.label_ui = False
        args.label_clients = False
        args.correlate_macs = False
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
        # Sollte nicht crashen
>       controller.run_analysis()

pytest/test_controllers.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/controllers.py:339: in run_analysis
    self._run_profiling()  # Benötigt state, den es jetzt als self.state hat
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.controllers.AnalysisController object at 0x7f72f73210>

    def _run_profiling(self):
        self.console.print(
            "\n[bold cyan]Starte automatisches Geräte-Profiling...[/bold cyan]"
        )
        device_map = {}
    
        # --- NEU: Versuch 1: TR-064 (FRITZ!Box) ---
        self.console.print(
            "[cyan]Versuch 1: Identifizierung über FRITZ!Box TR-064...[/cyan]"
        )
        # Passwort aus Argumenten oder interaktiv abfragen
        fritz_password = self.args.fritzbox_password
        if FritzHosts and not fritz_password:
            if (
                self.console.input(
                    "Haben Sie ein Passwort für Ihre FRITZ!Box gesetzt? (y/n): "
                ).lower()
                == "y"
            ):
                fritz_password = self.console.input(
                    "Bitte FRITZ!Box-Passwort eingeben: ", password=True
                )
    
        device_map = (
>           device_profiler.get_devices_from_fritzbox_tr064(password=fritz_password)
            or {}
        )
E       NameError: name 'device_profiler' is not defined

wlan_tool/controllers.py:487: NameError
__________ TestAnalysisController.test_run_analysis_multiple_actions ___________

self = <test_controllers.TestAnalysisController object at 0x7f7a4246d0>
mock_console = <MagicMock id='547421404688'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f734c6610>

    def test_run_analysis_multiple_actions(self, mock_console, populated_state):
        """Test Analyse mit mehreren Aktionen."""
        args = MagicMock()
        args.infer = True
        args.cluster_clients = 2
        args.cluster_aps = 2
        args.export_graph = "/tmp/test.gexf"
        args.label_ui = False
        args.label_clients = False
        args.correlate_macs = False
        args.model = None
        args.cluster_algo = "kmeans"
        args.no_mac_correlation = False
        args.graph_include_clients = False
        args.graph_min_activity = 0
        args.graph_min_duration = 0
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       with patch.object(controller, 'run_inference'):

pytest/test_controllers.py:372: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f734c7350>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <wlan_tool.controllers.AnalysisController object at 0x7f734c7250> does not have the attribute 'run_inference'

../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1419: AttributeError
_________ TestControllerEdgeCases.test_analysis_controller_empty_state _________

self = <test_controllers.TestControllerEdgeCases object at 0x7f7a425e50>
mock_console = <MagicMock id='547395644304'>

    def test_analysis_controller_empty_state(self, mock_console):
        """Test AnalysisController mit leerem State."""
        args = MagicMock()
        args.infer = True
        args.model = None
        config_data = {}
        plugins = {}
        new_events = []
        empty_state = WifiAnalysisState()
    
        controller = AnalysisController(args, config_data, mock_console, plugins, empty_state, new_events)
    
        # Sollte nicht crashen
>       controller.run_inference()
E       AttributeError: 'AnalysisController' object has no attribute 'run_inference'

pytest/test_controllers.py:420: AttributeError
________ TestControllerEdgeCases.test_analysis_controller_with_plugins _________

self = <test_controllers.TestControllerEdgeCases object at 0x7f7a426150>
mock_console = <MagicMock id='547490089168'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f72ab3910>

    def test_analysis_controller_with_plugins(self, mock_console, populated_state):
        """Test AnalysisController mit Plugins."""
        args = MagicMock()
        args.run_plugins = ["test_plugin"]
        config_data = {}
    
        mock_plugin = MagicMock()
        mock_plugin.run.return_value = None
        plugins = {"test_plugin": mock_plugin}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       controller.run_plugins()
E       AttributeError: 'AnalysisController' object has no attribute 'run_plugins'

pytest/test_controllers.py:435: AttributeError
____________ TestControllerIntegration.test_full_analysis_workflow _____________

self = <test_controllers.TestControllerIntegration object at 0x7f7a427fd0>
mock_console = <MagicMock id='547395418064'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f691f95d0>

    def test_full_analysis_workflow(self, mock_console, populated_state):
        """Test vollständiger Analyse-Workflow."""
        args = MagicMock()
        args.infer = True
        args.cluster_clients = 2
        args.cluster_aps = 2
        args.export_graph = "/tmp/test.gexf"
        args.label_ui = False
        args.label_clients = False
        args.correlate_macs = False
        args.model = None
        args.cluster_algo = "kmeans"
        args.no_mac_correlation = False
        args.graph_include_clients = False
        args.graph_min_activity = 0
        args.graph_min_duration = 0
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       with patch.object(controller, 'run_inference'):

pytest/test_controllers.py:491: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f7352a810>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <wlan_tool.controllers.AnalysisController object at 0x7f7352aa90> does not have the attribute 'run_inference'

../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1419: AttributeError
_____________________ TestLoggingSystem.test_setup_logging _____________________

self = <test_error_handling.TestLoggingSystem object at 0x7f7a347d50>

    def test_setup_logging(self):
        """Test Logging-Setup."""
        logger = setup_logging(
            log_level="DEBUG",
            enable_console=True,
            enable_performance_logging=True,
            enable_error_tracking=True
        )
    
        assert logger is not None
        assert logger.name == "wlan_tool"
>       assert logger.level == logging.DEBUG
E       NameError: name 'logging' is not defined

pytest/test_error_handling.py:317: NameError
___________ TestDatabaseErrorHandling.test_database_connection_error ___________

self = <test_error_handling.TestDatabaseErrorHandling object at 0x7f7a33b450>

    def test_database_connection_error(self):
        """Test Datenbankverbindungs-Fehler."""
        with pytest.raises(DatabaseError) as exc_info:
            from wlan_tool.storage.database import db_conn_ctx
            with db_conn_ctx("/invalid/path/database.db"):
                pass
    
        assert "Cannot create database directory" in str(exc_info.value)
>       assert exc_info.value.error_code == "SQLITE_ERROR"
E       AssertionError: assert 'DB_UNEXPECTED_ERROR' == 'SQLITE_ERROR'
E         
E         - SQLITE_ERROR
E         + DB_UNEXPECTED_ERROR

pytest/test_error_handling.py:345: AssertionError
----------------------------- Captured stdout call -----------------------------
2025-10-19 10:28:24,683 | DEBUG    | Starting operation: database_connection
2025-10-19 10:28:24,683 | ERROR    | Error in database_connection: WLANToolError: Cannot create database directory: /invalid/path (Code: DB_DIR_CREATION_FAILED) | Details: {'directory': '/invalid/path', 'original_error': "[Errno 13] Permission denied: '/invalid'"} (Code: DB_DIR_CREATION_FAILED) | Details: {'directory': '/invalid/path', 'original_error': "[Errno 13] Permission denied: '/invalid'"}
2025-10-19 10:28:24,690 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/pathlib.py", line 1116, in mkdir
    os.mkdir(self, mode)
FileNotFoundError: [Errno 2] No such file or directory: '/invalid/path'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 81, in db_conn_ctx
    db_dir.mkdir(parents=True, exist_ok=True)
  File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/pathlib.py", line 1120, in mkdir
    self.parent.mkdir(parents=True, exist_ok=True)
  File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/pathlib.py", line 1116, in mkdir
    os.mkdir(self, mode)
PermissionError: [Errno 13] Permission denied: '/invalid'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 83, in db_conn_ctx
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Cannot create database directory: /invalid/path (Code: DB_DIR_CREATION_FAILED) | Details: {'directory': '/invalid/path', 'original_error': "[Errno 13] Permission denied: '/invalid'"}

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in database_connection: WLANToolError: Cannot create database directory: /invalid/path (Code: DB_DIR_CREATION_FAILED) | Details: {'directory': '/invalid/path', 'original_error': "[Errno 13] Permission denied: '/invalid'"} (Code: DB_DIR_CREATION_FAILED) | Details: {'directory': '/invalid/path', 'original_error': "[Errno 13] Permission denied: '/invalid'"}
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/pathlib.py", line 1116, in mkdir
    os.mkdir(self, mode)
FileNotFoundError: [Errno 2] No such file or directory: '/invalid/path'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 81, in db_conn_ctx
    db_dir.mkdir(parents=True, exist_ok=True)
  File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/pathlib.py", line 1120, in mkdir
    self.parent.mkdir(parents=True, exist_ok=True)
  File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/pathlib.py", line 1116, in mkdir
    os.mkdir(self, mode)
PermissionError: [Errno 13] Permission denied: '/invalid'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 83, in db_conn_ctx
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Cannot create database directory: /invalid/path (Code: DB_DIR_CREATION_FAILED) | Details: {'directory': '/invalid/path', 'original_error': "[Errno 13] Permission denied: '/invalid'"}
___________ TestDatabaseErrorHandling.test_database_migration_error ____________

self = <test_error_handling.TestDatabaseErrorHandling object at 0x7f7a33aa90>

    def test_database_migration_error(self):
        """Test Datenbankmigrations-Fehler."""
        with tempfile.NamedTemporaryFile(suffix='.db', delete=False) as f:
            db_path = f.name
    
        try:
            # Erstelle ungültige Migration
            migrations_dir = Path("wlan_tool/assets/sql_data/versions")
            migrations_dir.mkdir(parents=True, exist_ok=True)
    
            invalid_migration = migrations_dir / "999_invalid.sql"
            invalid_migration.write_text("INVALID SQL SYNTAX")
    
>           with pytest.raises(DatabaseError):
E           Failed: DID NOT RAISE <class 'wlan_tool.exceptions.DatabaseError'>

pytest/test_error_handling.py:360: Failed
----------------------------- Captured stdout call -----------------------------
2025-10-19 10:28:24,721 | DEBUG    | Starting operation: database_migration
2025-10-19 10:28:24,722 | DEBUG    | Starting operation: database_connection
2025-10-19 10:28:24,737 | INFO     | Current DB version: 0. Looking for migrations...
2025-10-19 10:28:24,737 | INFO     | Applying migration: 001_initial_schema.sql (Version 1)
2025-10-19 10:28:24,747 | INFO     | DB successfully migrated to version 1
2025-10-19 10:28:24,748 | INFO     | Applying migration: 002_add_dns_table.sql (Version 2)
2025-10-19 10:28:24,749 | INFO     | DB successfully migrated to version 2
2025-10-19 10:28:24,749 | INFO     | Applying migration: 003_add_network_info.sql (Version 3)
2025-10-19 10:28:24,751 | INFO     | DB successfully migrated to version 3
2025-10-19 10:28:24,751 | INFO     | Applying migration: 004_add_indexes.sql (Version 4)
2025-10-19 10:28:24,753 | INFO     | DB successfully migrated to version 4
2025-10-19 10:28:24,753 | INFO     | Applying migration: 999_invalid.sql (Version 999)
2025-10-19 10:28:24,753 | ERROR    | Unexpected error during migration 999_invalid.sql: WLANToolError: Migration failed: 999_invalid.sql (Code: MIGRATION_EXECUTION_FAILED) | Details: {'migration_file': '999_invalid.sql', 'version': 999, 'sqlite_error': 'near "INVALID": syntax error'}
2025-10-19 10:28:24,774 | INFO     | Database is up to date.
------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_migration
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
INFO     wlan_tool.storage.database:database.py:157 Current DB version: 0. Looking for migrations...
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 001_initial_schema.sql (Version 1)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 1
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 002_add_dns_table.sql (Version 2)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 2
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 003_add_network_info.sql (Version 3)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 3
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 004_add_indexes.sql (Version 4)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 4
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 999_invalid.sql (Version 999)
ERROR    wlan_tool.storage.database:database.py:199 Unexpected error during migration 999_invalid.sql: WLANToolError: Migration failed: 999_invalid.sql (Code: MIGRATION_EXECUTION_FAILED) | Details: {'migration_file': '999_invalid.sql', 'version': 999, 'sqlite_error': 'near "INVALID": syntax error'}
INFO     wlan_tool.storage.database:database.py:204 Database is up to date.
__________ TestAnalysisErrorHandling.test_client_features_null_state ___________

self = <test_error_handling.TestAnalysisErrorHandling object at 0x7f7a347850>

    def test_client_features_null_state(self):
        """Test Client-Features mit None-State."""
        from wlan_tool.analysis.logic import features_for_client
    
>       with pytest.raises(ValidationError) as exc_info:
E       Failed: DID NOT RAISE <class 'wlan_tool.exceptions.ValidationError'>

pytest/test_error_handling.py:377: Failed
----------------------------- Captured stdout call -----------------------------
2025-10-19 10:28:24,807 | DEBUG    | Starting operation: client_features_extraction
2025-10-19 10:28:24,807 | ERROR    | Error in client_features_extraction: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'} (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}
2025-10-19 10:28:24,808 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 229, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}

2025-10-19 10:28:24,808 | ERROR    | Unexpected error in features_for_client: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}
2025-10-19 10:28:24,809 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 229, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_features_extraction
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in client_features_extraction: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'} (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 229, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}

ERROR    wlan_tool.analysis.logic:exceptions.py:165 Unexpected error in features_for_client: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}
DEBUG    wlan_tool.analysis.logic:exceptions.py:166 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 229, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}
_________ TestAnalysisErrorHandling.test_client_features_invalid_type __________

self = <test_error_handling.TestAnalysisErrorHandling object at 0x7f7a347710>

    def test_client_features_invalid_type(self):
        """Test Client-Features mit ungültigem Typ."""
        from wlan_tool.analysis.logic import features_for_client
    
>       with pytest.raises(ValidationError) as exc_info:
E       Failed: DID NOT RAISE <class 'wlan_tool.exceptions.ValidationError'>

pytest/test_error_handling.py:387: Failed
----------------------------- Captured stdout call -----------------------------
2025-10-19 10:28:24,837 | DEBUG    | Starting operation: client_features_extraction
2025-10-19 10:28:24,838 | ERROR    | Error in client_features_extraction: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"} (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}
2025-10-19 10:28:24,838 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 236, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}

2025-10-19 10:28:24,839 | ERROR    | Unexpected error in features_for_client: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}
2025-10-19 10:28:24,839 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 236, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_features_extraction
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in client_features_extraction: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"} (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 236, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}

ERROR    wlan_tool.analysis.logic:exceptions.py:165 Unexpected error in features_for_client: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}
DEBUG    wlan_tool.analysis.logic:exceptions.py:166 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 236, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}
_________ TestAnalysisErrorHandling.test_clustering_invalid_parameters _________

self = <test_error_handling.TestAnalysisErrorHandling object at 0x7f7a344790>

    def test_clustering_invalid_parameters(self):
        """Test Clustering mit ungültigen Parametern."""
        from wlan_tool.analysis.logic import cluster_clients
        from wlan_tool.storage.state import WifiAnalysisState
    
        state = WifiAnalysisState()
    
        # Teste ungültige n_clusters
>       with pytest.raises(ValidationError) as exc_info:
E       Failed: DID NOT RAISE <class 'wlan_tool.exceptions.ValidationError'>

pytest/test_error_handling.py:401: Failed
----------------------------- Captured stdout call -----------------------------
2025-10-19 10:28:24,868 | DEBUG    | Starting operation: client_clustering
2025-10-19 10:28:24,869 | ERROR    | Error in client_clustering: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0} (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}
2025-10-19 10:28:24,869 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 495, in cluster_clients
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}

2025-10-19 10:28:24,869 | ERROR    | Unexpected error in cluster_clients: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}
2025-10-19 10:28:24,870 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 495, in cluster_clients
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_clustering
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in client_clustering: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0} (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 495, in cluster_clients
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}

ERROR    wlan_tool.analysis.logic:exceptions.py:165 Unexpected error in cluster_clients: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}
DEBUG    wlan_tool.analysis.logic:exceptions.py:166 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 495, in cluster_clients
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}
___________ TestFileSystemErrorHandling.test_csv_export_invalid_path ___________

self = <test_error_handling.TestFileSystemErrorHandling object at 0x7f7a356b90>

    def test_csv_export_invalid_path(self):
        """Test CSV-Export mit ungültigem Pfad."""
        from wlan_tool.storage.database import export_confirmed_to_csv
    
>       with pytest.raises(ValidationError) as exc_info:
E       Failed: DID NOT RAISE <class 'wlan_tool.exceptions.ValidationError'>

pytest/test_error_handling.py:422: Failed
----------------------------- Captured stdout call -----------------------------
2025-10-19 10:28:24,900 | DEBUG    | Starting operation: csv_export
2025-10-19 10:28:24,901 | ERROR    | Error in csv_export: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''} (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}
2025-10-19 10:28:24,901 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}

2025-10-19 10:28:24,902 | ERROR    | Error in export_confirmed_to_csv: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}
2025-10-19 10:28:24,902 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: csv_export
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in csv_export: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''} (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}

ERROR    wlan_tool.storage.database:exceptions.py:153 Error in export_confirmed_to_csv: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}
DEBUG    wlan_tool.storage.database:exceptions.py:154 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}
____________ TestFileSystemErrorHandling.test_csv_export_missing_db ____________

self = <test_error_handling.TestFileSystemErrorHandling object at 0x7f7a33acd0>

    def test_csv_export_missing_db(self):
        """Test CSV-Export mit fehlender Datenbank."""
        from wlan_tool.storage.database import export_confirmed_to_csv
    
>       with pytest.raises(FileSystemError) as exc_info:
E       Failed: DID NOT RAISE <class 'wlan_tool.exceptions.FileSystemError'>

pytest/test_error_handling.py:432: Failed
----------------------------- Captured stdout call -----------------------------
2025-10-19 10:28:24,931 | DEBUG    | Starting operation: csv_export
2025-10-19 10:28:24,932 | ERROR    | Error in csv_export: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'} (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}
2025-10-19 10:28:24,933 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}

2025-10-19 10:28:24,933 | ERROR    | Error in export_confirmed_to_csv: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}
2025-10-19 10:28:24,934 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: csv_export
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in csv_export: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'} (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}

ERROR    wlan_tool.storage.database:exceptions.py:153 Error in export_confirmed_to_csv: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}
DEBUG    wlan_tool.storage.database:exceptions.py:154 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}
____________ TestErrorHandlingEdgeCases.test_nested_error_contexts _____________

self = <test_error_handling.TestErrorHandlingEdgeCases object at 0x7f7a338250>

    def test_nested_error_contexts(self):
        """Test verschachtelte Error-Contexts."""
        with ErrorContext("outer_operation", "OUTER_ERROR") as outer:
            with ErrorContext("inner_operation", "INNER_ERROR") as inner:
>               raise ValueError("Inner error")
E               ValueError: Inner error

pytest/test_error_handling.py:473: ValueError

The above exception was the direct cause of the following exception:

self = <test_error_handling.TestErrorHandlingEdgeCases object at 0x7f7a338250>

    def test_nested_error_contexts(self):
        """Test verschachtelte Error-Contexts."""
        with ErrorContext("outer_operation", "OUTER_ERROR") as outer:
>           with ErrorContext("inner_operation", "INNER_ERROR") as inner:

pytest/test_error_handling.py:472: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.exceptions.ErrorContext object at 0x7f73059a90>
exc_type = <class 'ValueError'>, exc_val = ValueError('Inner error')
exc_tb = <traceback object at 0x7f73058040>

    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type is not None:
            error_msg = f"Error in {self.operation}: {exc_val}"
    
            if isinstance(exc_val, WLANToolError):
                error_msg += f" (Code: {exc_val.error_code})"
                if exc_val.details:
                    error_msg += f" | Details: {exc_val.details}"
            else:
                error_msg += f" | Type: {exc_type.__name__}"
    
            self.logger.log(self.log_level, error_msg)
            self.logger.debug(f"Traceback: {traceback.format_exc()}")
    
            # Konvertiere zu WLANToolError falls nötig
            if not isinstance(exc_val, WLANToolError):
                wlan_error = WLANToolError(
                    message=str(exc_val),
                    error_code=self.error_code or "CONTEXT_ERROR",
                    details={
                        "operation": self.operation,
                        "original_type": exc_type.__name__,
                    },
                )
>               raise wlan_error from exc_val
E               wlan_tool.exceptions.WLANToolError: WLANToolError: Inner error (Code: INNER_ERROR) | Details: {'operation': 'inner_operation', 'original_type': 'ValueError'}

wlan_tool/exceptions.py:313: WLANToolError
----------------------------- Captured stdout call -----------------------------
2025-10-19 10:28:25,972 | DEBUG    | Starting operation: outer_operation
2025-10-19 10:28:25,972 | DEBUG    | Starting operation: inner_operation
2025-10-19 10:28:25,972 | ERROR    | Error in inner_operation: Inner error | Type: ValueError
2025-10-19 10:28:25,973 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/pytest/test_error_handling.py", line 473, in test_nested_error_contexts
    raise ValueError("Inner error")
ValueError: Inner error

2025-10-19 10:28:25,973 | ERROR    | Error in outer_operation: WLANToolError: Inner error (Code: INNER_ERROR) | Details: {'operation': 'inner_operation', 'original_type': 'ValueError'} (Code: INNER_ERROR) | Details: {'operation': 'inner_operation', 'original_type': 'ValueError'}
2025-10-19 10:28:25,974 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/pytest/test_error_handling.py", line 473, in test_nested_error_contexts
    raise ValueError("Inner error")
ValueError: Inner error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/pi/hacking/pytest/test_error_handling.py", line 472, in test_nested_error_contexts
    with ErrorContext("inner_operation", "INNER_ERROR") as inner:
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 313, in __exit__
    raise wlan_error from exc_val
wlan_tool.exceptions.WLANToolError: WLANToolError: Inner error (Code: INNER_ERROR) | Details: {'operation': 'inner_operation', 'original_type': 'ValueError'}

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: outer_operation
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: inner_operation
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in inner_operation: Inner error | Type: ValueError
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/pytest/test_error_handling.py", line 473, in test_nested_error_contexts
    raise ValueError("Inner error")
ValueError: Inner error

ERROR    wlan_tool.exceptions:exceptions.py:300 Error in outer_operation: WLANToolError: Inner error (Code: INNER_ERROR) | Details: {'operation': 'inner_operation', 'original_type': 'ValueError'} (Code: INNER_ERROR) | Details: {'operation': 'inner_operation', 'original_type': 'ValueError'}
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/pytest/test_error_handling.py", line 473, in test_nested_error_contexts
    raise ValueError("Inner error")
ValueError: Inner error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/pi/hacking/pytest/test_error_handling.py", line 472, in test_nested_error_contexts
    with ErrorContext("inner_operation", "INNER_ERROR") as inner:
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 313, in __exit__
    raise wlan_error from exc_val
wlan_tool.exceptions.WLANToolError: WLANToolError: Inner error (Code: INNER_ERROR) | Details: {'operation': 'inner_operation', 'original_type': 'ValueError'}
_____________ TestEndToEndWorkflow.test_complete_analysis_pipeline _____________

self = <test_integration.TestEndToEndWorkflow object at 0x7f7a328890>
sample_events = [{'beacon_interval': 102, 'bssid': '08:96:d7:1a:21:1c', 'cap': 17, 'channel': 6, ...}, {'client': 'a8:51:ab:0c:b9:e9',...-91, ...}, {'client': 'b2:87:23:15:7f:f2', 'ie_order_hash': 67890, 'ies': {0: ['MyOtherWLAN']}, 'rssi': -70, ...}, ...]
temp_db_file = '/tmp/tmpvnrwz8cx.db'

    def test_complete_analysis_pipeline(self, sample_events, temp_db_file):
        """Test kompletter Analyse-Pipeline."""
        # 1. Erstelle State aus Events
        state = WifiAnalysisState()
        state.build_from_events(sample_events)
    
        assert len(state.aps) > 0
        assert len(state.clients) > 0
    
        # 2. Führe Inferenz durch
        results = analysis.score_pairs_with_recency_and_matching(state)
        assert isinstance(results, list)
    
        # 3. Führe Client-Clustering durch
        clustered_df, feature_df = analysis.cluster_clients(state, n_clusters=2)
        if clustered_df is not None:
            assert len(clustered_df) > 0
    
        # 4. Führe AP-Clustering durch
>       ap_clustered_df = analysis.cluster_aps(state, n_clusters=2)

pytest/test_integration.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/analysis/logic.py:736: in cluster_aps
    df["cluster"] = kmeans.fit_predict(X_scaled)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1071: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1351: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1490: in fit
    self._check_params_vs_input(X)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1431: in _check_params_vs_input
    super()._check_params_vs_input(X, default_n_init=10)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = KMeans(n_clusters=2, random_state=42)
X = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])
default_n_init = 10

    def _check_params_vs_input(self, X, default_n_init=None):
        # n_clusters
        if X.shape[0] < self.n_clusters:
>           raise ValueError(
                f"n_samples={X.shape[0]} should be >= n_clusters={self.n_clusters}."
            )
E           ValueError: n_samples=1 should be >= n_clusters=2.

.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:879: ValueError
---------------------------- Captured stdout setup -----------------------------
2025-10-19 10:28:26,076 | DEBUG    | Starting operation: database_migration
2025-10-19 10:28:26,077 | DEBUG    | Starting operation: database_connection
2025-10-19 10:28:26,094 | INFO     | Current DB version: 0. Looking for migrations...
2025-10-19 10:28:26,094 | INFO     | Applying migration: 001_initial_schema.sql (Version 1)
2025-10-19 10:28:26,105 | INFO     | DB successfully migrated to version 1
2025-10-19 10:28:26,106 | INFO     | Applying migration: 002_add_dns_table.sql (Version 2)
2025-10-19 10:28:26,107 | INFO     | DB successfully migrated to version 2
2025-10-19 10:28:26,107 | INFO     | Applying migration: 003_add_network_info.sql (Version 3)
2025-10-19 10:28:26,109 | INFO     | DB successfully migrated to version 3
2025-10-19 10:28:26,109 | INFO     | Applying migration: 004_add_indexes.sql (Version 4)
2025-10-19 10:28:26,110 | INFO     | DB successfully migrated to version 4
2025-10-19 10:28:26,229 | INFO     | Database is up to date.
------------------------------ Captured log setup ------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_migration
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
INFO     wlan_tool.storage.database:database.py:157 Current DB version: 0. Looking for migrations...
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 001_initial_schema.sql (Version 1)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 1
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 002_add_dns_table.sql (Version 2)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 2
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 003_add_network_info.sql (Version 3)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 3
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 004_add_indexes.sql (Version 4)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 4
INFO     wlan_tool.storage.database:database.py:204 Database is up to date.
----------------------------- Captured stdout call -----------------------------
2025-10-19 10:28:26,231 | INFO     | Baue/Aktualisiere Zustand aus Event-Stream auf...
2025-10-19 10:28:26,232 | INFO     | Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
2025-10-19 10:28:26,241 | DEBUG    | Dynamische Normalisierungsfaktoren: {'beacon_count': 1.0, 'probe_resp_count': 1.0, 'supporting_clients': 1.0, 'seq_support': 1.0, 'rssi_std_max': 20.0}
2025-10-19 10:28:26,242 | DEBUG    | Starting operation: client_clustering
2025-10-19 10:28:26,243 | INFO     | Korreliere randomisierte MACs vor der Feature-Extraktion...
2025-10-19 10:28:26,243 | INFO     | Fand 0 Gruppen von potenziell zusammengehörigen randomisierten MACs.
2025-10-19 10:28:26,244 | DEBUG    | Starting operation: client_features_extraction
2025-10-19 10:28:26,244 | DEBUG    | Starting operation: client_features_extraction
2025-10-19 10:28:26,244 | DEBUG    | Starting operation: client_features_extraction
2025-10-19 10:28:26,258 | INFO     | Wende manuelle Feature-Gewichtungen für Standard-Clustering an...
2025-10-19 10:28:26,258 | DEBUG    | Gewichte Feature 'supports_11ax' mit Faktor 3.0.
2025-10-19 10:28:26,261 | DEBUG    | Gewichte Feature 'supports_11ac' mit Faktor 2.0.
2025-10-19 10:28:26,264 | DEBUG    | Gewichte Feature 'has_apple_ie' mit Faktor 2.5.
2025-10-19 10:28:26,267 | DEBUG    | Gewichte Feature 'has_ms_ie' mit Faktor 2.0.
2025-10-19 10:28:26,270 | DEBUG    | Gewichte Feature 'mimo_streams' mit Faktor 1.5.
2025-10-19 10:28:26,272 | DEBUG    | Gewichte Feature 'is_randomized_mac' mit Faktor 1.2.
2025-10-19 10:28:26,275 | DEBUG    | Gewichte Feature 'was_in_powersave' mit Faktor 1.2.
2025-10-19 10:28:26,278 | DEBUG    | Gewichte Feature 'probe_count' mit Faktor 1.0.
2025-10-19 10:28:26,281 | DEBUG    | Gewichte Feature 'seen_with_ap_count' mit Faktor 1.0.
2025-10-19 10:28:26,284 | INFO     | Verwende KMeans für das Clustering...
------------------------------ Captured log call -------------------------------
INFO     wlan_tool.storage.state:state.py:52 Baue/Aktualisiere Zustand aus Event-Stream auf...
INFO     wlan_tool.storage.state:state.py:57 Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
DEBUG    wlan_tool.analysis.logic:logic.py:148 Dynamische Normalisierungsfaktoren: {'beacon_count': 1.0, 'probe_resp_count': 1.0, 'supporting_clients': 1.0, 'seq_support': 1.0, 'rssi_std_max': 20.0}
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_clustering
INFO     wlan_tool.analysis.logic:logic.py:396 Korreliere randomisierte MACs vor der Feature-Extraktion...
INFO     wlan_tool.analysis.logic:logic.py:791 Fand 0 Gruppen von potenziell zusammengehörigen randomisierten MACs.
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_features_extraction
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_features_extraction
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_features_extraction
INFO     wlan_tool.analysis.logic:logic.py:584 Wende manuelle Feature-Gewichtungen für Standard-Clustering an...
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'supports_11ax' mit Faktor 3.0.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'supports_11ac' mit Faktor 2.0.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'has_apple_ie' mit Faktor 2.5.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'has_ms_ie' mit Faktor 2.0.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'mimo_streams' mit Faktor 1.5.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'is_randomized_mac' mit Faktor 1.2.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'was_in_powersave' mit Faktor 1.2.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'probe_count' mit Faktor 1.0.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'seen_with_ap_count' mit Faktor 1.0.
INFO     wlan_tool.analysis.logic:logic.py:609 Verwende KMeans für das Clustering...
________________ TestEndToEndWorkflow.test_database_integration ________________

self = <test_integration.TestEndToEndWorkflow object at 0x7f7a329590>
sample_events = [{'beacon_interval': 102, 'bssid': '08:96:d7:1a:21:1c', 'cap': 17, 'channel': 6, ...}, {'client': 'a8:51:ab:0c:b9:e9',...-91, ...}, {'client': 'b2:87:23:15:7f:f2', 'ie_order_hash': 67890, 'ies': {0: ['MyOtherWLAN']}, 'rssi': -70, ...}, ...]
temp_db_file = '/tmp/tmp8xny6ff7.db'

    def test_database_integration(self, sample_events, temp_db_file):
        """Test Datenbank-Integration."""
        # Schreibe Events in Datenbank
        with database.db_conn_ctx(temp_db_file) as conn:
            for event in sample_events:
>               database.add_event(conn, event)
E               AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

pytest/test_integration.py:64: AttributeError

The above exception was the direct cause of the following exception:

path = '/tmp/tmp8xny6ff7.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
>           with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):

wlan_tool/storage/database.py:68: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.exceptions.ErrorContext object at 0x7f73066790>
exc_type = <class 'AttributeError'>
exc_val = AttributeError("module 'wlan_tool.storage.database' has no attribute 'add_event'")
exc_tb = <traceback object at 0x7f73064d00>

    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type is not None:
            error_msg = f"Error in {self.operation}: {exc_val}"
    
            if isinstance(exc_val, WLANToolError):
                error_msg += f" (Code: {exc_val.error_code})"
                if exc_val.details:
                    error_msg += f" | Details: {exc_val.details}"
            else:
                error_msg += f" | Type: {exc_type.__name__}"
    
            self.logger.log(self.log_level, error_msg)
            self.logger.debug(f"Traceback: {traceback.format_exc()}")
    
            # Konvertiere zu WLANToolError falls nötig
            if not isinstance(exc_val, WLANToolError):
                wlan_error = WLANToolError(
                    message=str(exc_val),
                    error_code=self.error_code or "CONTEXT_ERROR",
                    details={
                        "operation": self.operation,
                        "original_type": exc_type.__name__,
                    },
                )
>               raise wlan_error from exc_val
E               wlan_tool.exceptions.WLANToolError: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}

wlan_tool/exceptions.py:313: WLANToolError

The above exception was the direct cause of the following exception:

self = <test_integration.TestEndToEndWorkflow object at 0x7f7a329590>
sample_events = [{'beacon_interval': 102, 'bssid': '08:96:d7:1a:21:1c', 'cap': 17, 'channel': 6, ...}, {'client': 'a8:51:ab:0c:b9:e9',...-91, ...}, {'client': 'b2:87:23:15:7f:f2', 'ie_order_hash': 67890, 'ies': {0: ['MyOtherWLAN']}, 'rssi': -70, ...}, ...]
temp_db_file = '/tmp/tmp8xny6ff7.db'

    def test_database_integration(self, sample_events, temp_db_file):
        """Test Datenbank-Integration."""
        # Schreibe Events in Datenbank
>       with database.db_conn_ctx(temp_db_file) as conn:

pytest/test_integration.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/contextlib.py:158: in __exit__
    self.gen.throw(typ, value, traceback)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

path = '/tmp/tmp8xny6ff7.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
            with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):
                # Validiere Datenbankpfad
                if not _validate_file_path(path):
                    raise ValidationError(
                        f"Invalid database path: {path}",
                        error_code="INVALID_DB_PATH",
                        details={"db_path": path},
                    )
    
                # Erstelle Verzeichnis falls nötig
                db_dir = Path(path).parent
                if not db_dir.exists():
                    try:
                        db_dir.mkdir(parents=True, exist_ok=True)
                    except OSError as e:
                        raise FileSystemError(
                            f"Cannot create database directory: {db_dir}",
                            error_code="DB_DIR_CREATION_FAILED",
                            details={"directory": str(db_dir), "original_error": str(e)},
                        ) from e
    
                # Verbinde zur Datenbank
                conn = sqlite3.connect(path, timeout=Constants.DB_CONNECTION_TIMEOUT)
                conn.row_factory = sqlite3.Row
    
                # Setze pragmas für bessere Performance und Fehlerbehandlung
                conn.execute("PRAGMA foreign_keys = ON")
                conn.execute("PRAGMA journal_mode = WAL")
                conn.execute("PRAGMA synchronous = NORMAL")
                conn.execute("PRAGMA cache_size = 10000")
                conn.execute("PRAGMA temp_store = MEMORY")
    
                yield conn
    
        except sqlite3.Error as e:
            if conn:
                conn.rollback()
            raise DatabaseError(
                get_error_message(ErrorCodes.DB_CONNECTION_FAILED, details=str(e)),
                error_code=ErrorCodes.DB_CONNECTION_FAILED.value,
                details={"db_path": path, "sqlite_error": str(e)},
            ) from e
        except Exception as e:
            if conn:
                conn.rollback()
>           raise DatabaseError(
                f"Unexpected database error: {e}",
                error_code="DB_UNEXPECTED_ERROR",
                details={"db_path": path, "original_error": str(e)},
            ) from e
E           wlan_tool.exceptions.DatabaseError: WLANToolError: Unexpected database error: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'} (Code: DB_UNEXPECTED_ERROR) | Details: {'db_path': '/tmp/tmp8xny6ff7.db', 'original_error': "WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}"}

wlan_tool/storage/database.py:113: DatabaseError
---------------------------- Captured stdout setup -----------------------------
2025-10-19 10:28:26,932 | DEBUG    | Starting operation: database_migration
2025-10-19 10:28:26,932 | DEBUG    | Starting operation: database_connection
2025-10-19 10:28:26,945 | INFO     | Current DB version: 0. Looking for migrations...
2025-10-19 10:28:26,946 | INFO     | Applying migration: 001_initial_schema.sql (Version 1)
2025-10-19 10:28:26,954 | INFO     | DB successfully migrated to version 1
2025-10-19 10:28:26,955 | INFO     | Applying migration: 002_add_dns_table.sql (Version 2)
2025-10-19 10:28:26,956 | INFO     | DB successfully migrated to version 2
2025-10-19 10:28:26,956 | INFO     | Applying migration: 003_add_network_info.sql (Version 3)
2025-10-19 10:28:26,958 | INFO     | DB successfully migrated to version 3
2025-10-19 10:28:26,958 | INFO     | Applying migration: 004_add_indexes.sql (Version 4)
2025-10-19 10:28:26,959 | INFO     | DB successfully migrated to version 4
2025-10-19 10:28:26,981 | INFO     | Database is up to date.
------------------------------ Captured log setup ------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_migration
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
INFO     wlan_tool.storage.database:database.py:157 Current DB version: 0. Looking for migrations...
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 001_initial_schema.sql (Version 1)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 1
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 002_add_dns_table.sql (Version 2)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 2
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 003_add_network_info.sql (Version 3)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 3
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 004_add_indexes.sql (Version 4)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 4
INFO     wlan_tool.storage.database:database.py:204 Database is up to date.
----------------------------- Captured stdout call -----------------------------
2025-10-19 10:28:26,983 | DEBUG    | Starting operation: database_connection
2025-10-19 10:28:26,984 | ERROR    | Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
2025-10-19 10:28:26,985 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/hacking/pytest/test_integration.py", line 64, in test_database_integration
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/hacking/pytest/test_integration.py", line 64, in test_database_integration
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'
_________________ TestEndToEndWorkflow.test_config_integration _________________

self = <test_integration.TestEndToEndWorkflow object at 0x7f7a32a790>

    def test_config_integration(self):
        """Test Konfigurations-Integration."""
        # Teste Konfigurations-Laden
>       config_data = utils.load_config()
E       TypeError: load_config() missing 1 required positional argument: 'profile'

pytest/test_integration.py:82: TypeError
_____________________ TestDataFlow.test_state_persistence ______________________

self = <test_integration.TestDataFlow object at 0x7f7a32aa10>
sample_events = [{'beacon_interval': 102, 'bssid': '08:96:d7:1a:21:1c', 'cap': 17, 'channel': 6, ...}, {'client': 'a8:51:ab:0c:b9:e9',...-91, ...}, {'client': 'b2:87:23:15:7f:f2', 'ie_order_hash': 67890, 'ies': {0: ['MyOtherWLAN']}, 'rssi': -70, ...}, ...]
temp_db_file = '/tmp/tmp5dwkwm37.db'

    def test_state_persistence(self, sample_events, temp_db_file):
        """Test State-Persistierung."""
        # Erstelle State
        state1 = WifiAnalysisState()
        state1.build_from_events(sample_events)
    
        # Schreibe in Datenbank
        with database.db_conn_ctx(temp_db_file) as conn:
            for event in sample_events:
>               database.add_event(conn, event)
E               AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

pytest/test_integration.py:130: AttributeError

The above exception was the direct cause of the following exception:

path = '/tmp/tmp5dwkwm37.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
>           with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):

wlan_tool/storage/database.py:68: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.exceptions.ErrorContext object at 0x7f7297f850>
exc_type = <class 'AttributeError'>
exc_val = AttributeError("module 'wlan_tool.storage.database' has no attribute 'add_event'")
exc_tb = <traceback object at 0x7f72a55480>

    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type is not None:
            error_msg = f"Error in {self.operation}: {exc_val}"
    
            if isinstance(exc_val, WLANToolError):
                error_msg += f" (Code: {exc_val.error_code})"
                if exc_val.details:
                    error_msg += f" | Details: {exc_val.details}"
            else:
                error_msg += f" | Type: {exc_type.__name__}"
    
            self.logger.log(self.log_level, error_msg)
            self.logger.debug(f"Traceback: {traceback.format_exc()}")
    
            # Konvertiere zu WLANToolError falls nötig
            if not isinstance(exc_val, WLANToolError):
                wlan_error = WLANToolError(
                    message=str(exc_val),
                    error_code=self.error_code or "CONTEXT_ERROR",
                    details={
                        "operation": self.operation,
                        "original_type": exc_type.__name__,
                    },
                )
>               raise wlan_error from exc_val
E               wlan_tool.exceptions.WLANToolError: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}

wlan_tool/exceptions.py:313: WLANToolError

The above exception was the direct cause of the following exception:

self = <test_integration.TestDataFlow object at 0x7f7a32aa10>
sample_events = [{'beacon_interval': 102, 'bssid': '08:96:d7:1a:21:1c', 'cap': 17, 'channel': 6, ...}, {'client': 'a8:51:ab:0c:b9:e9',...-91, ...}, {'client': 'b2:87:23:15:7f:f2', 'ie_order_hash': 67890, 'ies': {0: ['MyOtherWLAN']}, 'rssi': -70, ...}, ...]
temp_db_file = '/tmp/tmp5dwkwm37.db'

    def test_state_persistence(self, sample_events, temp_db_file):
        """Test State-Persistierung."""
        # Erstelle State
        state1 = WifiAnalysisState()
        state1.build_from_events(sample_events)
    
        # Schreibe in Datenbank
>       with database.db_conn_ctx(temp_db_file) as conn:

pytest/test_integration.py:128: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/contextlib.py:158: in __exit__
    self.gen.throw(typ, value, traceback)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

path = '/tmp/tmp5dwkwm37.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
            with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):
                # Validiere Datenbankpfad
                if not _validate_file_path(path):
                    raise ValidationError(
                        f"Invalid database path: {path}",
                        error_code="INVALID_DB_PATH",
                        details={"db_path": path},
                    )
    
                # Erstelle Verzeichnis falls nötig
                db_dir = Path(path).parent
                if not db_dir.exists():
                    try:
                        db_dir.mkdir(parents=True, exist_ok=True)
                    except OSError as e:
                        raise FileSystemError(
                            f"Cannot create database directory: {db_dir}",
                            error_code="DB_DIR_CREATION_FAILED",
                            details={"directory": str(db_dir), "original_error": str(e)},
                        ) from e
    
                # Verbinde zur Datenbank
                conn = sqlite3.connect(path, timeout=Constants.DB_CONNECTION_TIMEOUT)
                conn.row_factory = sqlite3.Row
    
                # Setze pragmas für bessere Performance und Fehlerbehandlung
                conn.execute("PRAGMA foreign_keys = ON")
                conn.execute("PRAGMA journal_mode = WAL")
                conn.execute("PRAGMA synchronous = NORMAL")
                conn.execute("PRAGMA cache_size = 10000")
                conn.execute("PRAGMA temp_store = MEMORY")
    
                yield conn
    
        except sqlite3.Error as e:
            if conn:
                conn.rollback()
            raise DatabaseError(
                get_error_message(ErrorCodes.DB_CONNECTION_FAILED, details=str(e)),
                error_code=ErrorCodes.DB_CONNECTION_FAILED.value,
                details={"db_path": path, "sqlite_error": str(e)},
            ) from e
        except Exception as e:
            if conn:
                conn.rollback()
>           raise DatabaseError(
                f"Unexpected database error: {e}",
                error_code="DB_UNEXPECTED_ERROR",
                details={"db_path": path, "original_error": str(e)},
            ) from e
E           wlan_tool.exceptions.DatabaseError: WLANToolError: Unexpected database error: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'} (Code: DB_UNEXPECTED_ERROR) | Details: {'db_path': '/tmp/tmp5dwkwm37.db', 'original_error': "WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}"}

wlan_tool/storage/database.py:113: DatabaseError
---------------------------- Captured stdout setup -----------------------------
2025-10-19 10:28:27,222 | DEBUG    | Starting operation: database_migration
2025-10-19 10:28:27,223 | DEBUG    | Starting operation: database_connection
2025-10-19 10:28:27,238 | INFO     | Current DB version: 0. Looking for migrations...
2025-10-19 10:28:27,238 | INFO     | Applying migration: 001_initial_schema.sql (Version 1)
2025-10-19 10:28:27,248 | INFO     | DB successfully migrated to version 1
2025-10-19 10:28:27,248 | INFO     | Applying migration: 002_add_dns_table.sql (Version 2)
2025-10-19 10:28:27,249 | INFO     | DB successfully migrated to version 2
2025-10-19 10:28:27,249 | INFO     | Applying migration: 003_add_network_info.sql (Version 3)
2025-10-19 10:28:27,251 | INFO     | DB successfully migrated to version 3
2025-10-19 10:28:27,251 | INFO     | Applying migration: 004_add_indexes.sql (Version 4)
2025-10-19 10:28:27,253 | INFO     | DB successfully migrated to version 4
2025-10-19 10:28:27,273 | INFO     | Database is up to date.
------------------------------ Captured log setup ------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_migration
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
INFO     wlan_tool.storage.database:database.py:157 Current DB version: 0. Looking for migrations...
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 001_initial_schema.sql (Version 1)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 1
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 002_add_dns_table.sql (Version 2)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 2
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 003_add_network_info.sql (Version 3)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 3
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 004_add_indexes.sql (Version 4)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 4
INFO     wlan_tool.storage.database:database.py:204 Database is up to date.
----------------------------- Captured stdout call -----------------------------
2025-10-19 10:28:27,274 | INFO     | Baue/Aktualisiere Zustand aus Event-Stream auf...
2025-10-19 10:28:27,275 | INFO     | Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
2025-10-19 10:28:27,275 | DEBUG    | Starting operation: database_connection
2025-10-19 10:28:27,277 | ERROR    | Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
2025-10-19 10:28:27,278 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/hacking/pytest/test_integration.py", line 130, in test_state_persistence
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

------------------------------ Captured log call -------------------------------
INFO     wlan_tool.storage.state:state.py:52 Baue/Aktualisiere Zustand aus Event-Stream auf...
INFO     wlan_tool.storage.state:state.py:57 Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/hacking/pytest/test_integration.py", line 130, in test_state_persistence
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'
________________ TestLargeDataset.test_large_dataset_processing ________________

self = <test_integration.TestLargeDataset object at 0x7f7a32b490>

    def test_large_dataset_processing(self):
        """Test Verarbeitung großer Datensätze."""
        # Erstelle großen State
        state = WifiAnalysisState()
    
        # Erstelle 100 APs
        for i in range(100):
            bssid = f"08:96:d7:1a:21:{i:02x}"
>           ap = state.aps[bssid] = state.aps.get(bssid, type(state).__dict__['aps'].__class__())()
E           KeyError: 'aps'

pytest/test_integration.py:158: KeyError
_______________ TestErrorRecovery.test_malformed_event_handling ________________

self = <test_integration.TestErrorRecovery object at 0x7f7a33b250>

    def test_malformed_event_handling(self):
        """Test Behandlung fehlerhafter Events."""
        state = WifiAnalysisState()
    
        # Teste verschiedene fehlerhafte Events
        malformed_events = [
            {},  # Leeres Event
            {'ts': time.time()},  # Nur Zeitstempel
            {'ts': time.time(), 'type': 'invalid'},  # Ungültiger Typ
            {'ts': time.time(), 'type': 'beacon'},  # Beacon ohne BSSID
        ]
    
        for event in malformed_events:
            # Sollte nicht crashen
            try:
>               state.update_from_event(event)

pytest/test_integration.py:241: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f72a90d90>
ev = {}, detailed_ies = False

    def update_from_event(self, ev: dict, detailed_ies: bool = False):
>       ts, ev_type = ev["ts"], ev.get("type")
E       KeyError: 'ts'

wlan_tool/storage/state.py:66: KeyError

During handling of the above exception, another exception occurred:

self = <test_integration.TestErrorRecovery object at 0x7f7a33b250>

    def test_malformed_event_handling(self):
        """Test Behandlung fehlerhafter Events."""
        state = WifiAnalysisState()
    
        # Teste verschiedene fehlerhafte Events
        malformed_events = [
            {},  # Leeres Event
            {'ts': time.time()},  # Nur Zeitstempel
            {'ts': time.time(), 'type': 'invalid'},  # Ungültiger Typ
            {'ts': time.time(), 'type': 'beacon'},  # Beacon ohne BSSID
        ]
    
        for event in malformed_events:
            # Sollte nicht crashen
            try:
                state.update_from_event(event)
            except Exception as e:
>               pytest.fail(f"Malformed event should be handled gracefully: {e}")
E               Failed: Malformed event should be handled gracefully: 'ts'

pytest/test_integration.py:243: Failed
______________ TestMemoryManagement.test_memory_usage_large_state ______________

self = <test_integration.TestMemoryManagement object at 0x7f7a31fb10>

    def test_memory_usage_large_state(self):
        """Test Speicherverbrauch mit großem State."""
        import psutil
        import os
    
        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss
    
        # Erstelle großen State
        state = WifiAnalysisState()
    
        for i in range(1000):
            mac = f"aa:bb:cc:dd:ee:{i:04x}"
>           client = state.clients[mac] = state.clients.get(mac, type(state).__dict__['clients'].__class__())()
E           KeyError: 'clients'

pytest/test_integration.py:295: KeyError
____________ TestMemoryManagement.test_state_pruning_memory_release ____________

self = <test_integration.TestMemoryManagement object at 0x7f7a31e210>

    def test_state_pruning_memory_release(self):
        """Test Speicherfreigabe durch State-Pruning."""
        import psutil
        import os
    
        process = psutil.Process(os.getpid())
    
        # Erstelle State mit alten und neuen Daten
        state = WifiAnalysisState()
    
        # Alte Clients (werden gepruned)
        for i in range(100):
            mac = f"old:aa:bb:cc:dd:ee:{i:02x}"
>           client = state.clients[mac] = state.clients.get(mac, type(state).__dict__['clients'].__class__())()
E           KeyError: 'clients'

pytest/test_integration.py:321: KeyError
_____________ TestAnalysisPerformance.test_clustering_performance ______________

self = <test_performance.TestAnalysisPerformance object at 0x7f7a312650>

    def test_clustering_performance(self):
        """Test Clustering-Performance."""
        # Erstelle State mit vielen Clients
        state = WifiAnalysisState()
    
        for i in range(200):
            mac = f"aa:bb:cc:dd:ee:{i:02x}"
>           client = state.clients[mac] = state.clients.get(mac, type(state).__dict__['clients'].__class__())()
E           KeyError: 'clients'

pytest/test_performance.py:147: KeyError
______________ TestAnalysisPerformance.test_inference_performance ______________

self = <test_performance.TestAnalysisPerformance object at 0x7f7a312cd0>

    def test_inference_performance(self):
        """Test Inferenz-Performance."""
        # Erstelle State mit APs und Clients
        state = WifiAnalysisState()
    
        # Erstelle 50 APs
        for i in range(50):
            bssid = f"08:96:d7:1a:21:{i:02x}"
>           ap = state.aps[bssid] = state.aps.get(bssid, type(state).__dict__['aps'].__class__())()
E           KeyError: 'aps'

pytest/test_performance.py:180: KeyError
_____________ TestMemoryPerformance.test_memory_usage_large_state ______________

self = <test_performance.TestMemoryPerformance object at 0x7f7a313810>

    def test_memory_usage_large_state(self):
        """Test Speicherverbrauch mit großem State."""
        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss
    
        # Erstelle großen State
        state = WifiAnalysisState()
    
        # 1000 Clients
        for i in range(1000):
            mac = f"aa:bb:cc:dd:ee:{i:04x}"
>           client = state.clients[mac] = state.clients.get(mac, type(state).__dict__['clients'].__class__())()
E           KeyError: 'clients'

pytest/test_performance.py:228: KeyError
___________ TestMemoryPerformance.test_memory_cleanup_after_pruning ____________

self = <test_performance.TestMemoryPerformance object at 0x7f7a3139d0>

    def test_memory_cleanup_after_pruning(self):
        """Test Speicherbereinigung nach Pruning."""
        process = psutil.Process(os.getpid())
    
        # Erstelle State mit alten und neuen Daten
        state = WifiAnalysisState()
    
        # 500 alte Clients (werden gepruned)
        for i in range(500):
            mac = f"old:aa:bb:cc:dd:ee:{i:03x}"
>           client = state.clients[mac] = state.clients.get(mac, type(state).__dict__['clients'].__class__())()
E           KeyError: 'clients'

pytest/test_performance.py:269: KeyError
___________ TestDatabasePerformance.test_database_write_performance ____________

self = <test_performance.TestDatabasePerformance object at 0x7f7a310190>
temp_db_file = '/tmp/tmpki9cdp1i.db'

    def test_database_write_performance(self, temp_db_file):
        """Test Datenbank-Schreib-Performance."""
        # Erstelle Test-Events
        events = []
        for i in range(1000):
            event = {
                'ts': time.time() + i,
                'type': 'beacon' if i % 2 == 0 else 'probe_req',
                'bssid': f'08:96:d7:1a:21:{i % 100:02x}',
                'ssid': f'SSID_{i % 50}',
                'rssi': -50 - (i % 50),
                'channel': (i % 13) + 1
            }
            events.append(event)
    
        start_time = time.time()
    
        with database.db_conn_ctx(temp_db_file) as conn:
            for event in events:
>               database.add_event(conn, event)
E               AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

pytest/test_performance.py:325: AttributeError

The above exception was the direct cause of the following exception:

path = '/tmp/tmpki9cdp1i.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
>           with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):

wlan_tool/storage/database.py:68: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.exceptions.ErrorContext object at 0x7f72a90410>
exc_type = <class 'AttributeError'>
exc_val = AttributeError("module 'wlan_tool.storage.database' has no attribute 'add_event'")
exc_tb = <traceback object at 0x7f72a902c0>

    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type is not None:
            error_msg = f"Error in {self.operation}: {exc_val}"
    
            if isinstance(exc_val, WLANToolError):
                error_msg += f" (Code: {exc_val.error_code})"
                if exc_val.details:
                    error_msg += f" | Details: {exc_val.details}"
            else:
                error_msg += f" | Type: {exc_type.__name__}"
    
            self.logger.log(self.log_level, error_msg)
            self.logger.debug(f"Traceback: {traceback.format_exc()}")
    
            # Konvertiere zu WLANToolError falls nötig
            if not isinstance(exc_val, WLANToolError):
                wlan_error = WLANToolError(
                    message=str(exc_val),
                    error_code=self.error_code or "CONTEXT_ERROR",
                    details={
                        "operation": self.operation,
                        "original_type": exc_type.__name__,
                    },
                )
>               raise wlan_error from exc_val
E               wlan_tool.exceptions.WLANToolError: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}

wlan_tool/exceptions.py:313: WLANToolError

The above exception was the direct cause of the following exception:

self = <test_performance.TestDatabasePerformance object at 0x7f7a310190>
temp_db_file = '/tmp/tmpki9cdp1i.db'

    def test_database_write_performance(self, temp_db_file):
        """Test Datenbank-Schreib-Performance."""
        # Erstelle Test-Events
        events = []
        for i in range(1000):
            event = {
                'ts': time.time() + i,
                'type': 'beacon' if i % 2 == 0 else 'probe_req',
                'bssid': f'08:96:d7:1a:21:{i % 100:02x}',
                'ssid': f'SSID_{i % 50}',
                'rssi': -50 - (i % 50),
                'channel': (i % 13) + 1
            }
            events.append(event)
    
        start_time = time.time()
    
>       with database.db_conn_ctx(temp_db_file) as conn:

pytest/test_performance.py:323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/contextlib.py:158: in __exit__
    self.gen.throw(typ, value, traceback)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

path = '/tmp/tmpki9cdp1i.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
            with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):
                # Validiere Datenbankpfad
                if not _validate_file_path(path):
                    raise ValidationError(
                        f"Invalid database path: {path}",
                        error_code="INVALID_DB_PATH",
                        details={"db_path": path},
                    )
    
                # Erstelle Verzeichnis falls nötig
                db_dir = Path(path).parent
                if not db_dir.exists():
                    try:
                        db_dir.mkdir(parents=True, exist_ok=True)
                    except OSError as e:
                        raise FileSystemError(
                            f"Cannot create database directory: {db_dir}",
                            error_code="DB_DIR_CREATION_FAILED",
                            details={"directory": str(db_dir), "original_error": str(e)},
                        ) from e
    
                # Verbinde zur Datenbank
                conn = sqlite3.connect(path, timeout=Constants.DB_CONNECTION_TIMEOUT)
                conn.row_factory = sqlite3.Row
    
                # Setze pragmas für bessere Performance und Fehlerbehandlung
                conn.execute("PRAGMA foreign_keys = ON")
                conn.execute("PRAGMA journal_mode = WAL")
                conn.execute("PRAGMA synchronous = NORMAL")
                conn.execute("PRAGMA cache_size = 10000")
                conn.execute("PRAGMA temp_store = MEMORY")
    
                yield conn
    
        except sqlite3.Error as e:
            if conn:
                conn.rollback()
            raise DatabaseError(
                get_error_message(ErrorCodes.DB_CONNECTION_FAILED, details=str(e)),
                error_code=ErrorCodes.DB_CONNECTION_FAILED.value,
                details={"db_path": path, "sqlite_error": str(e)},
            ) from e
        except Exception as e:
            if conn:
                conn.rollback()
>           raise DatabaseError(
                f"Unexpected database error: {e}",
                error_code="DB_UNEXPECTED_ERROR",
                details={"db_path": path, "original_error": str(e)},
            ) from e
E           wlan_tool.exceptions.DatabaseError: WLANToolError: Unexpected database error: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'} (Code: DB_UNEXPECTED_ERROR) | Details: {'db_path': '/tmp/tmpki9cdp1i.db', 'original_error': "WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}"}

wlan_tool/storage/database.py:113: DatabaseError
---------------------------- Captured stdout setup -----------------------------
2025-10-19 10:28:28,363 | DEBUG    | Starting operation: database_migration
2025-10-19 10:28:28,364 | DEBUG    | Starting operation: database_connection
2025-10-19 10:28:28,381 | INFO     | Current DB version: 0. Looking for migrations...
2025-10-19 10:28:28,381 | INFO     | Applying migration: 001_initial_schema.sql (Version 1)
2025-10-19 10:28:28,392 | INFO     | DB successfully migrated to version 1
2025-10-19 10:28:28,393 | INFO     | Applying migration: 002_add_dns_table.sql (Version 2)
2025-10-19 10:28:28,394 | INFO     | DB successfully migrated to version 2
2025-10-19 10:28:28,394 | INFO     | Applying migration: 003_add_network_info.sql (Version 3)
2025-10-19 10:28:28,396 | INFO     | DB successfully migrated to version 3
2025-10-19 10:28:28,396 | INFO     | Applying migration: 004_add_indexes.sql (Version 4)
2025-10-19 10:28:28,397 | INFO     | DB successfully migrated to version 4
2025-10-19 10:28:28,417 | INFO     | Database is up to date.
------------------------------ Captured log setup ------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_migration
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
INFO     wlan_tool.storage.database:database.py:157 Current DB version: 0. Looking for migrations...
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 001_initial_schema.sql (Version 1)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 1
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 002_add_dns_table.sql (Version 2)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 2
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 003_add_network_info.sql (Version 3)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 3
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 004_add_indexes.sql (Version 4)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 4
INFO     wlan_tool.storage.database:database.py:204 Database is up to date.
----------------------------- Captured stdout call -----------------------------
2025-10-19 10:28:28,424 | DEBUG    | Starting operation: database_connection
2025-10-19 10:28:28,426 | ERROR    | Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
2025-10-19 10:28:28,427 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/hacking/pytest/test_performance.py", line 325, in test_database_write_performance
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/hacking/pytest/test_performance.py", line 325, in test_database_write_performance
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'
____________ TestDatabasePerformance.test_database_read_performance ____________

self = <test_performance.TestDatabasePerformance object at 0x7f7a310ad0>
temp_db_file = '/tmp/tmpy39_7149.db'

    def test_database_read_performance(self, temp_db_file):
        """Test Datenbank-Lese-Performance."""
        # Schreibe Test-Events
        events = []
        for i in range(1000):
            event = {
                'ts': time.time() + i,
                'type': 'beacon' if i % 2 == 0 else 'probe_req',
                'bssid': f'08:96:d7:1a:21:{i % 100:02x}',
                'ssid': f'SSID_{i % 50}',
                'rssi': -50 - (i % 50),
                'channel': (i % 13) + 1
            }
            events.append(event)
    
        with database.db_conn_ctx(temp_db_file) as conn:
            for event in events:
>               database.add_event(conn, event)
E               AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

pytest/test_performance.py:351: AttributeError

The above exception was the direct cause of the following exception:

path = '/tmp/tmpy39_7149.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
>           with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):

wlan_tool/storage/database.py:68: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.exceptions.ErrorContext object at 0x7f734cc710>
exc_type = <class 'AttributeError'>
exc_val = AttributeError("module 'wlan_tool.storage.database' has no attribute 'add_event'")
exc_tb = <traceback object at 0x7f734cff40>

    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type is not None:
            error_msg = f"Error in {self.operation}: {exc_val}"
    
            if isinstance(exc_val, WLANToolError):
                error_msg += f" (Code: {exc_val.error_code})"
                if exc_val.details:
                    error_msg += f" | Details: {exc_val.details}"
            else:
                error_msg += f" | Type: {exc_type.__name__}"
    
            self.logger.log(self.log_level, error_msg)
            self.logger.debug(f"Traceback: {traceback.format_exc()}")
    
            # Konvertiere zu WLANToolError falls nötig
            if not isinstance(exc_val, WLANToolError):
                wlan_error = WLANToolError(
                    message=str(exc_val),
                    error_code=self.error_code or "CONTEXT_ERROR",
                    details={
                        "operation": self.operation,
                        "original_type": exc_type.__name__,
                    },
                )
>               raise wlan_error from exc_val
E               wlan_tool.exceptions.WLANToolError: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}

wlan_tool/exceptions.py:313: WLANToolError

The above exception was the direct cause of the following exception:

self = <test_performance.TestDatabasePerformance object at 0x7f7a310ad0>
temp_db_file = '/tmp/tmpy39_7149.db'

    def test_database_read_performance(self, temp_db_file):
        """Test Datenbank-Lese-Performance."""
        # Schreibe Test-Events
        events = []
        for i in range(1000):
            event = {
                'ts': time.time() + i,
                'type': 'beacon' if i % 2 == 0 else 'probe_req',
                'bssid': f'08:96:d7:1a:21:{i % 100:02x}',
                'ssid': f'SSID_{i % 50}',
                'rssi': -50 - (i % 50),
                'channel': (i % 13) + 1
            }
            events.append(event)
    
>       with database.db_conn_ctx(temp_db_file) as conn:

pytest/test_performance.py:349: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/contextlib.py:158: in __exit__
    self.gen.throw(typ, value, traceback)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

path = '/tmp/tmpy39_7149.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
            with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):
                # Validiere Datenbankpfad
                if not _validate_file_path(path):
                    raise ValidationError(
                        f"Invalid database path: {path}",
                        error_code="INVALID_DB_PATH",
                        details={"db_path": path},
                    )
    
                # Erstelle Verzeichnis falls nötig
                db_dir = Path(path).parent
                if not db_dir.exists():
                    try:
                        db_dir.mkdir(parents=True, exist_ok=True)
                    except OSError as e:
                        raise FileSystemError(
                            f"Cannot create database directory: {db_dir}",
                            error_code="DB_DIR_CREATION_FAILED",
                            details={"directory": str(db_dir), "original_error": str(e)},
                        ) from e
    
                # Verbinde zur Datenbank
                conn = sqlite3.connect(path, timeout=Constants.DB_CONNECTION_TIMEOUT)
                conn.row_factory = sqlite3.Row
    
                # Setze pragmas für bessere Performance und Fehlerbehandlung
                conn.execute("PRAGMA foreign_keys = ON")
                conn.execute("PRAGMA journal_mode = WAL")
                conn.execute("PRAGMA synchronous = NORMAL")
                conn.execute("PRAGMA cache_size = 10000")
                conn.execute("PRAGMA temp_store = MEMORY")
    
                yield conn
    
        except sqlite3.Error as e:
            if conn:
                conn.rollback()
            raise DatabaseError(
                get_error_message(ErrorCodes.DB_CONNECTION_FAILED, details=str(e)),
                error_code=ErrorCodes.DB_CONNECTION_FAILED.value,
                details={"db_path": path, "sqlite_error": str(e)},
            ) from e
        except Exception as e:
            if conn:
                conn.rollback()
>           raise DatabaseError(
                f"Unexpected database error: {e}",
                error_code="DB_UNEXPECTED_ERROR",
                details={"db_path": path, "original_error": str(e)},
            ) from e
E           wlan_tool.exceptions.DatabaseError: WLANToolError: Unexpected database error: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'} (Code: DB_UNEXPECTED_ERROR) | Details: {'db_path': '/tmp/tmpy39_7149.db', 'original_error': "WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}"}

wlan_tool/storage/database.py:113: DatabaseError
---------------------------- Captured stdout setup -----------------------------
2025-10-19 10:28:28,593 | DEBUG    | Starting operation: database_migration
2025-10-19 10:28:28,594 | DEBUG    | Starting operation: database_connection
2025-10-19 10:28:28,613 | INFO     | Current DB version: 0. Looking for migrations...
2025-10-19 10:28:28,614 | INFO     | Applying migration: 001_initial_schema.sql (Version 1)
2025-10-19 10:28:28,621 | INFO     | DB successfully migrated to version 1
2025-10-19 10:28:28,621 | INFO     | Applying migration: 002_add_dns_table.sql (Version 2)
2025-10-19 10:28:28,622 | INFO     | DB successfully migrated to version 2
2025-10-19 10:28:28,623 | INFO     | Applying migration: 003_add_network_info.sql (Version 3)
2025-10-19 10:28:28,624 | INFO     | DB successfully migrated to version 3
2025-10-19 10:28:28,624 | INFO     | Applying migration: 004_add_indexes.sql (Version 4)
2025-10-19 10:28:28,626 | INFO     | DB successfully migrated to version 4
2025-10-19 10:28:28,648 | INFO     | Database is up to date.
------------------------------ Captured log setup ------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_migration
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
INFO     wlan_tool.storage.database:database.py:157 Current DB version: 0. Looking for migrations...
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 001_initial_schema.sql (Version 1)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 1
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 002_add_dns_table.sql (Version 2)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 2
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 003_add_network_info.sql (Version 3)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 3
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 004_add_indexes.sql (Version 4)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 4
INFO     wlan_tool.storage.database:database.py:204 Database is up to date.
----------------------------- Captured stdout call -----------------------------
2025-10-19 10:28:28,654 | DEBUG    | Starting operation: database_connection
2025-10-19 10:28:28,656 | ERROR    | Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
2025-10-19 10:28:28,657 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/hacking/pytest/test_performance.py", line 351, in test_database_read_performance
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/hacking/pytest/test_performance.py", line 351, in test_database_read_performance
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'
________ TestScalabilityPerformance.test_scalability_with_dataset_size _________

self = <test_performance.TestScalabilityPerformance object at 0x7f7a313b50>

    def test_scalability_with_dataset_size(self):
        """Test Skalierbarkeit mit Datensatz-Größe."""
        dataset_sizes = [100, 500, 1000]
        processing_times = []
    
        for size in dataset_sizes:
            # Erstelle State mit gegebener Größe
            state = WifiAnalysisState()
    
            for i in range(size):
                mac = f"aa:bb:cc:dd:ee:{i:04x}"
>               client = state.clients[mac] = state.clients.get(mac, type(state).__dict__['clients'].__class__())()
E               KeyError: 'clients'

pytest/test_performance.py:440: KeyError
_______________ TestCLIModule.test_print_client_cluster_results ________________

self = <test_presentation.TestCLIModule object at 0x7f7a300ad0>
mock_console = <MagicMock id='547394091856'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f69293610>

    def test_print_client_cluster_results(self, mock_console, populated_state):
        """Test Client-Cluster-Ergebnis-Ausgabe."""
        from wlan_tool.analysis import logic as analysis
    
        # Erstelle Test-Cluster-Daten
        clustered_df, feature_df = analysis.cluster_clients(populated_state, n_clusters=2)
    
        if clustered_df is not None and not clustered_df.empty:
            # Mock args
            args = MagicMock()
            args.cluster_clients = 2
            args.cluster_algo = "kmeans"
            args.no_mac_correlation = False
    
            # Sollte nicht crashen
>           cli.print_client_cluster_results(args, populated_state, mock_console)

pytest/test_presentation.py:38: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = <MagicMock id='547235013456'>
state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f69293610>
console = <MagicMock id='547394091856'>

    def print_client_cluster_results(args, state, console):
        """Führt das Client-Clustering aus und gibt die Ergebnisse formatiert aus."""
        clustered_df, feature_df = analysis.cluster_clients(
            state,
            n_clusters=args.cluster_clients,
            algo_name=args.cluster_algo,
            use_correlation=(not args.no_mac_correlation),
        )
        """Gibt die Ergebnisse des Client-Clusterings formatiert aus."""
        if clustered_df is not None and not clustered_df.empty:
            console.print(
                "[yellow]Keine Client-Daten für das Clustering gefunden.[/yellow]"
            )
            return
    
>       title_correlation_str = "& Korrelation" if use_correlation else "& ohne Korrelation"
E       NameError: name 'use_correlation' is not defined

wlan_tool/presentation/cli.py:34: NameError
---------------------------- Captured stdout setup -----------------------------
2025-10-19 10:28:28,896 | INFO     | Baue/Aktualisiere Zustand aus Event-Stream auf...
2025-10-19 10:28:28,897 | INFO     | Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
------------------------------ Captured log setup ------------------------------
INFO     wlan_tool.storage.state:state.py:52 Baue/Aktualisiere Zustand aus Event-Stream auf...
INFO     wlan_tool.storage.state:state.py:57 Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
----------------------------- Captured stdout call -----------------------------
2025-10-19 10:28:28,899 | DEBUG    | Starting operation: client_clustering
2025-10-19 10:28:28,899 | INFO     | Korreliere randomisierte MACs vor der Feature-Extraktion...
2025-10-19 10:28:28,899 | INFO     | Fand 0 Gruppen von potenziell zusammengehörigen randomisierten MACs.
2025-10-19 10:28:28,899 | DEBUG    | Starting operation: client_features_extraction
2025-10-19 10:28:28,899 | DEBUG    | Starting operation: client_features_extraction
2025-10-19 10:28:28,900 | DEBUG    | Starting operation: client_features_extraction
2025-10-19 10:28:28,912 | INFO     | Wende manuelle Feature-Gewichtungen für Standard-Clustering an...
2025-10-19 10:28:28,913 | DEBUG    | Gewichte Feature 'supports_11ax' mit Faktor 3.0.
2025-10-19 10:28:28,916 | DEBUG    | Gewichte Feature 'supports_11ac' mit Faktor 2.0.
2025-10-19 10:28:28,919 | DEBUG    | Gewichte Feature 'has_apple_ie' mit Faktor 2.5.
2025-10-19 10:28:28,921 | DEBUG    | Gewichte Feature 'has_ms_ie' mit Faktor 2.0.
2025-10-19 10:28:28,924 | DEBUG    | Gewichte Feature 'mimo_streams' mit Faktor 1.5.
2025-10-19 10:28:28,927 | DEBUG    | Gewichte Feature 'is_randomized_mac' mit Faktor 1.2.
2025-10-19 10:28:28,929 | DEBUG    | Gewichte Feature 'was_in_powersave' mit Faktor 1.2.
2025-10-19 10:28:28,933 | DEBUG    | Gewichte Feature 'probe_count' mit Faktor 1.0.
2025-10-19 10:28:28,936 | DEBUG    | Gewichte Feature 'seen_with_ap_count' mit Faktor 1.0.
2025-10-19 10:28:28,938 | INFO     | Verwende KMeans für das Clustering...
2025-10-19 10:28:28,947 | ERROR    | Unexpected error in cluster_clients: cluster_clients() got an unexpected keyword argument 'algo_name'
2025-10-19 10:28:28,947 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
TypeError: cluster_clients() got an unexpected keyword argument 'algo_name'

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_clustering
INFO     wlan_tool.analysis.logic:logic.py:396 Korreliere randomisierte MACs vor der Feature-Extraktion...
INFO     wlan_tool.analysis.logic:logic.py:791 Fand 0 Gruppen von potenziell zusammengehörigen randomisierten MACs.
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_features_extraction
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_features_extraction
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_features_extraction
INFO     wlan_tool.analysis.logic:logic.py:584 Wende manuelle Feature-Gewichtungen für Standard-Clustering an...
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'supports_11ax' mit Faktor 3.0.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'supports_11ac' mit Faktor 2.0.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'has_apple_ie' mit Faktor 2.5.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'has_ms_ie' mit Faktor 2.0.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'mimo_streams' mit Faktor 1.5.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'is_randomized_mac' mit Faktor 1.2.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'was_in_powersave' mit Faktor 1.2.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'probe_count' mit Faktor 1.0.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'seen_with_ap_count' mit Faktor 1.0.
INFO     wlan_tool.analysis.logic:logic.py:609 Verwende KMeans für das Clustering...
ERROR    wlan_tool.analysis.logic:exceptions.py:165 Unexpected error in cluster_clients: cluster_clients() got an unexpected keyword argument 'algo_name'
DEBUG    wlan_tool.analysis.logic:exceptions.py:166 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
TypeError: cluster_clients() got an unexpected keyword argument 'algo_name'
_________________ TestCLIModule.test_print_ap_cluster_results __________________

self = <test_presentation.TestCLIModule object at 0x7f7a3011d0>
mock_console = <MagicMock id='547490041232'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f73533110>

    def test_print_ap_cluster_results(self, mock_console, populated_state):
        """Test AP-Cluster-Ergebnis-Ausgabe."""
        from wlan_tool.analysis import logic as analysis
    
        # Erstelle Test-AP-Cluster-Daten
>       clustered_df = analysis.cluster_aps(populated_state, n_clusters=2)

pytest/test_presentation.py:48: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/analysis/logic.py:736: in cluster_aps
    df["cluster"] = kmeans.fit_predict(X_scaled)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1071: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1351: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1490: in fit
    self._check_params_vs_input(X)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1431: in _check_params_vs_input
    super()._check_params_vs_input(X, default_n_init=10)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = KMeans(n_clusters=2, random_state=42)
X = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])
default_n_init = 10

    def _check_params_vs_input(self, X, default_n_init=None):
        # n_clusters
        if X.shape[0] < self.n_clusters:
>           raise ValueError(
                f"n_samples={X.shape[0]} should be >= n_clusters={self.n_clusters}."
            )
E           ValueError: n_samples=1 should be >= n_clusters=2.

.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:879: ValueError
---------------------------- Captured stdout setup -----------------------------
2025-10-19 10:28:28,992 | INFO     | Baue/Aktualisiere Zustand aus Event-Stream auf...
2025-10-19 10:28:28,993 | INFO     | Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
------------------------------ Captured log setup ------------------------------
INFO     wlan_tool.storage.state:state.py:52 Baue/Aktualisiere Zustand aus Event-Stream auf...
INFO     wlan_tool.storage.state:state.py:57 Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
________ TestCLIEdgeCases.test_print_client_cluster_results_empty_data _________

self = <test_presentation.TestCLIEdgeCases object at 0x7f7a2ea3d0>
mock_console = <MagicMock id='547395803984'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f73154090>

    def test_print_client_cluster_results_empty_data(self, mock_console, populated_state):
        """Test Client-Cluster-Ausgabe mit leeren Daten."""
        # Erstelle leeren State
        empty_state = WifiAnalysisState()
    
        args = MagicMock()
        args.cluster_clients = 2
        args.cluster_algo = "kmeans"
        args.no_mac_correlation = False
    
        # Sollte nicht crashen
>       cli.print_client_cluster_results(args, empty_state, mock_console)

pytest/test_presentation.py:281: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = <MagicMock id='547391628880'>
state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f73156510>
console = <MagicMock id='547395803984'>

    def print_client_cluster_results(args, state, console):
        """Führt das Client-Clustering aus und gibt die Ergebnisse formatiert aus."""
        clustered_df, feature_df = analysis.cluster_clients(
            state,
            n_clusters=args.cluster_clients,
            algo_name=args.cluster_algo,
            use_correlation=(not args.no_mac_correlation),
        )
        """Gibt die Ergebnisse des Client-Clusterings formatiert aus."""
        if clustered_df is not None and not clustered_df.empty:
            console.print(
                "[yellow]Keine Client-Daten für das Clustering gefunden.[/yellow]"
            )
            return
    
>       title_correlation_str = "& Korrelation" if use_correlation else "& ohne Korrelation"
E       NameError: name 'use_correlation' is not defined

wlan_tool/presentation/cli.py:34: NameError
---------------------------- Captured stdout setup -----------------------------
2025-10-19 10:28:29,738 | INFO     | Baue/Aktualisiere Zustand aus Event-Stream auf...
2025-10-19 10:28:29,738 | INFO     | Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
------------------------------ Captured log setup ------------------------------
INFO     wlan_tool.storage.state:state.py:52 Baue/Aktualisiere Zustand aus Event-Stream auf...
INFO     wlan_tool.storage.state:state.py:57 Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
----------------------------- Captured stdout call -----------------------------
2025-10-19 10:28:29,740 | ERROR    | Unexpected error in cluster_clients: cluster_clients() got an unexpected keyword argument 'algo_name'
2025-10-19 10:28:29,741 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
TypeError: cluster_clients() got an unexpected keyword argument 'algo_name'

------------------------------ Captured log call -------------------------------
ERROR    wlan_tool.analysis.logic:exceptions.py:165 Unexpected error in cluster_clients: cluster_clients() got an unexpected keyword argument 'algo_name'
DEBUG    wlan_tool.analysis.logic:exceptions.py:166 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
TypeError: cluster_clients() got an unexpected keyword argument 'algo_name'
_________________ TestPerformance.test_large_dataset_handling __________________

self = <test_presentation.TestPerformance object at 0x7f7a2eaed0>
mock_console = <MagicMock id='547384670288'>

    def test_large_dataset_handling(self, mock_console):
        """Test mit großen Datensätzen."""
        # Erstelle State mit vielen Clients
        state = WifiAnalysisState()
    
        for i in range(100):
            client = ClientState(mac=f"aa:bb:cc:dd:ee:{i:02x}")
            client.probes = {f"SSID_{i}"}
            client.all_packet_ts = np.array([time.time() - 100, time.time()])
>           client.rssi_w = Welford()
E           NameError: name 'Welford' is not defined

pytest/test_presentation.py:366: NameError
_____________ TestClientState.test_client_state_update_from_event ______________

self = <test_storage.TestClientState object at 0x7f7a20b810>

    def test_client_state_update_from_event(self):
        """Test ClientState-Update aus Event."""
        client = ClientState(mac="aa:bb:cc:dd:ee:ff")
        event = {
            'ts': time.time(),
            'type': 'probe_req',
            'client': 'aa:bb:cc:dd:ee:ff',
            'rssi': -50,
            'ies': {'probes': ['TestSSID']}
        }
    
        client.update_from_event(event)
        assert client.count == 1
>       assert 'TestSSID' in client.probes
E       AssertionError: assert 'TestSSID' in set()
E        +  where set() = ClientState(mac='aa:bb:cc:dd:ee:ff', first_seen=1760862509.89225, last_seen=1760862509.89225, count=1, probes=set(), s..., hostname=None, mcs_rates=Counter(), noise_w=Welford(n=0, mean=0.0, M2=0.0), fcs_error_count=0, ie_order_hashes=set()).probes

pytest/test_storage.py:97: AssertionError
_________________ TestAPState.test_ap_state_update_from_beacon _________________

self = <test_storage.TestAPState object at 0x7f7a1ff390>

    def test_ap_state_update_from_beacon(self):
        """Test APState-Update aus Beacon."""
        ap = APState(bssid="aa:bb:cc:dd:ee:ff", ssid="TestAP")
        event = {
            'ts': time.time(),
            'type': 'beacon',
            'bssid': 'aa:bb:cc:dd:ee:ff',
            'ssid': 'TestAP',
            'rssi': -50,
            'channel': 6,
            'beacon_interval': 102
        }
    
>       ap.update_from_event(event)
E       AttributeError: 'APState' object has no attribute 'update_from_event'

pytest/test_storage.py:141: AttributeError
___________________ TestWifiAnalysisState.test_state_pruning ___________________

self = <test_storage.TestWifiAnalysisState object at 0x7f7a1fe810>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f72a69e50>

    def test_state_pruning(self, populated_state):
        """Test State-Pruning."""
        state = populated_state
        assert 'DE:AD:BE:EF:00:00' in state.clients
    
        pruned_count = state.prune_state(time.time(), threshold_s=7200)
    
        assert pruned_count > 0
        assert 'DE:AD:BE:EF:00:00' not in state.clients
>       assert 'a8:51:ab:0c:b9:e9' in state.clients  # Sollte bleiben
E       AssertionError: assert 'a8:51:ab:0c:b9:e9' in {}
E        +  where {} = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f72a69e50>.clients

pytest/test_storage.py:203: AssertionError
---------------------------- Captured stdout setup -----------------------------
2025-10-19 10:28:29,959 | INFO     | Baue/Aktualisiere Zustand aus Event-Stream auf...
2025-10-19 10:28:29,960 | INFO     | Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
------------------------------ Captured log setup ------------------------------
INFO     wlan_tool.storage.state:state.py:52 Baue/Aktualisiere Zustand aus Event-Stream auf...
INFO     wlan_tool.storage.state:state.py:57 Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
----------------------------- Captured stdout call -----------------------------
2025-10-19 10:28:29,961 | INFO     | Zustand bereinigt: 1 APs, 3 Clients, 0 Seq-Einträge und 1 SSIDs entfernt.
------------------------------ Captured log call -------------------------------
INFO     wlan_tool.storage.state:state.py:237 Zustand bereinigt: 1 APs, 3 Clients, 0 Seq-Einträge und 1 SSIDs entfernt.
________________ TestWifiAnalysisState.test_state_ssid_mapping _________________

self = <test_storage.TestWifiAnalysisState object at 0x7f7a1fd1d0>
sample_events = [{'beacon_interval': 102, 'bssid': '08:96:d7:1a:21:1c', 'cap': 17, 'channel': 6, ...}, {'client': 'a8:51:ab:0c:b9:e9',...-91, ...}, {'client': 'b2:87:23:15:7f:f2', 'ie_order_hash': 67890, 'ies': {0: ['MyOtherWLAN']}, 'rssi': -70, ...}, ...]

    def test_state_ssid_mapping(self, sample_events):
        """Test SSID-Mapping-Funktionalität."""
        state = WifiAnalysisState()
        state.build_from_events(sample_events)
    
        # Teste SSID-Map
        assert 'MyTestWLAN' in state.ssid_map
        ssid_info = state.ssid_map['MyTestWLAN']
        assert '08:96:d7:1a:21:1c' in ssid_info['bssids']
>       assert 'a8:51:ab:0c:b9:e9' in ssid_info['sources']['probe_req']
E       AssertionError: assert 'a8:51:ab:0c:b9:e9' in set()

pytest/test_storage.py:214: AssertionError
----------------------------- Captured stdout call -----------------------------
2025-10-19 10:28:29,987 | INFO     | Baue/Aktualisiere Zustand aus Event-Stream auf...
2025-10-19 10:28:29,987 | INFO     | Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
------------------------------ Captured log call -------------------------------
INFO     wlan_tool.storage.state:state.py:52 Baue/Aktualisiere Zustand aus Event-Stream auf...
INFO     wlan_tool.storage.state:state.py:57 Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
_____________________ TestDatabaseModule.test_fetch_events _____________________

self = <test_storage.TestDatabaseModule object at 0x7f7a1e10d0>
in_memory_db = <sqlite3.Connection object at 0x7f74e01990>
sample_events = [{'beacon_interval': 102, 'bssid': '08:96:d7:1a:21:1c', 'cap': 17, 'channel': 6, ...}, {'client': 'a8:51:ab:0c:b9:e9',...-91, ...}, {'client': 'b2:87:23:15:7f:f2', 'ie_order_hash': 67890, 'ies': {0: ['MyOtherWLAN']}, 'rssi': -70, ...}, ...]

    def test_fetch_events(self, in_memory_db, sample_events):
        """Test Event-Abruf."""
        conn = in_memory_db
    
        # Schreibe Test-Events
        for event in sample_events[:2]:
>           database.add_event(conn, event)
E           AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

pytest/test_storage.py:260: AttributeError
______________________ TestDatabaseModule.test_add_label _______________________

self = <test_storage.TestDatabaseModule object at 0x7f7a1fdcd0>
in_memory_db = <sqlite3.Connection object at 0x7f74e035b0>

    def test_add_label(self, in_memory_db):
        """Test Label-Hinzufügung."""
        conn = in_memory_db
    
        database.add_label(conn, "TestSSID", "aa:bb:cc:dd:ee:ff", 1)
    
        cursor = conn.execute("SELECT * FROM labels WHERE ssid = ? AND bssid = ?",
                            ("TestSSID", "aa:bb:cc:dd:ee:ff"))
        result = cursor.fetchone()
        assert result is not None
>       assert result[2] == 1  # label = 1
E       AssertionError: assert 'aa:bb:cc:dd:ee:ff' == 1

pytest/test_storage.py:277: AssertionError
----------------------------- Captured stdout call -----------------------------
2025-10-19 10:28:30,686 | DEBUG    | Starting operation: add_label
2025-10-19 10:28:30,687 | DEBUG    | Added label: TestSSID -> aa:bb:cc:dd:ee:ff = 1 (source: ui)
------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: add_label
DEBUG    wlan_tool.storage.database:database.py:618 Added label: TestSSID -> aa:bb:cc:dd:ee:ff = 1 (source: ui)
________________ TestOUIFunctions.test_lookup_vendor_apple_mac _________________

self = <test_utils.TestOUIFunctions object at 0x7f7a1e2390>

    def test_lookup_vendor_apple_mac(self):
        """Test Vendor-Lookup für Apple-MAC."""
        # Apple MAC-Adresse
        mac = "a8:51:ab:0c:b9:e9"
        vendor = utils.lookup_vendor(mac)
    
>       assert vendor is not None
E       assert None is not None

pytest/test_utils.py:26: AssertionError
_______________ TestOUIFunctions.test_lookup_vendor_unknown_mac ________________

self = <test_utils.TestOUIFunctions object at 0x7f7a1e2b90>

    def test_lookup_vendor_unknown_mac(self):
        """Test Vendor-Lookup für unbekannte MAC."""
        # Unbekannte MAC-Adresse
        mac = "ff:ff:ff:ff:ff:ff"
        vendor = utils.lookup_vendor(mac)
    
        # Sollte None oder "Unknown" zurückgeben
>       assert vendor is None or vendor == "Unknown"
E       AssertionError: assert ('(Lokal / Randomisiert)' is None or '(Lokal / Randomisiert)' == 'Unknown'
E         
E         - Unknown
E         + (Lokal / Randomisiert))

pytest/test_utils.py:45: AssertionError
_________________ TestIEParsing.test_parse_ies_vendor_specific _________________

self = <test_utils.TestIEParsing object at 0x7f7a1eb190>

    def test_parse_ies_vendor_specific(self):
        """Test Vendor-spezifische IE-Parsing."""
        ies = {221: ['0017f20a010103040507080c']}  # Apple IE
        parsed = utils.parse_ies(ies, detailed=True)
    
        assert isinstance(parsed, dict)
        assert "vendor_specific" in parsed
>       assert "Apple" in parsed["vendor_specific"]
E       AssertionError: assert 'Apple' in {}

pytest/test_utils.py:131: AssertionError
_________________ TestIEParsing.test_parse_ies_ht_capabilities _________________

self = <test_utils.TestIEParsing object at 0x7f7a1eba50>

    def test_parse_ies_ht_capabilities(self):
        """Test HT-Capabilities-Parsing."""
        ies = {45: ['1f']}  # HT Capabilities
        parsed = utils.parse_ies(ies, detailed=True)
    
        assert isinstance(parsed, dict)
        assert "ht_caps" in parsed
>       assert "streams" in parsed["ht_caps"]
E       AssertionError: assert 'streams' in {'40mhz_support': True}

pytest/test_utils.py:140: AssertionError
_________________ TestUtilityFunctions.test_is_local_admin_mac _________________

self = <test_utils.TestUtilityFunctions object at 0x7f7a1e9290>

    def test_is_local_admin_mac(self):
        """Test lokale Admin-MAC-Erkennung."""
        # Lokale Admin-MAC
        assert utils.is_local_admin_mac("02:00:00:00:00:00") is True
        assert utils.is_local_admin_mac("06:00:00:00:00:00") is True
    
        # Globale MAC
        assert utils.is_local_admin_mac("00:00:00:00:00:00") is False
>       assert utils.is_local_admin_mac("aa:bb:cc:dd:ee:ff") is False
E       AssertionError: assert True is False
E        +  where True = <function is_local_admin_mac at 0x7f92d77380>('aa:bb:cc:dd:ee:ff')
E        +    where <function is_local_admin_mac at 0x7f92d77380> = utils.is_local_admin_mac

pytest/test_utils.py:171: AssertionError
___________________ TestUtilityFunctions.test_is_valid_bssid ___________________

self = <test_utils.TestUtilityFunctions object at 0x7f7a1e3a90>

    def test_is_valid_bssid(self):
        """Test BSSID-Validierung."""
        # Gültige BSSID
        assert utils.is_valid_bssid("aa:bb:cc:dd:ee:ff") is True
        assert utils.is_valid_bssid("00:11:22:33:44:55") is True
    
        # Ungültige BSSID
        assert utils.is_valid_bssid("") is False
        assert utils.is_valid_bssid("invalid") is False
>       assert utils.is_valid_bssid("aa:bb:cc:dd:ee") is False  # Zu kurz
E       AssertionError: assert True is False
E        +  where True = <function is_valid_bssid at 0x7f92d77420>('aa:bb:cc:dd:ee')
E        +    where <function is_valid_bssid at 0x7f92d77420> = utils.is_valid_bssid

pytest/test_utils.py:182: AssertionError
________________ TestUtilityFunctions.test_ie_fingerprint_hash _________________

self = <test_utils.TestUtilityFunctions object at 0x7f7a1e8f50>

    def test_ie_fingerprint_hash(self):
        """Test IE-Fingerprint-Hash."""
        ies = {
            0: ['TestSSID'],
            1: ['82848b96'],
            48: ['0100000fac040100000fac020100000fac028c00']
        }
    
        hash_value = utils.ie_fingerprint_hash(ies)
    
        assert isinstance(hash_value, str)
>       assert len(hash_value) == 32  # MD5-Hash-Länge
E       AssertionError: assert 40 == 32
E        +  where 40 = len('fb3a54a0b7ca1a713fd927a194ff191b7de45566')

pytest/test_utils.py:196: AssertionError
_____________ TestUtilityFunctions.test_ie_fingerprint_hash_empty ______________

self = <test_utils.TestUtilityFunctions object at 0x7f7a1e8290>

    def test_ie_fingerprint_hash_empty(self):
        """Test IE-Fingerprint-Hash mit leeren IEs."""
        ies = {}
    
        hash_value = utils.ie_fingerprint_hash(ies)
    
>       assert hash_value is None or hash_value == ""
E       AssertionError: assert ('da39a3ee5e6b4b0d3255bfef95601890afd80709' is None or 'da39a3ee5e6b...01890afd80709' == ''
E         
E         + da39a3ee5e6b4b0d3255bfef95601890afd80709)

pytest/test_utils.py:205: AssertionError
_________________ TestConfigFunctions.test_load_config_default _________________

self = <test_utils.TestConfigFunctions object at 0x7f7a1d3910>

    def test_load_config_default(self):
        """Test Konfigurations-Laden (Standard)."""
>       config_data = utils.load_config()
E       TypeError: load_config() missing 1 required positional argument: 'profile'

pytest/test_utils.py:226: TypeError
____________ TestConfigFunctions.test_load_config_specific_profile _____________

self = <test_utils.TestConfigFunctions object at 0x7f7a1d2a50>

    def test_load_config_specific_profile(self):
        """Test Konfigurations-Laden (spezifisches Profil)."""
        # Erstelle temporäre Konfigurationsdatei
        test_config = {
            "capture": {"interface": "test0", "duration": 60},
            "database": {"path": "test.db"}
        }
    
        with tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False) as f:
            yaml.dump(test_config, f)
            config_path = f.name
    
        try:
>           with patch('wlan_tool.utils.CONFIG_PATH', config_path):

pytest/test_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f72d2a210>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'wlan_tool.utils' from '/home/pi/hacking/wlan_tool/utils.py'> does not have the attribute 'CONFIG_PATH'

../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1419: AttributeError
______________ TestConfigFunctions.test_load_config_missing_file _______________

self = <test_utils.TestConfigFunctions object at 0x7f7a1d1450>

    def test_load_config_missing_file(self):
        """Test Konfigurations-Laden (fehlende Datei)."""
>       with patch('wlan_tool.utils.CONFIG_PATH', Path("/nonexistent/config.yaml")):

pytest/test_utils.py:255: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f72b394d0>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'wlan_tool.utils' from '/home/pi/hacking/wlan_tool/utils.py'> does not have the attribute 'CONFIG_PATH'

../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1419: AttributeError
________________ TestEdgeCases.test_ie_fingerprint_hash_unicode ________________

self = <test_utils.TestEdgeCases object at 0x7f7a1d05d0>

    def test_ie_fingerprint_hash_unicode(self):
        """Test IE-Fingerprint-Hash mit Unicode-Daten."""
        ies = {0: ['TestSSID_äöü']}  # Unicode-Zeichen
    
        hash_value = utils.ie_fingerprint_hash(ies)
    
        assert isinstance(hash_value, str)
>       assert len(hash_value) == 32
E       AssertionError: assert 40 == 32
E        +  where 40 = len('758ed0819e647ff1683744b0bc9b1ff7470f6d37')

pytest/test_utils.py:356: AssertionError
_____________ TestEdgeCases.test_config_loading_with_invalid_yaml ______________

self = <test_utils.TestEdgeCases object at 0x7f7a1d0f10>

    def test_config_loading_with_invalid_yaml(self):
        """Test Konfigurations-Laden mit ungültigem YAML."""
        invalid_yaml = "invalid: yaml: content: ["
    
        with tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False) as f:
            f.write(invalid_yaml)
            config_path = f.name
    
        try:
>           with patch('wlan_tool.utils.CONFIG_PATH', config_path):

pytest/test_utils.py:378: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f69bff510>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'wlan_tool.utils' from '/home/pi/hacking/wlan_tool/utils.py'> does not have the attribute 'CONFIG_PATH'

../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1419: AttributeError
__________ TestEndToEndWorkflow.test_complete_wifi_analysis_workflow ___________

self = <test_end_to_end.TestEndToEndWorkflow object at 0x7f792aaf50>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]
temp_dir = PosixPath('/tmp/tmpq3d8k7bg')

    @pytest.mark.integration
    @pytest.mark.slow
    def test_complete_wifi_analysis_workflow(self, large_dataset, temp_dir):
        """Test des kompletten WLAN-Analyse-Workflows."""
        # 1. Datenverarbeitung
        processor = WiFiDataProcessor()
        processed_data = processor.process_data(large_dataset)
    
        assert len(processed_data) == len(large_dataset)
        assert "processed_timestamp" in processed_data.columns
    
        # 2. Feature-Extraktion
        extractor = FeatureExtractor()
        features = extractor.extract_features(processed_data)
    
        assert features.shape[0] == len(processed_data)
        assert features.shape[1] > 0
    
        # 3. Clustering-Analyse
        analyzer = ClusteringAnalyzer()
>       labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)

tests/integration/test_end_to_end.py:42: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1071: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1351: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1481: in fit
    X = self._validate_data(
.venv/lib/python3.11/site-packages/sklearn/base.py:633: in _validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1003: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:126: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[-1.15579349,  0.        ,  0.        , ...,  0.        ,
         0.15614176, -0.97725852],
       [-1.1557934...176, -0.97725852],
       [ 1.35680105,  0.        ,  0.        , ...,  0.        ,
         0.15614176,  1.02327069]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:175: ValueError
____________ TestEndToEndWorkflow.test_plugin_integration_workflow _____________

self = <test_end_to_end.TestEndToEndWorkflow object at 0x7f792ab610>
sample_wifi_data =               timestamp device_id  ...  packet_count  bytes_transferred
0   2024-01-01 00:00:00  device_3  ...        ...15         206.754596
999 2024-01-01 16:39:00  device_1  ...           103         554.365485

[1000 rows x 11 columns]
temp_dir = PosixPath('/tmp/tmpialey12e')

    @pytest.mark.integration
    def test_plugin_integration_workflow(self, sample_wifi_data, temp_dir):
        """Test der Plugin-Integration im Workflow."""
        from plugins import load_all_plugins
    
        # Plugins laden
        plugin_dir = Path("plugins")
        plugins = load_all_plugins(plugin_dir)
    
        assert len(plugins) > 0
    
        # Features extrahieren
        extractor = FeatureExtractor()
        features = extractor.extract_features(sample_wifi_data)
    
        # Jedes Plugin testen
        for plugin in plugins:
            # Plugin-Dependencies prüfen
>           if not plugin.validate_dependencies():
E           AttributeError: 'str' object has no attribute 'validate_dependencies'

tests/integration/test_end_to_end.py:101: AttributeError
----------------------------- Captured stdout call -----------------------------
2025-10-19 10:28:32,636 | WARNING  | Einige ML-Bibliotheken nicht verfügbar: No module named 'hdbscan'
2025-10-19 10:28:32,638 | WARNING  | Dependencies ['hdbscan'] für Plugin 'Advanced Clustering' nicht verfügbar
2025-10-19 10:28:32,638 | WARNING  | Plugin clustering_advanced hat fehlende Dependencies
2025-10-19 10:28:32,641 | INFO     | Plugin 'Ensemble Models' v1.0.0 geladen
2025-10-19 10:28:32,644 | WARNING  | Dependencies ['umap-learn'] für Plugin 'UMAP Plot' nicht verfügbar
2025-10-19 10:28:32,644 | WARNING  | Plugin umap_plot hat fehlende Dependencies
2025-10-19 10:28:32,645 | INFO     | Plugin 'Sankey Diagram' v1.0.0 geladen
2025-10-19 10:28:32,647 | WARNING  | PyTorch oder Gym nicht verfügbar: No module named 'gym'
2025-10-19 10:28:32,652 | WARNING  | Dependencies ['gym'] für Plugin 'Reinforcement Learning' nicht verfügbar
2025-10-19 10:28:32,652 | WARNING  | Plugin reinforcement_learning hat fehlende Dependencies
2025-10-19 10:28:32,653 | INFO     | Plugin 'Example_Plugin' v1.0.0 geladen
------------------------------ Captured log call -------------------------------
WARNING  root:plugin.py:27 Einige ML-Bibliotheken nicht verfügbar: No module named 'hdbscan'
WARNING  plugins:__init__.py:68 Dependencies ['hdbscan'] für Plugin 'Advanced Clustering' nicht verfügbar
WARNING  plugins:__init__.py:97 Plugin clustering_advanced hat fehlende Dependencies
INFO     plugins:__init__.py:120 Plugin 'Ensemble Models' v1.0.0 geladen
WARNING  plugins:__init__.py:68 Dependencies ['umap-learn'] für Plugin 'UMAP Plot' nicht verfügbar
WARNING  plugins:__init__.py:97 Plugin umap_plot hat fehlende Dependencies
INFO     plugins:__init__.py:120 Plugin 'Sankey Diagram' v1.0.0 geladen
WARNING  root:plugin.py:28 PyTorch oder Gym nicht verfügbar: No module named 'gym'
WARNING  plugins:__init__.py:68 Dependencies ['gym'] für Plugin 'Reinforcement Learning' nicht verfügbar
WARNING  plugins:__init__.py:97 Plugin reinforcement_learning hat fehlende Dependencies
INFO     plugins:__init__.py:120 Plugin 'Example_Plugin' v1.0.0 geladen
_____________ TestEndToEndWorkflow.test_data_pipeline_with_file_io _____________

self = <test_end_to_end.TestEndToEndWorkflow object at 0x7f792abd10>
temp_dir = PosixPath('/tmp/tmpixxuoqge')

    @pytest.mark.integration
    def test_data_pipeline_with_file_io(self, temp_dir):
        """Test der Datenpipeline mit Datei-I/O."""
        # Test-Daten generieren
        n_samples = 1000
        test_data = pd.DataFrame(
            {
                "timestamp": pd.date_range(
                    "2024-01-01", periods=n_samples, freq="1min"
                ),
                "device_id": np.random.choice(
                    ["device_1", "device_2", "device_3"], n_samples
                ),
                "signal_strength": np.random.normal(-50, 10, n_samples),
                "frequency": np.random.choice([2.4, 5.0], n_samples),
                "channel": np.random.randint(1, 14, n_samples),
                "mac_address": [f"00:11:22:33:44:{i:02x}" for i in range(n_samples)],
                "ssid": np.random.choice(
                    ["WiFi_Home", "WiFi_Office", "Public_WiFi"], n_samples
                ),
                "encryption": np.random.choice(["WPA2", "WPA3", "Open"], n_samples),
                "data_rate": np.random.normal(54, 10, n_samples),
                "packet_count": np.random.poisson(100, n_samples),
                "bytes_transferred": np.random.exponential(1000, n_samples),
            }
        )
    
        # 1. Daten in CSV speichern
        input_file = temp_dir / "input_data.csv"
        test_data.to_csv(input_file, index=False)
    
        # 2. Daten laden und verarbeiten
        loaded_data = pd.read_csv(input_file)
        processor = WiFiDataProcessor()
        processed_data = processor.process_data(loaded_data)
    
        # 3. Features extrahieren
        extractor = FeatureExtractor()
        features = extractor.extract_features(processed_data)
    
        # 4. Clustering
        analyzer = ClusteringAnalyzer()
>       labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=3)

tests/integration/test_end_to_end.py:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1071: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1351: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1481: in fit
    X = self._validate_data(
.venv/lib/python3.11/site-packages/sklearn/base.py:633: in _validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1003: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:126: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[-1.62859019,  0.        ,  0.        , ...,  0.        ,
         0.        , -0.9900495 ],
       [-1.6285901...   ,  1.0100505 ],
       [ 1.69506325,  0.        ,  0.        , ...,  0.        ,
         0.        ,  1.0100505 ]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:175: ValueError
____________ TestEndToEndWorkflow.test_error_handling_and_recovery _____________

self = <test_end_to_end.TestEndToEndWorkflow object at 0x7f792bc490>
temp_dir = PosixPath('/tmp/tmpyz98in3j')

    @pytest.mark.integration
    def test_error_handling_and_recovery(self, temp_dir):
        """Test der Fehlerbehandlung und Wiederherstellung."""
        processor = WiFiDataProcessor()
        extractor = FeatureExtractor()
        analyzer = ClusteringAnalyzer()
    
        # Test mit ungültigen Daten
        invalid_data = pd.DataFrame(
            {
                "timestamp": ["invalid_date", "2024-01-01", "2024-01-02"],
                "signal_strength": [np.nan, -50, -60],
                "frequency": [1.0, 2.4, 5.0],  # Ungültige Frequenz
                "device_id": ["device_1", "device_2", "device_3"],
                "mac_address": [
                    "00:11:22:33:44:01",
                    "00:11:22:33:44:02",
                    "00:11:22:33:44:03",
                ],
                "ssid": ["WiFi_Home", "WiFi_Office", "Public_WiFi"],
                "encryption": ["WPA2", "WPA3", "Open"],
                "channel": [1, 6, 11],
                "data_rate": [54, 100, 54],
                "packet_count": [100, 200, 150],
                "bytes_transferred": [1000, 2000, 1500],
            }
        )
    
        # Verarbeitung sollte Fehler behandeln
        try:
>           processed_data = processor.process_data(invalid_data)

tests/integration/test_end_to_end.py:203: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/data_processing/wifi_processor.py:45: in process_data
    processed_data['processed_timestamp'] = pd.to_datetime(processed_data['timestamp'])
.venv/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:1067: in to_datetime
    values = convert_listlike(arg._values, format)
.venv/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:435: in _convert_listlike_datetimes
    result, tz_parsed = objects_to_datetime64(
.venv/lib/python3.11/site-packages/pandas/core/arrays/datetimes.py:2398: in objects_to_datetime64
    result, tz_parsed = tslib.array_to_datetime(
tslib.pyx:414: in pandas._libs.tslib.array_to_datetime
    ???
tslib.pyx:596: in pandas._libs.tslib.array_to_datetime
    ???
tslib.pyx:553: in pandas._libs.tslib.array_to_datetime
    ???
conversion.pyx:641: in pandas._libs.tslibs.conversion.convert_str_to_tsobject
    ???
parsing.pyx:336: in pandas._libs.tslibs.parsing.parse_datetime_string
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   pandas._libs.tslibs.parsing.DateParseError: Unknown datetime string format, unable to parse: invalid_date, at position 0

parsing.pyx:666: DateParseError

During handling of the above exception, another exception occurred:

self = <test_end_to_end.TestEndToEndWorkflow object at 0x7f792bc490>
temp_dir = PosixPath('/tmp/tmpyz98in3j')

    @pytest.mark.integration
    def test_error_handling_and_recovery(self, temp_dir):
        """Test der Fehlerbehandlung und Wiederherstellung."""
        processor = WiFiDataProcessor()
        extractor = FeatureExtractor()
        analyzer = ClusteringAnalyzer()
    
        # Test mit ungültigen Daten
        invalid_data = pd.DataFrame(
            {
                "timestamp": ["invalid_date", "2024-01-01", "2024-01-02"],
                "signal_strength": [np.nan, -50, -60],
                "frequency": [1.0, 2.4, 5.0],  # Ungültige Frequenz
                "device_id": ["device_1", "device_2", "device_3"],
                "mac_address": [
                    "00:11:22:33:44:01",
                    "00:11:22:33:44:02",
                    "00:11:22:33:44:03",
                ],
                "ssid": ["WiFi_Home", "WiFi_Office", "Public_WiFi"],
                "encryption": ["WPA2", "WPA3", "Open"],
                "channel": [1, 6, 11],
                "data_rate": [54, 100, 54],
                "packet_count": [100, 200, 150],
                "bytes_transferred": [1000, 2000, 1500],
            }
        )
    
        # Verarbeitung sollte Fehler behandeln
        try:
            processed_data = processor.process_data(invalid_data)
            # Wenn erfolgreich, sollten ungültige Daten bereinigt sein
            assert len(processed_data) <= len(invalid_data)
        except Exception as e:
            # Fehler sollten informativ sein
>           assert "Invalid" in str(e) or "Missing" in str(e)
E           AssertionError: assert ('Invalid' in 'Unknown datetime string format, unable to parse: invalid_date, at position 0' or 'Missing' in 'Unknown datetime string format, unable to parse: invalid_date, at position 0')
E            +  where 'Unknown datetime string format, unable to parse: invalid_date, at position 0' = str(DateParseError('Unknown datetime string format, unable to parse: invalid_date, at position 0'))
E            +  and   'Unknown datetime string format, unable to parse: invalid_date, at position 0' = str(DateParseError('Unknown datetime string format, unable to parse: invalid_date, at position 0'))

tests/integration/test_end_to_end.py:208: AssertionError
_______________ TestEndToEndWorkflow.test_performance_under_load _______________

self = <test_end_to_end.TestEndToEndWorkflow object at 0x7f792bc350>
temp_dir = PosixPath('/tmp/tmpd790gb_0')

    @pytest.mark.integration
    def test_performance_under_load(self, temp_dir):
        """Test der Performance unter Last."""
        import time
    
        # Große Datenmenge
        n_samples = 50000
        large_data = pd.DataFrame(
            {
                "timestamp": pd.date_range("2024-01-01", periods=n_samples, freq="1s"),
                "device_id": np.random.choice(
                    [f"device_{i}" for i in range(100)], n_samples
                ),
                "signal_strength": np.random.normal(-50, 10, n_samples),
                "frequency": np.random.choice([2.4, 5.0], n_samples),
                "channel": np.random.randint(1, 14, n_samples),
                "mac_address": [f"00:11:22:33:44:{i:02x}" for i in range(n_samples)],
                "ssid": np.random.choice(
                    ["WiFi_Home", "WiFi_Office", "Public_WiFi"], n_samples
                ),
                "encryption": np.random.choice(["WPA2", "WPA3", "Open"], n_samples),
                "data_rate": np.random.normal(54, 10, n_samples),
                "packet_count": np.random.poisson(100, n_samples),
                "bytes_transferred": np.random.exponential(1000, n_samples),
            }
        )
    
        processor = WiFiDataProcessor()
        extractor = FeatureExtractor()
        analyzer = ClusteringAnalyzer()
    
        # Performance-Messung
        start_time = time.time()
    
        # Verarbeitung
        processed_data = processor.process_data(large_data)
        features = extractor.extract_features(processed_data)
>       labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)

tests/integration/test_end_to_end.py:259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1071: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1351: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1481: in fit
    X = self._validate_data(
.venv/lib/python3.11/site-packages/sklearn/base.py:633: in _validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1003: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:126: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[-1.6100241 ,  0.        ,  0.        , ...,  0.        ,
         0.        , -1.00344594],
       [-1.6100241...   ,  0.9965659 ],
       [ 1.63599223,  0.        ,  0.        , ...,  0.        ,
         0.        , -1.00344594]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:175: ValueError
_______________ TestEndToEndWorkflow.test_concurrent_processing ________________

self = <test_end_to_end.TestEndToEndWorkflow object at 0x7f792bcb90>
temp_dir = PosixPath('/tmp/tmprfv9gqou')

    @pytest.mark.integration
    def test_concurrent_processing(self, temp_dir):
        """Test der parallelen Verarbeitung."""
        import threading
        from concurrent.futures import ThreadPoolExecutor
    
        def process_chunk(chunk_data):
            """Verarbeitet einen Daten-Chunk."""
            processor = WiFiDataProcessor()
            extractor = FeatureExtractor()
            analyzer = ClusteringAnalyzer()
    
            processed_data = processor.process_data(chunk_data)
            features = extractor.extract_features(processed_data)
            labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=3)
    
            return {
                "chunk_id": threading.current_thread().ident,
                "n_samples": len(chunk_data),
                "n_clusters": len(np.unique(labels)),
            }
    
        # Daten in Chunks aufteilen
        n_chunks = 4
        chunk_size = 1000
        n_samples = n_chunks * chunk_size
    
        test_data = pd.DataFrame(
            {
                "timestamp": pd.date_range(
                    "2024-01-01", periods=n_samples, freq="1min"
                ),
                "device_id": np.random.choice(
                    [f"device_{i}" for i in range(50)], n_samples
                ),
                "signal_strength": np.random.normal(-50, 10, n_samples),
                "frequency": np.random.choice([2.4, 5.0], n_samples),
                "channel": np.random.randint(1, 14, n_samples),
                "mac_address": [f"00:11:22:33:44:{i:02x}" for i in range(n_samples)],
                "ssid": np.random.choice(
                    ["WiFi_Home", "WiFi_Office", "Public_WiFi"], n_samples
                ),
                "encryption": np.random.choice(["WPA2", "WPA3", "Open"], n_samples),
                "data_rate": np.random.normal(54, 10, n_samples),
                "packet_count": np.random.poisson(100, n_samples),
                "bytes_transferred": np.random.exponential(1000, n_samples),
            }
        )
    
        chunks = [
            test_data.iloc[i * chunk_size : (i + 1) * chunk_size]
            for i in range(n_chunks)
        ]
    
        # Parallele Verarbeitung
        with ThreadPoolExecutor(max_workers=n_chunks) as executor:
            futures = [executor.submit(process_chunk, chunk) for chunk in chunks]
>           results = [future.result() for future in futures]

tests/integration/test_end_to_end.py:328: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/integration/test_end_to_end.py:328: in <listcomp>
    results = [future.result() for future in futures]
../.pyenv/versions/3.11.9/lib/python3.11/concurrent/futures/_base.py:456: in result
    return self.__get_result()
../.pyenv/versions/3.11.9/lib/python3.11/concurrent/futures/_base.py:401: in __get_result
    raise self._exception
../.pyenv/versions/3.11.9/lib/python3.11/concurrent/futures/thread.py:58: in run
    result = self.fn(*self.args, **self.kwargs)
tests/integration/test_end_to_end.py:285: in process_chunk
    labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=3)
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1071: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1351: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1481: in fit
    X = self._validate_data(
.venv/lib/python3.11/site-packages/sklearn/base.py:633: in _validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1003: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:126: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[-1.62859019,  0.        ,  0.        , ...,  0.11020775,
        -0.38663966, -1.06832936],
       [-1.6285901...14 ,  0.93604092],
       [ 1.69506325,  0.        ,  0.        , ...,  0.11020775,
         0.31126587,  0.93604092]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:175: ValueError
_______________ TestClusteringBenchmarks.test_kmeans_performance _______________

self = <test_benchmarks.TestClusteringBenchmarks object at 0x7f792c5210>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f72eb4150>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_kmeans_performance(self, benchmark, large_dataset):
        """Benchmark für K-Means Clustering."""
        analyzer = ClusteringAnalyzer()
    
        # Features extrahieren
        feature_extractor = FeatureExtractor()
        features = feature_extractor.extract_features(large_dataset)
    
        def clustering_func():
            return analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)
    
>       result = benchmark(clustering_func)

tests/performance/test_benchmarks.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:156: in __call__
    return self._raw(function_to_benchmark, *args, **kwargs)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:180: in _raw
    duration, iterations, loops_range = self._calibrate_timer(runner)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:318: in _calibrate_timer
    duration = runner(loops_range)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:109: in runner
    function_to_benchmark(*args, **kwargs)
tests/performance/test_benchmarks.py:29: in clustering_func
    return analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1071: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1351: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1481: in fit
    X = self._validate_data(
.venv/lib/python3.11/site-packages/sklearn/base.py:633: in _validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1003: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:126: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176, -0.97725852],
       [ 0.       ...176, -0.97725852],
       [ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176,  1.02327069]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:175: ValueError
_______________ TestClusteringBenchmarks.test_dbscan_performance _______________

self = <test_benchmarks.TestClusteringBenchmarks object at 0x7f792c5810>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f73528410>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_dbscan_performance(self, benchmark, large_dataset):
        """Benchmark für DBSCAN Clustering."""
        analyzer = ClusteringAnalyzer()
    
        feature_extractor = FeatureExtractor()
        features = feature_extractor.extract_features(large_dataset)
    
        def clustering_func():
            return analyzer.cluster_data(
                features, algorithm="dbscan", eps=0.5, min_samples=5
            )
    
>       result = benchmark(clustering_func)

tests/performance/test_benchmarks.py:51: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:156: in __call__
    return self._raw(function_to_benchmark, *args, **kwargs)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:180: in _raw
    duration, iterations, loops_range = self._calibrate_timer(runner)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:318: in _calibrate_timer
    duration = runner(loops_range)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:109: in runner
    function_to_benchmark(*args, **kwargs)
tests/performance/test_benchmarks.py:47: in clustering_func
    return analyzer.cluster_data(
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1071: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1351: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1481: in fit
    X = self._validate_data(
.venv/lib/python3.11/site-packages/sklearn/base.py:633: in _validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1003: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:126: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176, -0.97725852],
       [ 0.       ...176, -0.97725852],
       [ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176,  1.02327069]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:175: ValueError
____________ TestClusteringBenchmarks.test_hierarchical_performance ____________

self = <test_benchmarks.TestClusteringBenchmarks object at 0x7f792c5e10>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f72139010>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_hierarchical_performance(self, benchmark, large_dataset):
        """Benchmark für Hierarchical Clustering."""
        analyzer = ClusteringAnalyzer()
    
        feature_extractor = FeatureExtractor()
        features = feature_extractor.extract_features(large_dataset)
    
        def clustering_func():
            return analyzer.cluster_data(
                features, algorithm="hierarchical", n_clusters=5
            )
    
>       result = benchmark(clustering_func)

tests/performance/test_benchmarks.py:71: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:156: in __call__
    return self._raw(function_to_benchmark, *args, **kwargs)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:180: in _raw
    duration, iterations, loops_range = self._calibrate_timer(runner)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:318: in _calibrate_timer
    duration = runner(loops_range)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:109: in runner
    function_to_benchmark(*args, **kwargs)
tests/performance/test_benchmarks.py:67: in clustering_func
    return analyzer.cluster_data(
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1071: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1351: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1481: in fit
    X = self._validate_data(
.venv/lib/python3.11/site-packages/sklearn/base.py:633: in _validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1003: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:126: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176, -0.97725852],
       [ 0.       ...176, -0.97725852],
       [ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176,  1.02327069]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:175: ValueError
_____________ TestClusteringBenchmarks.test_clustering_scalability _____________

self = <test_benchmarks.TestClusteringBenchmarks object at 0x7f792c6490>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f72d47c50>

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_clustering_scalability(self, benchmark):
        """Test Skalierbarkeit mit verschiedenen Datengrößen."""
        sizes = [1000, 5000, 10000, 20000]
        times = []
    
        for size in sizes:
            # Generiere Test-Daten
            X = np.random.randn(size, 20)
            analyzer = ClusteringAnalyzer()
    
            def clustering_func():
                return analyzer.cluster_data(X, algorithm="kmeans", n_clusters=5)
    
            result = benchmark(clustering_func)
>           times.append(result.stats.mean)
E           AttributeError: 'numpy.ndarray' object has no attribute 'stats'

tests/performance/test_benchmarks.py:93: AttributeError
________ TestDataProcessingBenchmarks.test_data_processing_performance _________

self = <test_benchmarks.TestDataProcessingBenchmarks object at 0x7f792c6bd0>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f720dccd0>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_data_processing_performance(self, benchmark, large_dataset):
        """Benchmark für Datenverarbeitung."""
        processor = WiFiDataProcessor()
    
        def processing_func():
            return processor.process_data(large_dataset)
    
        result = benchmark(processing_func)
    
        # Datenverarbeitung sollte schnell sein
>       assert result.stats.mean < 1.0

tests/performance/test_benchmarks.py:121: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self =                timestamp  device_id  ...  bytes_transferred  processed_timestamp
0    2024-01-01 00:00:00  device_51  ...01 02:46:38
9999 2024-01-01 02:46:39   device_7  ...         594.132395  2024-01-01 02:46:39

[10000 rows x 12 columns]
name = 'stats'

    @final
    def __getattr__(self, name: str):
        """
        After regular attribute access, try looking up the name
        This allows simpler access to columns for interactive use.
        """
        # Note: obj.x will always call obj.__getattribute__('x') prior to
        # calling obj.__getattr__('x').
        if (
            name not in self._internal_names_set
            and name not in self._metadata
            and name not in self._accessors
            and self._info_axis._can_hold_identifiers_and_holds_name(name)
        ):
            return self[name]
>       return object.__getattribute__(self, name)
E       AttributeError: 'DataFrame' object has no attribute 'stats'

.venv/lib/python3.11/site-packages/pandas/core/generic.py:6293: AttributeError
_______ TestDataProcessingBenchmarks.test_feature_extraction_performance _______

self = <test_benchmarks.TestDataProcessingBenchmarks object at 0x7f792c7210>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f728b8510>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_feature_extraction_performance(self, benchmark, large_dataset):
        """Benchmark für Feature-Extraktion."""
        extractor = FeatureExtractor()
    
        def extraction_func():
            return extractor.extract_features(large_dataset)
    
        result = benchmark(extraction_func)
    
        # Feature-Extraktion sollte effizient sein
>       assert result.stats.mean < 2.0
E       AttributeError: 'numpy.ndarray' object has no attribute 'stats'

tests/performance/test_benchmarks.py:136: AttributeError
________ TestDataProcessingBenchmarks.test_feature_scaling_performance _________

self = <test_benchmarks.TestDataProcessingBenchmarks object at 0x7f792c7910>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f78f31350>

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_feature_scaling_performance(self, benchmark):
        """Benchmark für Feature-Skalierung."""
        extractor = FeatureExtractor()
    
        # Große Feature-Matrix
        features = np.random.randn(50000, 100)
    
        def scaling_func():
            return extractor.scale_features(features)
    
        result = benchmark(scaling_func)
    
        # Skalierung sollte sehr schnell sein
>       assert result.stats.mean < 0.5
E       AttributeError: 'numpy.ndarray' object has no attribute 'stats'

tests/performance/test_benchmarks.py:154: AttributeError
_________ TestClassificationBenchmarks.test_random_forest_performance __________

self = <test_benchmarks.TestClassificationBenchmarks object at 0x7f792d0090>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f72b90490>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_random_forest_performance(self, benchmark, large_dataset):
        """Benchmark für Random Forest Klassifikation."""
        classifier = DeviceClassifier()
    
        # Features und Labels generieren
        feature_extractor = FeatureExtractor()
        features = feature_extractor.extract_features(large_dataset)
        labels = np.random.randint(0, 5, len(features))
    
        def classification_func():
            classifier.train(features, labels)
            return classifier.predict(features)
    
        result = benchmark(classification_func)
    
        # Random Forest sollte effizient sein
>       assert result.stats.mean < 3.0
E       AttributeError: 'numpy.ndarray' object has no attribute 'stats'

tests/performance/test_benchmarks.py:179: AttributeError
______________ TestClassificationBenchmarks.test_svm_performance _______________

self = <test_benchmarks.TestClassificationBenchmarks object at 0x7f792c6790>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f731e57d0>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_svm_performance(self, benchmark, large_dataset):
        """Benchmark für SVM Klassifikation."""
        classifier = DeviceClassifier(algorithm="svm")
    
        feature_extractor = FeatureExtractor()
        features = feature_extractor.extract_features(large_dataset)
        labels = np.random.randint(0, 5, len(features))
    
        def classification_func():
            classifier.train(features, labels)
            return classifier.predict(features)
    
>       result = benchmark(classification_func)

tests/performance/test_benchmarks.py:196: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:156: in __call__
    return self._raw(function_to_benchmark, *args, **kwargs)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:180: in _raw
    duration, iterations, loops_range = self._calibrate_timer(runner)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:318: in _calibrate_timer
    duration = runner(loops_range)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:109: in runner
    function_to_benchmark(*args, **kwargs)
tests/performance/test_benchmarks.py:193: in classification_func
    classifier.train(features, labels)
wlan_tool/analysis/device_classification.py:64: in train
    self.model.fit(X, y)
.venv/lib/python3.11/site-packages/sklearn/base.py:1351: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/svm/_base.py:190: in fit
    X, y = self._validate_data(
.venv/lib/python3.11/site-packages/sklearn/base.py:650: in _validate_data
    X, y = check_X_y(X, y, **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1192: in check_X_y
    X = check_array(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1003: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:126: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176, -0.97725852],
       [ 0.       ...176, -0.97725852],
       [ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176,  1.02327069]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           SVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:175: ValueError
______________ TestMemoryBenchmarks.test_memory_usage_clustering _______________

self = <test_benchmarks.TestMemoryBenchmarks object at 0x7f792d06d0>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f731a6a90>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    @pytest.mark.memory
    def test_memory_usage_clustering(self, benchmark, large_dataset):
        """Benchmark für Speichernutzung beim Clustering."""
        analyzer = ClusteringAnalyzer()
        feature_extractor = FeatureExtractor()
    
        def memory_intensive_func():
            # Features extrahieren
            features = feature_extractor.extract_features(large_dataset)
    
            # Clustering durchführen
            labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)
    
            # Zusätzliche Berechnungen
            unique_labels = np.unique(labels)
            cluster_sizes = [np.sum(labels == label) for label in unique_labels]
    
            return {
                "n_clusters": len(unique_labels),
                "cluster_sizes": cluster_sizes,
                "features_shape": features.shape,
            }
    
>       result = benchmark(memory_intensive_func)

tests/performance/test_benchmarks.py:231: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:156: in __call__
    return self._raw(function_to_benchmark, *args, **kwargs)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:180: in _raw
    duration, iterations, loops_range = self._calibrate_timer(runner)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:318: in _calibrate_timer
    duration = runner(loops_range)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:109: in runner
    function_to_benchmark(*args, **kwargs)
tests/performance/test_benchmarks.py:219: in memory_intensive_func
    labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1071: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1351: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1481: in fit
    X = self._validate_data(
.venv/lib/python3.11/site-packages/sklearn/base.py:633: in _validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1003: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:126: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176, -0.97725852],
       [ 0.       ...176, -0.97725852],
       [ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176,  1.02327069]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:175: ValueError
_____________ TestMemoryBenchmarks.test_memory_usage_large_dataset _____________

self = <test_benchmarks.TestMemoryBenchmarks object at 0x7f792d0a90>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f72caf150>

    @pytest.mark.benchmark
    @pytest.mark.performance
    @pytest.mark.memory
    def test_memory_usage_large_dataset(self, benchmark):
        """Benchmark für Speichernutzung mit sehr großen Datensätzen."""
        # Sehr großer Datensatz
        n_samples = 100000
        n_features = 50
    
        def large_dataset_func():
            # Große Daten generieren
            X = np.random.randn(n_samples, n_features)
    
            # Clustering mit reduzierter Komplexität
            from sklearn.cluster import MiniBatchKMeans
    
            kmeans = MiniBatchKMeans(n_clusters=10, batch_size=1000)
            labels = kmeans.fit_predict(X)
    
            return {
                "n_samples": n_samples,
                "n_features": n_features,
                "n_clusters": len(np.unique(labels)),
            }
    
        result = benchmark(large_dataset_func)
    
        # Auch bei großen Datensätzen sollte es in angemessener Zeit laufen
>       assert result.stats.mean < 10.0
E       AttributeError: 'dict' object has no attribute 'stats'

tests/performance/test_benchmarks.py:265: AttributeError
________ TestConcurrentBenchmarks.test_parallel_processing_performance _________

self = <test_benchmarks.TestConcurrentBenchmarks object at 0x7f792d0e90>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f702d3c10>

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_parallel_processing_performance(self, benchmark):
        """Benchmark für parallele Verarbeitung."""
        import threading
        from concurrent.futures import ThreadPoolExecutor
    
        def process_chunk(chunk_data):
            """Verarbeitet einen Daten-Chunk."""
            analyzer = ClusteringAnalyzer()
            return analyzer.cluster_data(chunk_data, algorithm="kmeans", n_clusters=3)
    
        def parallel_processing_func():
            # Daten in Chunks aufteilen
            n_chunks = 4
            chunk_size = 2500
            X = np.random.randn(n_chunks * chunk_size, 20)
            chunks = [X[i * chunk_size : (i + 1) * chunk_size] for i in range(n_chunks)]
    
            # Parallele Verarbeitung
            with ThreadPoolExecutor(max_workers=n_chunks) as executor:
                futures = [executor.submit(process_chunk, chunk) for chunk in chunks]
                results = [future.result() for future in futures]
    
            return results
    
        result = benchmark(parallel_processing_func)
    
        # Parallele Verarbeitung sollte effizienter sein
>       assert result.stats.mean < 3.0
E       AttributeError: 'list' object has no attribute 'stats'

tests/performance/test_benchmarks.py:301: AttributeError
__________________ TestIOBenchmarks.test_file_io_performance ___________________

self = <test_benchmarks.TestIOBenchmarks object at 0x7f792d1310>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f72c80250>
temp_dir = PosixPath('/tmp/tmp47a0nrqg')

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_file_io_performance(self, benchmark, temp_dir):
        """Benchmark für Datei-I/O."""
        import pickle
    
        # Große Daten generieren
        large_data = np.random.randn(10000, 50)
        file_path = temp_dir / "test_data.pkl"
    
        def io_func():
            # Speichern
            with open(file_path, "wb") as f:
                pickle.dump(large_data, f)
    
            # Laden
            with open(file_path, "rb") as f:
                loaded_data = pickle.load(f)
    
            return loaded_data.shape
    
        result = benchmark(io_func)
    
        # I/O sollte schnell sein
>       assert result.stats.mean < 1.0
E       AttributeError: 'tuple' object has no attribute 'stats'

tests/performance/test_benchmarks.py:332: AttributeError
___________________ TestIOBenchmarks.test_csv_io_performance ___________________

self = <test_benchmarks.TestIOBenchmarks object at 0x7f792d1910>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f72c864d0>
temp_dir = PosixPath('/tmp/tmp6p9388ar')
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_csv_io_performance(self, benchmark, temp_dir, large_dataset):
        """Benchmark für CSV-I/O."""
        csv_path = temp_dir / "test_data.csv"
    
        def csv_io_func():
            # Speichern
            large_dataset.to_csv(csv_path, index=False)
    
            # Laden
            loaded_data = pd.read_csv(csv_path)
    
            return loaded_data.shape
    
        result = benchmark(csv_io_func)
    
        # CSV-I/O kann langsamer sein
>       assert result.stats.mean < 2.0
E       AttributeError: 'tuple' object has no attribute 'stats'

tests/performance/test_benchmarks.py:353: AttributeError
_________________ TestMemoryUsage.test_memory_usage_clustering _________________

self = <test_memory_profiling.TestMemoryUsage object at 0x7f79303a10>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.memory
    @pytest.mark.performance
    def test_memory_usage_clustering(self, large_dataset):
        """Test Speichernutzung beim Clustering."""
        process = psutil.Process(os.getpid())
        memory_before = process.memory_info().rss / 1024 / 1024
    
        analyzer = ClusteringAnalyzer()
        feature_extractor = FeatureExtractor()
    
        # Features extrahieren
        features = feature_extractor.extract_features(large_dataset)
        memory_after_features = process.memory_info().rss / 1024 / 1024
    
        # Clustering durchführen
>       labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)

tests/performance/test_memory_profiling.py:77: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1071: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1351: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1481: in fit
    X = self._validate_data(
.venv/lib/python3.11/site-packages/sklearn/base.py:633: in _validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1003: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:126: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176, -0.97725852],
       [ 0.       ...176, -0.97725852],
       [ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176,  1.02327069]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:175: ValueError
=============================== warnings summary ===============================
tests/conftest.py:12
  /home/pi/hacking/tests/conftest.py:12: DeprecationWarning: 
  Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),
  (to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)
  but was not found to be installed on your system.
  If this would cause problems for you,
  please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466
          
    import pandas as pd

pytest/test_integration.py:192
  /home/pi/hacking/pytest/test_integration.py:192: PytestUnknownMarkWarning: Unknown pytest.mark.network - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.network

plugins/clustering_advanced/tests/test_clustering_advanced.py::TestAdvancedClusteringPlugin::test_optics_clustering
plugins/clustering_advanced/tests/test_clustering_advanced.py::TestAdvancedClusteringPlugin::test_plugin_run_with_sufficient_data
  /home/pi/hacking/.venv/lib/python3.11/site-packages/sklearn/cluster/_optics.py:659: UserWarning: All reachability values are inf. Set a larger max_eps or all data will be considered outliers.
    warnings.warn(

plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_model_performance_evaluation
  /home/pi/hacking/.venv/lib/python3.11/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.
    warnings.warn(

plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_model_performance_evaluation
plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_model_performance_evaluation
plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_model_performance_evaluation
plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_model_performance_evaluation
plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_model_performance_evaluation
plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_model_performance_evaluation
  /home/pi/hacking/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:455: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.
    opt_res = optimize.minimize(

plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_model_performance_evaluation
plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_model_performance_evaluation
plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_model_performance_evaluation
plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_model_performance_evaluation
plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_model_performance_evaluation
plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_model_performance_evaluation
  /home/pi/hacking/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
  STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.
  
  Increase the number of iterations (max_iter) or scale the data as shown in:
      https://scikit-learn.org/stable/modules/preprocessing.html
  Please also refer to the documentation for alternative solver options:
      https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
    n_iter_i = _check_optimize_result(

plugins/ensemble_models/tests/test_ensemble_models.py: 40 warnings
  /home/pi/hacking/.venv/lib/python3.11/site-packages/sklearn/model_selection/_split.py:737: UserWarning:
  
  The least populated class in y has only 3 members, which is less than n_splits=5.

plugins/ensemble_models/tests/test_ensemble_models.py: 60 warnings
  /home/pi/hacking/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:455: DeprecationWarning:
  
  scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.

plugins/ensemble_models/tests/test_ensemble_models.py: 24 warnings
  /home/pi/hacking/.venv/lib/python3.11/site-packages/sklearn/model_selection/_split.py:737: UserWarning:
  
  The least populated class in y has only 2 members, which is less than n_splits=5.

plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_plugin_run_with_sufficient_data
plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_plugin_run_with_sufficient_data
plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_plugin_run_with_sufficient_data
plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_plugin_run_with_sufficient_data
plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_plugin_run_with_sufficient_data
plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_plugin_run_with_sufficient_data
  /home/pi/hacking/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning:
  
  The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.

pytest/test_capture.py::TestSniffingIntegration::test_sniff_with_writer_mock
  /home/pi/hacking/.venv/lib/python3.11/site-packages/_pytest/threadexception.py:77: PytestUnhandledThreadExceptionWarning:
  
  Exception in thread ChannelHopper
  
  Traceback (most recent call last):
    File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/threading.py", line 1045, in _bootstrap_inner
      self.run()
    File "/home/pi/hacking/wlan_tool/capture/sniffer.py", line 207, in run
      subprocess.run(command, check=True, capture_output=True, text=True)
    File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/subprocess.py", line 550, in run
      stdout, stderr = process.communicate(input, timeout=timeout)
      ^^^^^^^^^^^^^^
  ValueError: not enough values to unpack (expected 2, got 0)

tests/integration/test_end_to_end.py::TestEndToEndWorkflow::test_error_handling_and_recovery
  /home/pi/hacking/wlan_tool/data_processing/wifi_processor.py:45: UserWarning:
  
  Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html

-------------------------------------------------------------------------------------------------- benchmark: 9 tests --------------------------------------------------------------------------------------------------
Name (time in ms)                               Min                   Max                  Mean              StdDev                Median                 IQR            Outliers      OPS            Rounds  Iterations
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
test_file_io_performance                    24.7494 (1.0)        183.4476 (3.48)       136.1277 (2.60)      20.3526 (119.56)     135.2244 (2.59)      10.4624 (52.63)         7;6   7.3460 (0.38)         50           1
test_feature_extraction_performance         52.1343 (2.11)        52.6953 (1.0)         52.3365 (1.0)        0.1702 (1.0)         52.2953 (1.0)        0.1988 (1.0)           5;0  19.1071 (1.0)          16           1
test_data_processing_performance            60.4756 (2.44)        63.0197 (1.20)        61.5668 (1.18)       0.9459 (5.56)        61.5195 (1.18)       1.1394 (5.73)          2;0  16.2425 (0.85)          5           1
test_clustering_scalability                 89.4984 (3.62)       104.3164 (1.98)       100.3664 (1.92)       4.6856 (27.53)      100.8539 (1.93)       4.4184 (22.23)         2;1   9.9635 (0.52)         11           1
test_feature_scaling_performance           153.1119 (6.19)       158.8291 (3.01)       154.5722 (2.95)       2.4474 (14.38)      153.2437 (2.93)       2.4148 (12.15)         1;0   6.4695 (0.34)          5           1
test_parallel_processing_performance       172.2920 (6.96)       214.7625 (4.08)       192.5087 (3.68)      17.2898 (101.57)     187.9188 (3.59)      31.3988 (157.96)        3;0   5.1946 (0.27)          7           1
test_csv_io_performance                    325.0622 (13.13)      381.7355 (7.24)       336.6621 (6.43)      25.1997 (148.04)     325.4137 (6.22)      14.8589 (74.75)         1;1   2.9703 (0.16)          5           1
test_memory_usage_large_dataset            464.4555 (18.77)      800.9043 (15.20)      652.2800 (12.46)    141.3838 (830.59)     714.5412 (13.66)    228.1745 (>1000.0)       2;0   1.5331 (0.08)          5           1
test_random_forest_performance           7,818.1755 (315.89)   7,906.1963 (150.04)   7,873.7600 (150.44)    36.0030 (211.51)   7,869.6855 (150.49)    49.1709 (247.36)        1;0   0.1270 (0.01)          5           1
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Legend:
  Outliers: 1 Standard Deviation from Mean; 1.5 IQR (InterQuartile Range) from 1st Quartile and 3rd Quartile.
  OPS: Operations Per Second, computed as 1 / Mean
=========================== short test summary info ============================
FAILED plugins/clustering_advanced/tests/test_clustering_advanced.py::TestAdvancedClusteringPlugin::test_spectral_clustering
FAILED plugins/clustering_advanced/tests/test_clustering_advanced.py::TestAdvancedClusteringPlugin::test_hierarchical_clustering
FAILED plugins/clustering_advanced/tests/test_clustering_advanced.py::TestAdvancedClusteringPlugin::test_gaussian_mixture
FAILED plugins/clustering_advanced/tests/test_clustering_advanced.py::TestAdvancedClusteringPlugin::test_hdbscan_clustering
FAILED plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_performance_visualization_creation
FAILED plugins/reinforcement_learning/tests/test_reinforcement_learning.py::TestReinforcementLearningPlugin::test_environment_observation
FAILED plugins/reinforcement_learning/tests/test_reinforcement_learning.py::TestReinforcementLearningPlugin::test_plugin_run_with_sufficient_data
FAILED plugins/reinforcement_learning/tests/test_reinforcement_learning.py::TestReinforcementLearningPlugin::test_plugin_run_without_pytorch
FAILED plugins/umap_plot/tests/test_umap_plot.py::TestUMAPPlotPlugin::test_plugin_run_with_valid_data
FAILED plugins/umap_plot/tests/test_umap_plot.py::TestUMAPPlotPlugin::test_plugin_run_without_clustered_data
FAILED plugins/umap_plot/tests/test_umap_plot.py::TestUMAPPlotPlugin::test_plugin_run_with_empty_feature_data
FAILED plugins/umap_plot/tests/test_umap_plot.py::TestUMAPPlotPlugin::test_plugin_run_with_exception
FAILED pytest/test_analysis.py::TestAnalysisLogic::test_profile_clusters - Ke...
FAILED pytest/test_analysis.py::TestAnalysisLogic::test_cluster_aps - ValueEr...
FAILED pytest/test_analysis.py::TestAnalysisLogic::test_profile_ap_clusters
FAILED pytest/test_analysis.py::TestDeviceProfiler::test_create_device_fingerprint_empty_state
FAILED pytest/test_analysis.py::TestGraphExport::test_build_export_graph - As...
FAILED pytest/test_analysis.py::TestGraphExport::test_discover_attributes - A...
FAILED pytest/test_analysis.py::TestAnalysisEdgeCases::test_single_client_analysis
FAILED pytest/test_analysis.py::TestAnalysisEdgeCases::test_malformed_event_handling
FAILED pytest/test_app.py::TestUtilsModule::test_intelligent_vendor_lookup - ...
FAILED pytest/test_app.py::TestAnalysisModule::test_features_for_client_behavior
FAILED pytest/test_app.py::TestAnalysisModule::test_cluster_clients_runs - At...
FAILED pytest/test_app.py::TestAnalysisModule::test_profile_clusters - Attrib...
FAILED pytest/test_capture.py::TestPacketParsing::test_packet_to_event_probe_request
FAILED pytest/test_capture.py::TestPacketParsing::test_packet_to_event_data_frame
FAILED pytest/test_capture.py::TestPacketParsing::test_packet_to_event_with_dhcp
FAILED pytest/test_capture.py::TestChannelHopper::test_channel_hopper_command_failure
FAILED pytest/test_capture.py::TestIEExtraction::test_extract_seq - assert 0 ...
FAILED pytest/test_capture.py::TestErrorHandling::test_packet_to_event_encoding_error
FAILED pytest/test_controllers.py::TestCaptureController::test_select_interface_automatic
FAILED pytest/test_controllers.py::TestCaptureController::test_select_interface_no_interfaces
FAILED pytest/test_controllers.py::TestCaptureController::test_setup_monitor_mode_failure
FAILED pytest/test_controllers.py::TestAnalysisController::test_analysis_controller_initialization
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_inference
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_client_clustering
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_ap_clustering
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_graph_export
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_labeling_ui
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_client_labeling_ui
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_mac_correlation
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_analysis_no_actions
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_analysis_multiple_actions
FAILED pytest/test_controllers.py::TestControllerEdgeCases::test_analysis_controller_empty_state
FAILED pytest/test_controllers.py::TestControllerEdgeCases::test_analysis_controller_with_plugins
FAILED pytest/test_controllers.py::TestControllerIntegration::test_full_analysis_workflow
FAILED pytest/test_error_handling.py::TestLoggingSystem::test_setup_logging
FAILED pytest/test_error_handling.py::TestDatabaseErrorHandling::test_database_connection_error
FAILED pytest/test_error_handling.py::TestDatabaseErrorHandling::test_database_migration_error
FAILED pytest/test_error_handling.py::TestAnalysisErrorHandling::test_client_features_null_state
FAILED pytest/test_error_handling.py::TestAnalysisErrorHandling::test_client_features_invalid_type
FAILED pytest/test_error_handling.py::TestAnalysisErrorHandling::test_clustering_invalid_parameters
FAILED pytest/test_error_handling.py::TestFileSystemErrorHandling::test_csv_export_invalid_path
FAILED pytest/test_error_handling.py::TestFileSystemErrorHandling::test_csv_export_missing_db
FAILED pytest/test_error_handling.py::TestErrorHandlingEdgeCases::test_nested_error_contexts
FAILED pytest/test_integration.py::TestEndToEndWorkflow::test_complete_analysis_pipeline
FAILED pytest/test_integration.py::TestEndToEndWorkflow::test_database_integration
FAILED pytest/test_integration.py::TestEndToEndWorkflow::test_config_integration
FAILED pytest/test_integration.py::TestDataFlow::test_state_persistence - wla...
FAILED pytest/test_integration.py::TestLargeDataset::test_large_dataset_processing
FAILED pytest/test_integration.py::TestErrorRecovery::test_malformed_event_handling
FAILED pytest/test_integration.py::TestMemoryManagement::test_memory_usage_large_state
FAILED pytest/test_integration.py::TestMemoryManagement::test_state_pruning_memory_release
FAILED pytest/test_performance.py::TestAnalysisPerformance::test_clustering_performance
FAILED pytest/test_performance.py::TestAnalysisPerformance::test_inference_performance
FAILED pytest/test_performance.py::TestMemoryPerformance::test_memory_usage_large_state
FAILED pytest/test_performance.py::TestMemoryPerformance::test_memory_cleanup_after_pruning
FAILED pytest/test_performance.py::TestDatabasePerformance::test_database_write_performance
FAILED pytest/test_performance.py::TestDatabasePerformance::test_database_read_performance
FAILED pytest/test_performance.py::TestScalabilityPerformance::test_scalability_with_dataset_size
FAILED pytest/test_presentation.py::TestCLIModule::test_print_client_cluster_results
FAILED pytest/test_presentation.py::TestCLIModule::test_print_ap_cluster_results
FAILED pytest/test_presentation.py::TestCLIEdgeCases::test_print_client_cluster_results_empty_data
FAILED pytest/test_presentation.py::TestPerformance::test_large_dataset_handling
FAILED pytest/test_storage.py::TestClientState::test_client_state_update_from_event
FAILED pytest/test_storage.py::TestAPState::test_ap_state_update_from_beacon
FAILED pytest/test_storage.py::TestWifiAnalysisState::test_state_pruning - As...
FAILED pytest/test_storage.py::TestWifiAnalysisState::test_state_ssid_mapping
FAILED pytest/test_storage.py::TestDatabaseModule::test_fetch_events - Attrib...
FAILED pytest/test_storage.py::TestDatabaseModule::test_add_label - Assertion...
FAILED pytest/test_utils.py::TestOUIFunctions::test_lookup_vendor_apple_mac
FAILED pytest/test_utils.py::TestOUIFunctions::test_lookup_vendor_unknown_mac
FAILED pytest/test_utils.py::TestIEParsing::test_parse_ies_vendor_specific - ...
FAILED pytest/test_utils.py::TestIEParsing::test_parse_ies_ht_capabilities - ...
FAILED pytest/test_utils.py::TestUtilityFunctions::test_is_local_admin_mac - ...
FAILED pytest/test_utils.py::TestUtilityFunctions::test_is_valid_bssid - Asse...
FAILED pytest/test_utils.py::TestUtilityFunctions::test_ie_fingerprint_hash
FAILED pytest/test_utils.py::TestUtilityFunctions::test_ie_fingerprint_hash_empty
FAILED pytest/test_utils.py::TestConfigFunctions::test_load_config_default - ...
FAILED pytest/test_utils.py::TestConfigFunctions::test_load_config_specific_profile
FAILED pytest/test_utils.py::TestConfigFunctions::test_load_config_missing_file
FAILED pytest/test_utils.py::TestEdgeCases::test_ie_fingerprint_hash_unicode
FAILED pytest/test_utils.py::TestEdgeCases::test_config_loading_with_invalid_yaml
FAILED tests/integration/test_end_to_end.py::TestEndToEndWorkflow::test_complete_wifi_analysis_workflow
FAILED tests/integration/test_end_to_end.py::TestEndToEndWorkflow::test_plugin_integration_workflow
FAILED tests/integration/test_end_to_end.py::TestEndToEndWorkflow::test_data_pipeline_with_file_io
FAILED tests/integration/test_end_to_end.py::TestEndToEndWorkflow::test_error_handling_and_recovery
FAILED tests/integration/test_end_to_end.py::TestEndToEndWorkflow::test_performance_under_load
FAILED tests/integration/test_end_to_end.py::TestEndToEndWorkflow::test_concurrent_processing
FAILED tests/performance/test_benchmarks.py::TestClusteringBenchmarks::test_kmeans_performance
FAILED tests/performance/test_benchmarks.py::TestClusteringBenchmarks::test_dbscan_performance
FAILED tests/performance/test_benchmarks.py::TestClusteringBenchmarks::test_hierarchical_performance
FAILED tests/performance/test_benchmarks.py::TestClusteringBenchmarks::test_clustering_scalability
FAILED tests/performance/test_benchmarks.py::TestDataProcessingBenchmarks::test_data_processing_performance
FAILED tests/performance/test_benchmarks.py::TestDataProcessingBenchmarks::test_feature_extraction_performance
FAILED tests/performance/test_benchmarks.py::TestDataProcessingBenchmarks::test_feature_scaling_performance
FAILED tests/performance/test_benchmarks.py::TestClassificationBenchmarks::test_random_forest_performance
FAILED tests/performance/test_benchmarks.py::TestClassificationBenchmarks::test_svm_performance
FAILED tests/performance/test_benchmarks.py::TestMemoryBenchmarks::test_memory_usage_clustering
FAILED tests/performance/test_benchmarks.py::TestMemoryBenchmarks::test_memory_usage_large_dataset
FAILED tests/performance/test_benchmarks.py::TestConcurrentBenchmarks::test_parallel_processing_performance
FAILED tests/performance/test_benchmarks.py::TestIOBenchmarks::test_file_io_performance
FAILED tests/performance/test_benchmarks.py::TestIOBenchmarks::test_csv_io_performance
FAILED tests/performance/test_memory_profiling.py::TestMemoryUsage::test_memory_usage_clustering
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! KeyboardInterrupt !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
/home/pi/hacking/.venv/lib/python3.11/site-packages/sklearn/tree/_classes.py:472: KeyboardInterrupt
(to show a full traceback on KeyboardInterrupt use --full-trace)
========== 114 failed, 186 passed, 149 warnings in 765.66s (0:12:45) ===========
============================= test session starts ==============================
platform linux -- Python 3.11.9, pytest-8.2.0, pluggy-1.6.0
benchmark: 5.1.0 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)
rootdir: /home/pi/hacking
configfile: pytest.ini
plugins: xdist-3.8.0, hypothesis-6.142.1, cov-7.0.0, mock-3.12.0, html-4.1.1, benchmark-5.1.0, Faker-37.11.0, metadata-3.1.1, json-report-1.5.0
collected 360 items

plugins/clustering_advanced/tests/test_clustering_advanced.py .......... [  2%]
.....                                                                    [  4%]
plugins/ensemble_models/tests/test_ensemble_models.py .....Argument expected for the -m option
usage: python3 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
============================= test session starts ==============================
platform linux -- Python 3.11.9, pytest-8.2.0, pluggy-1.6.0
benchmark: 5.1.0 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)
rootdir: /home/pi/hacking
configfile: pytest.ini
plugins: xdist-3.8.0, hypothesis-6.142.1, cov-7.0.0, mock-3.12.0, html-4.1.1, benchmark-5.1.0, Faker-37.11.0, metadata-3.1.1, json-report-1.5.0
collected 360 items

plugins/clustering_advanced/tests/test_clustering_advanced.py .......... [  2%]
.....                                                                    [  4%]
plugins/ensemble_models/tests/test_ensemble_models.py ........F.         [  6%]
plugins/example_plugin/tests/test_example_plugin.py ..                   [  7%]
plugins/reinforcement_learning/tests/test_reinforcement_learning.py .... [  8%]
.F......FF....                                                           [ 12%]
plugins/sankey/tests/test_sankey.py ......                               [ 14%]
plugins/umap_plot/tests/test_umap_plot.py ........                       [ 16%]
pytest/test_analysis.py ........F.FF...F...FF..F.F                       [ 23%]
pytest/test_app.py ..F...FFF..                                           [ 26%]
pytest/test_capture.py .FF..F....F......F.F.                             [ 32%]
pytest/test_controllers.py .FF..F...FFFFFFFFFF..FF.F                     [ 39%]
pytest/test_error_handling.py ......................F..FFFFFFF..F...     [ 50%]
pytest/test_integration.py FFF.FF..F..FF                                 [ 53%]
pytest/test_performance.py ....FFFFFF.F                                  [ 56%]
pytest/test_presentation.py FF...........F....F.                         [ 62%]
pytest/test_storage.py ......F..F....FF..FF...                           [ 68%]
pytest/test_utils.py F.F......FF..FFFF.FFF.....F.F                       [ 76%]
tests/integration/test_end_to_end.py FFFFFF                              [ 78%]
tests/performance/test_benchmarks.py FFFFFFFFFFFFFF                      [ 82%]
tests/performance/test_memory_profiling.py ..F...F.....                  [ 85%]
tests/unit/test_data_processing.py ................F.....                [ 91%]
tests/unit/test_ml_models.py .F..FFFFF.......F..FFFFFFFFFF               [100%]

=================================== FAILURES ===================================
_______ TestEnsembleModelsPlugin.test_performance_visualization_creation _______

self = <MagicMock name='make_subplots' id='547791909392'>

    def assert_called_once(self):
        """assert that the mock was called only once.
        """
        if not self.call_count == 1:
            msg = ("Expected '%s' to have been called once. Called %s times.%s"
                   % (self._mock_name or 'mock',
                      self.call_count,
                      self._calls_repr()))
>           raise AssertionError(msg)
E           AssertionError: Expected 'make_subplots' to have been called once. Called 0 times.

../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:918: AssertionError

During handling of the above exception, another exception occurred:

self = <plugins.ensemble_models.tests.test_ensemble_models.TestEnsembleModelsPlugin object at 0x7f8ab64910>
plugin = <plugins.ensemble_models.plugin.Plugin object at 0x7f6028a7d0>
temp_outdir = PosixPath('/tmp/pytest-of-pi/pytest-3/test_performance_visualization0/output')

    def test_performance_visualization_creation(self, plugin, temp_outdir):
        """Test Erstellung der Performance-Visualisierung."""
        temp_outdir.mkdir(exist_ok=True)
    
        # Mock Performance-Metriken
        from plugins.ensemble_models.plugin import ModelPerformance
        performance_metrics = [
            ModelPerformance("Model1", 0.8, 0.75, 0.8, 0.77, 0.78, 0.02, 1.0, 0.1),
            ModelPerformance("Model2", 0.85, 0.82, 0.85, 0.83, 0.84, 0.01, 1.5, 0.15),
        ]
    
        with patch('plotly.graph_objects') as mock_go:
            with patch('plotly.subplots.make_subplots') as mock_subplots:
                mock_fig = MagicMock()
                mock_subplots.return_value = mock_fig
    
                plugin._create_performance_visualization(performance_metrics, temp_outdir)
    
                # Überprüfe, dass Plotly-Funktionen aufgerufen wurden
>               mock_subplots.assert_called_once()
E               AssertionError: Expected 'make_subplots' to have been called once. Called 0 times.

plugins/ensemble_models/tests/test_ensemble_models.py:257: AssertionError
_________ TestReinforcementLearningPlugin.test_environment_observation _________

self = <plugins.reinforcement_learning.tests.test_reinforcement_learning.TestReinforcementLearningPlugin object at 0x7f8ab90cd0>
plugin = <plugins.reinforcement_learning.plugin.Plugin object at 0x7f604cf650>
mock_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f604cd950>
mock_events = [{'client': 'aa:bb:cc:dd:ee:00', 'ts': 1000.0, 'type': 'probe_req'}, {'client': 'aa:bb:cc:dd:ee:01', 'ts': 1001.0, 'type': 'probe_req'}]

    def test_environment_observation(self, plugin, mock_state, mock_events):
        """Test Environment Observation."""
        env = plugin._WiFiScanningEnvironment(mock_state, mock_events)
        obs = env._get_observation()
    
        assert len(obs) == 10
        assert all(0 <= val <= 1 for val in obs)  # Normalisierte Werte
>       assert obs[0] == 1.0 / 48.0  # current_channel normalisiert
E       assert 0.020833334 == (1.0 / 48.0)

plugins/reinforcement_learning/tests/test_reinforcement_learning.py:141: AssertionError
_____ TestReinforcementLearningPlugin.test_plugin_run_with_sufficient_data _____

self = <MagicMock name='dump' id='547075509264'>

    def assert_called(self):
        """assert that the mock was called at least once
        """
        if self.call_count == 0:
            msg = ("Expected '%s' to have been called." %
                   (self._mock_name or 'mock'))
>           raise AssertionError(msg)
E           AssertionError: Expected 'dump' to have been called.

../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:908: AssertionError

During handling of the above exception, another exception occurred:

self = <plugins.reinforcement_learning.tests.test_reinforcement_learning.TestReinforcementLearningPlugin object at 0x7f8aba1050>
plugin = <plugins.reinforcement_learning.plugin.Plugin object at 0x7f60534710>
mock_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f605364d0>
mock_events = [{'client': 'aa:bb:cc:dd:ee:00', 'ts': 1000.0, 'type': 'probe_req'}, {'client': 'aa:bb:cc:dd:ee:01', 'ts': 1001.0, 'type': 'probe_req'}]
mock_console = <MagicMock id='547075520016'>
temp_outdir = PosixPath('/tmp/pytest-of-pi/pytest-3/test_plugin_run_with_sufficien2/output')

    def test_plugin_run_with_sufficient_data(self, plugin, mock_state, mock_events, mock_console, temp_outdir):
        """Test Plugin-Ausführung mit ausreichenden Daten."""
        temp_outdir.mkdir(exist_ok=True)
    
        with patch('joblib.dump') as mock_dump:
            with patch('builtins.open', create=True) as mock_open:
                plugin.run(mock_state, mock_events, mock_console, temp_outdir)
    
        # Überprüfe, dass Console-Ausgaben gemacht wurden
        assert mock_console.print.called
    
        # Überprüfe, dass Ergebnisse gespeichert wurden
>       mock_dump.assert_called()
E       AssertionError: Expected 'dump' to have been called.

plugins/reinforcement_learning/tests/test_reinforcement_learning.py:260: AssertionError
------------------------------ Captured log call -------------------------------
ERROR    plugins.reinforcement_learning.plugin:plugin.py:165 Fehler bei der RL-Optimierung: 'NoneType' object has no attribute 'shape'
Traceback (most recent call last):
  File "/home/pi/hacking/plugins/reinforcement_learning/plugin.py", line 94, in run
    raise ImportError("PyTorch nicht verfügbar")
ImportError: PyTorch nicht verfügbar

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/pi/hacking/plugins/reinforcement_learning/plugin.py", line 97, in run
    state_size=env.observation_space.shape[0],
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
_______ TestReinforcementLearningPlugin.test_plugin_run_without_pytorch ________

self = <plugins.reinforcement_learning.tests.test_reinforcement_learning.TestReinforcementLearningPlugin object at 0x7f8aba1710>
plugin = <plugins.reinforcement_learning.plugin.Plugin object at 0x7f604014d0>
mock_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f60400c90>
mock_events = [{'client': 'aa:bb:cc:dd:ee:00', 'ts': 1000.0, 'type': 'probe_req'}, {'client': 'aa:bb:cc:dd:ee:01', 'ts': 1001.0, 'type': 'probe_req'}]
mock_console = <MagicMock id='547075667024'>
temp_outdir = PosixPath('/tmp/pytest-of-pi/pytest-3/test_plugin_run_without_pytorc0/output')

    def test_plugin_run_without_pytorch(self, plugin, mock_state, mock_events, mock_console, temp_outdir):
        """Test Plugin-Ausführung ohne PyTorch (Fallback zu Simple RL)."""
        temp_outdir.mkdir(exist_ok=True)
    
        with patch('plugins.reinforcement_learning.plugin.torch', None):
            with patch('joblib.dump') as mock_dump:
                with patch('builtins.open', create=True) as mock_open:
                    plugin.run(mock_state, mock_events, mock_console, temp_outdir)
    
        # Überprüfe, dass Console-Ausgaben gemacht wurden
        assert mock_console.print.called
    
        # Überprüfe, dass Simple RL Agent verwendet wurde
        console_calls = [str(call) for call in mock_console.print.call_args_list]
>       assert any("Q-Learning" in call for call in console_calls)
E       assert False
E        +  where False = any(<generator object TestReinforcementLearningPlugin.test_plugin_run_without_pytorch.<locals>.<genexpr> at 0x7f8aecb6b0>)

plugins/reinforcement_learning/tests/test_reinforcement_learning.py:277: AssertionError
------------------------------ Captured log call -------------------------------
ERROR    plugins.reinforcement_learning.plugin:plugin.py:165 Fehler bei der RL-Optimierung: 'NoneType' object has no attribute 'shape'
Traceback (most recent call last):
  File "/home/pi/hacking/plugins/reinforcement_learning/plugin.py", line 94, in run
    raise ImportError("PyTorch nicht verfügbar")
ImportError: PyTorch nicht verfügbar

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/pi/hacking/plugins/reinforcement_learning/plugin.py", line 97, in run
    state_size=env.observation_space.shape[0],
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
___________________ TestAnalysisLogic.test_profile_clusters ____________________

self = <test_analysis.TestAnalysisLogic object at 0x7f68d67cd0>

    def test_profile_clusters(self):
        """Test Cluster-Profilierung."""
        feature_data = {
            'original_macs': ['mac1', 'mac2', 'mac3'],
            'feature1': [10, 20, 15],
            'feature2': [1, 2, 1.5]
        }
        feature_df = pd.DataFrame(feature_data)
    
        cluster_data = {
            'original_macs': ['mac1', 'mac2', 'mac3'],
            'cluster': [0, 0, 1]
        }
        clustered_df = pd.DataFrame(cluster_data)
    
>       profiles = analysis.profile_clusters(feature_df, clustered_df)

pytest/test_analysis.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/analysis/logic.py:666: in profile_clusters
    profiles["details"] = full_df.set_index("mac").to_dict(orient="index")
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self =   original_macs  feature1  feature2  cluster
0          mac1        10       1.0        0
1          mac2        20       2.0        0
2          mac3        15       1.5        1
keys = ['mac']

    def set_index(
        self,
        keys,
        *,
        drop: bool = True,
        append: bool = False,
        inplace: bool = False,
        verify_integrity: bool = False,
    ) -> DataFrame | None:
        """
        Set the DataFrame index using existing columns.
    
        Set the DataFrame index (row labels) using one or more existing
        columns or arrays (of the correct length). The index can replace the
        existing index or expand on it.
    
        Parameters
        ----------
        keys : label or array-like or list of labels/arrays
            This parameter can be either a single column key, a single array of
            the same length as the calling DataFrame, or a list containing an
            arbitrary combination of column keys and arrays. Here, "array"
            encompasses :class:`Series`, :class:`Index`, ``np.ndarray``, and
            instances of :class:`~collections.abc.Iterator`.
        drop : bool, default True
            Delete columns to be used as the new index.
        append : bool, default False
            Whether to append columns to existing index.
        inplace : bool, default False
            Whether to modify the DataFrame rather than creating a new one.
        verify_integrity : bool, default False
            Check the new index for duplicates. Otherwise defer the check until
            necessary. Setting to False will improve the performance of this
            method.
    
        Returns
        -------
        DataFrame or None
            Changed row labels or None if ``inplace=True``.
    
        See Also
        --------
        DataFrame.reset_index : Opposite of set_index.
        DataFrame.reindex : Change to new indices or expand indices.
        DataFrame.reindex_like : Change to same indices as other DataFrame.
    
        Examples
        --------
        >>> df = pd.DataFrame({'month': [1, 4, 7, 10],
        ...                    'year': [2012, 2014, 2013, 2014],
        ...                    'sale': [55, 40, 84, 31]})
        >>> df
           month  year  sale
        0      1  2012    55
        1      4  2014    40
        2      7  2013    84
        3     10  2014    31
    
        Set the index to become the 'month' column:
    
        >>> df.set_index('month')
               year  sale
        month
        1      2012    55
        4      2014    40
        7      2013    84
        10     2014    31
    
        Create a MultiIndex using columns 'year' and 'month':
    
        >>> df.set_index(['year', 'month'])
                    sale
        year  month
        2012  1     55
        2014  4     40
        2013  7     84
        2014  10    31
    
        Create a MultiIndex using an Index and a column:
    
        >>> df.set_index([pd.Index([1, 2, 3, 4]), 'year'])
                 month  sale
           year
        1  2012  1      55
        2  2014  4      40
        3  2013  7      84
        4  2014  10     31
    
        Create a MultiIndex using two Series:
    
        >>> s = pd.Series([1, 2, 3, 4])
        >>> df.set_index([s, s**2])
              month  year  sale
        1 1       1  2012    55
        2 4       4  2014    40
        3 9       7  2013    84
        4 16     10  2014    31
        """
        inplace = validate_bool_kwarg(inplace, "inplace")
        self._check_inplace_and_allows_duplicate_labels(inplace)
        if not isinstance(keys, list):
            keys = [keys]
    
        err_msg = (
            'The parameter "keys" may be a column key, one-dimensional '
            "array, or a list containing only valid column keys and "
            "one-dimensional arrays."
        )
    
        missing: list[Hashable] = []
        for col in keys:
            if isinstance(col, (Index, Series, np.ndarray, list, abc.Iterator)):
                # arrays are fine as long as they are one-dimensional
                # iterators get converted to list below
                if getattr(col, "ndim", 1) != 1:
                    raise ValueError(err_msg)
            else:
                # everything else gets tried as a key; see GH 24969
                try:
                    found = col in self.columns
                except TypeError as err:
                    raise TypeError(
                        f"{err_msg}. Received column of type {type(col)}"
                    ) from err
                else:
                    if not found:
                        missing.append(col)
    
        if missing:
>           raise KeyError(f"None of {missing} are in the columns")
E           KeyError: "None of ['mac'] are in the columns"

.venv/lib/python3.11/site-packages/pandas/core/frame.py:6106: KeyError
______________________ TestAnalysisLogic.test_cluster_aps ______________________

self = <test_analysis.TestAnalysisLogic object at 0x7f68d65450>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f8ae45150>

    def test_cluster_aps(self, populated_state):
        """Test AP-Clustering."""
>       clustered_df = analysis.cluster_aps(populated_state, n_clusters=2)

pytest/test_analysis.py:166: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/analysis/logic.py:736: in cluster_aps
    df["cluster"] = kmeans.fit_predict(X_scaled)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1064: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1456: in fit
    self._check_params_vs_input(X)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1396: in _check_params_vs_input
    super()._check_params_vs_input(X, default_n_init=10)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = KMeans(n_clusters=2, random_state=42)
X = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])
default_n_init = 10

    def _check_params_vs_input(self, X, default_n_init=None):
        # n_clusters
        if X.shape[0] < self.n_clusters:
>           raise ValueError(
                f"n_samples={X.shape[0]} should be >= n_clusters={self.n_clusters}."
            )
E           ValueError: n_samples=1 should be >= n_clusters=2.

.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:871: ValueError
__________________ TestAnalysisLogic.test_profile_ap_clusters __________________

self = Index(['bssid', 'ssid', 'vendor', 'cluster', 'supports_11k', 'supports_11v',
       'supports_11r'],
      dtype='object')
key = 'channel'

    def get_loc(self, key):
        """
        Get integer location, slice or boolean mask for requested label.
    
        Parameters
        ----------
        key : label
    
        Returns
        -------
        int if unique index, slice if monotonic index, else mask
    
        Examples
        --------
        >>> unique_index = pd.Index(list('abc'))
        >>> unique_index.get_loc('b')
        1
    
        >>> monotonic_index = pd.Index(list('abbc'))
        >>> monotonic_index.get_loc('b')
        slice(1, 3, None)
    
        >>> non_monotonic_index = pd.Index(list('abcb'))
        >>> non_monotonic_index.get_loc('b')
        array([False,  True, False,  True])
        """
        casted_key = self._maybe_cast_indexer(key)
        try:
>           return self._engine.get_loc(casted_key)

.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3802: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
index.pyx:153: in pandas._libs.index.IndexEngine.get_loc
    ???
index.pyx:182: in pandas._libs.index.IndexEngine.get_loc
    ???
pandas/_libs/hashtable_class_helper.pxi:7081: in pandas._libs.hashtable.PyObjectHashTable.get_item
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   KeyError: 'channel'

pandas/_libs/hashtable_class_helper.pxi:7089: KeyError

The above exception was the direct cause of the following exception:

self = <test_analysis.TestAnalysisLogic object at 0x7f68d70810>

    def test_profile_ap_clusters(self):
        """Test AP-Cluster-Profilierung."""
        cluster_data = {
            'bssid': ['ap1', 'ap2'],
            'ssid': ['SSID1', 'SSID2'],
            'vendor': ['Vendor1', 'Vendor2'],
            'cluster': [0, 1],
            'supports_11k': [True, False],
            'supports_11v': [True, False],
            'supports_11r': [False, True]
        }
        clustered_df = pd.DataFrame(cluster_data)
    
>       profiles = analysis.profile_ap_clusters(clustered_df)

pytest/test_analysis.py:187: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/analysis/logic.py:766: in profile_ap_clusters
    "channels": cluster_data["channel"].value_counts().to_dict(),
.venv/lib/python3.11/site-packages/pandas/core/frame.py:4090: in __getitem__
    indexer = self.columns.get_loc(key)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Index(['bssid', 'ssid', 'vendor', 'cluster', 'supports_11k', 'supports_11v',
       'supports_11r'],
      dtype='object')
key = 'channel'

    def get_loc(self, key):
        """
        Get integer location, slice or boolean mask for requested label.
    
        Parameters
        ----------
        key : label
    
        Returns
        -------
        int if unique index, slice if monotonic index, else mask
    
        Examples
        --------
        >>> unique_index = pd.Index(list('abc'))
        >>> unique_index.get_loc('b')
        1
    
        >>> monotonic_index = pd.Index(list('abbc'))
        >>> monotonic_index.get_loc('b')
        slice(1, 3, None)
    
        >>> non_monotonic_index = pd.Index(list('abcb'))
        >>> non_monotonic_index.get_loc('b')
        array([False,  True, False,  True])
        """
        casted_key = self._maybe_cast_indexer(key)
        try:
            return self._engine.get_loc(casted_key)
        except KeyError as err:
            if isinstance(casted_key, slice) or (
                isinstance(casted_key, abc.Iterable)
                and any(isinstance(x, slice) for x in casted_key)
            ):
                raise InvalidIndexError(key)
>           raise KeyError(key) from err
E           KeyError: 'channel'

.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3809: KeyError
________ TestDeviceProfiler.test_create_device_fingerprint_empty_state _________

self = <test_analysis.TestDeviceProfiler object at 0x7f68d71b10>

    def test_create_device_fingerprint_empty_state(self):
        """Test Fingerprint mit leerem ClientState."""
        empty_client = ClientState(mac="aa:bb:cc:dd:ee:ff")
        fingerprint = create_device_fingerprint(empty_client)
    
>       assert fingerprint == ""  # Sollte leer sein für leeren State
E       AssertionError: assert 'd41d8cd98f00...00998ecf8427e' == ''
E         
E         + d41d8cd98f00b204e9800998ecf8427e

pytest/test_analysis.py:251: AssertionError
___________________ TestGraphExport.test_build_export_graph ____________________

self = <test_analysis.TestGraphExport object at 0x7f68d73710>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f8b085a90>

    def test_build_export_graph(self, populated_state):
        """Test Graph-Aufbau für Export."""
        # Erstelle Test-Daten
        ap_data = {
            'bssid': ['08:96:d7:1a:21:1c'],
            'ssid': ['MyTestWLAN'],
            'vendor': ['TestVendor'],
            'cluster': [0],
            'channel': [6],
            'rssi_mean': [-50.0],
            'supports_11k': [False],
            'supports_11v': [False],
            'supports_11r': [False]
        }
        clustered_ap_df = pd.DataFrame(ap_data)
    
        aps_to_export = {'08:96:d7:1a:21:1c': populated_state.aps['08:96:d7:1a:21:1c']}
        clients_to_export = {}
    
        graph = analysis._build_export_graph(
            populated_state,
            clustered_ap_df,
            aps_to_export,
            clients_to_export,
            include_clients=False,
            clustered_client_df=None
        )
    
        assert graph is not None
        assert graph.number_of_nodes() > 0
>       assert 'start' in graph.graph
E       AssertionError: assert 'start' in {'mode': 'dynamic', 'timeformat': 'datetime'}
E        +  where {'mode': 'dynamic', 'timeformat': 'datetime'} = <networkx.classes.graph.Graph object at 0x7f8b0878d0>.graph

pytest/test_analysis.py:319: AssertionError
___________________ TestGraphExport.test_discover_attributes ___________________

self = <test_analysis.TestGraphExport object at 0x7f68d73d10>

    def test_discover_attributes(self):
        """Test Attribut-Entdeckung für GEXF."""
        import networkx as nx
    
        G = nx.Graph()
        G.add_node("node1", type="AP", activity=10, vendor="Test")
        G.add_edge("node1", "node2", weight=1.5, kind="Association")
    
        node_attrs, edge_attrs = analysis._discover_attributes(G)
    
        assert isinstance(node_attrs, dict)
        assert isinstance(edge_attrs, dict)
        assert 'type' in node_attrs
        assert 'activity' in node_attrs
>       assert 'weight' in edge_attrs
E       AssertionError: assert 'weight' in {}

pytest/test_analysis.py:336: AssertionError
______________ TestAnalysisEdgeCases.test_single_client_analysis _______________

self = <test_analysis.TestAnalysisEdgeCases object at 0x7f68d75450>

    def test_single_client_analysis(self):
        """Test Analyse mit nur einem Client."""
        state = WifiAnalysisState()
        client = ClientState(mac="aa:bb:cc:dd:ee:ff")
>       client.all_packet_ts = np.array([time.time(), time.time() + 1])
E       NameError: name 'time' is not defined

pytest/test_analysis.py:379: NameError
_____________ TestAnalysisEdgeCases.test_malformed_event_handling ______________

self = <test_analysis.TestAnalysisEdgeCases object at 0x7f68d76190>

    def test_malformed_event_handling(self):
        """Test Behandlung von fehlerhaften Events."""
        state = WifiAnalysisState()
    
        # Teste mit unvollständigem Event
>       malformed_event = {'ts': time.time(), 'type': 'beacon'}  # Fehlt bssid
E       NameError: name 'time' is not defined

pytest/test_analysis.py:406: NameError
________________ TestUtilsModule.test_intelligent_vendor_lookup ________________

self = <test_app.TestUtilsModule object at 0x7f68d80110>

    def test_intelligent_vendor_lookup(self):
>       assert "Apple" in utils.lookup_vendor("a8:51:ab:0c:b9:e9")
E       TypeError: argument of type 'NoneType' is not iterable

pytest/test_app.py:71: TypeError
_____________ TestAnalysisModule.test_features_for_client_behavior _____________

self = <test_app.TestAnalysisModule object at 0x7f68d81b50>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f8b085410>

    def test_features_for_client_behavior(self, populated_state):
        client = populated_state.clients['a8:51:ab:0c:b9:e9']
>       features = analysis.features_for_client_behavior(client)
E       AttributeError: module 'wlan_tool.analysis' has no attribute 'features_for_client_behavior'

pytest/test_app.py:108: AttributeError
_________________ TestAnalysisModule.test_cluster_clients_runs _________________

self = <test_app.TestAnalysisModule object at 0x7f68d82250>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f8aeee7d0>

    def test_cluster_clients_runs(self, populated_state):
>       clustered_df, feature_df = analysis.cluster_clients(populated_state, algo="kmeans", n_clusters=2)
E       AttributeError: module 'wlan_tool.analysis' has no attribute 'cluster_clients'

pytest/test_app.py:117: AttributeError
___________________ TestAnalysisModule.test_profile_clusters ___________________

self = <test_app.TestAnalysisModule object at 0x7f68d82850>

    def test_profile_clusters(self):
        feature_data = {'original_macs': ['mac1', 'mac2'], 'feature1': [10, 20], 'feature2': [1, 2]}
        feature_df = pd.DataFrame(feature_data)
        cluster_data = {'original_macs': ['mac1', 'mac2'], 'cluster': [0, 0]}
        clustered_df = pd.DataFrame(cluster_data)
>       profiles = analysis.profile_clusters(feature_df, clustered_df)
E       AttributeError: module 'wlan_tool.analysis' has no attribute 'profile_clusters'

pytest/test_app.py:128: AttributeError
_____________ TestPacketParsing.test_packet_to_event_probe_request _____________

self = <test_capture.TestPacketParsing object at 0x7f68d96550>

    def test_packet_to_event_probe_request(self):
        """Test Probe-Request-Paket zu Event-Konvertierung."""
        rt_layer = RadioTap(
            present="Flags+Channel+dBm_AntSignal",
            Flags="",
            ChannelFrequency=2412,
            dBm_AntSignal=-60
        )
        dot11_layer = Dot11(
            type=0, subtype=4,
            addr1='ff:ff:ff:ff:ff:ff',  # Broadcast
            addr2='aa:bb:cc:dd:ee:ff'   # Client
        )
        ssid_ie = Dot11Elt(
            ID=0,
            info=b'TestSSID'
        )
    
        pkt = rt_layer / dot11_layer / ssid_ie
        pkt.time = time.time()
    
        event = capture.packet_to_event(pkt)
    
        assert event is not None
        assert event['type'] == 'probe_req'
        assert event['client'] == 'aa:bb:cc:dd:ee:ff'
        assert event['rssi'] == -60
        # SSID wird als Hex-String gespeichert, dann dekodiert
>       assert 'TestSSID' in event['probes']
E       KeyError: 'probes'

pytest/test_capture.py:63: KeyError
______________ TestPacketParsing.test_packet_to_event_data_frame _______________

self = <test_capture.TestPacketParsing object at 0x7f68d96890>

    def test_packet_to_event_data_frame(self):
        """Test Data-Frame zu Event-Konvertierung."""
>       rt_layer = RadioTap(
            present="Flags+Channel+dBm_AntSignal+MCS_index",
            Flags="",
            ChannelFrequency=2412,
            dBm_AntSignal=-55,
            MCS_index=7
        )

pytest/test_capture.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.11/site-packages/scapy/base_classes.py:399: in __call__
    i.__init__(*args, **kargs)
.venv/lib/python3.11/site-packages/scapy/packet.py:178: in __init__
    self.get_field(fname).any2i(self, value)
.venv/lib/python3.11/site-packages/scapy/fields.py:3052: in any2i
    return self._fixup_val(super(FlagsField, self).any2i(pkt, x))
.venv/lib/python3.11/site-packages/scapy/fields.py:3048: in _fixup_val
    return FlagValue(x, self.names)
.venv/lib/python3.11/site-packages/scapy/fields.py:2835: in __init__
    self.value = self._fixvalue(value)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'FlagValue' object has no attribute 'value'") raised in repr()] FlagValue object at 0x7f8af3b1c0>
value = ['Flags', 'Channel', 'dBm_AntSignal', 'MCS_index']

    def _fixvalue(self, value):
        # type: (Any) -> int
        if not value:
            return 0
        if isinstance(value, six.string_types):
            value = value.split('+') if self.multi else list(value)
        if isinstance(value, list):
            y = 0
            for i in value:
>               y |= 1 << self.names.index(i)
E               ValueError: 'MCS_index' is not in list

.venv/lib/python3.11/site-packages/scapy/fields.py:2827: ValueError
_______________ TestPacketParsing.test_packet_to_event_with_dhcp _______________

self = <test_capture.TestPacketParsing object at 0x7f68d975d0>

    def test_packet_to_event_with_dhcp(self):
        """Test Paket mit DHCP-Informationen."""
        from scapy.layers.dhcp import DHCP, BOOTP
    
        rt_layer = RadioTap(
            present="Flags+Channel+dBm_AntSignal",
            Flags="",
            ChannelFrequency=2412,
            dBm_AntSignal=-50
        )
        dot11_layer = Dot11(
            type=2, subtype=0,
            addr1='aa:bb:cc:dd:ee:ff',
            addr2='11:22:33:44:55:66'
        )
        bootp_layer = BOOTP(chaddr=b'\x11\x22\x33\x44\x55\x66')
        dhcp_layer = DHCP(options=[(53, 3), (12, b'TestHostname')])  # DHCP Request mit Hostname
    
        pkt = rt_layer / dot11_layer / bootp_layer / dhcp_layer
        pkt.time = time.time()
    
        event = capture.packet_to_event(pkt)
    
        assert event is not None
        assert event['type'] == 'data'
>       assert event['hostname'] == 'TestHostname'
E       KeyError: 'hostname'

pytest/test_capture.py:155: KeyError
____________ TestChannelHopper.test_channel_hopper_command_failure _____________

self = <test_capture.TestChannelHopper object at 0x7f68d99690>
mock_run = <MagicMock name='run' id='547087267280'>

    @patch('subprocess.run')
    def test_channel_hopper_command_failure(self, mock_run):
        """Test ChannelHopper bei Kommando-Fehlern."""
>       mock_run.side_effect = subprocess.CalledProcessError(1, "iw")
E       NameError: name 'subprocess' is not defined

pytest/test_capture.py:235: NameError
______________________ TestIEExtraction.test_extract_seq _______________________

self = <test_capture.TestIEExtraction object at 0x7f68da46d0>

    def test_extract_seq(self):
        """Test Sequenznummer-Extraktion."""
        dot11 = Dot11(SC=0x1234)  # SC = 0x1234, >> 4 = 0x123
    
        seq = capture._extract_seq(dot11)
        assert seq == 0x123
    
        # Test mit None
        seq = capture._extract_seq(None)
>       assert seq is None
E       assert 0 is None

pytest/test_capture.py:379: AssertionError
____________ TestErrorHandling.test_packet_to_event_encoding_error _____________

self = <test_capture.TestErrorHandling object at 0x7f68da54d0>

    def test_packet_to_event_encoding_error(self):
        """Test mit Encoding-Fehlern."""
        rt_layer = RadioTap()
        dot11_layer = Dot11(type=0, subtype=8, addr3='aa:bb:cc:dd:ee:ff')
        beacon_layer = Dot11Beacon()
        # Erstelle IE mit ungültigem UTF-8
        ssid_ie = Dot11Elt(ID=0, info=b'\xff\xfe\xfd')
    
        pkt = rt_layer / dot11_layer / beacon_layer / ssid_ie
        pkt.time = time.time()
    
        # Sollte nicht crashen
        event = capture.packet_to_event(pkt)
        if event is not None:
>           assert event['ssid'] == "<binary>"  # Sollte als binary markiert werden
E           AssertionError: assert '<hidden>' == '<binary>'
E             
E             - <binary>
E             + <hidden>

pytest/test_capture.py:412: AssertionError
____________ TestCaptureController.test_select_interface_automatic _____________

self = <test_controllers.TestCaptureController object at 0x7f68da7a90>
mock_find_interfaces = <MagicMock name='find_wlan_interfaces' id='547010901328'>
mock_console = <MagicMock id='547010645648'>

    @patch('wlan_tool.pre_run_checks.find_wlan_interfaces')
    def test_select_interface_automatic(self, mock_find_interfaces, mock_console):
        """Test automatische Interface-Auswahl."""
        mock_find_interfaces.return_value = ["wlan0", "wlan1"]
    
        args = MagicMock()
        args.iface = None
        config_data = {}
    
        controller = CaptureController(args, config_data, mock_console)
    
        with patch('rich.prompt.Prompt.ask', return_value="wlan0"):
>           iface = controller._select_interface()

pytest/test_controllers.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.controllers.CaptureController object at 0x7f5c62c910>

    def _select_interface(self) -> Optional[str]:
        """Wählt das zu verwendende physische WLAN-Interface aus."""
        iface = self.args.iface
        if not iface:
            self.console.print(
                "[bold cyan]Kein Interface angegeben. Suche nach geeigneten WLAN-Interfaces...[/bold cyan]"
            )
>           suitable_ifaces = pre_run_checks.find_wlan_interfaces()
E           NameError: name 'pre_run_checks' is not defined

wlan_tool/controllers.py:124: NameError
__________ TestCaptureController.test_select_interface_no_interfaces ___________

self = <test_controllers.TestCaptureController object at 0x7f68dac0d0>
mock_find_interfaces = <MagicMock name='find_wlan_interfaces' id='547010892432'>
mock_console = <MagicMock id='547010921040'>

    @patch('wlan_tool.pre_run_checks.find_wlan_interfaces')
    def test_select_interface_no_interfaces(self, mock_find_interfaces, mock_console):
        """Test Interface-Auswahl ohne verfügbare Interfaces."""
        mock_find_interfaces.return_value = []
    
        args = MagicMock()
        args.iface = None
        config_data = {}
    
        controller = CaptureController(args, config_data, mock_console)
    
>       iface = controller._select_interface()

pytest/test_controllers.py:57: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.controllers.CaptureController object at 0x7f607de350>

    def _select_interface(self) -> Optional[str]:
        """Wählt das zu verwendende physische WLAN-Interface aus."""
        iface = self.args.iface
        if not iface:
            self.console.print(
                "[bold cyan]Kein Interface angegeben. Suche nach geeigneten WLAN-Interfaces...[/bold cyan]"
            )
>           suitable_ifaces = pre_run_checks.find_wlan_interfaces()
E           NameError: name 'pre_run_checks' is not defined

wlan_tool/controllers.py:124: NameError
____________ TestCaptureController.test_setup_monitor_mode_failure _____________

self = <test_controllers.TestCaptureController object at 0x7f68dad390>
mock_run = <MagicMock name='run' id='547010701392'>
mock_console = <MagicMock id='547790520592'>

    @patch('subprocess.run')
    def test_setup_monitor_mode_failure(self, mock_run, mock_console):
        """Test Monitor-Mode-Setup (Fehler)."""
>       mock_run.side_effect = subprocess.CalledProcessError(1, "airmon-ng")
E       NameError: name 'subprocess' is not defined

pytest/test_controllers.py:89: NameError
________ TestAnalysisController.test_analysis_controller_initialization ________

self = <test_controllers.TestAnalysisController object at 0x7f68daedd0>
mock_console = <MagicMock id='547009600848'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f5c4eaf90>

    def test_analysis_controller_initialization(self, mock_console, populated_state):
        """Test AnalysisController-Initialisierung."""
        args = MagicMock()
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
        assert controller.args == args
        assert controller.config_data == config_data
        assert controller.console == mock_console
        assert controller.plugins == plugins
>       assert controller.state == populated_state
E       AttributeError: 'AnalysisController' object has no attribute 'state'

pytest/test_controllers.py:201: AttributeError
__________________ TestAnalysisController.test_run_inference ___________________

self = <test_controllers.TestAnalysisController object at 0x7f68da6fd0>
mock_score = <MagicMock name='score_pairs_with_recency_and_matching' id='547009748368'>
mock_console = <MagicMock id='547009609040'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f5c527e50>

    @patch('wlan_tool.analysis.logic.score_pairs_with_recency_and_matching')
    def test_run_inference(self, mock_score, mock_console, populated_state):
        """Test Inferenz-Ausführung."""
        mock_score.return_value = []
    
        args = MagicMock()
        args.infer = True
        args.model = None
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       controller.run_inference()
E       AttributeError: 'AnalysisController' object has no attribute 'run_inference'

pytest/test_controllers.py:218: AttributeError
______________ TestAnalysisController.test_run_client_clustering _______________

self = <test_controllers.TestAnalysisController object at 0x7f68dad190>
mock_cluster = <MagicMock name='cluster_clients' id='547009779792'>
mock_console = <MagicMock id='547009592656'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f5c52d590>

    @patch('wlan_tool.analysis.logic.cluster_clients')
    def test_run_client_clustering(self, mock_cluster, mock_console, populated_state):
        """Test Client-Clustering."""
        mock_cluster.return_value = (None, None)
    
        args = MagicMock()
        args.cluster_clients = 2
        args.cluster_algo = "kmeans"
        args.no_mac_correlation = False
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       controller.run_client_clustering()
E       AttributeError: 'AnalysisController' object has no attribute 'run_client_clustering'

pytest/test_controllers.py:237: AttributeError
________________ TestAnalysisController.test_run_ap_clustering _________________

self = <test_controllers.TestAnalysisController object at 0x7f68daf550>
mock_cluster = <MagicMock name='cluster_aps' id='547010673104'>
mock_console = <MagicMock id='547009719696'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f5c5279d0>

    @patch('wlan_tool.analysis.logic.cluster_aps')
    def test_run_ap_clustering(self, mock_cluster, mock_console, populated_state):
        """Test AP-Clustering."""
        mock_cluster.return_value = None
    
        args = MagicMock()
        args.cluster_aps = 2
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       controller.run_ap_clustering()
E       AttributeError: 'AnalysisController' object has no attribute 'run_ap_clustering'

pytest/test_controllers.py:254: AttributeError
_________________ TestAnalysisController.test_run_graph_export _________________

self = <test_controllers.TestAnalysisController object at 0x7f68daf8d0>
mock_export = <MagicMock name='export_ap_graph' id='547009046480'>
mock_console = <MagicMock id='547009279248'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f5c47a8d0>

    @patch('wlan_tool.analysis.logic.export_ap_graph')
    def test_run_graph_export(self, mock_export, mock_console, populated_state):
        """Test Graph-Export."""
        mock_export.return_value = True
    
        args = MagicMock()
        args.export_graph = "/tmp/test.gexf"
        args.cluster_aps = 2
        args.graph_include_clients = False
        args.graph_min_activity = 0
        args.graph_min_duration = 0
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       with patch.object(controller, 'run_ap_clustering', return_value=None):

pytest/test_controllers.py:275: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f5c4f2a90>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <wlan_tool.controllers.AnalysisController object at 0x7f5c479e50> does not have the attribute 'run_ap_clustering'

../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1419: AttributeError
_________________ TestAnalysisController.test_run_labeling_ui __________________

self = <test_controllers.TestAnalysisController object at 0x7f68dafc50>
mock_label_ui = <MagicMock name='interactive_label_ui' id='547008865552'>
mock_console = <MagicMock id='547009781648'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f5c44c350>

    @patch('wlan_tool.presentation.cli.interactive_label_ui')
    def test_run_labeling_ui(self, mock_label_ui, mock_console, populated_state):
        """Test Labeling-UI."""
        args = MagicMock()
        args.label_ui = True
        args.db = "test.db"
        args.label_db = "labels.db"
        args.model = "model.pkl"
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       controller.run_labeling_ui()
E       AttributeError: 'AnalysisController' object has no attribute 'run_labeling_ui'

pytest/test_controllers.py:294: AttributeError
______________ TestAnalysisController.test_run_client_labeling_ui ______________

self = <test_controllers.TestAnalysisController object at 0x7f68daffd0>
mock_client_label_ui = <MagicMock name='interactive_client_label_ui' id='547009152784'>
mock_console = <MagicMock id='547008873104'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f5c497510>

    @patch('wlan_tool.presentation.cli.interactive_client_label_ui')
    def test_run_client_labeling_ui(self, mock_client_label_ui, mock_console, populated_state):
        """Test Client-Labeling-UI."""
        args = MagicMock()
        args.label_clients = True
        args.label_db = "labels.db"
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       controller.run_client_labeling_ui()
E       AttributeError: 'AnalysisController' object has no attribute 'run_client_labeling_ui'

pytest/test_controllers.py:310: AttributeError
_______________ TestAnalysisController.test_run_mac_correlation ________________

self = <test_controllers.TestAnalysisController object at 0x7f68bb8550>
mock_correlate = <MagicMock name='correlate_devices_by_fingerprint' id='547010839120'>
mock_console = <MagicMock id='547009108432'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f5c631710>

    @patch('wlan_tool.analysis.device_profiler.correlate_devices_by_fingerprint')
    def test_run_mac_correlation(self, mock_correlate, mock_console, populated_state):
        """Test MAC-Korrelation."""
        mock_correlate.return_value = {}
    
        args = MagicMock()
        args.correlate_macs = True
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       controller.run_mac_correlation()
E       AttributeError: 'AnalysisController' object has no attribute 'run_mac_correlation'

pytest/test_controllers.py:327: AttributeError
_____________ TestAnalysisController.test_run_analysis_no_actions ______________

self = <test_controllers.TestAnalysisController object at 0x7f68bb8bd0>
mock_console = <MagicMock id='547009630544'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f5c486ad0>

    def test_run_analysis_no_actions(self, mock_console, populated_state):
        """Test Analyse ohne Aktionen."""
        args = MagicMock()
        args.infer = False
        args.cluster_clients = None
        args.cluster_aps = None
        args.export_graph = None
        args.label_ui = False
        args.label_clients = False
        args.correlate_macs = False
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
        # Sollte nicht crashen
>       controller.run_analysis()

pytest/test_controllers.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/controllers.py:339: in run_analysis
    self._run_profiling()  # Benötigt state, den es jetzt als self.state hat
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.controllers.AnalysisController object at 0x7f5c484ad0>

    def _run_profiling(self):
        self.console.print(
            "\n[bold cyan]Starte automatisches Geräte-Profiling...[/bold cyan]"
        )
        device_map = {}
    
        # --- NEU: Versuch 1: TR-064 (FRITZ!Box) ---
        self.console.print(
            "[cyan]Versuch 1: Identifizierung über FRITZ!Box TR-064...[/cyan]"
        )
        # Passwort aus Argumenten oder interaktiv abfragen
        fritz_password = self.args.fritzbox_password
        if FritzHosts and not fritz_password:
            if (
                self.console.input(
                    "Haben Sie ein Passwort für Ihre FRITZ!Box gesetzt? (y/n): "
                ).lower()
                == "y"
            ):
                fritz_password = self.console.input(
                    "Bitte FRITZ!Box-Passwort eingeben: ", password=True
                )
    
        device_map = (
>           device_profiler.get_devices_from_fritzbox_tr064(password=fritz_password)
            or {}
        )
E       NameError: name 'device_profiler' is not defined

wlan_tool/controllers.py:487: NameError
__________ TestAnalysisController.test_run_analysis_multiple_actions ___________

self = <test_controllers.TestAnalysisController object at 0x7f68bb9250>
mock_console = <MagicMock id='547009446992'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f5c077c50>

    def test_run_analysis_multiple_actions(self, mock_console, populated_state):
        """Test Analyse mit mehreren Aktionen."""
        args = MagicMock()
        args.infer = True
        args.cluster_clients = 2
        args.cluster_aps = 2
        args.export_graph = "/tmp/test.gexf"
        args.label_ui = False
        args.label_clients = False
        args.correlate_macs = False
        args.model = None
        args.cluster_algo = "kmeans"
        args.no_mac_correlation = False
        args.graph_include_clients = False
        args.graph_min_activity = 0
        args.graph_min_duration = 0
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       with patch.object(controller, 'run_inference'):

pytest/test_controllers.py:372: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f5c45f590>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <wlan_tool.controllers.AnalysisController object at 0x7f5c45f710> does not have the attribute 'run_inference'

../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1419: AttributeError
_________ TestControllerEdgeCases.test_analysis_controller_empty_state _________

self = <test_controllers.TestControllerEdgeCases object at 0x7f68bbaad0>
mock_console = <MagicMock id='547005270928'>

    def test_analysis_controller_empty_state(self, mock_console):
        """Test AnalysisController mit leerem State."""
        args = MagicMock()
        args.infer = True
        args.model = None
        config_data = {}
        plugins = {}
        new_events = []
        empty_state = WifiAnalysisState()
    
        controller = AnalysisController(args, config_data, mock_console, plugins, empty_state, new_events)
    
        # Sollte nicht crashen
>       controller.run_inference()
E       AttributeError: 'AnalysisController' object has no attribute 'run_inference'

pytest/test_controllers.py:420: AttributeError
________ TestControllerEdgeCases.test_analysis_controller_with_plugins _________

self = <test_controllers.TestControllerEdgeCases object at 0x7f68bbb250>
mock_console = <MagicMock id='547008919056'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f5c1073d0>

    def test_analysis_controller_with_plugins(self, mock_console, populated_state):
        """Test AnalysisController mit Plugins."""
        args = MagicMock()
        args.run_plugins = ["test_plugin"]
        config_data = {}
    
        mock_plugin = MagicMock()
        mock_plugin.run.return_value = None
        plugins = {"test_plugin": mock_plugin}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       controller.run_plugins()
E       AttributeError: 'AnalysisController' object has no attribute 'run_plugins'

pytest/test_controllers.py:435: AttributeError
____________ TestControllerIntegration.test_full_analysis_workflow _____________

self = <test_controllers.TestControllerIntegration object at 0x7f68bc8190>
mock_console = <MagicMock id='547005160656'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f5c0e9c10>

    def test_full_analysis_workflow(self, mock_console, populated_state):
        """Test vollständiger Analyse-Workflow."""
        args = MagicMock()
        args.infer = True
        args.cluster_clients = 2
        args.cluster_aps = 2
        args.export_graph = "/tmp/test.gexf"
        args.label_ui = False
        args.label_clients = False
        args.correlate_macs = False
        args.model = None
        args.cluster_algo = "kmeans"
        args.no_mac_correlation = False
        args.graph_include_clients = False
        args.graph_min_activity = 0
        args.graph_min_duration = 0
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       with patch.object(controller, 'run_inference'):

pytest/test_controllers.py:491: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f5c0e91d0>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <wlan_tool.controllers.AnalysisController object at 0x7f5c46ba10> does not have the attribute 'run_inference'

../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1419: AttributeError
_____________________ TestLoggingSystem.test_setup_logging _____________________

self = <test_error_handling.TestLoggingSystem object at 0x7f68c25050>

    def test_setup_logging(self):
        """Test Logging-Setup."""
        logger = setup_logging(
            log_level="DEBUG",
            enable_console=True,
            enable_performance_logging=True,
            enable_error_tracking=True
        )
    
        assert logger is not None
        assert logger.name == "wlan_tool"
>       assert logger.level == logging.DEBUG
E       NameError: name 'logging' is not defined

pytest/test_error_handling.py:317: NameError
___________ TestDatabaseErrorHandling.test_database_connection_error ___________

self = <test_error_handling.TestDatabaseErrorHandling object at 0x7f68c26250>

    def test_database_connection_error(self):
        """Test Datenbankverbindungs-Fehler."""
        with pytest.raises(DatabaseError) as exc_info:
            from wlan_tool.storage.database import db_conn_ctx
            with db_conn_ctx("/invalid/path/database.db"):
                pass
    
        assert "Cannot create database directory" in str(exc_info.value)
>       assert exc_info.value.error_code == "SQLITE_ERROR"
E       AssertionError: assert 'DB_UNEXPECTED_ERROR' == 'SQLITE_ERROR'
E         
E         - SQLITE_ERROR
E         + DB_UNEXPECTED_ERROR

pytest/test_error_handling.py:345: AssertionError
----------------------------- Captured stdout call -----------------------------
2025-10-19 11:18:22,748 | DEBUG    | Starting operation: database_connection
2025-10-19 11:18:22,748 | ERROR    | Error in database_connection: WLANToolError: Cannot create database directory: /invalid/path (Code: DB_DIR_CREATION_FAILED) | Details: {'directory': '/invalid/path', 'original_error': "[Errno 13] Permission denied: '/invalid'"} (Code: DB_DIR_CREATION_FAILED) | Details: {'directory': '/invalid/path', 'original_error': "[Errno 13] Permission denied: '/invalid'"}
2025-10-19 11:18:22,754 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/pathlib.py", line 1116, in mkdir
    os.mkdir(self, mode)
FileNotFoundError: [Errno 2] No such file or directory: '/invalid/path'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 81, in db_conn_ctx
    db_dir.mkdir(parents=True, exist_ok=True)
  File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/pathlib.py", line 1120, in mkdir
    self.parent.mkdir(parents=True, exist_ok=True)
  File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/pathlib.py", line 1116, in mkdir
    os.mkdir(self, mode)
PermissionError: [Errno 13] Permission denied: '/invalid'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 83, in db_conn_ctx
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Cannot create database directory: /invalid/path (Code: DB_DIR_CREATION_FAILED) | Details: {'directory': '/invalid/path', 'original_error': "[Errno 13] Permission denied: '/invalid'"}

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in database_connection: WLANToolError: Cannot create database directory: /invalid/path (Code: DB_DIR_CREATION_FAILED) | Details: {'directory': '/invalid/path', 'original_error': "[Errno 13] Permission denied: '/invalid'"} (Code: DB_DIR_CREATION_FAILED) | Details: {'directory': '/invalid/path', 'original_error': "[Errno 13] Permission denied: '/invalid'"}
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/pathlib.py", line 1116, in mkdir
    os.mkdir(self, mode)
FileNotFoundError: [Errno 2] No such file or directory: '/invalid/path'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 81, in db_conn_ctx
    db_dir.mkdir(parents=True, exist_ok=True)
  File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/pathlib.py", line 1120, in mkdir
    self.parent.mkdir(parents=True, exist_ok=True)
  File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/pathlib.py", line 1116, in mkdir
    os.mkdir(self, mode)
PermissionError: [Errno 13] Permission denied: '/invalid'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 83, in db_conn_ctx
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Cannot create database directory: /invalid/path (Code: DB_DIR_CREATION_FAILED) | Details: {'directory': '/invalid/path', 'original_error': "[Errno 13] Permission denied: '/invalid'"}
___________ TestDatabaseErrorHandling.test_database_migration_error ____________

self = <test_error_handling.TestDatabaseErrorHandling object at 0x7f68c26850>

    def test_database_migration_error(self):
        """Test Datenbankmigrations-Fehler."""
        with tempfile.NamedTemporaryFile(suffix='.db', delete=False) as f:
            db_path = f.name
    
        try:
            # Erstelle ungültige Migration
            migrations_dir = Path("wlan_tool/assets/sql_data/versions")
            migrations_dir.mkdir(parents=True, exist_ok=True)
    
            invalid_migration = migrations_dir / "999_invalid.sql"
            invalid_migration.write_text("INVALID SQL SYNTAX")
    
>           with pytest.raises(DatabaseError):
E           Failed: DID NOT RAISE <class 'wlan_tool.exceptions.DatabaseError'>

pytest/test_error_handling.py:360: Failed
----------------------------- Captured stdout call -----------------------------
2025-10-19 11:18:22,795 | DEBUG    | Starting operation: database_migration
2025-10-19 11:18:22,796 | DEBUG    | Starting operation: database_connection
2025-10-19 11:18:22,812 | INFO     | Current DB version: 0. Looking for migrations...
2025-10-19 11:18:22,813 | INFO     | Applying migration: 001_initial_schema.sql (Version 1)
2025-10-19 11:18:22,823 | INFO     | DB successfully migrated to version 1
2025-10-19 11:18:22,824 | INFO     | Applying migration: 002_add_dns_table.sql (Version 2)
2025-10-19 11:18:22,825 | INFO     | DB successfully migrated to version 2
2025-10-19 11:18:22,825 | INFO     | Applying migration: 003_add_network_info.sql (Version 3)
2025-10-19 11:18:22,827 | INFO     | DB successfully migrated to version 3
2025-10-19 11:18:22,827 | INFO     | Applying migration: 004_add_indexes.sql (Version 4)
2025-10-19 11:18:22,828 | INFO     | DB successfully migrated to version 4
2025-10-19 11:18:22,829 | INFO     | Applying migration: 999_invalid.sql (Version 999)
2025-10-19 11:18:22,829 | ERROR    | Unexpected error during migration 999_invalid.sql: WLANToolError: Migration failed: 999_invalid.sql (Code: MIGRATION_EXECUTION_FAILED) | Details: {'migration_file': '999_invalid.sql', 'version': 999, 'sqlite_error': 'near "INVALID": syntax error'}
2025-10-19 11:18:22,851 | INFO     | Database is up to date.
------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_migration
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
INFO     wlan_tool.storage.database:database.py:157 Current DB version: 0. Looking for migrations...
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 001_initial_schema.sql (Version 1)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 1
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 002_add_dns_table.sql (Version 2)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 2
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 003_add_network_info.sql (Version 3)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 3
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 004_add_indexes.sql (Version 4)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 4
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 999_invalid.sql (Version 999)
ERROR    wlan_tool.storage.database:database.py:199 Unexpected error during migration 999_invalid.sql: WLANToolError: Migration failed: 999_invalid.sql (Code: MIGRATION_EXECUTION_FAILED) | Details: {'migration_file': '999_invalid.sql', 'version': 999, 'sqlite_error': 'near "INVALID": syntax error'}
INFO     wlan_tool.storage.database:database.py:204 Database is up to date.
__________ TestAnalysisErrorHandling.test_client_features_null_state ___________

self = <test_error_handling.TestAnalysisErrorHandling object at 0x7f68c27110>

    def test_client_features_null_state(self):
        """Test Client-Features mit None-State."""
        from wlan_tool.analysis.logic import features_for_client
    
>       with pytest.raises(ValidationError) as exc_info:
E       Failed: DID NOT RAISE <class 'wlan_tool.exceptions.ValidationError'>

pytest/test_error_handling.py:377: Failed
----------------------------- Captured stdout call -----------------------------
2025-10-19 11:18:22,880 | DEBUG    | Starting operation: client_features_extraction
2025-10-19 11:18:22,880 | ERROR    | Error in client_features_extraction: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'} (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}
2025-10-19 11:18:22,881 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 229, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}

2025-10-19 11:18:22,881 | ERROR    | Unexpected error in features_for_client: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}
2025-10-19 11:18:22,882 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 229, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_features_extraction
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in client_features_extraction: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'} (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 229, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}

ERROR    wlan_tool.analysis.logic:exceptions.py:165 Unexpected error in features_for_client: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}
DEBUG    wlan_tool.analysis.logic:exceptions.py:166 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 229, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}
_________ TestAnalysisErrorHandling.test_client_features_invalid_type __________

self = <test_error_handling.TestAnalysisErrorHandling object at 0x7f68c27710>

    def test_client_features_invalid_type(self):
        """Test Client-Features mit ungültigem Typ."""
        from wlan_tool.analysis.logic import features_for_client
    
>       with pytest.raises(ValidationError) as exc_info:
E       Failed: DID NOT RAISE <class 'wlan_tool.exceptions.ValidationError'>

pytest/test_error_handling.py:387: Failed
----------------------------- Captured stdout call -----------------------------
2025-10-19 11:18:22,911 | DEBUG    | Starting operation: client_features_extraction
2025-10-19 11:18:22,912 | ERROR    | Error in client_features_extraction: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"} (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}
2025-10-19 11:18:22,912 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 236, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}

2025-10-19 11:18:22,913 | ERROR    | Unexpected error in features_for_client: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}
2025-10-19 11:18:22,913 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 236, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_features_extraction
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in client_features_extraction: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"} (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 236, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}

ERROR    wlan_tool.analysis.logic:exceptions.py:165 Unexpected error in features_for_client: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}
DEBUG    wlan_tool.analysis.logic:exceptions.py:166 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 236, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}
_________ TestAnalysisErrorHandling.test_clustering_invalid_parameters _________

self = <test_error_handling.TestAnalysisErrorHandling object at 0x7f68c27d10>

    def test_clustering_invalid_parameters(self):
        """Test Clustering mit ungültigen Parametern."""
        from wlan_tool.analysis.logic import cluster_clients
        from wlan_tool.storage.state import WifiAnalysisState
    
        state = WifiAnalysisState()
    
        # Teste ungültige n_clusters
>       with pytest.raises(ValidationError) as exc_info:
E       Failed: DID NOT RAISE <class 'wlan_tool.exceptions.ValidationError'>

pytest/test_error_handling.py:401: Failed
----------------------------- Captured stdout call -----------------------------
2025-10-19 11:18:22,942 | DEBUG    | Starting operation: client_clustering
2025-10-19 11:18:22,942 | ERROR    | Error in client_clustering: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0} (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}
2025-10-19 11:18:22,943 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 495, in cluster_clients
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}

2025-10-19 11:18:22,943 | ERROR    | Unexpected error in cluster_clients: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}
2025-10-19 11:18:22,944 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 495, in cluster_clients
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_clustering
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in client_clustering: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0} (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 495, in cluster_clients
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}

ERROR    wlan_tool.analysis.logic:exceptions.py:165 Unexpected error in cluster_clients: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}
DEBUG    wlan_tool.analysis.logic:exceptions.py:166 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 495, in cluster_clients
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}
___________ TestFileSystemErrorHandling.test_csv_export_invalid_path ___________

self = <test_error_handling.TestFileSystemErrorHandling object at 0x7f68c30590>

    def test_csv_export_invalid_path(self):
        """Test CSV-Export mit ungültigem Pfad."""
        from wlan_tool.storage.database import export_confirmed_to_csv
    
>       with pytest.raises(ValidationError) as exc_info:
E       Failed: DID NOT RAISE <class 'wlan_tool.exceptions.ValidationError'>

pytest/test_error_handling.py:422: Failed
----------------------------- Captured stdout call -----------------------------
2025-10-19 11:18:22,972 | DEBUG    | Starting operation: csv_export
2025-10-19 11:18:22,973 | ERROR    | Error in csv_export: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''} (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}
2025-10-19 11:18:22,973 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}

2025-10-19 11:18:22,973 | ERROR    | Error in export_confirmed_to_csv: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}
2025-10-19 11:18:22,974 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: csv_export
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in csv_export: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''} (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}

ERROR    wlan_tool.storage.database:exceptions.py:153 Error in export_confirmed_to_csv: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}
DEBUG    wlan_tool.storage.database:exceptions.py:154 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}
____________ TestFileSystemErrorHandling.test_csv_export_missing_db ____________

self = <test_error_handling.TestFileSystemErrorHandling object at 0x7f68c30b90>

    def test_csv_export_missing_db(self):
        """Test CSV-Export mit fehlender Datenbank."""
        from wlan_tool.storage.database import export_confirmed_to_csv
    
>       with pytest.raises(FileSystemError) as exc_info:
E       Failed: DID NOT RAISE <class 'wlan_tool.exceptions.FileSystemError'>

pytest/test_error_handling.py:432: Failed
----------------------------- Captured stdout call -----------------------------
2025-10-19 11:18:23,003 | DEBUG    | Starting operation: csv_export
2025-10-19 11:18:23,004 | ERROR    | Error in csv_export: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'} (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}
2025-10-19 11:18:23,005 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}

2025-10-19 11:18:23,005 | ERROR    | Error in export_confirmed_to_csv: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}
2025-10-19 11:18:23,005 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: csv_export
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in csv_export: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'} (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}

ERROR    wlan_tool.storage.database:exceptions.py:153 Error in export_confirmed_to_csv: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}
DEBUG    wlan_tool.storage.database:exceptions.py:154 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}
____________ TestErrorHandlingEdgeCases.test_nested_error_contexts _____________

self = <test_error_handling.TestErrorHandlingEdgeCases object at 0x7f68c322d0>

    def test_nested_error_contexts(self):
        """Test verschachtelte Error-Contexts."""
        with ErrorContext("outer_operation", "OUTER_ERROR") as outer:
            with ErrorContext("inner_operation", "INNER_ERROR") as inner:
>               raise ValueError("Inner error")
E               ValueError: Inner error

pytest/test_error_handling.py:473: ValueError

The above exception was the direct cause of the following exception:

self = <test_error_handling.TestErrorHandlingEdgeCases object at 0x7f68c322d0>

    def test_nested_error_contexts(self):
        """Test verschachtelte Error-Contexts."""
        with ErrorContext("outer_operation", "OUTER_ERROR") as outer:
>           with ErrorContext("inner_operation", "INNER_ERROR") as inner:

pytest/test_error_handling.py:472: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.exceptions.ErrorContext object at 0x7f5c359790>
exc_type = <class 'ValueError'>, exc_val = ValueError('Inner error')
exc_tb = <traceback object at 0x7f5c3582c0>

    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type is not None:
            error_msg = f"Error in {self.operation}: {exc_val}"
    
            if isinstance(exc_val, WLANToolError):
                error_msg += f" (Code: {exc_val.error_code})"
                if exc_val.details:
                    error_msg += f" | Details: {exc_val.details}"
            else:
                error_msg += f" | Type: {exc_type.__name__}"
    
            self.logger.log(self.log_level, error_msg)
            self.logger.debug(f"Traceback: {traceback.format_exc()}")
    
            # Konvertiere zu WLANToolError falls nötig
            if not isinstance(exc_val, WLANToolError):
                wlan_error = WLANToolError(
                    message=str(exc_val),
                    error_code=self.error_code or "CONTEXT_ERROR",
                    details={
                        "operation": self.operation,
                        "original_type": exc_type.__name__,
                    },
                )
>               raise wlan_error from exc_val
E               wlan_tool.exceptions.WLANToolError: WLANToolError: Inner error (Code: INNER_ERROR) | Details: {'operation': 'inner_operation', 'original_type': 'ValueError'}

wlan_tool/exceptions.py:313: WLANToolError
----------------------------- Captured stdout call -----------------------------
2025-10-19 11:18:24,041 | DEBUG    | Starting operation: outer_operation
2025-10-19 11:18:24,042 | DEBUG    | Starting operation: inner_operation
2025-10-19 11:18:24,042 | ERROR    | Error in inner_operation: Inner error | Type: ValueError
2025-10-19 11:18:24,043 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/pytest/test_error_handling.py", line 473, in test_nested_error_contexts
    raise ValueError("Inner error")
ValueError: Inner error

2025-10-19 11:18:24,043 | ERROR    | Error in outer_operation: WLANToolError: Inner error (Code: INNER_ERROR) | Details: {'operation': 'inner_operation', 'original_type': 'ValueError'} (Code: INNER_ERROR) | Details: {'operation': 'inner_operation', 'original_type': 'ValueError'}
2025-10-19 11:18:24,044 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/pytest/test_error_handling.py", line 473, in test_nested_error_contexts
    raise ValueError("Inner error")
ValueError: Inner error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/pi/hacking/pytest/test_error_handling.py", line 472, in test_nested_error_contexts
    with ErrorContext("inner_operation", "INNER_ERROR") as inner:
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 313, in __exit__
    raise wlan_error from exc_val
wlan_tool.exceptions.WLANToolError: WLANToolError: Inner error (Code: INNER_ERROR) | Details: {'operation': 'inner_operation', 'original_type': 'ValueError'}

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: outer_operation
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: inner_operation
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in inner_operation: Inner error | Type: ValueError
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/pytest/test_error_handling.py", line 473, in test_nested_error_contexts
    raise ValueError("Inner error")
ValueError: Inner error

ERROR    wlan_tool.exceptions:exceptions.py:300 Error in outer_operation: WLANToolError: Inner error (Code: INNER_ERROR) | Details: {'operation': 'inner_operation', 'original_type': 'ValueError'} (Code: INNER_ERROR) | Details: {'operation': 'inner_operation', 'original_type': 'ValueError'}
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/pytest/test_error_handling.py", line 473, in test_nested_error_contexts
    raise ValueError("Inner error")
ValueError: Inner error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/pi/hacking/pytest/test_error_handling.py", line 472, in test_nested_error_contexts
    with ErrorContext("inner_operation", "INNER_ERROR") as inner:
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 313, in __exit__
    raise wlan_error from exc_val
wlan_tool.exceptions.WLANToolError: WLANToolError: Inner error (Code: INNER_ERROR) | Details: {'operation': 'inner_operation', 'original_type': 'ValueError'}
_____________ TestEndToEndWorkflow.test_complete_analysis_pipeline _____________

self = <test_integration.TestEndToEndWorkflow object at 0x7f68c33ed0>
sample_events = [{'beacon_interval': 102, 'bssid': '08:96:d7:1a:21:1c', 'cap': 17, 'channel': 6, ...}, {'client': 'a8:51:ab:0c:b9:e9',...-91, ...}, {'client': 'b2:87:23:15:7f:f2', 'ie_order_hash': 67890, 'ies': {0: ['MyOtherWLAN']}, 'rssi': -70, ...}, ...]
temp_db_file = '/tmp/tmp81n8lmbj.db'

    def test_complete_analysis_pipeline(self, sample_events, temp_db_file):
        """Test kompletter Analyse-Pipeline."""
        # 1. Erstelle State aus Events
        state = WifiAnalysisState()
        state.build_from_events(sample_events)
    
        assert len(state.aps) > 0
        assert len(state.clients) > 0
    
        # 2. Führe Inferenz durch
        results = analysis.score_pairs_with_recency_and_matching(state)
        assert isinstance(results, list)
    
        # 3. Führe Client-Clustering durch
        clustered_df, feature_df = analysis.cluster_clients(state, n_clusters=2)
        if clustered_df is not None:
            assert len(clustered_df) > 0
    
        # 4. Führe AP-Clustering durch
>       ap_clustered_df = analysis.cluster_aps(state, n_clusters=2)

pytest/test_integration.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/analysis/logic.py:736: in cluster_aps
    df["cluster"] = kmeans.fit_predict(X_scaled)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1064: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1456: in fit
    self._check_params_vs_input(X)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1396: in _check_params_vs_input
    super()._check_params_vs_input(X, default_n_init=10)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = KMeans(n_clusters=2, random_state=42)
X = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])
default_n_init = 10

    def _check_params_vs_input(self, X, default_n_init=None):
        # n_clusters
        if X.shape[0] < self.n_clusters:
>           raise ValueError(
                f"n_samples={X.shape[0]} should be >= n_clusters={self.n_clusters}."
            )
E           ValueError: n_samples=1 should be >= n_clusters=2.

.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:871: ValueError
---------------------------- Captured stdout setup -----------------------------
2025-10-19 11:18:24,146 | DEBUG    | Starting operation: database_migration
2025-10-19 11:18:24,147 | DEBUG    | Starting operation: database_connection
2025-10-19 11:18:24,170 | INFO     | Current DB version: 0. Looking for migrations...
2025-10-19 11:18:24,170 | INFO     | Applying migration: 001_initial_schema.sql (Version 1)
2025-10-19 11:18:24,177 | INFO     | DB successfully migrated to version 1
2025-10-19 11:18:24,178 | INFO     | Applying migration: 002_add_dns_table.sql (Version 2)
2025-10-19 11:18:24,179 | INFO     | DB successfully migrated to version 2
2025-10-19 11:18:24,179 | INFO     | Applying migration: 003_add_network_info.sql (Version 3)
2025-10-19 11:18:24,181 | INFO     | DB successfully migrated to version 3
2025-10-19 11:18:24,181 | INFO     | Applying migration: 004_add_indexes.sql (Version 4)
2025-10-19 11:18:24,183 | INFO     | DB successfully migrated to version 4
2025-10-19 11:18:24,204 | INFO     | Database is up to date.
------------------------------ Captured log setup ------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_migration
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
INFO     wlan_tool.storage.database:database.py:157 Current DB version: 0. Looking for migrations...
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 001_initial_schema.sql (Version 1)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 1
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 002_add_dns_table.sql (Version 2)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 2
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 003_add_network_info.sql (Version 3)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 3
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 004_add_indexes.sql (Version 4)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 4
INFO     wlan_tool.storage.database:database.py:204 Database is up to date.
----------------------------- Captured stdout call -----------------------------
2025-10-19 11:18:24,205 | INFO     | Baue/Aktualisiere Zustand aus Event-Stream auf...
2025-10-19 11:18:24,206 | INFO     | Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
2025-10-19 11:18:24,216 | DEBUG    | Dynamische Normalisierungsfaktoren: {'beacon_count': 1.0, 'probe_resp_count': 1.0, 'supporting_clients': 1.0, 'seq_support': 1.0, 'rssi_std_max': 20.0}
2025-10-19 11:18:24,217 | DEBUG    | Starting operation: client_clustering
2025-10-19 11:18:24,217 | INFO     | Korreliere randomisierte MACs vor der Feature-Extraktion...
2025-10-19 11:18:24,217 | INFO     | Fand 0 Gruppen von potenziell zusammengehörigen randomisierten MACs.
2025-10-19 11:18:24,218 | DEBUG    | Starting operation: client_features_extraction
2025-10-19 11:18:24,218 | DEBUG    | Starting operation: client_features_extraction
2025-10-19 11:18:24,219 | DEBUG    | Starting operation: client_features_extraction
2025-10-19 11:18:24,232 | INFO     | Wende manuelle Feature-Gewichtungen für Standard-Clustering an...
2025-10-19 11:18:24,233 | DEBUG    | Gewichte Feature 'supports_11ax' mit Faktor 3.0.
2025-10-19 11:18:24,236 | DEBUG    | Gewichte Feature 'supports_11ac' mit Faktor 2.0.
2025-10-19 11:18:24,239 | DEBUG    | Gewichte Feature 'has_apple_ie' mit Faktor 2.5.
2025-10-19 11:18:24,242 | DEBUG    | Gewichte Feature 'has_ms_ie' mit Faktor 2.0.
2025-10-19 11:18:24,244 | DEBUG    | Gewichte Feature 'mimo_streams' mit Faktor 1.5.
2025-10-19 11:18:24,247 | DEBUG    | Gewichte Feature 'is_randomized_mac' mit Faktor 1.2.
2025-10-19 11:18:24,250 | DEBUG    | Gewichte Feature 'was_in_powersave' mit Faktor 1.2.
2025-10-19 11:18:24,253 | DEBUG    | Gewichte Feature 'probe_count' mit Faktor 1.0.
2025-10-19 11:18:24,255 | DEBUG    | Gewichte Feature 'seen_with_ap_count' mit Faktor 1.0.
2025-10-19 11:18:24,258 | INFO     | Verwende KMeans für das Clustering...
------------------------------ Captured log call -------------------------------
INFO     wlan_tool.storage.state:state.py:52 Baue/Aktualisiere Zustand aus Event-Stream auf...
INFO     wlan_tool.storage.state:state.py:57 Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
DEBUG    wlan_tool.analysis.logic:logic.py:148 Dynamische Normalisierungsfaktoren: {'beacon_count': 1.0, 'probe_resp_count': 1.0, 'supporting_clients': 1.0, 'seq_support': 1.0, 'rssi_std_max': 20.0}
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_clustering
INFO     wlan_tool.analysis.logic:logic.py:396 Korreliere randomisierte MACs vor der Feature-Extraktion...
INFO     wlan_tool.analysis.logic:logic.py:791 Fand 0 Gruppen von potenziell zusammengehörigen randomisierten MACs.
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_features_extraction
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_features_extraction
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_features_extraction
INFO     wlan_tool.analysis.logic:logic.py:584 Wende manuelle Feature-Gewichtungen für Standard-Clustering an...
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'supports_11ax' mit Faktor 3.0.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'supports_11ac' mit Faktor 2.0.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'has_apple_ie' mit Faktor 2.5.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'has_ms_ie' mit Faktor 2.0.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'mimo_streams' mit Faktor 1.5.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'is_randomized_mac' mit Faktor 1.2.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'was_in_powersave' mit Faktor 1.2.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'probe_count' mit Faktor 1.0.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'seen_with_ap_count' mit Faktor 1.0.
INFO     wlan_tool.analysis.logic:logic.py:609 Verwende KMeans für das Clustering...
________________ TestEndToEndWorkflow.test_database_integration ________________

self = <test_integration.TestEndToEndWorkflow object at 0x7f68c402d0>
sample_events = [{'beacon_interval': 102, 'bssid': '08:96:d7:1a:21:1c', 'cap': 17, 'channel': 6, ...}, {'client': 'a8:51:ab:0c:b9:e9',...-91, ...}, {'client': 'b2:87:23:15:7f:f2', 'ie_order_hash': 67890, 'ies': {0: ['MyOtherWLAN']}, 'rssi': -70, ...}, ...]
temp_db_file = '/tmp/tmpih_rkx5x.db'

    def test_database_integration(self, sample_events, temp_db_file):
        """Test Datenbank-Integration."""
        # Schreibe Events in Datenbank
        with database.db_conn_ctx(temp_db_file) as conn:
            for event in sample_events:
>               database.add_event(conn, event)
E               AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

pytest/test_integration.py:64: AttributeError

The above exception was the direct cause of the following exception:

path = '/tmp/tmpih_rkx5x.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
>           with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):

wlan_tool/storage/database.py:68: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.exceptions.ErrorContext object at 0x7f5c0c7b90>
exc_type = <class 'AttributeError'>
exc_val = AttributeError("module 'wlan_tool.storage.database' has no attribute 'add_event'")
exc_tb = <traceback object at 0x7f5c0c5f80>

    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type is not None:
            error_msg = f"Error in {self.operation}: {exc_val}"
    
            if isinstance(exc_val, WLANToolError):
                error_msg += f" (Code: {exc_val.error_code})"
                if exc_val.details:
                    error_msg += f" | Details: {exc_val.details}"
            else:
                error_msg += f" | Type: {exc_type.__name__}"
    
            self.logger.log(self.log_level, error_msg)
            self.logger.debug(f"Traceback: {traceback.format_exc()}")
    
            # Konvertiere zu WLANToolError falls nötig
            if not isinstance(exc_val, WLANToolError):
                wlan_error = WLANToolError(
                    message=str(exc_val),
                    error_code=self.error_code or "CONTEXT_ERROR",
                    details={
                        "operation": self.operation,
                        "original_type": exc_type.__name__,
                    },
                )
>               raise wlan_error from exc_val
E               wlan_tool.exceptions.WLANToolError: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}

wlan_tool/exceptions.py:313: WLANToolError

The above exception was the direct cause of the following exception:

self = <test_integration.TestEndToEndWorkflow object at 0x7f68c402d0>
sample_events = [{'beacon_interval': 102, 'bssid': '08:96:d7:1a:21:1c', 'cap': 17, 'channel': 6, ...}, {'client': 'a8:51:ab:0c:b9:e9',...-91, ...}, {'client': 'b2:87:23:15:7f:f2', 'ie_order_hash': 67890, 'ies': {0: ['MyOtherWLAN']}, 'rssi': -70, ...}, ...]
temp_db_file = '/tmp/tmpih_rkx5x.db'

    def test_database_integration(self, sample_events, temp_db_file):
        """Test Datenbank-Integration."""
        # Schreibe Events in Datenbank
>       with database.db_conn_ctx(temp_db_file) as conn:

pytest/test_integration.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/contextlib.py:158: in __exit__
    self.gen.throw(typ, value, traceback)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

path = '/tmp/tmpih_rkx5x.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
            with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):
                # Validiere Datenbankpfad
                if not _validate_file_path(path):
                    raise ValidationError(
                        f"Invalid database path: {path}",
                        error_code="INVALID_DB_PATH",
                        details={"db_path": path},
                    )
    
                # Erstelle Verzeichnis falls nötig
                db_dir = Path(path).parent
                if not db_dir.exists():
                    try:
                        db_dir.mkdir(parents=True, exist_ok=True)
                    except OSError as e:
                        raise FileSystemError(
                            f"Cannot create database directory: {db_dir}",
                            error_code="DB_DIR_CREATION_FAILED",
                            details={"directory": str(db_dir), "original_error": str(e)},
                        ) from e
    
                # Verbinde zur Datenbank
                conn = sqlite3.connect(path, timeout=Constants.DB_CONNECTION_TIMEOUT)
                conn.row_factory = sqlite3.Row
    
                # Setze pragmas für bessere Performance und Fehlerbehandlung
                conn.execute("PRAGMA foreign_keys = ON")
                conn.execute("PRAGMA journal_mode = WAL")
                conn.execute("PRAGMA synchronous = NORMAL")
                conn.execute("PRAGMA cache_size = 10000")
                conn.execute("PRAGMA temp_store = MEMORY")
    
                yield conn
    
        except sqlite3.Error as e:
            if conn:
                conn.rollback()
            raise DatabaseError(
                get_error_message(ErrorCodes.DB_CONNECTION_FAILED, details=str(e)),
                error_code=ErrorCodes.DB_CONNECTION_FAILED.value,
                details={"db_path": path, "sqlite_error": str(e)},
            ) from e
        except Exception as e:
            if conn:
                conn.rollback()
>           raise DatabaseError(
                f"Unexpected database error: {e}",
                error_code="DB_UNEXPECTED_ERROR",
                details={"db_path": path, "original_error": str(e)},
            ) from e
E           wlan_tool.exceptions.DatabaseError: WLANToolError: Unexpected database error: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'} (Code: DB_UNEXPECTED_ERROR) | Details: {'db_path': '/tmp/tmpih_rkx5x.db', 'original_error': "WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}"}

wlan_tool/storage/database.py:113: DatabaseError
---------------------------- Captured stdout setup -----------------------------
2025-10-19 11:18:25,352 | DEBUG    | Starting operation: database_migration
2025-10-19 11:18:25,353 | DEBUG    | Starting operation: database_connection
2025-10-19 11:18:25,369 | INFO     | Current DB version: 0. Looking for migrations...
2025-10-19 11:18:25,370 | INFO     | Applying migration: 001_initial_schema.sql (Version 1)
2025-10-19 11:18:25,378 | INFO     | DB successfully migrated to version 1
2025-10-19 11:18:25,378 | INFO     | Applying migration: 002_add_dns_table.sql (Version 2)
2025-10-19 11:18:25,379 | INFO     | DB successfully migrated to version 2
2025-10-19 11:18:25,380 | INFO     | Applying migration: 003_add_network_info.sql (Version 3)
2025-10-19 11:18:25,381 | INFO     | DB successfully migrated to version 3
2025-10-19 11:18:25,381 | INFO     | Applying migration: 004_add_indexes.sql (Version 4)
2025-10-19 11:18:25,383 | INFO     | DB successfully migrated to version 4
2025-10-19 11:18:25,404 | INFO     | Database is up to date.
------------------------------ Captured log setup ------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_migration
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
INFO     wlan_tool.storage.database:database.py:157 Current DB version: 0. Looking for migrations...
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 001_initial_schema.sql (Version 1)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 1
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 002_add_dns_table.sql (Version 2)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 2
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 003_add_network_info.sql (Version 3)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 3
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 004_add_indexes.sql (Version 4)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 4
INFO     wlan_tool.storage.database:database.py:204 Database is up to date.
----------------------------- Captured stdout call -----------------------------
2025-10-19 11:18:25,406 | DEBUG    | Starting operation: database_connection
2025-10-19 11:18:25,408 | ERROR    | Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
2025-10-19 11:18:25,409 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/hacking/pytest/test_integration.py", line 64, in test_database_integration
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/hacking/pytest/test_integration.py", line 64, in test_database_integration
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'
_________________ TestEndToEndWorkflow.test_config_integration _________________

self = <test_integration.TestEndToEndWorkflow object at 0x7f68c40610>

    def test_config_integration(self):
        """Test Konfigurations-Integration."""
        # Teste Konfigurations-Laden
>       config_data = utils.load_config()
E       TypeError: load_config() missing 1 required positional argument: 'profile'

pytest/test_integration.py:82: TypeError
_____________________ TestDataFlow.test_state_persistence ______________________

self = <test_integration.TestDataFlow object at 0x7f68c41490>
sample_events = [{'beacon_interval': 102, 'bssid': '08:96:d7:1a:21:1c', 'cap': 17, 'channel': 6, ...}, {'client': 'a8:51:ab:0c:b9:e9',...-91, ...}, {'client': 'b2:87:23:15:7f:f2', 'ie_order_hash': 67890, 'ies': {0: ['MyOtherWLAN']}, 'rssi': -70, ...}, ...]
temp_db_file = '/tmp/tmp2sifqzlt.db'

    def test_state_persistence(self, sample_events, temp_db_file):
        """Test State-Persistierung."""
        # Erstelle State
        state1 = WifiAnalysisState()
        state1.build_from_events(sample_events)
    
        # Schreibe in Datenbank
        with database.db_conn_ctx(temp_db_file) as conn:
            for event in sample_events:
>               database.add_event(conn, event)
E               AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

pytest/test_integration.py:130: AttributeError

The above exception was the direct cause of the following exception:

path = '/tmp/tmp2sifqzlt.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
>           with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):

wlan_tool/storage/database.py:68: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.exceptions.ErrorContext object at 0x7f5c4c7ed0>
exc_type = <class 'AttributeError'>
exc_val = AttributeError("module 'wlan_tool.storage.database' has no attribute 'add_event'")
exc_tb = <traceback object at 0x7f5c4c4b80>

    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type is not None:
            error_msg = f"Error in {self.operation}: {exc_val}"
    
            if isinstance(exc_val, WLANToolError):
                error_msg += f" (Code: {exc_val.error_code})"
                if exc_val.details:
                    error_msg += f" | Details: {exc_val.details}"
            else:
                error_msg += f" | Type: {exc_type.__name__}"
    
            self.logger.log(self.log_level, error_msg)
            self.logger.debug(f"Traceback: {traceback.format_exc()}")
    
            # Konvertiere zu WLANToolError falls nötig
            if not isinstance(exc_val, WLANToolError):
                wlan_error = WLANToolError(
                    message=str(exc_val),
                    error_code=self.error_code or "CONTEXT_ERROR",
                    details={
                        "operation": self.operation,
                        "original_type": exc_type.__name__,
                    },
                )
>               raise wlan_error from exc_val
E               wlan_tool.exceptions.WLANToolError: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}

wlan_tool/exceptions.py:313: WLANToolError

The above exception was the direct cause of the following exception:

self = <test_integration.TestDataFlow object at 0x7f68c41490>
sample_events = [{'beacon_interval': 102, 'bssid': '08:96:d7:1a:21:1c', 'cap': 17, 'channel': 6, ...}, {'client': 'a8:51:ab:0c:b9:e9',...-91, ...}, {'client': 'b2:87:23:15:7f:f2', 'ie_order_hash': 67890, 'ies': {0: ['MyOtherWLAN']}, 'rssi': -70, ...}, ...]
temp_db_file = '/tmp/tmp2sifqzlt.db'

    def test_state_persistence(self, sample_events, temp_db_file):
        """Test State-Persistierung."""
        # Erstelle State
        state1 = WifiAnalysisState()
        state1.build_from_events(sample_events)
    
        # Schreibe in Datenbank
>       with database.db_conn_ctx(temp_db_file) as conn:

pytest/test_integration.py:128: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/contextlib.py:158: in __exit__
    self.gen.throw(typ, value, traceback)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

path = '/tmp/tmp2sifqzlt.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
            with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):
                # Validiere Datenbankpfad
                if not _validate_file_path(path):
                    raise ValidationError(
                        f"Invalid database path: {path}",
                        error_code="INVALID_DB_PATH",
                        details={"db_path": path},
                    )
    
                # Erstelle Verzeichnis falls nötig
                db_dir = Path(path).parent
                if not db_dir.exists():
                    try:
                        db_dir.mkdir(parents=True, exist_ok=True)
                    except OSError as e:
                        raise FileSystemError(
                            f"Cannot create database directory: {db_dir}",
                            error_code="DB_DIR_CREATION_FAILED",
                            details={"directory": str(db_dir), "original_error": str(e)},
                        ) from e
    
                # Verbinde zur Datenbank
                conn = sqlite3.connect(path, timeout=Constants.DB_CONNECTION_TIMEOUT)
                conn.row_factory = sqlite3.Row
    
                # Setze pragmas für bessere Performance und Fehlerbehandlung
                conn.execute("PRAGMA foreign_keys = ON")
                conn.execute("PRAGMA journal_mode = WAL")
                conn.execute("PRAGMA synchronous = NORMAL")
                conn.execute("PRAGMA cache_size = 10000")
                conn.execute("PRAGMA temp_store = MEMORY")
    
                yield conn
    
        except sqlite3.Error as e:
            if conn:
                conn.rollback()
            raise DatabaseError(
                get_error_message(ErrorCodes.DB_CONNECTION_FAILED, details=str(e)),
                error_code=ErrorCodes.DB_CONNECTION_FAILED.value,
                details={"db_path": path, "sqlite_error": str(e)},
            ) from e
        except Exception as e:
            if conn:
                conn.rollback()
>           raise DatabaseError(
                f"Unexpected database error: {e}",
                error_code="DB_UNEXPECTED_ERROR",
                details={"db_path": path, "original_error": str(e)},
            ) from e
E           wlan_tool.exceptions.DatabaseError: WLANToolError: Unexpected database error: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'} (Code: DB_UNEXPECTED_ERROR) | Details: {'db_path': '/tmp/tmp2sifqzlt.db', 'original_error': "WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}"}

wlan_tool/storage/database.py:113: DatabaseError
---------------------------- Captured stdout setup -----------------------------
2025-10-19 11:18:25,644 | DEBUG    | Starting operation: database_migration
2025-10-19 11:18:25,644 | DEBUG    | Starting operation: database_connection
2025-10-19 11:18:25,658 | INFO     | Current DB version: 0. Looking for migrations...
2025-10-19 11:18:25,659 | INFO     | Applying migration: 001_initial_schema.sql (Version 1)
2025-10-19 11:18:25,667 | INFO     | DB successfully migrated to version 1
2025-10-19 11:18:25,668 | INFO     | Applying migration: 002_add_dns_table.sql (Version 2)
2025-10-19 11:18:25,669 | INFO     | DB successfully migrated to version 2
2025-10-19 11:18:25,669 | INFO     | Applying migration: 003_add_network_info.sql (Version 3)
2025-10-19 11:18:25,671 | INFO     | DB successfully migrated to version 3
2025-10-19 11:18:25,671 | INFO     | Applying migration: 004_add_indexes.sql (Version 4)
2025-10-19 11:18:25,672 | INFO     | DB successfully migrated to version 4
2025-10-19 11:18:25,693 | INFO     | Database is up to date.
------------------------------ Captured log setup ------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_migration
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
INFO     wlan_tool.storage.database:database.py:157 Current DB version: 0. Looking for migrations...
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 001_initial_schema.sql (Version 1)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 1
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 002_add_dns_table.sql (Version 2)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 2
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 003_add_network_info.sql (Version 3)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 3
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 004_add_indexes.sql (Version 4)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 4
INFO     wlan_tool.storage.database:database.py:204 Database is up to date.
----------------------------- Captured stdout call -----------------------------
2025-10-19 11:18:25,695 | INFO     | Baue/Aktualisiere Zustand aus Event-Stream auf...
2025-10-19 11:18:25,696 | INFO     | Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
2025-10-19 11:18:25,696 | DEBUG    | Starting operation: database_connection
2025-10-19 11:18:25,698 | ERROR    | Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
2025-10-19 11:18:25,699 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/hacking/pytest/test_integration.py", line 130, in test_state_persistence
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

------------------------------ Captured log call -------------------------------
INFO     wlan_tool.storage.state:state.py:52 Baue/Aktualisiere Zustand aus Event-Stream auf...
INFO     wlan_tool.storage.state:state.py:57 Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/hacking/pytest/test_integration.py", line 130, in test_state_persistence
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'
________________ TestLargeDataset.test_large_dataset_processing ________________

self = <test_integration.TestLargeDataset object at 0x7f68c41cd0>

    def test_large_dataset_processing(self):
        """Test Verarbeitung großer Datensätze."""
        # Erstelle großen State
        state = WifiAnalysisState()
    
        # Erstelle 100 APs
        for i in range(100):
            bssid = f"08:96:d7:1a:21:{i:02x}"
>           ap = state.aps[bssid] = state.aps.get(bssid, type(state).__dict__['aps'].__class__())()
E           KeyError: 'aps'

pytest/test_integration.py:158: KeyError
_______________ TestErrorRecovery.test_malformed_event_handling ________________

self = <test_integration.TestErrorRecovery object at 0x7f68c433d0>

    def test_malformed_event_handling(self):
        """Test Behandlung fehlerhafter Events."""
        state = WifiAnalysisState()
    
        # Teste verschiedene fehlerhafte Events
        malformed_events = [
            {},  # Leeres Event
            {'ts': time.time()},  # Nur Zeitstempel
            {'ts': time.time(), 'type': 'invalid'},  # Ungültiger Typ
            {'ts': time.time(), 'type': 'beacon'},  # Beacon ohne BSSID
        ]
    
        for event in malformed_events:
            # Sollte nicht crashen
            try:
>               state.update_from_event(event)

pytest/test_integration.py:241: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f5c501250>
ev = {}, detailed_ies = False

    def update_from_event(self, ev: dict, detailed_ies: bool = False):
>       ts, ev_type = ev["ts"], ev.get("type")
E       KeyError: 'ts'

wlan_tool/storage/state.py:66: KeyError

During handling of the above exception, another exception occurred:

self = <test_integration.TestErrorRecovery object at 0x7f68c433d0>

    def test_malformed_event_handling(self):
        """Test Behandlung fehlerhafter Events."""
        state = WifiAnalysisState()
    
        # Teste verschiedene fehlerhafte Events
        malformed_events = [
            {},  # Leeres Event
            {'ts': time.time()},  # Nur Zeitstempel
            {'ts': time.time(), 'type': 'invalid'},  # Ungültiger Typ
            {'ts': time.time(), 'type': 'beacon'},  # Beacon ohne BSSID
        ]
    
        for event in malformed_events:
            # Sollte nicht crashen
            try:
                state.update_from_event(event)
            except Exception as e:
>               pytest.fail(f"Malformed event should be handled gracefully: {e}")
E               Failed: Malformed event should be handled gracefully: 'ts'

pytest/test_integration.py:243: Failed
______________ TestMemoryManagement.test_memory_usage_large_state ______________

self = <test_integration.TestMemoryManagement object at 0x7f68c48890>

    def test_memory_usage_large_state(self):
        """Test Speicherverbrauch mit großem State."""
        import psutil
        import os
    
        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss
    
        # Erstelle großen State
        state = WifiAnalysisState()
    
        for i in range(1000):
            mac = f"aa:bb:cc:dd:ee:{i:04x}"
>           client = state.clients[mac] = state.clients.get(mac, type(state).__dict__['clients'].__class__())()
E           KeyError: 'clients'

pytest/test_integration.py:295: KeyError
____________ TestMemoryManagement.test_state_pruning_memory_release ____________

self = <test_integration.TestMemoryManagement object at 0x7f68c48e90>

    def test_state_pruning_memory_release(self):
        """Test Speicherfreigabe durch State-Pruning."""
        import psutil
        import os
    
        process = psutil.Process(os.getpid())
    
        # Erstelle State mit alten und neuen Daten
        state = WifiAnalysisState()
    
        # Alte Clients (werden gepruned)
        for i in range(100):
            mac = f"old:aa:bb:cc:dd:ee:{i:02x}"
>           client = state.clients[mac] = state.clients.get(mac, type(state).__dict__['clients'].__class__())()
E           KeyError: 'clients'

pytest/test_integration.py:321: KeyError
_____________ TestAnalysisPerformance.test_clustering_performance ______________

self = <test_performance.TestAnalysisPerformance object at 0x7f68c4b690>

    def test_clustering_performance(self):
        """Test Clustering-Performance."""
        # Erstelle State mit vielen Clients
        state = WifiAnalysisState()
    
        for i in range(200):
            mac = f"aa:bb:cc:dd:ee:{i:02x}"
>           client = state.clients[mac] = state.clients.get(mac, type(state).__dict__['clients'].__class__())()
E           KeyError: 'clients'

pytest/test_performance.py:147: KeyError
______________ TestAnalysisPerformance.test_inference_performance ______________

self = <test_performance.TestAnalysisPerformance object at 0x7f68c4bc90>

    def test_inference_performance(self):
        """Test Inferenz-Performance."""
        # Erstelle State mit APs und Clients
        state = WifiAnalysisState()
    
        # Erstelle 50 APs
        for i in range(50):
            bssid = f"08:96:d7:1a:21:{i:02x}"
>           ap = state.aps[bssid] = state.aps.get(bssid, type(state).__dict__['aps'].__class__())()
E           KeyError: 'aps'

pytest/test_performance.py:180: KeyError
_____________ TestMemoryPerformance.test_memory_usage_large_state ______________

self = <test_performance.TestMemoryPerformance object at 0x7f68c50550>

    def test_memory_usage_large_state(self):
        """Test Speicherverbrauch mit großem State."""
        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss
    
        # Erstelle großen State
        state = WifiAnalysisState()
    
        # 1000 Clients
        for i in range(1000):
            mac = f"aa:bb:cc:dd:ee:{i:04x}"
>           client = state.clients[mac] = state.clients.get(mac, type(state).__dict__['clients'].__class__())()
E           KeyError: 'clients'

pytest/test_performance.py:228: KeyError
___________ TestMemoryPerformance.test_memory_cleanup_after_pruning ____________

self = <test_performance.TestMemoryPerformance object at 0x7f68c50b50>

    def test_memory_cleanup_after_pruning(self):
        """Test Speicherbereinigung nach Pruning."""
        process = psutil.Process(os.getpid())
    
        # Erstelle State mit alten und neuen Daten
        state = WifiAnalysisState()
    
        # 500 alte Clients (werden gepruned)
        for i in range(500):
            mac = f"old:aa:bb:cc:dd:ee:{i:03x}"
>           client = state.clients[mac] = state.clients.get(mac, type(state).__dict__['clients'].__class__())()
E           KeyError: 'clients'

pytest/test_performance.py:269: KeyError
___________ TestDatabasePerformance.test_database_write_performance ____________

self = <test_performance.TestDatabasePerformance object at 0x7f68c51450>
temp_db_file = '/tmp/tmpm04j2bqu.db'

    def test_database_write_performance(self, temp_db_file):
        """Test Datenbank-Schreib-Performance."""
        # Erstelle Test-Events
        events = []
        for i in range(1000):
            event = {
                'ts': time.time() + i,
                'type': 'beacon' if i % 2 == 0 else 'probe_req',
                'bssid': f'08:96:d7:1a:21:{i % 100:02x}',
                'ssid': f'SSID_{i % 50}',
                'rssi': -50 - (i % 50),
                'channel': (i % 13) + 1
            }
            events.append(event)
    
        start_time = time.time()
    
        with database.db_conn_ctx(temp_db_file) as conn:
            for event in events:
>               database.add_event(conn, event)
E               AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

pytest/test_performance.py:325: AttributeError

The above exception was the direct cause of the following exception:

path = '/tmp/tmpm04j2bqu.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
>           with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):

wlan_tool/storage/database.py:68: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.exceptions.ErrorContext object at 0x7f5c4683d0>
exc_type = <class 'AttributeError'>
exc_val = AttributeError("module 'wlan_tool.storage.database' has no attribute 'add_event'")
exc_tb = <traceback object at 0x7f5c468a40>

    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type is not None:
            error_msg = f"Error in {self.operation}: {exc_val}"
    
            if isinstance(exc_val, WLANToolError):
                error_msg += f" (Code: {exc_val.error_code})"
                if exc_val.details:
                    error_msg += f" | Details: {exc_val.details}"
            else:
                error_msg += f" | Type: {exc_type.__name__}"
    
            self.logger.log(self.log_level, error_msg)
            self.logger.debug(f"Traceback: {traceback.format_exc()}")
    
            # Konvertiere zu WLANToolError falls nötig
            if not isinstance(exc_val, WLANToolError):
                wlan_error = WLANToolError(
                    message=str(exc_val),
                    error_code=self.error_code or "CONTEXT_ERROR",
                    details={
                        "operation": self.operation,
                        "original_type": exc_type.__name__,
                    },
                )
>               raise wlan_error from exc_val
E               wlan_tool.exceptions.WLANToolError: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}

wlan_tool/exceptions.py:313: WLANToolError

The above exception was the direct cause of the following exception:

self = <test_performance.TestDatabasePerformance object at 0x7f68c51450>
temp_db_file = '/tmp/tmpm04j2bqu.db'

    def test_database_write_performance(self, temp_db_file):
        """Test Datenbank-Schreib-Performance."""
        # Erstelle Test-Events
        events = []
        for i in range(1000):
            event = {
                'ts': time.time() + i,
                'type': 'beacon' if i % 2 == 0 else 'probe_req',
                'bssid': f'08:96:d7:1a:21:{i % 100:02x}',
                'ssid': f'SSID_{i % 50}',
                'rssi': -50 - (i % 50),
                'channel': (i % 13) + 1
            }
            events.append(event)
    
        start_time = time.time()
    
>       with database.db_conn_ctx(temp_db_file) as conn:

pytest/test_performance.py:323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/contextlib.py:158: in __exit__
    self.gen.throw(typ, value, traceback)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

path = '/tmp/tmpm04j2bqu.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
            with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):
                # Validiere Datenbankpfad
                if not _validate_file_path(path):
                    raise ValidationError(
                        f"Invalid database path: {path}",
                        error_code="INVALID_DB_PATH",
                        details={"db_path": path},
                    )
    
                # Erstelle Verzeichnis falls nötig
                db_dir = Path(path).parent
                if not db_dir.exists():
                    try:
                        db_dir.mkdir(parents=True, exist_ok=True)
                    except OSError as e:
                        raise FileSystemError(
                            f"Cannot create database directory: {db_dir}",
                            error_code="DB_DIR_CREATION_FAILED",
                            details={"directory": str(db_dir), "original_error": str(e)},
                        ) from e
    
                # Verbinde zur Datenbank
                conn = sqlite3.connect(path, timeout=Constants.DB_CONNECTION_TIMEOUT)
                conn.row_factory = sqlite3.Row
    
                # Setze pragmas für bessere Performance und Fehlerbehandlung
                conn.execute("PRAGMA foreign_keys = ON")
                conn.execute("PRAGMA journal_mode = WAL")
                conn.execute("PRAGMA synchronous = NORMAL")
                conn.execute("PRAGMA cache_size = 10000")
                conn.execute("PRAGMA temp_store = MEMORY")
    
                yield conn
    
        except sqlite3.Error as e:
            if conn:
                conn.rollback()
            raise DatabaseError(
                get_error_message(ErrorCodes.DB_CONNECTION_FAILED, details=str(e)),
                error_code=ErrorCodes.DB_CONNECTION_FAILED.value,
                details={"db_path": path, "sqlite_error": str(e)},
            ) from e
        except Exception as e:
            if conn:
                conn.rollback()
>           raise DatabaseError(
                f"Unexpected database error: {e}",
                error_code="DB_UNEXPECTED_ERROR",
                details={"db_path": path, "original_error": str(e)},
            ) from e
E           wlan_tool.exceptions.DatabaseError: WLANToolError: Unexpected database error: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'} (Code: DB_UNEXPECTED_ERROR) | Details: {'db_path': '/tmp/tmpm04j2bqu.db', 'original_error': "WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}"}

wlan_tool/storage/database.py:113: DatabaseError
---------------------------- Captured stdout setup -----------------------------
2025-10-19 11:18:26,798 | DEBUG    | Starting operation: database_migration
2025-10-19 11:18:26,798 | DEBUG    | Starting operation: database_connection
2025-10-19 11:18:26,813 | INFO     | Current DB version: 0. Looking for migrations...
2025-10-19 11:18:26,813 | INFO     | Applying migration: 001_initial_schema.sql (Version 1)
2025-10-19 11:18:26,823 | INFO     | DB successfully migrated to version 1
2025-10-19 11:18:26,823 | INFO     | Applying migration: 002_add_dns_table.sql (Version 2)
2025-10-19 11:18:26,825 | INFO     | DB successfully migrated to version 2
2025-10-19 11:18:26,825 | INFO     | Applying migration: 003_add_network_info.sql (Version 3)
2025-10-19 11:18:26,826 | INFO     | DB successfully migrated to version 3
2025-10-19 11:18:26,827 | INFO     | Applying migration: 004_add_indexes.sql (Version 4)
2025-10-19 11:18:26,828 | INFO     | DB successfully migrated to version 4
2025-10-19 11:18:26,849 | INFO     | Database is up to date.
------------------------------ Captured log setup ------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_migration
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
INFO     wlan_tool.storage.database:database.py:157 Current DB version: 0. Looking for migrations...
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 001_initial_schema.sql (Version 1)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 1
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 002_add_dns_table.sql (Version 2)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 2
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 003_add_network_info.sql (Version 3)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 3
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 004_add_indexes.sql (Version 4)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 4
INFO     wlan_tool.storage.database:database.py:204 Database is up to date.
----------------------------- Captured stdout call -----------------------------
2025-10-19 11:18:26,855 | DEBUG    | Starting operation: database_connection
2025-10-19 11:18:26,857 | ERROR    | Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
2025-10-19 11:18:26,859 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/hacking/pytest/test_performance.py", line 325, in test_database_write_performance
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/hacking/pytest/test_performance.py", line 325, in test_database_write_performance
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'
____________ TestDatabasePerformance.test_database_read_performance ____________

self = <test_performance.TestDatabasePerformance object at 0x7f68c51ad0>
temp_db_file = '/tmp/tmp0i1ogkod.db'

    def test_database_read_performance(self, temp_db_file):
        """Test Datenbank-Lese-Performance."""
        # Schreibe Test-Events
        events = []
        for i in range(1000):
            event = {
                'ts': time.time() + i,
                'type': 'beacon' if i % 2 == 0 else 'probe_req',
                'bssid': f'08:96:d7:1a:21:{i % 100:02x}',
                'ssid': f'SSID_{i % 50}',
                'rssi': -50 - (i % 50),
                'channel': (i % 13) + 1
            }
            events.append(event)
    
        with database.db_conn_ctx(temp_db_file) as conn:
            for event in events:
>               database.add_event(conn, event)
E               AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

pytest/test_performance.py:351: AttributeError

The above exception was the direct cause of the following exception:

path = '/tmp/tmp0i1ogkod.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
>           with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):

wlan_tool/storage/database.py:68: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.exceptions.ErrorContext object at 0x7f5c360110>
exc_type = <class 'AttributeError'>
exc_val = AttributeError("module 'wlan_tool.storage.database' has no attribute 'add_event'")
exc_tb = <traceback object at 0x7f5c51e000>

    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type is not None:
            error_msg = f"Error in {self.operation}: {exc_val}"
    
            if isinstance(exc_val, WLANToolError):
                error_msg += f" (Code: {exc_val.error_code})"
                if exc_val.details:
                    error_msg += f" | Details: {exc_val.details}"
            else:
                error_msg += f" | Type: {exc_type.__name__}"
    
            self.logger.log(self.log_level, error_msg)
            self.logger.debug(f"Traceback: {traceback.format_exc()}")
    
            # Konvertiere zu WLANToolError falls nötig
            if not isinstance(exc_val, WLANToolError):
                wlan_error = WLANToolError(
                    message=str(exc_val),
                    error_code=self.error_code or "CONTEXT_ERROR",
                    details={
                        "operation": self.operation,
                        "original_type": exc_type.__name__,
                    },
                )
>               raise wlan_error from exc_val
E               wlan_tool.exceptions.WLANToolError: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}

wlan_tool/exceptions.py:313: WLANToolError

The above exception was the direct cause of the following exception:

self = <test_performance.TestDatabasePerformance object at 0x7f68c51ad0>
temp_db_file = '/tmp/tmp0i1ogkod.db'

    def test_database_read_performance(self, temp_db_file):
        """Test Datenbank-Lese-Performance."""
        # Schreibe Test-Events
        events = []
        for i in range(1000):
            event = {
                'ts': time.time() + i,
                'type': 'beacon' if i % 2 == 0 else 'probe_req',
                'bssid': f'08:96:d7:1a:21:{i % 100:02x}',
                'ssid': f'SSID_{i % 50}',
                'rssi': -50 - (i % 50),
                'channel': (i % 13) + 1
            }
            events.append(event)
    
>       with database.db_conn_ctx(temp_db_file) as conn:

pytest/test_performance.py:349: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/contextlib.py:158: in __exit__
    self.gen.throw(typ, value, traceback)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

path = '/tmp/tmp0i1ogkod.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
            with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):
                # Validiere Datenbankpfad
                if not _validate_file_path(path):
                    raise ValidationError(
                        f"Invalid database path: {path}",
                        error_code="INVALID_DB_PATH",
                        details={"db_path": path},
                    )
    
                # Erstelle Verzeichnis falls nötig
                db_dir = Path(path).parent
                if not db_dir.exists():
                    try:
                        db_dir.mkdir(parents=True, exist_ok=True)
                    except OSError as e:
                        raise FileSystemError(
                            f"Cannot create database directory: {db_dir}",
                            error_code="DB_DIR_CREATION_FAILED",
                            details={"directory": str(db_dir), "original_error": str(e)},
                        ) from e
    
                # Verbinde zur Datenbank
                conn = sqlite3.connect(path, timeout=Constants.DB_CONNECTION_TIMEOUT)
                conn.row_factory = sqlite3.Row
    
                # Setze pragmas für bessere Performance und Fehlerbehandlung
                conn.execute("PRAGMA foreign_keys = ON")
                conn.execute("PRAGMA journal_mode = WAL")
                conn.execute("PRAGMA synchronous = NORMAL")
                conn.execute("PRAGMA cache_size = 10000")
                conn.execute("PRAGMA temp_store = MEMORY")
    
                yield conn
    
        except sqlite3.Error as e:
            if conn:
                conn.rollback()
            raise DatabaseError(
                get_error_message(ErrorCodes.DB_CONNECTION_FAILED, details=str(e)),
                error_code=ErrorCodes.DB_CONNECTION_FAILED.value,
                details={"db_path": path, "sqlite_error": str(e)},
            ) from e
        except Exception as e:
            if conn:
                conn.rollback()
>           raise DatabaseError(
                f"Unexpected database error: {e}",
                error_code="DB_UNEXPECTED_ERROR",
                details={"db_path": path, "original_error": str(e)},
            ) from e
E           wlan_tool.exceptions.DatabaseError: WLANToolError: Unexpected database error: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'} (Code: DB_UNEXPECTED_ERROR) | Details: {'db_path': '/tmp/tmp0i1ogkod.db', 'original_error': "WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}"}

wlan_tool/storage/database.py:113: DatabaseError
---------------------------- Captured stdout setup -----------------------------
2025-10-19 11:18:27,020 | DEBUG    | Starting operation: database_migration
2025-10-19 11:18:27,021 | DEBUG    | Starting operation: database_connection
2025-10-19 11:18:27,036 | INFO     | Current DB version: 0. Looking for migrations...
2025-10-19 11:18:27,037 | INFO     | Applying migration: 001_initial_schema.sql (Version 1)
2025-10-19 11:18:27,047 | INFO     | DB successfully migrated to version 1
2025-10-19 11:18:27,047 | INFO     | Applying migration: 002_add_dns_table.sql (Version 2)
2025-10-19 11:18:27,049 | INFO     | DB successfully migrated to version 2
2025-10-19 11:18:27,049 | INFO     | Applying migration: 003_add_network_info.sql (Version 3)
2025-10-19 11:18:27,050 | INFO     | DB successfully migrated to version 3
2025-10-19 11:18:27,051 | INFO     | Applying migration: 004_add_indexes.sql (Version 4)
2025-10-19 11:18:27,052 | INFO     | DB successfully migrated to version 4
2025-10-19 11:18:27,073 | INFO     | Database is up to date.
------------------------------ Captured log setup ------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_migration
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
INFO     wlan_tool.storage.database:database.py:157 Current DB version: 0. Looking for migrations...
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 001_initial_schema.sql (Version 1)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 1
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 002_add_dns_table.sql (Version 2)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 2
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 003_add_network_info.sql (Version 3)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 3
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 004_add_indexes.sql (Version 4)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 4
INFO     wlan_tool.storage.database:database.py:204 Database is up to date.
----------------------------- Captured stdout call -----------------------------
2025-10-19 11:18:27,079 | DEBUG    | Starting operation: database_connection
2025-10-19 11:18:27,081 | ERROR    | Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
2025-10-19 11:18:27,083 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/hacking/pytest/test_performance.py", line 351, in test_database_read_performance
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/hacking/pytest/test_performance.py", line 351, in test_database_read_performance
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'
________ TestScalabilityPerformance.test_scalability_with_dataset_size _________

self = <test_performance.TestScalabilityPerformance object at 0x7f68c52b90>

    def test_scalability_with_dataset_size(self):
        """Test Skalierbarkeit mit Datensatz-Größe."""
        dataset_sizes = [100, 500, 1000]
        processing_times = []
    
        for size in dataset_sizes:
            # Erstelle State mit gegebener Größe
            state = WifiAnalysisState()
    
            for i in range(size):
                mac = f"aa:bb:cc:dd:ee:{i:04x}"
>               client = state.clients[mac] = state.clients.get(mac, type(state).__dict__['clients'].__class__())()
E               KeyError: 'clients'

pytest/test_performance.py:440: KeyError
_______________ TestCLIModule.test_print_client_cluster_results ________________

self = <test_presentation.TestCLIModule object at 0x7f68c4ba90>
mock_console = <MagicMock id='547008085328'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f8aee0850>

    def test_print_client_cluster_results(self, mock_console, populated_state):
        """Test Client-Cluster-Ergebnis-Ausgabe."""
        from wlan_tool.analysis import logic as analysis
    
        # Erstelle Test-Cluster-Daten
        clustered_df, feature_df = analysis.cluster_clients(populated_state, n_clusters=2)
    
        if clustered_df is not None and not clustered_df.empty:
            # Mock args
            args = MagicMock()
            args.cluster_clients = 2
            args.cluster_algo = "kmeans"
            args.no_mac_correlation = False
    
            # Sollte nicht crashen
>           cli.print_client_cluster_results(args, populated_state, mock_console)

pytest/test_presentation.py:38: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = <MagicMock id='547791712464'>
state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f8aee0850>
console = <MagicMock id='547008085328'>

    def print_client_cluster_results(args, state, console):
        """Führt das Client-Clustering aus und gibt die Ergebnisse formatiert aus."""
        clustered_df, feature_df = analysis.cluster_clients(
            state,
            n_clusters=args.cluster_clients,
            algo_name=args.cluster_algo,
            use_correlation=(not args.no_mac_correlation),
        )
        """Gibt die Ergebnisse des Client-Clusterings formatiert aus."""
        if clustered_df is not None and not clustered_df.empty:
            console.print(
                "[yellow]Keine Client-Daten für das Clustering gefunden.[/yellow]"
            )
            return
    
>       title_correlation_str = "& Korrelation" if use_correlation else "& ohne Korrelation"
E       NameError: name 'use_correlation' is not defined

wlan_tool/presentation/cli.py:34: NameError
---------------------------- Captured stdout setup -----------------------------
2025-10-19 11:18:27,338 | INFO     | Baue/Aktualisiere Zustand aus Event-Stream auf...
2025-10-19 11:18:27,339 | INFO     | Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
------------------------------ Captured log setup ------------------------------
INFO     wlan_tool.storage.state:state.py:52 Baue/Aktualisiere Zustand aus Event-Stream auf...
INFO     wlan_tool.storage.state:state.py:57 Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
----------------------------- Captured stdout call -----------------------------
2025-10-19 11:18:27,340 | DEBUG    | Starting operation: client_clustering
2025-10-19 11:18:27,341 | INFO     | Korreliere randomisierte MACs vor der Feature-Extraktion...
2025-10-19 11:18:27,341 | INFO     | Fand 0 Gruppen von potenziell zusammengehörigen randomisierten MACs.
2025-10-19 11:18:27,341 | DEBUG    | Starting operation: client_features_extraction
2025-10-19 11:18:27,341 | DEBUG    | Starting operation: client_features_extraction
2025-10-19 11:18:27,341 | DEBUG    | Starting operation: client_features_extraction
2025-10-19 11:18:27,355 | INFO     | Wende manuelle Feature-Gewichtungen für Standard-Clustering an...
2025-10-19 11:18:27,355 | DEBUG    | Gewichte Feature 'supports_11ax' mit Faktor 3.0.
2025-10-19 11:18:27,358 | DEBUG    | Gewichte Feature 'supports_11ac' mit Faktor 2.0.
2025-10-19 11:18:27,361 | DEBUG    | Gewichte Feature 'has_apple_ie' mit Faktor 2.5.
2025-10-19 11:18:27,364 | DEBUG    | Gewichte Feature 'has_ms_ie' mit Faktor 2.0.
2025-10-19 11:18:27,367 | DEBUG    | Gewichte Feature 'mimo_streams' mit Faktor 1.5.
2025-10-19 11:18:27,369 | DEBUG    | Gewichte Feature 'is_randomized_mac' mit Faktor 1.2.
2025-10-19 11:18:27,372 | DEBUG    | Gewichte Feature 'was_in_powersave' mit Faktor 1.2.
2025-10-19 11:18:27,375 | DEBUG    | Gewichte Feature 'probe_count' mit Faktor 1.0.
2025-10-19 11:18:27,378 | DEBUG    | Gewichte Feature 'seen_with_ap_count' mit Faktor 1.0.
2025-10-19 11:18:27,381 | INFO     | Verwende KMeans für das Clustering...
2025-10-19 11:18:27,390 | ERROR    | Unexpected error in cluster_clients: cluster_clients() got an unexpected keyword argument 'algo_name'
2025-10-19 11:18:27,391 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
TypeError: cluster_clients() got an unexpected keyword argument 'algo_name'

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_clustering
INFO     wlan_tool.analysis.logic:logic.py:396 Korreliere randomisierte MACs vor der Feature-Extraktion...
INFO     wlan_tool.analysis.logic:logic.py:791 Fand 0 Gruppen von potenziell zusammengehörigen randomisierten MACs.
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_features_extraction
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_features_extraction
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_features_extraction
INFO     wlan_tool.analysis.logic:logic.py:584 Wende manuelle Feature-Gewichtungen für Standard-Clustering an...
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'supports_11ax' mit Faktor 3.0.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'supports_11ac' mit Faktor 2.0.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'has_apple_ie' mit Faktor 2.5.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'has_ms_ie' mit Faktor 2.0.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'mimo_streams' mit Faktor 1.5.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'is_randomized_mac' mit Faktor 1.2.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'was_in_powersave' mit Faktor 1.2.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'probe_count' mit Faktor 1.0.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'seen_with_ap_count' mit Faktor 1.0.
INFO     wlan_tool.analysis.logic:logic.py:609 Verwende KMeans für das Clustering...
ERROR    wlan_tool.analysis.logic:exceptions.py:165 Unexpected error in cluster_clients: cluster_clients() got an unexpected keyword argument 'algo_name'
DEBUG    wlan_tool.analysis.logic:exceptions.py:166 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
TypeError: cluster_clients() got an unexpected keyword argument 'algo_name'
_________________ TestCLIModule.test_print_ap_cluster_results __________________

self = <test_presentation.TestCLIModule object at 0x7f68c64cd0>
mock_console = <MagicMock id='547008878352'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f5c49ab10>

    def test_print_ap_cluster_results(self, mock_console, populated_state):
        """Test AP-Cluster-Ergebnis-Ausgabe."""
        from wlan_tool.analysis import logic as analysis
    
        # Erstelle Test-AP-Cluster-Daten
>       clustered_df = analysis.cluster_aps(populated_state, n_clusters=2)

pytest/test_presentation.py:48: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/analysis/logic.py:736: in cluster_aps
    df["cluster"] = kmeans.fit_predict(X_scaled)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1064: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1456: in fit
    self._check_params_vs_input(X)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1396: in _check_params_vs_input
    super()._check_params_vs_input(X, default_n_init=10)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = KMeans(n_clusters=2, random_state=42)
X = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])
default_n_init = 10

    def _check_params_vs_input(self, X, default_n_init=None):
        # n_clusters
        if X.shape[0] < self.n_clusters:
>           raise ValueError(
                f"n_samples={X.shape[0]} should be >= n_clusters={self.n_clusters}."
            )
E           ValueError: n_samples=1 should be >= n_clusters=2.

.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:871: ValueError
---------------------------- Captured stdout setup -----------------------------
2025-10-19 11:18:27,437 | INFO     | Baue/Aktualisiere Zustand aus Event-Stream auf...
2025-10-19 11:18:27,438 | INFO     | Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
------------------------------ Captured log setup ------------------------------
INFO     wlan_tool.storage.state:state.py:52 Baue/Aktualisiere Zustand aus Event-Stream auf...
INFO     wlan_tool.storage.state:state.py:57 Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
________ TestCLIEdgeCases.test_print_client_cluster_results_empty_data _________

self = <test_presentation.TestCLIEdgeCases object at 0x7f68c69790>
mock_console = <MagicMock id='547079370960'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f60431510>

    def test_print_client_cluster_results_empty_data(self, mock_console, populated_state):
        """Test Client-Cluster-Ausgabe mit leeren Daten."""
        # Erstelle leeren State
        empty_state = WifiAnalysisState()
    
        args = MagicMock()
        args.cluster_clients = 2
        args.cluster_algo = "kmeans"
        args.no_mac_correlation = False
    
        # Sollte nicht crashen
>       cli.print_client_cluster_results(args, empty_state, mock_console)

pytest/test_presentation.py:281: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = <MagicMock id='547075855440'>
state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f60431cd0>
console = <MagicMock id='547079370960'>

    def print_client_cluster_results(args, state, console):
        """Führt das Client-Clustering aus und gibt die Ergebnisse formatiert aus."""
        clustered_df, feature_df = analysis.cluster_clients(
            state,
            n_clusters=args.cluster_clients,
            algo_name=args.cluster_algo,
            use_correlation=(not args.no_mac_correlation),
        )
        """Gibt die Ergebnisse des Client-Clusterings formatiert aus."""
        if clustered_df is not None and not clustered_df.empty:
            console.print(
                "[yellow]Keine Client-Daten für das Clustering gefunden.[/yellow]"
            )
            return
    
>       title_correlation_str = "& Korrelation" if use_correlation else "& ohne Korrelation"
E       NameError: name 'use_correlation' is not defined

wlan_tool/presentation/cli.py:34: NameError
---------------------------- Captured stdout setup -----------------------------
2025-10-19 11:18:27,851 | INFO     | Baue/Aktualisiere Zustand aus Event-Stream auf...
2025-10-19 11:18:27,851 | INFO     | Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
------------------------------ Captured log setup ------------------------------
INFO     wlan_tool.storage.state:state.py:52 Baue/Aktualisiere Zustand aus Event-Stream auf...
INFO     wlan_tool.storage.state:state.py:57 Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
----------------------------- Captured stdout call -----------------------------
2025-10-19 11:18:27,853 | ERROR    | Unexpected error in cluster_clients: cluster_clients() got an unexpected keyword argument 'algo_name'
2025-10-19 11:18:27,855 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
TypeError: cluster_clients() got an unexpected keyword argument 'algo_name'

------------------------------ Captured log call -------------------------------
ERROR    wlan_tool.analysis.logic:exceptions.py:165 Unexpected error in cluster_clients: cluster_clients() got an unexpected keyword argument 'algo_name'
DEBUG    wlan_tool.analysis.logic:exceptions.py:166 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
TypeError: cluster_clients() got an unexpected keyword argument 'algo_name'
_________________ TestPerformance.test_large_dataset_handling __________________

self = <test_presentation.TestPerformance object at 0x7f68c6bc10>
mock_console = <MagicMock id='547085815568'>

    def test_large_dataset_handling(self, mock_console):
        """Test mit großen Datensätzen."""
        # Erstelle State mit vielen Clients
        state = WifiAnalysisState()
    
        for i in range(100):
            client = ClientState(mac=f"aa:bb:cc:dd:ee:{i:02x}")
            client.probes = {f"SSID_{i}"}
            client.all_packet_ts = np.array([time.time() - 100, time.time()])
>           client.rssi_w = Welford()
E           NameError: name 'Welford' is not defined

pytest/test_presentation.py:366: NameError
_____________ TestClientState.test_client_state_update_from_event ______________

self = <test_storage.TestClientState object at 0x7f68c763d0>

    def test_client_state_update_from_event(self):
        """Test ClientState-Update aus Event."""
        client = ClientState(mac="aa:bb:cc:dd:ee:ff")
        event = {
            'ts': time.time(),
            'type': 'probe_req',
            'client': 'aa:bb:cc:dd:ee:ff',
            'rssi': -50,
            'ies': {'probes': ['TestSSID']}
        }
    
        client.update_from_event(event)
        assert client.count == 1
>       assert 'TestSSID' in client.probes
E       AssertionError: assert 'TestSSID' in set()
E        +  where set() = ClientState(mac='aa:bb:cc:dd:ee:ff', first_seen=1760865508.00093, last_seen=1760865508.00093, count=1, probes=set(), s..., hostname=None, mcs_rates=Counter(), noise_w=Welford(n=0, mean=0.0, M2=0.0), fcs_error_count=0, ie_order_hashes=set()).probes

pytest/test_storage.py:97: AssertionError
_________________ TestAPState.test_ap_state_update_from_beacon _________________

self = <test_storage.TestAPState object at 0x7f68c77810>

    def test_ap_state_update_from_beacon(self):
        """Test APState-Update aus Beacon."""
        ap = APState(bssid="aa:bb:cc:dd:ee:ff", ssid="TestAP")
        event = {
            'ts': time.time(),
            'type': 'beacon',
            'bssid': 'aa:bb:cc:dd:ee:ff',
            'ssid': 'TestAP',
            'rssi': -50,
            'channel': 6,
            'beacon_interval': 102
        }
    
>       ap.update_from_event(event)
E       AttributeError: 'APState' object has no attribute 'update_from_event'

pytest/test_storage.py:141: AttributeError
___________________ TestWifiAnalysisState.test_state_pruning ___________________

self = <test_storage.TestWifiAnalysisState object at 0x7f68c8db10>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f60939f50>

    def test_state_pruning(self, populated_state):
        """Test State-Pruning."""
        state = populated_state
        assert 'DE:AD:BE:EF:00:00' in state.clients
    
        pruned_count = state.prune_state(time.time(), threshold_s=7200)
    
        assert pruned_count > 0
        assert 'DE:AD:BE:EF:00:00' not in state.clients
>       assert 'a8:51:ab:0c:b9:e9' in state.clients  # Sollte bleiben
E       AssertionError: assert 'a8:51:ab:0c:b9:e9' in {}
E        +  where {} = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f60939f50>.clients

pytest/test_storage.py:203: AssertionError
---------------------------- Captured stdout setup -----------------------------
2025-10-19 11:18:28,071 | INFO     | Baue/Aktualisiere Zustand aus Event-Stream auf...
2025-10-19 11:18:28,071 | INFO     | Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
------------------------------ Captured log setup ------------------------------
INFO     wlan_tool.storage.state:state.py:52 Baue/Aktualisiere Zustand aus Event-Stream auf...
INFO     wlan_tool.storage.state:state.py:57 Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
----------------------------- Captured stdout call -----------------------------
2025-10-19 11:18:28,073 | INFO     | Zustand bereinigt: 1 APs, 3 Clients, 0 Seq-Einträge und 1 SSIDs entfernt.
------------------------------ Captured log call -------------------------------
INFO     wlan_tool.storage.state:state.py:237 Zustand bereinigt: 1 APs, 3 Clients, 0 Seq-Einträge und 1 SSIDs entfernt.
________________ TestWifiAnalysisState.test_state_ssid_mapping _________________

self = <test_storage.TestWifiAnalysisState object at 0x7f68c75350>
sample_events = [{'beacon_interval': 102, 'bssid': '08:96:d7:1a:21:1c', 'cap': 17, 'channel': 6, ...}, {'client': 'a8:51:ab:0c:b9:e9',...-91, ...}, {'client': 'b2:87:23:15:7f:f2', 'ie_order_hash': 67890, 'ies': {0: ['MyOtherWLAN']}, 'rssi': -70, ...}, ...]

    def test_state_ssid_mapping(self, sample_events):
        """Test SSID-Mapping-Funktionalität."""
        state = WifiAnalysisState()
        state.build_from_events(sample_events)
    
        # Teste SSID-Map
        assert 'MyTestWLAN' in state.ssid_map
        ssid_info = state.ssid_map['MyTestWLAN']
        assert '08:96:d7:1a:21:1c' in ssid_info['bssids']
>       assert 'a8:51:ab:0c:b9:e9' in ssid_info['sources']['probe_req']
E       AssertionError: assert 'a8:51:ab:0c:b9:e9' in set()

pytest/test_storage.py:214: AssertionError
----------------------------- Captured stdout call -----------------------------
2025-10-19 11:18:28,096 | INFO     | Baue/Aktualisiere Zustand aus Event-Stream auf...
2025-10-19 11:18:28,097 | INFO     | Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
------------------------------ Captured log call -------------------------------
INFO     wlan_tool.storage.state:state.py:52 Baue/Aktualisiere Zustand aus Event-Stream auf...
INFO     wlan_tool.storage.state:state.py:57 Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
_____________________ TestDatabaseModule.test_fetch_events _____________________

self = <test_storage.TestDatabaseModule object at 0x7f68c8e250>
in_memory_db = <sqlite3.Connection object at 0x7f8aee55d0>
sample_events = [{'beacon_interval': 102, 'bssid': '08:96:d7:1a:21:1c', 'cap': 17, 'channel': 6, ...}, {'client': 'a8:51:ab:0c:b9:e9',...-91, ...}, {'client': 'b2:87:23:15:7f:f2', 'ie_order_hash': 67890, 'ies': {0: ['MyOtherWLAN']}, 'rssi': -70, ...}, ...]

    def test_fetch_events(self, in_memory_db, sample_events):
        """Test Event-Abruf."""
        conn = in_memory_db
    
        # Schreibe Test-Events
        for event in sample_events[:2]:
>           database.add_event(conn, event)
E           AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

pytest/test_storage.py:260: AttributeError
______________________ TestDatabaseModule.test_add_label _______________________

self = <test_storage.TestDatabaseModule object at 0x7f68c8e650>
in_memory_db = <sqlite3.Connection object at 0x7f8aee6020>

    def test_add_label(self, in_memory_db):
        """Test Label-Hinzufügung."""
        conn = in_memory_db
    
        database.add_label(conn, "TestSSID", "aa:bb:cc:dd:ee:ff", 1)
    
        cursor = conn.execute("SELECT * FROM labels WHERE ssid = ? AND bssid = ?",
                            ("TestSSID", "aa:bb:cc:dd:ee:ff"))
        result = cursor.fetchone()
        assert result is not None
>       assert result[2] == 1  # label = 1
E       AssertionError: assert 'aa:bb:cc:dd:ee:ff' == 1

pytest/test_storage.py:277: AssertionError
----------------------------- Captured stdout call -----------------------------
2025-10-19 11:18:28,801 | DEBUG    | Starting operation: add_label
2025-10-19 11:18:28,801 | DEBUG    | Added label: TestSSID -> aa:bb:cc:dd:ee:ff = 1 (source: ui)
------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: add_label
DEBUG    wlan_tool.storage.database:database.py:618 Added label: TestSSID -> aa:bb:cc:dd:ee:ff = 1 (source: ui)
________________ TestOUIFunctions.test_lookup_vendor_apple_mac _________________

self = <test_utils.TestOUIFunctions object at 0x7f68c960d0>

    def test_lookup_vendor_apple_mac(self):
        """Test Vendor-Lookup für Apple-MAC."""
        # Apple MAC-Adresse
        mac = "a8:51:ab:0c:b9:e9"
        vendor = utils.lookup_vendor(mac)
    
>       assert vendor is not None
E       assert None is not None

pytest/test_utils.py:26: AssertionError
_______________ TestOUIFunctions.test_lookup_vendor_unknown_mac ________________

self = <test_utils.TestOUIFunctions object at 0x7f68c96cd0>

    def test_lookup_vendor_unknown_mac(self):
        """Test Vendor-Lookup für unbekannte MAC."""
        # Unbekannte MAC-Adresse
        mac = "ff:ff:ff:ff:ff:ff"
        vendor = utils.lookup_vendor(mac)
    
        # Sollte None oder "Unknown" zurückgeben
>       assert vendor is None or vendor == "Unknown"
E       AssertionError: assert ('(Lokal / Randomisiert)' is None or '(Lokal / Randomisiert)' == 'Unknown'
E         
E         - Unknown
E         + (Lokal / Randomisiert))

pytest/test_utils.py:45: AssertionError
_________________ TestIEParsing.test_parse_ies_vendor_specific _________________

self = <test_utils.TestIEParsing object at 0x7f68ca4a50>

    def test_parse_ies_vendor_specific(self):
        """Test Vendor-spezifische IE-Parsing."""
        ies = {221: ['0017f20a010103040507080c']}  # Apple IE
        parsed = utils.parse_ies(ies, detailed=True)
    
        assert isinstance(parsed, dict)
        assert "vendor_specific" in parsed
>       assert "Apple" in parsed["vendor_specific"]
E       AssertionError: assert 'Apple' in {}

pytest/test_utils.py:131: AssertionError
_________________ TestIEParsing.test_parse_ies_ht_capabilities _________________

self = <test_utils.TestIEParsing object at 0x7f68ca4dd0>

    def test_parse_ies_ht_capabilities(self):
        """Test HT-Capabilities-Parsing."""
        ies = {45: ['1f']}  # HT Capabilities
        parsed = utils.parse_ies(ies, detailed=True)
    
        assert isinstance(parsed, dict)
        assert "ht_caps" in parsed
>       assert "streams" in parsed["ht_caps"]
E       AssertionError: assert 'streams' in {'40mhz_support': True}

pytest/test_utils.py:140: AssertionError
_________________ TestUtilityFunctions.test_is_local_admin_mac _________________

self = <test_utils.TestUtilityFunctions object at 0x7f68ca5e10>

    def test_is_local_admin_mac(self):
        """Test lokale Admin-MAC-Erkennung."""
        # Lokale Admin-MAC
        assert utils.is_local_admin_mac("02:00:00:00:00:00") is True
        assert utils.is_local_admin_mac("06:00:00:00:00:00") is True
    
        # Globale MAC
        assert utils.is_local_admin_mac("00:00:00:00:00:00") is False
>       assert utils.is_local_admin_mac("aa:bb:cc:dd:ee:ff") is False
E       AssertionError: assert True is False
E        +  where True = <function is_local_admin_mac at 0x7f9fca0540>('aa:bb:cc:dd:ee:ff')
E        +    where <function is_local_admin_mac at 0x7f9fca0540> = utils.is_local_admin_mac

pytest/test_utils.py:171: AssertionError
___________________ TestUtilityFunctions.test_is_valid_bssid ___________________

self = <test_utils.TestUtilityFunctions object at 0x7f68ca6410>

    def test_is_valid_bssid(self):
        """Test BSSID-Validierung."""
        # Gültige BSSID
        assert utils.is_valid_bssid("aa:bb:cc:dd:ee:ff") is True
        assert utils.is_valid_bssid("00:11:22:33:44:55") is True
    
        # Ungültige BSSID
        assert utils.is_valid_bssid("") is False
        assert utils.is_valid_bssid("invalid") is False
>       assert utils.is_valid_bssid("aa:bb:cc:dd:ee") is False  # Zu kurz
E       AssertionError: assert True is False
E        +  where True = <function is_valid_bssid at 0x7f9fca05e0>('aa:bb:cc:dd:ee')
E        +    where <function is_valid_bssid at 0x7f9fca05e0> = utils.is_valid_bssid

pytest/test_utils.py:182: AssertionError
________________ TestUtilityFunctions.test_ie_fingerprint_hash _________________

self = <test_utils.TestUtilityFunctions object at 0x7f68ca6a10>

    def test_ie_fingerprint_hash(self):
        """Test IE-Fingerprint-Hash."""
        ies = {
            0: ['TestSSID'],
            1: ['82848b96'],
            48: ['0100000fac040100000fac020100000fac028c00']
        }
    
        hash_value = utils.ie_fingerprint_hash(ies)
    
        assert isinstance(hash_value, str)
>       assert len(hash_value) == 32  # MD5-Hash-Länge
E       AssertionError: assert 40 == 32
E        +  where 40 = len('fb3a54a0b7ca1a713fd927a194ff191b7de45566')

pytest/test_utils.py:196: AssertionError
_____________ TestUtilityFunctions.test_ie_fingerprint_hash_empty ______________

self = <test_utils.TestUtilityFunctions object at 0x7f68ca7050>

    def test_ie_fingerprint_hash_empty(self):
        """Test IE-Fingerprint-Hash mit leeren IEs."""
        ies = {}
    
        hash_value = utils.ie_fingerprint_hash(ies)
    
>       assert hash_value is None or hash_value == ""
E       AssertionError: assert ('da39a3ee5e6b4b0d3255bfef95601890afd80709' is None or 'da39a3ee5e6b...01890afd80709' == ''
E         
E         + da39a3ee5e6b4b0d3255bfef95601890afd80709)

pytest/test_utils.py:205: AssertionError
_________________ TestConfigFunctions.test_load_config_default _________________

self = <test_utils.TestConfigFunctions object at 0x7f68ca7e90>

    def test_load_config_default(self):
        """Test Konfigurations-Laden (Standard)."""
>       config_data = utils.load_config()
E       TypeError: load_config() missing 1 required positional argument: 'profile'

pytest/test_utils.py:226: TypeError
____________ TestConfigFunctions.test_load_config_specific_profile _____________

self = <test_utils.TestConfigFunctions object at 0x7f68ab44d0>

    def test_load_config_specific_profile(self):
        """Test Konfigurations-Laden (spezifisches Profil)."""
        # Erstelle temporäre Konfigurationsdatei
        test_config = {
            "capture": {"interface": "test0", "duration": 60},
            "database": {"path": "test.db"}
        }
    
        with tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False) as f:
            yaml.dump(test_config, f)
            config_path = f.name
    
        try:
>           with patch('wlan_tool.utils.CONFIG_PATH', config_path):

pytest/test_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f60dddf90>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'wlan_tool.utils' from '/home/pi/hacking/wlan_tool/utils.py'> does not have the attribute 'CONFIG_PATH'

../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1419: AttributeError
______________ TestConfigFunctions.test_load_config_missing_file _______________

self = <test_utils.TestConfigFunctions object at 0x7f68ab4ad0>

    def test_load_config_missing_file(self):
        """Test Konfigurations-Laden (fehlende Datei)."""
>       with patch('wlan_tool.utils.CONFIG_PATH', Path("/nonexistent/config.yaml")):

pytest/test_utils.py:255: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f604ced50>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'wlan_tool.utils' from '/home/pi/hacking/wlan_tool/utils.py'> does not have the attribute 'CONFIG_PATH'

../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1419: AttributeError
________________ TestEdgeCases.test_ie_fingerprint_hash_unicode ________________

self = <test_utils.TestEdgeCases object at 0x7f68ab7650>

    def test_ie_fingerprint_hash_unicode(self):
        """Test IE-Fingerprint-Hash mit Unicode-Daten."""
        ies = {0: ['TestSSID_äöü']}  # Unicode-Zeichen
    
        hash_value = utils.ie_fingerprint_hash(ies)
    
        assert isinstance(hash_value, str)
>       assert len(hash_value) == 32
E       AssertionError: assert 40 == 32
E        +  where 40 = len('758ed0819e647ff1683744b0bc9b1ff7470f6d37')

pytest/test_utils.py:356: AssertionError
_____________ TestEdgeCases.test_config_loading_with_invalid_yaml ______________

self = <test_utils.TestEdgeCases object at 0x7f68ca5c10>

    def test_config_loading_with_invalid_yaml(self):
        """Test Konfigurations-Laden mit ungültigem YAML."""
        invalid_yaml = "invalid: yaml: content: ["
    
        with tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False) as f:
            f.write(invalid_yaml)
            config_path = f.name
    
        try:
>           with patch('wlan_tool.utils.CONFIG_PATH', config_path):

pytest/test_utils.py:378: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f5c4ffb90>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'wlan_tool.utils' from '/home/pi/hacking/wlan_tool/utils.py'> does not have the attribute 'CONFIG_PATH'

../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1419: AttributeError
__________ TestEndToEndWorkflow.test_complete_wifi_analysis_workflow ___________

self = <test_end_to_end.TestEndToEndWorkflow object at 0x7f6868f1d0>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]
temp_dir = PosixPath('/tmp/tmpova_xe25')

    @pytest.mark.integration
    @pytest.mark.slow
    def test_complete_wifi_analysis_workflow(self, large_dataset, temp_dir):
        """Test des kompletten WLAN-Analyse-Workflows."""
        # 1. Datenverarbeitung
        processor = WiFiDataProcessor()
        processed_data = processor.process_data(large_dataset)
    
        assert len(processed_data) == len(large_dataset)
        assert "processed_timestamp" in processed_data.columns
    
        # 2. Feature-Extraktion
        extractor = FeatureExtractor()
        features = extractor.extract_features(processed_data)
    
        assert features.shape[0] == len(processed_data)
        assert features.shape[1] > 0
    
        # 3. Clustering-Analyse
        analyzer = ClusteringAnalyzer()
>       labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)

tests/integration/test_end_to_end.py:42: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1064: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1446: in fit
    X = validate_data(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2944: in validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1107: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:120: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[-1.15579349,  0.        ,  0.        , ...,  0.        ,
         0.15614176, -0.97725852],
       [-1.1557934...176, -0.97725852],
       [ 1.35680105,  0.        ,  0.        , ...,  0.        ,
         0.15614176,  1.02327069]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:169: ValueError
____________ TestEndToEndWorkflow.test_plugin_integration_workflow _____________

self = <test_end_to_end.TestEndToEndWorkflow object at 0x7f67bfedd0>
sample_wifi_data =               timestamp device_id  ...  packet_count  bytes_transferred
0   2024-01-01 00:00:00  device_3  ...        ...15         206.754596
999 2024-01-01 16:39:00  device_1  ...           103         554.365485

[1000 rows x 11 columns]
temp_dir = PosixPath('/tmp/tmplcdg8ehg')

    @pytest.mark.integration
    def test_plugin_integration_workflow(self, sample_wifi_data, temp_dir):
        """Test der Plugin-Integration im Workflow."""
        from plugins import load_all_plugins
    
        # Plugins laden
        plugin_dir = Path("plugins")
        plugins = load_all_plugins(plugin_dir)
    
        assert len(plugins) > 0
    
        # Features extrahieren
        extractor = FeatureExtractor()
        features = extractor.extract_features(sample_wifi_data)
    
        # Jedes Plugin testen
        for plugin in plugins:
            # Plugin-Dependencies prüfen
>           if not plugin.validate_dependencies():
E           AttributeError: 'str' object has no attribute 'validate_dependencies'

tests/integration/test_end_to_end.py:101: AttributeError
----------------------------- Captured stdout call -----------------------------
2025-10-19 11:18:30,956 | INFO     | Plugin 'Advanced Clustering' v1.0.0 geladen
2025-10-19 11:18:30,960 | INFO     | Plugin 'Ensemble Models' v1.0.0 geladen
2025-10-19 11:18:30,962 | WARNING  | Dependencies ['umap-learn'] für Plugin 'UMAP Plot' nicht verfügbar
2025-10-19 11:18:30,962 | WARNING  | Plugin umap_plot hat fehlende Dependencies
2025-10-19 11:18:30,963 | INFO     | Plugin 'Sankey Diagram' v1.0.0 geladen
2025-10-19 11:18:30,965 | WARNING  | PyTorch oder Gym nicht verfügbar: No module named 'gym'
2025-10-19 11:18:30,970 | WARNING  | Dependencies ['gym'] für Plugin 'Reinforcement Learning' nicht verfügbar
2025-10-19 11:18:30,970 | WARNING  | Plugin reinforcement_learning hat fehlende Dependencies
2025-10-19 11:18:30,971 | INFO     | Plugin 'Example_Plugin' v1.0.0 geladen
------------------------------ Captured log call -------------------------------
INFO     plugins:__init__.py:120 Plugin 'Advanced Clustering' v1.0.0 geladen
INFO     plugins:__init__.py:120 Plugin 'Ensemble Models' v1.0.0 geladen
WARNING  plugins:__init__.py:68 Dependencies ['umap-learn'] für Plugin 'UMAP Plot' nicht verfügbar
WARNING  plugins:__init__.py:97 Plugin umap_plot hat fehlende Dependencies
INFO     plugins:__init__.py:120 Plugin 'Sankey Diagram' v1.0.0 geladen
WARNING  root:plugin.py:28 PyTorch oder Gym nicht verfügbar: No module named 'gym'
WARNING  plugins:__init__.py:68 Dependencies ['gym'] für Plugin 'Reinforcement Learning' nicht verfügbar
WARNING  plugins:__init__.py:97 Plugin reinforcement_learning hat fehlende Dependencies
INFO     plugins:__init__.py:120 Plugin 'Example_Plugin' v1.0.0 geladen
_____________ TestEndToEndWorkflow.test_data_pipeline_with_file_io _____________

self = <test_end_to_end.TestEndToEndWorkflow object at 0x7f67bff4d0>
temp_dir = PosixPath('/tmp/tmpl3bxbnvv')

    @pytest.mark.integration
    def test_data_pipeline_with_file_io(self, temp_dir):
        """Test der Datenpipeline mit Datei-I/O."""
        # Test-Daten generieren
        n_samples = 1000
        test_data = pd.DataFrame(
            {
                "timestamp": pd.date_range(
                    "2024-01-01", periods=n_samples, freq="1min"
                ),
                "device_id": np.random.choice(
                    ["device_1", "device_2", "device_3"], n_samples
                ),
                "signal_strength": np.random.normal(-50, 10, n_samples),
                "frequency": np.random.choice([2.4, 5.0], n_samples),
                "channel": np.random.randint(1, 14, n_samples),
                "mac_address": [f"00:11:22:33:44:{i:02x}" for i in range(n_samples)],
                "ssid": np.random.choice(
                    ["WiFi_Home", "WiFi_Office", "Public_WiFi"], n_samples
                ),
                "encryption": np.random.choice(["WPA2", "WPA3", "Open"], n_samples),
                "data_rate": np.random.normal(54, 10, n_samples),
                "packet_count": np.random.poisson(100, n_samples),
                "bytes_transferred": np.random.exponential(1000, n_samples),
            }
        )
    
        # 1. Daten in CSV speichern
        input_file = temp_dir / "input_data.csv"
        test_data.to_csv(input_file, index=False)
    
        # 2. Daten laden und verarbeiten
        loaded_data = pd.read_csv(input_file)
        processor = WiFiDataProcessor()
        processed_data = processor.process_data(loaded_data)
    
        # 3. Features extrahieren
        extractor = FeatureExtractor()
        features = extractor.extract_features(processed_data)
    
        # 4. Clustering
        analyzer = ClusteringAnalyzer()
>       labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=3)

tests/integration/test_end_to_end.py:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1064: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1446: in fit
    X = validate_data(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2944: in validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1107: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:120: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[-1.62859019,  0.        ,  0.        , ...,  0.        ,
         0.        , -0.9900495 ],
       [-1.6285901...   ,  1.0100505 ],
       [ 1.69506325,  0.        ,  0.        , ...,  0.        ,
         0.        ,  1.0100505 ]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:169: ValueError
____________ TestEndToEndWorkflow.test_error_handling_and_recovery _____________

self = <test_end_to_end.TestEndToEndWorkflow object at 0x7f67bffc10>
temp_dir = PosixPath('/tmp/tmp_racxm3u')

    @pytest.mark.integration
    def test_error_handling_and_recovery(self, temp_dir):
        """Test der Fehlerbehandlung und Wiederherstellung."""
        processor = WiFiDataProcessor()
        extractor = FeatureExtractor()
        analyzer = ClusteringAnalyzer()
    
        # Test mit ungültigen Daten
        invalid_data = pd.DataFrame(
            {
                "timestamp": ["invalid_date", "2024-01-01", "2024-01-02"],
                "signal_strength": [np.nan, -50, -60],
                "frequency": [1.0, 2.4, 5.0],  # Ungültige Frequenz
                "device_id": ["device_1", "device_2", "device_3"],
                "mac_address": [
                    "00:11:22:33:44:01",
                    "00:11:22:33:44:02",
                    "00:11:22:33:44:03",
                ],
                "ssid": ["WiFi_Home", "WiFi_Office", "Public_WiFi"],
                "encryption": ["WPA2", "WPA3", "Open"],
                "channel": [1, 6, 11],
                "data_rate": [54, 100, 54],
                "packet_count": [100, 200, 150],
                "bytes_transferred": [1000, 2000, 1500],
            }
        )
    
        # Verarbeitung sollte Fehler behandeln
        try:
>           processed_data = processor.process_data(invalid_data)

tests/integration/test_end_to_end.py:203: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/data_processing/wifi_processor.py:45: in process_data
    processed_data['processed_timestamp'] = pd.to_datetime(processed_data['timestamp'])
.venv/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:1067: in to_datetime
    values = convert_listlike(arg._values, format)
.venv/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:435: in _convert_listlike_datetimes
    result, tz_parsed = objects_to_datetime64(
.venv/lib/python3.11/site-packages/pandas/core/arrays/datetimes.py:2398: in objects_to_datetime64
    result, tz_parsed = tslib.array_to_datetime(
tslib.pyx:414: in pandas._libs.tslib.array_to_datetime
    ???
tslib.pyx:596: in pandas._libs.tslib.array_to_datetime
    ???
tslib.pyx:553: in pandas._libs.tslib.array_to_datetime
    ???
conversion.pyx:641: in pandas._libs.tslibs.conversion.convert_str_to_tsobject
    ???
parsing.pyx:336: in pandas._libs.tslibs.parsing.parse_datetime_string
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   pandas._libs.tslibs.parsing.DateParseError: Unknown datetime string format, unable to parse: invalid_date, at position 0

parsing.pyx:666: DateParseError

During handling of the above exception, another exception occurred:

self = <test_end_to_end.TestEndToEndWorkflow object at 0x7f67bffc10>
temp_dir = PosixPath('/tmp/tmp_racxm3u')

    @pytest.mark.integration
    def test_error_handling_and_recovery(self, temp_dir):
        """Test der Fehlerbehandlung und Wiederherstellung."""
        processor = WiFiDataProcessor()
        extractor = FeatureExtractor()
        analyzer = ClusteringAnalyzer()
    
        # Test mit ungültigen Daten
        invalid_data = pd.DataFrame(
            {
                "timestamp": ["invalid_date", "2024-01-01", "2024-01-02"],
                "signal_strength": [np.nan, -50, -60],
                "frequency": [1.0, 2.4, 5.0],  # Ungültige Frequenz
                "device_id": ["device_1", "device_2", "device_3"],
                "mac_address": [
                    "00:11:22:33:44:01",
                    "00:11:22:33:44:02",
                    "00:11:22:33:44:03",
                ],
                "ssid": ["WiFi_Home", "WiFi_Office", "Public_WiFi"],
                "encryption": ["WPA2", "WPA3", "Open"],
                "channel": [1, 6, 11],
                "data_rate": [54, 100, 54],
                "packet_count": [100, 200, 150],
                "bytes_transferred": [1000, 2000, 1500],
            }
        )
    
        # Verarbeitung sollte Fehler behandeln
        try:
            processed_data = processor.process_data(invalid_data)
            # Wenn erfolgreich, sollten ungültige Daten bereinigt sein
            assert len(processed_data) <= len(invalid_data)
        except Exception as e:
            # Fehler sollten informativ sein
>           assert "Invalid" in str(e) or "Missing" in str(e)
E           AssertionError: assert ('Invalid' in 'Unknown datetime string format, unable to parse: invalid_date, at position 0' or 'Missing' in 'Unknown datetime string format, unable to parse: invalid_date, at position 0')
E            +  where 'Unknown datetime string format, unable to parse: invalid_date, at position 0' = str(DateParseError('Unknown datetime string format, unable to parse: invalid_date, at position 0'))
E            +  and   'Unknown datetime string format, unable to parse: invalid_date, at position 0' = str(DateParseError('Unknown datetime string format, unable to parse: invalid_date, at position 0'))

tests/integration/test_end_to_end.py:208: AssertionError
_______________ TestEndToEndWorkflow.test_performance_under_load _______________

self = <test_end_to_end.TestEndToEndWorkflow object at 0x7f67c04350>
temp_dir = PosixPath('/tmp/tmpamcljjbh')

    @pytest.mark.integration
    def test_performance_under_load(self, temp_dir):
        """Test der Performance unter Last."""
        import time
    
        # Große Datenmenge
        n_samples = 50000
        large_data = pd.DataFrame(
            {
                "timestamp": pd.date_range("2024-01-01", periods=n_samples, freq="1s"),
                "device_id": np.random.choice(
                    [f"device_{i}" for i in range(100)], n_samples
                ),
                "signal_strength": np.random.normal(-50, 10, n_samples),
                "frequency": np.random.choice([2.4, 5.0], n_samples),
                "channel": np.random.randint(1, 14, n_samples),
                "mac_address": [f"00:11:22:33:44:{i:02x}" for i in range(n_samples)],
                "ssid": np.random.choice(
                    ["WiFi_Home", "WiFi_Office", "Public_WiFi"], n_samples
                ),
                "encryption": np.random.choice(["WPA2", "WPA3", "Open"], n_samples),
                "data_rate": np.random.normal(54, 10, n_samples),
                "packet_count": np.random.poisson(100, n_samples),
                "bytes_transferred": np.random.exponential(1000, n_samples),
            }
        )
    
        processor = WiFiDataProcessor()
        extractor = FeatureExtractor()
        analyzer = ClusteringAnalyzer()
    
        # Performance-Messung
        start_time = time.time()
    
        # Verarbeitung
        processed_data = processor.process_data(large_data)
        features = extractor.extract_features(processed_data)
>       labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)

tests/integration/test_end_to_end.py:259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1064: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1446: in fit
    X = validate_data(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2944: in validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1107: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:120: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[-1.6100241 ,  0.        ,  0.        , ...,  0.        ,
         0.        , -1.00344594],
       [-1.6100241...   ,  0.9965659 ],
       [ 1.63599223,  0.        ,  0.        , ...,  0.        ,
         0.        , -1.00344594]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:169: ValueError
_______________ TestEndToEndWorkflow.test_concurrent_processing ________________

self = <test_end_to_end.TestEndToEndWorkflow object at 0x7f67c04a50>
temp_dir = PosixPath('/tmp/tmpvx28e4wq')

    @pytest.mark.integration
    def test_concurrent_processing(self, temp_dir):
        """Test der parallelen Verarbeitung."""
        import threading
        from concurrent.futures import ThreadPoolExecutor
    
        def process_chunk(chunk_data):
            """Verarbeitet einen Daten-Chunk."""
            processor = WiFiDataProcessor()
            extractor = FeatureExtractor()
            analyzer = ClusteringAnalyzer()
    
            processed_data = processor.process_data(chunk_data)
            features = extractor.extract_features(processed_data)
            labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=3)
    
            return {
                "chunk_id": threading.current_thread().ident,
                "n_samples": len(chunk_data),
                "n_clusters": len(np.unique(labels)),
            }
    
        # Daten in Chunks aufteilen
        n_chunks = 4
        chunk_size = 1000
        n_samples = n_chunks * chunk_size
    
        test_data = pd.DataFrame(
            {
                "timestamp": pd.date_range(
                    "2024-01-01", periods=n_samples, freq="1min"
                ),
                "device_id": np.random.choice(
                    [f"device_{i}" for i in range(50)], n_samples
                ),
                "signal_strength": np.random.normal(-50, 10, n_samples),
                "frequency": np.random.choice([2.4, 5.0], n_samples),
                "channel": np.random.randint(1, 14, n_samples),
                "mac_address": [f"00:11:22:33:44:{i:02x}" for i in range(n_samples)],
                "ssid": np.random.choice(
                    ["WiFi_Home", "WiFi_Office", "Public_WiFi"], n_samples
                ),
                "encryption": np.random.choice(["WPA2", "WPA3", "Open"], n_samples),
                "data_rate": np.random.normal(54, 10, n_samples),
                "packet_count": np.random.poisson(100, n_samples),
                "bytes_transferred": np.random.exponential(1000, n_samples),
            }
        )
    
        chunks = [
            test_data.iloc[i * chunk_size : (i + 1) * chunk_size]
            for i in range(n_chunks)
        ]
    
        # Parallele Verarbeitung
        with ThreadPoolExecutor(max_workers=n_chunks) as executor:
            futures = [executor.submit(process_chunk, chunk) for chunk in chunks]
>           results = [future.result() for future in futures]

tests/integration/test_end_to_end.py:328: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/integration/test_end_to_end.py:328: in <listcomp>
    results = [future.result() for future in futures]
../.pyenv/versions/3.11.9/lib/python3.11/concurrent/futures/_base.py:456: in result
    return self.__get_result()
../.pyenv/versions/3.11.9/lib/python3.11/concurrent/futures/_base.py:401: in __get_result
    raise self._exception
../.pyenv/versions/3.11.9/lib/python3.11/concurrent/futures/thread.py:58: in run
    result = self.fn(*self.args, **self.kwargs)
tests/integration/test_end_to_end.py:285: in process_chunk
    labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=3)
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1064: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1446: in fit
    X = validate_data(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2944: in validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1107: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:120: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[-1.62859019,  0.        ,  0.        , ...,  0.11020775,
        -0.38663966, -1.06832936],
       [-1.6285901...14 ,  0.93604092],
       [ 1.69506325,  0.        ,  0.        , ...,  0.11020775,
         0.31126587,  0.93604092]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:169: ValueError
_______________ TestClusteringBenchmarks.test_kmeans_performance _______________

self = <test_benchmarks.TestClusteringBenchmarks object at 0x7f67c1d1d0>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f605c13d0>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_kmeans_performance(self, benchmark, large_dataset):
        """Benchmark für K-Means Clustering."""
        analyzer = ClusteringAnalyzer()
    
        # Features extrahieren
        feature_extractor = FeatureExtractor()
        features = feature_extractor.extract_features(large_dataset)
    
        def clustering_func():
            return analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)
    
>       result = benchmark(clustering_func)

tests/performance/test_benchmarks.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:156: in __call__
    return self._raw(function_to_benchmark, *args, **kwargs)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:180: in _raw
    duration, iterations, loops_range = self._calibrate_timer(runner)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:318: in _calibrate_timer
    duration = runner(loops_range)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:109: in runner
    function_to_benchmark(*args, **kwargs)
tests/performance/test_benchmarks.py:29: in clustering_func
    return analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1064: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1446: in fit
    X = validate_data(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2944: in validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1107: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:120: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176, -0.97725852],
       [ 0.       ...176, -0.97725852],
       [ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176,  1.02327069]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:169: ValueError
_______________ TestClusteringBenchmarks.test_dbscan_performance _______________

self = <test_benchmarks.TestClusteringBenchmarks object at 0x7f67c1d7d0>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f600bb6d0>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_dbscan_performance(self, benchmark, large_dataset):
        """Benchmark für DBSCAN Clustering."""
        analyzer = ClusteringAnalyzer()
    
        feature_extractor = FeatureExtractor()
        features = feature_extractor.extract_features(large_dataset)
    
        def clustering_func():
            return analyzer.cluster_data(
                features, algorithm="dbscan", eps=0.5, min_samples=5
            )
    
>       result = benchmark(clustering_func)

tests/performance/test_benchmarks.py:51: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:156: in __call__
    return self._raw(function_to_benchmark, *args, **kwargs)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:180: in _raw
    duration, iterations, loops_range = self._calibrate_timer(runner)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:318: in _calibrate_timer
    duration = runner(loops_range)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:109: in runner
    function_to_benchmark(*args, **kwargs)
tests/performance/test_benchmarks.py:47: in clustering_func
    return analyzer.cluster_data(
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1064: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1446: in fit
    X = validate_data(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2944: in validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1107: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:120: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176, -0.97725852],
       [ 0.       ...176, -0.97725852],
       [ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176,  1.02327069]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:169: ValueError
____________ TestClusteringBenchmarks.test_hierarchical_performance ____________

self = <test_benchmarks.TestClusteringBenchmarks object at 0x7f67bfea90>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f607005d0>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_hierarchical_performance(self, benchmark, large_dataset):
        """Benchmark für Hierarchical Clustering."""
        analyzer = ClusteringAnalyzer()
    
        feature_extractor = FeatureExtractor()
        features = feature_extractor.extract_features(large_dataset)
    
        def clustering_func():
            return analyzer.cluster_data(
                features, algorithm="hierarchical", n_clusters=5
            )
    
>       result = benchmark(clustering_func)

tests/performance/test_benchmarks.py:71: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:156: in __call__
    return self._raw(function_to_benchmark, *args, **kwargs)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:180: in _raw
    duration, iterations, loops_range = self._calibrate_timer(runner)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:318: in _calibrate_timer
    duration = runner(loops_range)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:109: in runner
    function_to_benchmark(*args, **kwargs)
tests/performance/test_benchmarks.py:67: in clustering_func
    return analyzer.cluster_data(
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1064: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1446: in fit
    X = validate_data(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2944: in validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1107: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:120: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176, -0.97725852],
       [ 0.       ...176, -0.97725852],
       [ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176,  1.02327069]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:169: ValueError
_____________ TestClusteringBenchmarks.test_clustering_scalability _____________

self = <test_benchmarks.TestClusteringBenchmarks object at 0x7f67c1dd10>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f5fe943d0>

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_clustering_scalability(self, benchmark):
        """Test Skalierbarkeit mit verschiedenen Datengrößen."""
        sizes = [1000, 5000, 10000, 20000]
        times = []
    
        for size in sizes:
            # Generiere Test-Daten
            X = np.random.randn(size, 20)
            analyzer = ClusteringAnalyzer()
    
            def clustering_func():
                return analyzer.cluster_data(X, algorithm="kmeans", n_clusters=5)
    
            result = benchmark(clustering_func)
>           times.append(result.stats.mean)
E           AttributeError: 'numpy.ndarray' object has no attribute 'stats'

tests/performance/test_benchmarks.py:93: AttributeError
________ TestDataProcessingBenchmarks.test_data_processing_performance _________

self = <test_benchmarks.TestDataProcessingBenchmarks object at 0x7f67c1e110>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f5fe80450>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_data_processing_performance(self, benchmark, large_dataset):
        """Benchmark für Datenverarbeitung."""
        processor = WiFiDataProcessor()
    
        def processing_func():
            return processor.process_data(large_dataset)
    
        result = benchmark(processing_func)
    
        # Datenverarbeitung sollte schnell sein
>       assert result.stats.mean < 1.0

tests/performance/test_benchmarks.py:121: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self =                timestamp  device_id  ...  bytes_transferred  processed_timestamp
0    2024-01-01 00:00:00  device_51  ...01 02:46:38
9999 2024-01-01 02:46:39   device_7  ...         594.132395  2024-01-01 02:46:39

[10000 rows x 12 columns]
name = 'stats'

    @final
    def __getattr__(self, name: str):
        """
        After regular attribute access, try looking up the name
        This allows simpler access to columns for interactive use.
        """
        # Note: obj.x will always call obj.__getattribute__('x') prior to
        # calling obj.__getattr__('x').
        if (
            name not in self._internal_names_set
            and name not in self._metadata
            and name not in self._accessors
            and self._info_axis._can_hold_identifiers_and_holds_name(name)
        ):
            return self[name]
>       return object.__getattribute__(self, name)
E       AttributeError: 'DataFrame' object has no attribute 'stats'

.venv/lib/python3.11/site-packages/pandas/core/generic.py:6293: AttributeError
_______ TestDataProcessingBenchmarks.test_feature_extraction_performance _______

self = <test_benchmarks.TestDataProcessingBenchmarks object at 0x7f67c1e490>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f61979410>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_feature_extraction_performance(self, benchmark, large_dataset):
        """Benchmark für Feature-Extraktion."""
        extractor = FeatureExtractor()
    
        def extraction_func():
            return extractor.extract_features(large_dataset)
    
        result = benchmark(extraction_func)
    
        # Feature-Extraktion sollte effizient sein
>       assert result.stats.mean < 2.0
E       AttributeError: 'numpy.ndarray' object has no attribute 'stats'

tests/performance/test_benchmarks.py:136: AttributeError
________ TestDataProcessingBenchmarks.test_feature_scaling_performance _________

self = <test_benchmarks.TestDataProcessingBenchmarks object at 0x7f67c1e990>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f5c38e0d0>

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_feature_scaling_performance(self, benchmark):
        """Benchmark für Feature-Skalierung."""
        extractor = FeatureExtractor()
    
        # Große Feature-Matrix
        features = np.random.randn(50000, 100)
    
        def scaling_func():
            return extractor.scale_features(features)
    
        result = benchmark(scaling_func)
    
        # Skalierung sollte sehr schnell sein
>       assert result.stats.mean < 0.5
E       AttributeError: 'numpy.ndarray' object has no attribute 'stats'

tests/performance/test_benchmarks.py:154: AttributeError
_________ TestClassificationBenchmarks.test_random_forest_performance __________

self = <test_benchmarks.TestClassificationBenchmarks object at 0x7f67c1f190>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f68d80190>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_random_forest_performance(self, benchmark, large_dataset):
        """Benchmark für Random Forest Klassifikation."""
        classifier = DeviceClassifier()
    
        # Features und Labels generieren
        feature_extractor = FeatureExtractor()
        features = feature_extractor.extract_features(large_dataset)
        labels = np.random.randint(0, 5, len(features))
    
        def classification_func():
            classifier.train(features, labels)
            return classifier.predict(features)
    
        result = benchmark(classification_func)
    
        # Random Forest sollte effizient sein
>       assert result.stats.mean < 3.0
E       AttributeError: 'numpy.ndarray' object has no attribute 'stats'

tests/performance/test_benchmarks.py:179: AttributeError
______________ TestClassificationBenchmarks.test_svm_performance _______________

self = <test_benchmarks.TestClassificationBenchmarks object at 0x7f67c1f790>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f60520d50>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_svm_performance(self, benchmark, large_dataset):
        """Benchmark für SVM Klassifikation."""
        classifier = DeviceClassifier(algorithm="svm")
    
        feature_extractor = FeatureExtractor()
        features = feature_extractor.extract_features(large_dataset)
        labels = np.random.randint(0, 5, len(features))
    
        def classification_func():
            classifier.train(features, labels)
            return classifier.predict(features)
    
>       result = benchmark(classification_func)

tests/performance/test_benchmarks.py:196: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:156: in __call__
    return self._raw(function_to_benchmark, *args, **kwargs)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:180: in _raw
    duration, iterations, loops_range = self._calibrate_timer(runner)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:318: in _calibrate_timer
    duration = runner(loops_range)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:109: in runner
    function_to_benchmark(*args, **kwargs)
tests/performance/test_benchmarks.py:193: in classification_func
    classifier.train(features, labels)
wlan_tool/analysis/device_classification.py:64: in train
    self.model.fit(X, y)
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/svm/_base.py:196: in fit
    X, y = validate_data(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2961: in validate_data
    X, y = check_X_y(X, y, **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1370: in check_X_y
    X = check_array(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1107: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:120: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176, -0.97725852],
       [ 0.       ...176, -0.97725852],
       [ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176,  1.02327069]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           SVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:169: ValueError
______________ TestMemoryBenchmarks.test_memory_usage_clustering _______________

self = <test_benchmarks.TestMemoryBenchmarks object at 0x7f67c1ff90>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f8b07f210>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    @pytest.mark.memory
    def test_memory_usage_clustering(self, benchmark, large_dataset):
        """Benchmark für Speichernutzung beim Clustering."""
        analyzer = ClusteringAnalyzer()
        feature_extractor = FeatureExtractor()
    
        def memory_intensive_func():
            # Features extrahieren
            features = feature_extractor.extract_features(large_dataset)
    
            # Clustering durchführen
            labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)
    
            # Zusätzliche Berechnungen
            unique_labels = np.unique(labels)
            cluster_sizes = [np.sum(labels == label) for label in unique_labels]
    
            return {
                "n_clusters": len(unique_labels),
                "cluster_sizes": cluster_sizes,
                "features_shape": features.shape,
            }
    
>       result = benchmark(memory_intensive_func)

tests/performance/test_benchmarks.py:231: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:156: in __call__
    return self._raw(function_to_benchmark, *args, **kwargs)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:180: in _raw
    duration, iterations, loops_range = self._calibrate_timer(runner)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:318: in _calibrate_timer
    duration = runner(loops_range)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:109: in runner
    function_to_benchmark(*args, **kwargs)
tests/performance/test_benchmarks.py:219: in memory_intensive_func
    labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1064: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1446: in fit
    X = validate_data(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2944: in validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1107: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:120: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176, -0.97725852],
       [ 0.       ...176, -0.97725852],
       [ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176,  1.02327069]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:169: ValueError
_____________ TestMemoryBenchmarks.test_memory_usage_large_dataset _____________

self = <test_benchmarks.TestMemoryBenchmarks object at 0x7f67c24610>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f6051b650>

    @pytest.mark.benchmark
    @pytest.mark.performance
    @pytest.mark.memory
    def test_memory_usage_large_dataset(self, benchmark):
        """Benchmark für Speichernutzung mit sehr großen Datensätzen."""
        # Sehr großer Datensatz
        n_samples = 100000
        n_features = 50
    
        def large_dataset_func():
            # Große Daten generieren
            X = np.random.randn(n_samples, n_features)
    
            # Clustering mit reduzierter Komplexität
            from sklearn.cluster import MiniBatchKMeans
    
            kmeans = MiniBatchKMeans(n_clusters=10, batch_size=1000)
            labels = kmeans.fit_predict(X)
    
            return {
                "n_samples": n_samples,
                "n_features": n_features,
                "n_clusters": len(np.unique(labels)),
            }
    
        result = benchmark(large_dataset_func)
    
        # Auch bei großen Datensätzen sollte es in angemessener Zeit laufen
>       assert result.stats.mean < 10.0
E       AttributeError: 'dict' object has no attribute 'stats'

tests/performance/test_benchmarks.py:265: AttributeError
________ TestConcurrentBenchmarks.test_parallel_processing_performance _________

self = <test_benchmarks.TestConcurrentBenchmarks object at 0x7f67c24dd0>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f6051ae90>

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_parallel_processing_performance(self, benchmark):
        """Benchmark für parallele Verarbeitung."""
        import threading
        from concurrent.futures import ThreadPoolExecutor
    
        def process_chunk(chunk_data):
            """Verarbeitet einen Daten-Chunk."""
            analyzer = ClusteringAnalyzer()
            return analyzer.cluster_data(chunk_data, algorithm="kmeans", n_clusters=3)
    
        def parallel_processing_func():
            # Daten in Chunks aufteilen
            n_chunks = 4
            chunk_size = 2500
            X = np.random.randn(n_chunks * chunk_size, 20)
            chunks = [X[i * chunk_size : (i + 1) * chunk_size] for i in range(n_chunks)]
    
            # Parallele Verarbeitung
            with ThreadPoolExecutor(max_workers=n_chunks) as executor:
                futures = [executor.submit(process_chunk, chunk) for chunk in chunks]
                results = [future.result() for future in futures]
    
            return results
    
        result = benchmark(parallel_processing_func)
    
        # Parallele Verarbeitung sollte effizienter sein
>       assert result.stats.mean < 3.0
E       AttributeError: 'list' object has no attribute 'stats'

tests/performance/test_benchmarks.py:301: AttributeError
__________________ TestIOBenchmarks.test_file_io_performance ___________________

self = <test_benchmarks.TestIOBenchmarks object at 0x7f67c25550>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f5d0dda50>
temp_dir = PosixPath('/tmp/tmpih9ekda_')

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_file_io_performance(self, benchmark, temp_dir):
        """Benchmark für Datei-I/O."""
        import pickle
    
        # Große Daten generieren
        large_data = np.random.randn(10000, 50)
        file_path = temp_dir / "test_data.pkl"
    
        def io_func():
            # Speichern
            with open(file_path, "wb") as f:
                pickle.dump(large_data, f)
    
            # Laden
            with open(file_path, "rb") as f:
                loaded_data = pickle.load(f)
    
            return loaded_data.shape
    
        result = benchmark(io_func)
    
        # I/O sollte schnell sein
>       assert result.stats.mean < 1.0
E       AttributeError: 'tuple' object has no attribute 'stats'

tests/performance/test_benchmarks.py:332: AttributeError
___________________ TestIOBenchmarks.test_csv_io_performance ___________________

self = <test_benchmarks.TestIOBenchmarks object at 0x7f67c25b50>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f5d0e1ed0>
temp_dir = PosixPath('/tmp/tmpngxekyyj')
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_csv_io_performance(self, benchmark, temp_dir, large_dataset):
        """Benchmark für CSV-I/O."""
        csv_path = temp_dir / "test_data.csv"
    
        def csv_io_func():
            # Speichern
            large_dataset.to_csv(csv_path, index=False)
    
            # Laden
            loaded_data = pd.read_csv(csv_path)
    
            return loaded_data.shape
    
        result = benchmark(csv_io_func)
    
        # CSV-I/O kann langsamer sein
>       assert result.stats.mean < 2.0
E       AttributeError: 'tuple' object has no attribute 'stats'

tests/performance/test_benchmarks.py:353: AttributeError
_________________ TestMemoryUsage.test_memory_usage_clustering _________________

self = <test_memory_profiling.TestMemoryUsage object at 0x7f67c53190>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.memory
    @pytest.mark.performance
    def test_memory_usage_clustering(self, large_dataset):
        """Test Speichernutzung beim Clustering."""
        process = psutil.Process(os.getpid())
        memory_before = process.memory_info().rss / 1024 / 1024
    
        analyzer = ClusteringAnalyzer()
        feature_extractor = FeatureExtractor()
    
        # Features extrahieren
        features = feature_extractor.extract_features(large_dataset)
        memory_after_features = process.memory_info().rss / 1024 / 1024
    
        # Clustering durchführen
>       labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)

tests/performance/test_memory_profiling.py:77: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1064: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1446: in fit
    X = validate_data(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2944: in validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1107: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:120: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176, -0.97725852],
       [ 0.       ...176, -0.97725852],
       [ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176,  1.02327069]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:169: ValueError
______________ TestMemoryProfiling.test_detailed_memory_profiling ______________

self = <test_memory_profiling.TestMemoryProfiling object at 0x7f67c60610>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.memory
    @pytest.mark.performance
    def test_detailed_memory_profiling(self, large_dataset):
        """Detailliertes Memory-Profiling der WLAN-Analyse."""
        from memory_profiler import memory_usage
    
        def analyze_wifi_data():
            """WLAN-Datenanalyse mit Memory-Tracking."""
            processor = WiFiDataProcessor()
            extractor = FeatureExtractor()
            analyzer = ClusteringAnalyzer()
    
            # 1. Daten verarbeiten
            processed_data = processor.process_data(large_dataset)
    
            # 2. Features extrahieren
            features = extractor.extract_features(processed_data)
    
            # 3. Clustering
            labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)
    
            # 4. Ergebnisse zusammenfassen
            unique_labels = np.unique(labels)
            cluster_sizes = [np.sum(labels == label) for label in unique_labels]
    
            return {
                "n_clusters": len(unique_labels),
                "cluster_sizes": cluster_sizes,
                "features_shape": features.shape,
            }
    
        # Memory-Usage während der Ausführung messen
>       mem_usage = memory_usage(analyze_wifi_data, interval=0.1)

tests/performance/test_memory_profiling.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.11/site-packages/memory_profiler.py:379: in memory_usage
    returned = f(*args, **kw)
tests/performance/test_memory_profiling.py:208: in analyze_wifi_data
    labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1064: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1446: in fit
    X = validate_data(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2944: in validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1107: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:120: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[-1.15579349,  0.        ,  0.        , ...,  0.        ,
         0.15614176, -0.97725852],
       [-1.1557934...176, -0.97725852],
       [ 1.35680105,  0.        ,  0.        , ...,  0.        ,
         0.15614176,  1.02327069]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:169: ValueError
__________________ TestDataValidator.test_validate_valid_data __________________

self = <test_data_processing.TestDataValidator object at 0x7f67c75550>
sample_wifi_data =               timestamp device_id  ...  packet_count  bytes_transferred
0   2024-01-01 00:00:00  device_3  ...        ...15         206.754596
999 2024-01-01 16:39:00  device_1  ...           103         554.365485

[1000 rows x 11 columns]

    def test_validate_valid_data(self, sample_wifi_data):
        """Test Validierung gültiger Daten."""
        validator = DataValidator()
        is_valid, errors = validator.validate(sample_wifi_data)
    
>       assert is_valid
E       assert False

tests/unit/test_data_processing.py:178: AssertionError
_____________________ TestClusteringModel.test_fit_kmeans ______________________

self = <test_ml_models.TestClusteringModel object at 0x7f678575d0>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])

    def test_fit_kmeans(self, sample_features):
        """Test K-Means Clustering."""
        model = ClusteringModel(algorithm="kmeans", n_clusters=3)
>       model.fit(sample_features)

tests/unit/test_ml_models.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/clustering_model.py:53: in fit
    self.model = self._create_model()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.clustering_model.ClusteringModel object at 0x7f8ae4a210>
n_clusters = 3

    def _create_model(self, n_clusters: Optional[int] = None) -> Any:
        """Erstellt das Clustering-Modell."""
        if self.algorithm == 'kmeans':
            n_clusters = n_clusters or self.kwargs.get('n_clusters', 5)
>           return KMeans(n_clusters=n_clusters, random_state=42, **self.kwargs)
E           TypeError: sklearn.cluster._kmeans.KMeans() got multiple values for keyword argument 'n_clusters'

wlan_tool/ml_models/clustering_model.py:36: TypeError
__________________ TestClusteringModel.test_predict_after_fit __________________

self = <test_ml_models.TestClusteringModel object at 0x7f67868850>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])

    def test_predict_after_fit(self, sample_features):
        """Test Vorhersage nach Training."""
        model = ClusteringModel(algorithm="kmeans", n_clusters=3)
>       model.fit(sample_features)

tests/unit/test_ml_models.py:52: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/clustering_model.py:53: in fit
    self.model = self._create_model()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.clustering_model.ClusteringModel object at 0x7f60efff90>
n_clusters = 3

    def _create_model(self, n_clusters: Optional[int] = None) -> Any:
        """Erstellt das Clustering-Modell."""
        if self.algorithm == 'kmeans':
            n_clusters = n_clusters or self.kwargs.get('n_clusters', 5)
>           return KMeans(n_clusters=n_clusters, random_state=42, **self.kwargs)
E           TypeError: sklearn.cluster._kmeans.KMeans() got multiple values for keyword argument 'n_clusters'

wlan_tool/ml_models/clustering_model.py:36: TypeError
_________________ TestClusteringModel.test_get_cluster_centers _________________

self = <test_ml_models.TestClusteringModel object at 0x7f67868f90>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])

    def test_get_cluster_centers(self, sample_features):
        """Test Cluster-Zentren abrufen."""
        model = ClusteringModel(algorithm="kmeans", n_clusters=3)
>       model.fit(sample_features)

tests/unit/test_ml_models.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/clustering_model.py:53: in fit
    self.model = self._create_model()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.clustering_model.ClusteringModel object at 0x7f604e5e90>
n_clusters = 3

    def _create_model(self, n_clusters: Optional[int] = None) -> Any:
        """Erstellt das Clustering-Modell."""
        if self.algorithm == 'kmeans':
            n_clusters = n_clusters or self.kwargs.get('n_clusters', 5)
>           return KMeans(n_clusters=n_clusters, random_state=42, **self.kwargs)
E           TypeError: sklearn.cluster._kmeans.KMeans() got multiple values for keyword argument 'n_clusters'

wlan_tool/ml_models/clustering_model.py:36: TypeError
_________________ TestClusteringModel.test_evaluate_clustering _________________

self = <test_ml_models.TestClusteringModel object at 0x7f678696d0>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])

    def test_evaluate_clustering(self, sample_features):
        """Test Clustering-Evaluation."""
        model = ClusteringModel(algorithm="kmeans", n_clusters=3)
>       model.fit(sample_features)

tests/unit/test_ml_models.py:73: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/clustering_model.py:53: in fit
    self.model = self._create_model()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.clustering_model.ClusteringModel object at 0x7f5c742e50>
n_clusters = 3

    def _create_model(self, n_clusters: Optional[int] = None) -> Any:
        """Erstellt das Clustering-Modell."""
        if self.algorithm == 'kmeans':
            n_clusters = n_clusters or self.kwargs.get('n_clusters', 5)
>           return KMeans(n_clusters=n_clusters, random_state=42, **self.kwargs)
E           TypeError: sklearn.cluster._kmeans.KMeans() got multiple values for keyword argument 'n_clusters'

wlan_tool/ml_models/clustering_model.py:36: TypeError
__________________ TestClusteringModel.test_invalid_algorithm __________________

self = <test_ml_models.TestClusteringModel object at 0x7f678571d0>

    def test_invalid_algorithm(self):
        """Test mit ungültigem Algorithmus."""
>       with pytest.raises(ValueError, match="Unsupported algorithm"):
E       Failed: DID NOT RAISE <class 'ValueError'>

tests/unit/test_ml_models.py:86: Failed
______________ TestClusteringModel.test_hyperparameter_validation ______________

self = <test_ml_models.TestClusteringModel object at 0x7f67869bd0>

    def test_hyperparameter_validation(self):
        """Test Hyperparameter-Validierung."""
        # Ungültige n_clusters
>       with pytest.raises(ValueError, match="n_clusters must be positive"):
E       Failed: DID NOT RAISE <class 'ValueError'>

tests/unit/test_ml_models.py:92: Failed
________________ TestClassificationModel.test_cross_validation _________________

self = <test_ml_models.TestClassificationModel object at 0x7f67874a90>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
sample_labels = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])

    def test_cross_validation(self, sample_features, sample_labels):
        """Test Cross-Validation."""
        model = ClassificationModel(algorithm="random_forest", n_estimators=10)
    
>       cv_scores = model.cross_validate(sample_features, sample_labels, cv=3)

tests/unit/test_ml_models.py:177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f6029e850>
X = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
y = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])
cv = 3

    def cross_validate(self, X: np.ndarray, y: np.ndarray, cv: int = 5) -> Dict[str, List[float]]:
        """Führt Cross-Validation durch."""
        if not self.is_fitted:
>           raise ValueError("Model must be fitted first")
E           ValueError: Model must be fitted first

wlan_tool/ml_models/classification_model.py:103: ValueError
_________________ TestEnsembleModel.test_fit_voting_classifier _________________

self = <test_ml_models.TestEnsembleModel object at 0x7f67876090>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
sample_labels = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])

    def test_fit_voting_classifier(self, sample_features, sample_labels):
        """Test Voting Classifier Training."""
        model = EnsembleModel(
            algorithm="voting",
            estimators=[
                ("rf", ClassificationModel(algorithm="random_forest")),
                ("svm", ClassificationModel(algorithm="svm")),
            ],
        )
>       model.fit(sample_features, sample_labels)

tests/unit/test_ml_models.py:215: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/ensemble_model.py:62: in fit
    self.model = self._create_model(estimators=estimators)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.ensemble_model.EnsembleModel object at 0x7f6776e310>
base_estimator = None
estimators = [('rf', <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f6776d650>), ('svm', <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f6776c950>)]

    def _create_model(self, base_estimator=None, estimators=None) -> Any:
        """Erstellt das Ensemble-Modell."""
        if self.algorithm == 'voting':
            if estimators is None:
                raise ValueError("Voting requires estimators list")
>           return VotingClassifier(estimators=estimators, **self.kwargs)
E           TypeError: sklearn.ensemble._voting.VotingClassifier() got multiple values for keyword argument 'estimators'

wlan_tool/ml_models/ensemble_model.py:36: TypeError
______________________ TestEnsembleModel.test_fit_bagging ______________________

self = <test_ml_models.TestEnsembleModel object at 0x7f67876790>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
sample_labels = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])

    def test_fit_bagging(self, sample_features, sample_labels):
        """Test Bagging Training."""
        model = EnsembleModel(
            algorithm="bagging",
            base_estimator=ClassificationModel(algorithm="random_forest"),
            n_estimators=5,
        )
>       model.fit(sample_features, sample_labels)

tests/unit/test_ml_models.py:227: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/ensemble_model.py:67: in fit
    self.model = self._create_model(base_estimator=base_estimator)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.ensemble_model.EnsembleModel object at 0x7f60d5f290>
base_estimator = <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f60d5da90>
estimators = None

    def _create_model(self, base_estimator=None, estimators=None) -> Any:
        """Erstellt das Ensemble-Modell."""
        if self.algorithm == 'voting':
            if estimators is None:
                raise ValueError("Voting requires estimators list")
            return VotingClassifier(estimators=estimators, **self.kwargs)
        elif self.algorithm == 'bagging':
            if base_estimator is None:
                raise ValueError("Bagging requires base_estimator")
>           return BaggingClassifier(base_estimator=base_estimator, **self.kwargs)
E           TypeError: sklearn.ensemble._bagging.BaggingClassifier() got multiple values for keyword argument 'base_estimator'

wlan_tool/ml_models/ensemble_model.py:40: TypeError
_____________________ TestEnsembleModel.test_fit_boosting ______________________

self = <test_ml_models.TestEnsembleModel object at 0x7f67876ed0>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
sample_labels = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])

    def test_fit_boosting(self, sample_features, sample_labels):
        """Test Boosting Training."""
        model = EnsembleModel(
            algorithm="boosting",
            base_estimator=ClassificationModel(algorithm="random_forest"),
            n_estimators=5,
        )
>       model.fit(sample_features, sample_labels)

tests/unit/test_ml_models.py:239: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/ensemble_model.py:67: in fit
    self.model = self._create_model(base_estimator=base_estimator)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.ensemble_model.EnsembleModel object at 0x7f5c4e26d0>
base_estimator = <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f5c4e3ed0>
estimators = None

    def _create_model(self, base_estimator=None, estimators=None) -> Any:
        """Erstellt das Ensemble-Modell."""
        if self.algorithm == 'voting':
            if estimators is None:
                raise ValueError("Voting requires estimators list")
            return VotingClassifier(estimators=estimators, **self.kwargs)
        elif self.algorithm == 'bagging':
            if base_estimator is None:
                raise ValueError("Bagging requires base_estimator")
            return BaggingClassifier(base_estimator=base_estimator, **self.kwargs)
        elif self.algorithm == 'boosting':
            if base_estimator is None:
                raise ValueError("Boosting requires base_estimator")
>           return AdaBoostClassifier(base_estimator=base_estimator, **self.kwargs)
E           TypeError: sklearn.ensemble._weight_boosting.AdaBoostClassifier() got multiple values for keyword argument 'base_estimator'

wlan_tool/ml_models/ensemble_model.py:44: TypeError
___________________ TestEnsembleModel.test_predict_ensemble ____________________

self = <test_ml_models.TestEnsembleModel object at 0x7f678775d0>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
sample_labels = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])

    def test_predict_ensemble(self, sample_features, sample_labels):
        """Test Ensemble-Vorhersage."""
        model = EnsembleModel(
            algorithm="voting",
            estimators=[
                ("rf", ClassificationModel(algorithm="random_forest")),
                ("svm", ClassificationModel(algorithm="svm")),
            ],
        )
>       model.fit(sample_features, sample_labels)

tests/unit/test_ml_models.py:253: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/ensemble_model.py:62: in fit
    self.model = self._create_model(estimators=estimators)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.ensemble_model.EnsembleModel object at 0x7f8aed9250>
base_estimator = None
estimators = [('rf', <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f8aed8650>), ('svm', <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f8aed8610>)]

    def _create_model(self, base_estimator=None, estimators=None) -> Any:
        """Erstellt das Ensemble-Modell."""
        if self.algorithm == 'voting':
            if estimators is None:
                raise ValueError("Voting requires estimators list")
>           return VotingClassifier(estimators=estimators, **self.kwargs)
E           TypeError: sklearn.ensemble._voting.VotingClassifier() got multiple values for keyword argument 'estimators'

wlan_tool/ml_models/ensemble_model.py:36: TypeError
___________________ TestEnsembleModel.test_evaluate_ensemble ___________________

self = <test_ml_models.TestEnsembleModel object at 0x7f67877cd0>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
sample_labels = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])

    def test_evaluate_ensemble(self, sample_features, sample_labels):
        """Test Ensemble-Evaluation."""
        model = EnsembleModel(
            algorithm="voting",
            estimators=[
                ("rf", ClassificationModel(algorithm="random_forest")),
                ("svm", ClassificationModel(algorithm="svm")),
            ],
        )
>       model.fit(sample_features, sample_labels)

tests/unit/test_ml_models.py:269: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/ensemble_model.py:62: in fit
    self.model = self._create_model(estimators=estimators)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.ensemble_model.EnsembleModel object at 0x7f60e0aad0>
base_estimator = None
estimators = [('rf', <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f60e095d0>), ('svm', <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f60e0a1d0>)]

    def _create_model(self, base_estimator=None, estimators=None) -> Any:
        """Erstellt das Ensemble-Modell."""
        if self.algorithm == 'voting':
            if estimators is None:
                raise ValueError("Voting requires estimators list")
>           return VotingClassifier(estimators=estimators, **self.kwargs)
E           TypeError: sklearn.ensemble._voting.VotingClassifier() got multiple values for keyword argument 'estimators'

wlan_tool/ml_models/ensemble_model.py:36: TypeError
___________ TestEnsembleModel.test_individual_estimator_performance ____________

self = <test_ml_models.TestEnsembleModel object at 0x7f6787c410>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
sample_labels = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])

    def test_individual_estimator_performance(self, sample_features, sample_labels):
        """Test Performance einzelner Estimators."""
        model = EnsembleModel(
            algorithm="voting",
            estimators=[
                ("rf", ClassificationModel(algorithm="random_forest")),
                ("svm", ClassificationModel(algorithm="svm")),
            ],
        )
>       model.fit(sample_features, sample_labels)

tests/unit/test_ml_models.py:287: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/ensemble_model.py:62: in fit
    self.model = self._create_model(estimators=estimators)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.ensemble_model.EnsembleModel object at 0x7f8aec3e10>
base_estimator = None
estimators = [('rf', <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f8aec2610>), ('svm', <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f8aec1a10>)]

    def _create_model(self, base_estimator=None, estimators=None) -> Any:
        """Erstellt das Ensemble-Modell."""
        if self.algorithm == 'voting':
            if estimators is None:
                raise ValueError("Voting requires estimators list")
>           return VotingClassifier(estimators=estimators, **self.kwargs)
E           TypeError: sklearn.ensemble._voting.VotingClassifier() got multiple values for keyword argument 'estimators'

wlan_tool/ml_models/ensemble_model.py:36: TypeError
___________________ TestEnsembleModel.test_invalid_algorithm ___________________

self = <test_ml_models.TestEnsembleModel object at 0x7f6787cad0>

    def test_invalid_algorithm(self):
        """Test mit ungültigem Ensemble-Algorithmus."""
>       with pytest.raises(ValueError, match="Unsupported ensemble algorithm"):
E       Failed: DID NOT RAISE <class 'ValueError'>

tests/unit/test_ml_models.py:298: Failed
___________________ TestEnsembleModel.test_empty_estimators ____________________

self = <test_ml_models.TestEnsembleModel object at 0x7f6787d190>

    def test_empty_estimators(self):
        """Test mit leerer Estimator-Liste."""
>       with pytest.raises(ValueError, match="At least one estimator required"):
E       Failed: DID NOT RAISE <class 'ValueError'>

tests/unit/test_ml_models.py:303: Failed
__________________ TestModelPersistence.test_save_load_model ___________________

self = <test_ml_models.TestModelPersistence object at 0x7f678772d0>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
sample_labels = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])
temp_dir = PosixPath('/tmp/tmpob9eue4t')

    def test_save_load_model(self, sample_features, sample_labels, temp_dir):
        """Test Speichern und Laden von Modellen."""
        # Training
        model = ClassificationModel(algorithm="random_forest", n_estimators=10)
        model.fit(sample_features, sample_labels)
    
        # Speichern
        model_path = temp_dir / "test_model.pkl"
>       model.save(model_path)
E       AttributeError: 'ClassificationModel' object has no attribute 'save'

tests/unit/test_ml_models.py:318: AttributeError
_________________ TestModelPersistence.test_save_load_ensemble _________________

self = <test_ml_models.TestModelPersistence object at 0x7f6786be50>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
sample_labels = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])
temp_dir = PosixPath('/tmp/tmp16s0jvqj')

    def test_save_load_ensemble(self, sample_features, sample_labels, temp_dir):
        """Test Speichern und Laden von Ensemble-Modellen."""
        # Training
        model = EnsembleModel(
            algorithm="voting",
            estimators=[
                ("rf", ClassificationModel(algorithm="random_forest")),
                ("svm", ClassificationModel(algorithm="svm")),
            ],
        )
>       model.fit(sample_features, sample_labels)

tests/unit/test_ml_models.py:344: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/ensemble_model.py:62: in fit
    self.model = self._create_model(estimators=estimators)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.ensemble_model.EnsembleModel object at 0x7f6029e710>
base_estimator = None
estimators = [('rf', <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f6029fe90>), ('svm', <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f6029e6d0>)]

    def _create_model(self, base_estimator=None, estimators=None) -> Any:
        """Erstellt das Ensemble-Modell."""
        if self.algorithm == 'voting':
            if estimators is None:
                raise ValueError("Voting requires estimators list")
>           return VotingClassifier(estimators=estimators, **self.kwargs)
E           TypeError: sklearn.ensemble._voting.VotingClassifier() got multiple values for keyword argument 'estimators'

wlan_tool/ml_models/ensemble_model.py:36: TypeError
=============================== warnings summary ===============================
tests/conftest.py:12
  /home/pi/hacking/tests/conftest.py:12: DeprecationWarning: 
  Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),
  (to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)
  but was not found to be installed on your system.
  If this would cause problems for you,
  please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466
          
    import pandas as pd

pytest/test_integration.py:192
  /home/pi/hacking/pytest/test_integration.py:192: PytestUnknownMarkWarning: Unknown pytest.mark.network - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.network

plugins/clustering_advanced/tests/test_clustering_advanced.py::TestAdvancedClusteringPlugin::test_optics_clustering
  /home/pi/hacking/.venv/lib/python3.11/site-packages/sklearn/cluster/_optics.py:664: UserWarning: All reachability values are inf. Set a larger max_eps or all data will be considered outliers.
    warnings.warn(

plugins/clustering_advanced/tests/test_clustering_advanced.py::TestAdvancedClusteringPlugin::test_hdbscan_clustering
plugins/clustering_advanced/tests/test_clustering_advanced.py::TestAdvancedClusteringPlugin::test_hdbscan_clustering
  /home/pi/hacking/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.
    warnings.warn(

plugins/clustering_advanced/tests/test_clustering_advanced.py::TestAdvancedClusteringPlugin::test_plugin_run_with_sufficient_data
  /home/pi/hacking/.venv/lib/python3.11/site-packages/sklearn/cluster/_optics.py:664: UserWarning:
  
  All reachability values are inf. Set a larger max_eps or all data will be considered outliers.

plugins/clustering_advanced/tests/test_clustering_advanced.py::TestAdvancedClusteringPlugin::test_plugin_run_with_sufficient_data
plugins/clustering_advanced/tests/test_clustering_advanced.py::TestAdvancedClusteringPlugin::test_plugin_run_with_sufficient_data
  /home/pi/hacking/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:
  
  'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.

plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_model_performance_evaluation
  /home/pi/hacking/.venv/lib/python3.11/site-packages/sklearn/model_selection/_split.py:805: UserWarning:
  
  The least populated class in y has only 4 members, which is less than n_splits=5.

plugins/ensemble_models/tests/test_ensemble_models.py: 66 warnings
  /home/pi/hacking/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:451: DeprecationWarning:
  
  scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.

plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_model_performance_evaluation
plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_model_performance_evaluation
plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_model_performance_evaluation
plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_model_performance_evaluation
plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_model_performance_evaluation
plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_model_performance_evaluation
  /home/pi/hacking/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:
  
  lbfgs failed to converge (status=1):
  STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.
  
  Increase the number of iterations (max_iter) or scale the data as shown in:
      https://scikit-learn.org/stable/modules/preprocessing.html
  Please also refer to the documentation for alternative solver options:
      https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

plugins/ensemble_models/tests/test_ensemble_models.py: 40 warnings
  /home/pi/hacking/.venv/lib/python3.11/site-packages/sklearn/model_selection/_split.py:805: UserWarning:
  
  The least populated class in y has only 3 members, which is less than n_splits=5.

plugins/ensemble_models/tests/test_ensemble_models.py: 24 warnings
  /home/pi/hacking/.venv/lib/python3.11/site-packages/sklearn/model_selection/_split.py:805: UserWarning:
  
  The least populated class in y has only 2 members, which is less than n_splits=5.

pytest/test_capture.py::TestSniffingIntegration::test_sniff_with_writer_mock
  /home/pi/hacking/.venv/lib/python3.11/site-packages/_pytest/threadexception.py:77: PytestUnhandledThreadExceptionWarning:
  
  Exception in thread ChannelHopper
  
  Traceback (most recent call last):
    File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/threading.py", line 1045, in _bootstrap_inner
      self.run()
    File "/home/pi/hacking/wlan_tool/capture/sniffer.py", line 207, in run
      subprocess.run(command, check=True, capture_output=True, text=True)
    File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/subprocess.py", line 550, in run
      stdout, stderr = process.communicate(input, timeout=timeout)
      ^^^^^^^^^^^^^^
  ValueError: not enough values to unpack (expected 2, got 0)

tests/integration/test_end_to_end.py::TestEndToEndWorkflow::test_error_handling_and_recovery
  /home/pi/hacking/wlan_tool/data_processing/wifi_processor.py:45: UserWarning:
  
  Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html

-------------------------------------------------------------------------------------------------- benchmark: 9 tests --------------------------------------------------------------------------------------------------
Name (time in ms)                               Min                   Max                  Mean              StdDev                Median                 IQR            Outliers      OPS            Rounds  Iterations
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
test_file_io_performance                    23.7164 (1.0)        202.2655 (3.77)       137.3219 (2.57)      26.3499 (261.19)     134.3780 (2.52)      17.1669 (150.22)      13;10   7.2822 (0.39)         53           1
test_feature_extraction_performance         53.2606 (2.25)        53.5887 (1.0)         53.4295 (1.0)        0.1009 (1.0)         53.4247 (1.0)        0.1143 (1.0)           6;0  18.7162 (1.0)          16           1
test_data_processing_performance            60.0770 (2.53)       562.5605 (10.50)       92.5430 (1.73)     125.3402 (>1000.0)     61.2656 (1.15)       1.3652 (11.95)         1;1  10.8058 (0.58)         16           1
test_clustering_scalability                 82.6197 (3.48)       104.3352 (1.95)        92.6516 (1.73)       5.9098 (58.58)       90.9957 (1.70)       4.5418 (39.74)         3;3  10.7931 (0.58)         12           1
test_feature_scaling_performance           152.6998 (6.44)       153.5645 (2.87)       153.0906 (2.87)       0.4182 (4.15)       152.8334 (2.86)       0.7369 (6.45)          2;0   6.5321 (0.35)          5           1
test_parallel_processing_performance       180.7430 (7.62)       231.5425 (4.32)       204.3306 (3.82)      20.5874 (204.07)     197.4159 (3.70)      36.4021 (318.54)        2;0   4.8940 (0.26)          7           1
test_csv_io_performance                    339.7552 (14.33)      375.8380 (7.01)       348.5648 (6.52)      15.3067 (151.73)     342.2107 (6.41)      10.5374 (92.21)         1;1   2.8689 (0.15)          5           1
test_memory_usage_large_dataset            532.0115 (22.43)      742.3528 (13.85)      649.3289 (12.15)    107.7645 (>1000.0)    701.1699 (13.12)    206.1761 (>1000.0)       2;0   1.5401 (0.08)          5           1
test_random_forest_performance           7,974.5532 (336.25)   8,081.3882 (150.80)   8,018.9636 (150.08)    51.5667 (511.15)   7,985.1631 (149.47)    89.4610 (782.84)        1;0   0.1247 (0.01)          5           1
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Legend:
  Outliers: 1 Standard Deviation from Mean; 1.5 IQR (InterQuartile Range) from 1st Quartile and 3rd Quartile.
  OPS: Operations Per Second, computed as 1 / Mean
=========================== short test summary info ============================
FAILED plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_performance_visualization_creation
FAILED plugins/reinforcement_learning/tests/test_reinforcement_learning.py::TestReinforcementLearningPlugin::test_environment_observation
FAILED plugins/reinforcement_learning/tests/test_reinforcement_learning.py::TestReinforcementLearningPlugin::test_plugin_run_with_sufficient_data
FAILED plugins/reinforcement_learning/tests/test_reinforcement_learning.py::TestReinforcementLearningPlugin::test_plugin_run_without_pytorch
FAILED pytest/test_analysis.py::TestAnalysisLogic::test_profile_clusters - Ke...
FAILED pytest/test_analysis.py::TestAnalysisLogic::test_cluster_aps - ValueEr...
FAILED pytest/test_analysis.py::TestAnalysisLogic::test_profile_ap_clusters
FAILED pytest/test_analysis.py::TestDeviceProfiler::test_create_device_fingerprint_empty_state
FAILED pytest/test_analysis.py::TestGraphExport::test_build_export_graph - As...
FAILED pytest/test_analysis.py::TestGraphExport::test_discover_attributes - A...
FAILED pytest/test_analysis.py::TestAnalysisEdgeCases::test_single_client_analysis
FAILED pytest/test_analysis.py::TestAnalysisEdgeCases::test_malformed_event_handling
FAILED pytest/test_app.py::TestUtilsModule::test_intelligent_vendor_lookup - ...
FAILED pytest/test_app.py::TestAnalysisModule::test_features_for_client_behavior
FAILED pytest/test_app.py::TestAnalysisModule::test_cluster_clients_runs - At...
FAILED pytest/test_app.py::TestAnalysisModule::test_profile_clusters - Attrib...
FAILED pytest/test_capture.py::TestPacketParsing::test_packet_to_event_probe_request
FAILED pytest/test_capture.py::TestPacketParsing::test_packet_to_event_data_frame
FAILED pytest/test_capture.py::TestPacketParsing::test_packet_to_event_with_dhcp
FAILED pytest/test_capture.py::TestChannelHopper::test_channel_hopper_command_failure
FAILED pytest/test_capture.py::TestIEExtraction::test_extract_seq - assert 0 ...
FAILED pytest/test_capture.py::TestErrorHandling::test_packet_to_event_encoding_error
FAILED pytest/test_controllers.py::TestCaptureController::test_select_interface_automatic
FAILED pytest/test_controllers.py::TestCaptureController::test_select_interface_no_interfaces
FAILED pytest/test_controllers.py::TestCaptureController::test_setup_monitor_mode_failure
FAILED pytest/test_controllers.py::TestAnalysisController::test_analysis_controller_initialization
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_inference
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_client_clustering
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_ap_clustering
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_graph_export
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_labeling_ui
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_client_labeling_ui
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_mac_correlation
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_analysis_no_actions
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_analysis_multiple_actions
FAILED pytest/test_controllers.py::TestControllerEdgeCases::test_analysis_controller_empty_state
FAILED pytest/test_controllers.py::TestControllerEdgeCases::test_analysis_controller_with_plugins
FAILED pytest/test_controllers.py::TestControllerIntegration::test_full_analysis_workflow
FAILED pytest/test_error_handling.py::TestLoggingSystem::test_setup_logging
FAILED pytest/test_error_handling.py::TestDatabaseErrorHandling::test_database_connection_error
FAILED pytest/test_error_handling.py::TestDatabaseErrorHandling::test_database_migration_error
FAILED pytest/test_error_handling.py::TestAnalysisErrorHandling::test_client_features_null_state
FAILED pytest/test_error_handling.py::TestAnalysisErrorHandling::test_client_features_invalid_type
FAILED pytest/test_error_handling.py::TestAnalysisErrorHandling::test_clustering_invalid_parameters
FAILED pytest/test_error_handling.py::TestFileSystemErrorHandling::test_csv_export_invalid_path
FAILED pytest/test_error_handling.py::TestFileSystemErrorHandling::test_csv_export_missing_db
FAILED pytest/test_error_handling.py::TestErrorHandlingEdgeCases::test_nested_error_contexts
FAILED pytest/test_integration.py::TestEndToEndWorkflow::test_complete_analysis_pipeline
FAILED pytest/test_integration.py::TestEndToEndWorkflow::test_database_integration
FAILED pytest/test_integration.py::TestEndToEndWorkflow::test_config_integration
FAILED pytest/test_integration.py::TestDataFlow::test_state_persistence - wla...
FAILED pytest/test_integration.py::TestLargeDataset::test_large_dataset_processing
FAILED pytest/test_integration.py::TestErrorRecovery::test_malformed_event_handling
FAILED pytest/test_integration.py::TestMemoryManagement::test_memory_usage_large_state
FAILED pytest/test_integration.py::TestMemoryManagement::test_state_pruning_memory_release
FAILED pytest/test_performance.py::TestAnalysisPerformance::test_clustering_performance
FAILED pytest/test_performance.py::TestAnalysisPerformance::test_inference_performance
FAILED pytest/test_performance.py::TestMemoryPerformance::test_memory_usage_large_state
FAILED pytest/test_performance.py::TestMemoryPerformance::test_memory_cleanup_after_pruning
FAILED pytest/test_performance.py::TestDatabasePerformance::test_database_write_performance
FAILED pytest/test_performance.py::TestDatabasePerformance::test_database_read_performance
FAILED pytest/test_performance.py::TestScalabilityPerformance::test_scalability_with_dataset_size
FAILED pytest/test_presentation.py::TestCLIModule::test_print_client_cluster_results
FAILED pytest/test_presentation.py::TestCLIModule::test_print_ap_cluster_results
FAILED pytest/test_presentation.py::TestCLIEdgeCases::test_print_client_cluster_results_empty_data
FAILED pytest/test_presentation.py::TestPerformance::test_large_dataset_handling
FAILED pytest/test_storage.py::TestClientState::test_client_state_update_from_event
FAILED pytest/test_storage.py::TestAPState::test_ap_state_update_from_beacon
FAILED pytest/test_storage.py::TestWifiAnalysisState::test_state_pruning - As...
FAILED pytest/test_storage.py::TestWifiAnalysisState::test_state_ssid_mapping
FAILED pytest/test_storage.py::TestDatabaseModule::test_fetch_events - Attrib...
FAILED pytest/test_storage.py::TestDatabaseModule::test_add_label - Assertion...
FAILED pytest/test_utils.py::TestOUIFunctions::test_lookup_vendor_apple_mac
FAILED pytest/test_utils.py::TestOUIFunctions::test_lookup_vendor_unknown_mac
FAILED pytest/test_utils.py::TestIEParsing::test_parse_ies_vendor_specific - ...
FAILED pytest/test_utils.py::TestIEParsing::test_parse_ies_ht_capabilities - ...
FAILED pytest/test_utils.py::TestUtilityFunctions::test_is_local_admin_mac - ...
FAILED pytest/test_utils.py::TestUtilityFunctions::test_is_valid_bssid - Asse...
FAILED pytest/test_utils.py::TestUtilityFunctions::test_ie_fingerprint_hash
FAILED pytest/test_utils.py::TestUtilityFunctions::test_ie_fingerprint_hash_empty
FAILED pytest/test_utils.py::TestConfigFunctions::test_load_config_default - ...
FAILED pytest/test_utils.py::TestConfigFunctions::test_load_config_specific_profile
FAILED pytest/test_utils.py::TestConfigFunctions::test_load_config_missing_file
FAILED pytest/test_utils.py::TestEdgeCases::test_ie_fingerprint_hash_unicode
FAILED pytest/test_utils.py::TestEdgeCases::test_config_loading_with_invalid_yaml
FAILED tests/integration/test_end_to_end.py::TestEndToEndWorkflow::test_complete_wifi_analysis_workflow
FAILED tests/integration/test_end_to_end.py::TestEndToEndWorkflow::test_plugin_integration_workflow
FAILED tests/integration/test_end_to_end.py::TestEndToEndWorkflow::test_data_pipeline_with_file_io
FAILED tests/integration/test_end_to_end.py::TestEndToEndWorkflow::test_error_handling_and_recovery
FAILED tests/integration/test_end_to_end.py::TestEndToEndWorkflow::test_performance_under_load
FAILED tests/integration/test_end_to_end.py::TestEndToEndWorkflow::test_concurrent_processing
FAILED tests/performance/test_benchmarks.py::TestClusteringBenchmarks::test_kmeans_performance
FAILED tests/performance/test_benchmarks.py::TestClusteringBenchmarks::test_dbscan_performance
FAILED tests/performance/test_benchmarks.py::TestClusteringBenchmarks::test_hierarchical_performance
FAILED tests/performance/test_benchmarks.py::TestClusteringBenchmarks::test_clustering_scalability
FAILED tests/performance/test_benchmarks.py::TestDataProcessingBenchmarks::test_data_processing_performance
FAILED tests/performance/test_benchmarks.py::TestDataProcessingBenchmarks::test_feature_extraction_performance
FAILED tests/performance/test_benchmarks.py::TestDataProcessingBenchmarks::test_feature_scaling_performance
FAILED tests/performance/test_benchmarks.py::TestClassificationBenchmarks::test_random_forest_performance
FAILED tests/performance/test_benchmarks.py::TestClassificationBenchmarks::test_svm_performance
FAILED tests/performance/test_benchmarks.py::TestMemoryBenchmarks::test_memory_usage_clustering
FAILED tests/performance/test_benchmarks.py::TestMemoryBenchmarks::test_memory_usage_large_dataset
FAILED tests/performance/test_benchmarks.py::TestConcurrentBenchmarks::test_parallel_processing_performance
FAILED tests/performance/test_benchmarks.py::TestIOBenchmarks::test_file_io_performance
FAILED tests/performance/test_benchmarks.py::TestIOBenchmarks::test_csv_io_performance
FAILED tests/performance/test_memory_profiling.py::TestMemoryUsage::test_memory_usage_clustering
FAILED tests/performance/test_memory_profiling.py::TestMemoryProfiling::test_detailed_memory_profiling
FAILED tests/unit/test_data_processing.py::TestDataValidator::test_validate_valid_data
FAILED tests/unit/test_ml_models.py::TestClusteringModel::test_fit_kmeans - T...
FAILED tests/unit/test_ml_models.py::TestClusteringModel::test_predict_after_fit
FAILED tests/unit/test_ml_models.py::TestClusteringModel::test_get_cluster_centers
FAILED tests/unit/test_ml_models.py::TestClusteringModel::test_evaluate_clustering
FAILED tests/unit/test_ml_models.py::TestClusteringModel::test_invalid_algorithm
FAILED tests/unit/test_ml_models.py::TestClusteringModel::test_hyperparameter_validation
FAILED tests/unit/test_ml_models.py::TestClassificationModel::test_cross_validation
FAILED tests/unit/test_ml_models.py::TestEnsembleModel::test_fit_voting_classifier
FAILED tests/unit/test_ml_models.py::TestEnsembleModel::test_fit_bagging - Ty...
FAILED tests/unit/test_ml_models.py::TestEnsembleModel::test_fit_boosting - T...
FAILED tests/unit/test_ml_models.py::TestEnsembleModel::test_predict_ensemble
FAILED tests/unit/test_ml_models.py::TestEnsembleModel::test_evaluate_ensemble
FAILED tests/unit/test_ml_models.py::TestEnsembleModel::test_individual_estimator_performance
FAILED tests/unit/test_ml_models.py::TestEnsembleModel::test_invalid_algorithm
FAILED tests/unit/test_ml_models.py::TestEnsembleModel::test_empty_estimators
FAILED tests/unit/test_ml_models.py::TestModelPersistence::test_save_load_model
FAILED tests/unit/test_ml_models.py::TestModelPersistence::test_save_load_ensemble
========== 125 failed, 235 passed, 147 warnings in 929.90s (0:15:29) ===========
============================= test session starts ==============================
platform linux -- Python 3.11.9, pytest-8.2.0, pluggy-1.6.0
benchmark: 5.1.0 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)
rootdir: /home/pi/hacking
configfile: pytest.ini
plugins: xdist-3.8.0, hypothesis-6.142.1, cov-7.0.0, mock-3.12.0, html-4.1.1, benchmark-5.1.0, Faker-37.11.0, metadata-3.1.1, json-report-1.5.0
collected 360 items

plugins/clustering_advanced/tests/test_clustering_advanced.py .......... [  2%]
.....                                                                    [  4%]
plugins/ensemble_models/tests/test_ensemble_models.py ........F.         [  6%]
plugins/example_plugin/tests/test_example_plugin.py ..                   [  7%]
plugins/reinforcement_learning/tests/test_reinforcement_learning.py .... [  8%]
.F......FF....                                                           [ 12%]
plugins/sankey/tests/test_sankey.py ......                               [ 14%]
plugins/umap_plot/tests/test_umap_plot.py ........                       [ 16%]
pytest/test_analysis.py ........F.FF...F...FF..F.F                       [ 23%]
pytest/test_app.py ..F...FFF..                                           [ 26%]
pytest/test_capture.py .FF..F....F......F.F.                             [ 32%]
pytest/test_controllers.py .FF..F...FFFFFFFFFF..FF.F                     [ 39%]
pytest/test_error_handling.py ......................F..FFFFFFF..F...     [ 50%]
pytest/test_integration.py FFF.FF..F..FF                                 [ 53%]
pytest/test_performance.py ....FFFFFF.F                                  [ 56%]
pytest/test_presentation.py FF...........F....F.                         [ 62%]
pytest/test_storage.py ......F..F....FF..FF...                           [ 68%]
pytest/test_utils.py F.F......FF..FFFF.FFF.....F.F                       [ 76%]
tests/integration/test_end_to_end.py FFFFFF                              [ 78%]
tests/performance/test_benchmarks.py FFFFFFFFFFFFFF                      [ 82%]
tests/performance/test_memory_profiling.py ..F...F....F                  [ 85%]
tests/unit/test_data_processing.py ................F.....                [ 91%]
tests/unit/test_ml_models.py .F..FFFFF.......F..FFFFFFFFFF               [100%]

=================================== FAILURES ===================================
_______ TestEnsembleModelsPlugin.test_performance_visualization_creation _______

self = <MagicMock name='make_subplots' id='547541187792'>

    def assert_called_once(self):
        """assert that the mock was called only once.
        """
        if not self.call_count == 1:
            msg = ("Expected '%s' to have been called once. Called %s times.%s"
                   % (self._mock_name or 'mock',
                      self.call_count,
                      self._calls_repr()))
>           raise AssertionError(msg)
E           AssertionError: Expected 'make_subplots' to have been called once. Called 0 times.

../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:918: AssertionError

During handling of the above exception, another exception occurred:

self = <plugins.ensemble_models.tests.test_ensemble_models.TestEnsembleModelsPlugin object at 0x7f7bb809d0>
plugin = <plugins.ensemble_models.plugin.Plugin object at 0x7f7c008910>
temp_outdir = PosixPath('/tmp/pytest-of-pi/pytest-4/test_performance_visualization0/output')

    def test_performance_visualization_creation(self, plugin, temp_outdir):
        """Test Erstellung der Performance-Visualisierung."""
        temp_outdir.mkdir(exist_ok=True)
    
        # Mock Performance-Metriken
        from plugins.ensemble_models.plugin import ModelPerformance
        performance_metrics = [
            ModelPerformance("Model1", 0.8, 0.75, 0.8, 0.77, 0.78, 0.02, 1.0, 0.1),
            ModelPerformance("Model2", 0.85, 0.82, 0.85, 0.83, 0.84, 0.01, 1.5, 0.15),
        ]
    
        with patch('plotly.graph_objects') as mock_go:
            with patch('plotly.subplots.make_subplots') as mock_subplots:
                mock_fig = MagicMock()
                mock_subplots.return_value = mock_fig
    
                plugin._create_performance_visualization(performance_metrics, temp_outdir)
    
                # Überprüfe, dass Plotly-Funktionen aufgerufen wurden
>               mock_subplots.assert_called_once()
E               AssertionError: Expected 'make_subplots' to have been called once. Called 0 times.

plugins/ensemble_models/tests/test_ensemble_models.py:257: AssertionError
_________ TestReinforcementLearningPlugin.test_environment_observation _________

self = <plugins.reinforcement_learning.tests.test_reinforcement_learning.TestReinforcementLearningPlugin object at 0x7f7bbb0ed0>
plugin = <plugins.reinforcement_learning.plugin.Plugin object at 0x7f515832d0>
mock_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f51581d50>
mock_events = [{'client': 'aa:bb:cc:dd:ee:00', 'ts': 1000.0, 'type': 'probe_req'}, {'client': 'aa:bb:cc:dd:ee:01', 'ts': 1001.0, 'type': 'probe_req'}]

    def test_environment_observation(self, plugin, mock_state, mock_events):
        """Test Environment Observation."""
        env = plugin._WiFiScanningEnvironment(mock_state, mock_events)
        obs = env._get_observation()
    
        assert len(obs) == 10
        assert all(0 <= val <= 1 for val in obs)  # Normalisierte Werte
>       assert obs[0] == 1.0 / 48.0  # current_channel normalisiert
E       assert 0.020833334 == (1.0 / 48.0)

plugins/reinforcement_learning/tests/test_reinforcement_learning.py:141: AssertionError
_____ TestReinforcementLearningPlugin.test_plugin_run_with_sufficient_data _____

self = <MagicMock name='dump' id='546825950800'>

    def assert_called(self):
        """assert that the mock was called at least once
        """
        if self.call_count == 0:
            msg = ("Expected '%s' to have been called." %
                   (self._mock_name or 'mock'))
>           raise AssertionError(msg)
E           AssertionError: Expected 'dump' to have been called.

../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:908: AssertionError

During handling of the above exception, another exception occurred:

self = <plugins.reinforcement_learning.tests.test_reinforcement_learning.TestReinforcementLearningPlugin object at 0x7f7bbbd250>
plugin = <plugins.reinforcement_learning.plugin.Plugin object at 0x7f5146a6d0>
mock_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f51469850>
mock_events = [{'client': 'aa:bb:cc:dd:ee:00', 'ts': 1000.0, 'type': 'probe_req'}, {'client': 'aa:bb:cc:dd:ee:01', 'ts': 1001.0, 'type': 'probe_req'}]
mock_console = <MagicMock id='546824433104'>
temp_outdir = PosixPath('/tmp/pytest-of-pi/pytest-4/test_plugin_run_with_sufficien2/output')

    def test_plugin_run_with_sufficient_data(self, plugin, mock_state, mock_events, mock_console, temp_outdir):
        """Test Plugin-Ausführung mit ausreichenden Daten."""
        temp_outdir.mkdir(exist_ok=True)
    
        with patch('joblib.dump') as mock_dump:
            with patch('builtins.open', create=True) as mock_open:
                plugin.run(mock_state, mock_events, mock_console, temp_outdir)
    
        # Überprüfe, dass Console-Ausgaben gemacht wurden
        assert mock_console.print.called
    
        # Überprüfe, dass Ergebnisse gespeichert wurden
>       mock_dump.assert_called()
E       AssertionError: Expected 'dump' to have been called.

plugins/reinforcement_learning/tests/test_reinforcement_learning.py:260: AssertionError
------------------------------ Captured log call -------------------------------
ERROR    plugins.reinforcement_learning.plugin:plugin.py:165 Fehler bei der RL-Optimierung: 'NoneType' object has no attribute 'shape'
Traceback (most recent call last):
  File "/home/pi/hacking/plugins/reinforcement_learning/plugin.py", line 94, in run
    raise ImportError("PyTorch nicht verfügbar")
ImportError: PyTorch nicht verfügbar

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/pi/hacking/plugins/reinforcement_learning/plugin.py", line 97, in run
    state_size=env.observation_space.shape[0],
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
_______ TestReinforcementLearningPlugin.test_plugin_run_without_pytorch ________

self = <plugins.reinforcement_learning.tests.test_reinforcement_learning.TestReinforcementLearningPlugin object at 0x7f7bbbd910>
plugin = <plugins.reinforcement_learning.plugin.Plugin object at 0x7f5161fb90>
mock_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f5161d990>
mock_events = [{'client': 'aa:bb:cc:dd:ee:00', 'ts': 1000.0, 'type': 'probe_req'}, {'client': 'aa:bb:cc:dd:ee:01', 'ts': 1001.0, 'type': 'probe_req'}]
mock_console = <MagicMock id='546826210064'>
temp_outdir = PosixPath('/tmp/pytest-of-pi/pytest-4/test_plugin_run_without_pytorc0/output')

    def test_plugin_run_without_pytorch(self, plugin, mock_state, mock_events, mock_console, temp_outdir):
        """Test Plugin-Ausführung ohne PyTorch (Fallback zu Simple RL)."""
        temp_outdir.mkdir(exist_ok=True)
    
        with patch('plugins.reinforcement_learning.plugin.torch', None):
            with patch('joblib.dump') as mock_dump:
                with patch('builtins.open', create=True) as mock_open:
                    plugin.run(mock_state, mock_events, mock_console, temp_outdir)
    
        # Überprüfe, dass Console-Ausgaben gemacht wurden
        assert mock_console.print.called
    
        # Überprüfe, dass Simple RL Agent verwendet wurde
        console_calls = [str(call) for call in mock_console.print.call_args_list]
>       assert any("Q-Learning" in call for call in console_calls)
E       assert False
E        +  where False = any(<generator object TestReinforcementLearningPlugin.test_plugin_run_without_pytorch.<locals>.<genexpr> at 0x7f51bfe9b0>)

plugins/reinforcement_learning/tests/test_reinforcement_learning.py:277: AssertionError
------------------------------ Captured log call -------------------------------
ERROR    plugins.reinforcement_learning.plugin:plugin.py:165 Fehler bei der RL-Optimierung: 'NoneType' object has no attribute 'shape'
Traceback (most recent call last):
  File "/home/pi/hacking/plugins/reinforcement_learning/plugin.py", line 94, in run
    raise ImportError("PyTorch nicht verfügbar")
ImportError: PyTorch nicht verfügbar

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/pi/hacking/plugins/reinforcement_learning/plugin.py", line 97, in run
    state_size=env.observation_space.shape[0],
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
___________________ TestAnalysisLogic.test_profile_clusters ____________________

self = <test_analysis.TestAnalysisLogic object at 0x7f59e53bd0>

    def test_profile_clusters(self):
        """Test Cluster-Profilierung."""
        feature_data = {
            'original_macs': ['mac1', 'mac2', 'mac3'],
            'feature1': [10, 20, 15],
            'feature2': [1, 2, 1.5]
        }
        feature_df = pd.DataFrame(feature_data)
    
        cluster_data = {
            'original_macs': ['mac1', 'mac2', 'mac3'],
            'cluster': [0, 0, 1]
        }
        clustered_df = pd.DataFrame(cluster_data)
    
>       profiles = analysis.profile_clusters(feature_df, clustered_df)

pytest/test_analysis.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/analysis/logic.py:666: in profile_clusters
    profiles["details"] = full_df.set_index("mac").to_dict(orient="index")
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self =   original_macs  feature1  feature2  cluster
0          mac1        10       1.0        0
1          mac2        20       2.0        0
2          mac3        15       1.5        1
keys = ['mac']

    def set_index(
        self,
        keys,
        *,
        drop: bool = True,
        append: bool = False,
        inplace: bool = False,
        verify_integrity: bool = False,
    ) -> DataFrame | None:
        """
        Set the DataFrame index using existing columns.
    
        Set the DataFrame index (row labels) using one or more existing
        columns or arrays (of the correct length). The index can replace the
        existing index or expand on it.
    
        Parameters
        ----------
        keys : label or array-like or list of labels/arrays
            This parameter can be either a single column key, a single array of
            the same length as the calling DataFrame, or a list containing an
            arbitrary combination of column keys and arrays. Here, "array"
            encompasses :class:`Series`, :class:`Index`, ``np.ndarray``, and
            instances of :class:`~collections.abc.Iterator`.
        drop : bool, default True
            Delete columns to be used as the new index.
        append : bool, default False
            Whether to append columns to existing index.
        inplace : bool, default False
            Whether to modify the DataFrame rather than creating a new one.
        verify_integrity : bool, default False
            Check the new index for duplicates. Otherwise defer the check until
            necessary. Setting to False will improve the performance of this
            method.
    
        Returns
        -------
        DataFrame or None
            Changed row labels or None if ``inplace=True``.
    
        See Also
        --------
        DataFrame.reset_index : Opposite of set_index.
        DataFrame.reindex : Change to new indices or expand indices.
        DataFrame.reindex_like : Change to same indices as other DataFrame.
    
        Examples
        --------
        >>> df = pd.DataFrame({'month': [1, 4, 7, 10],
        ...                    'year': [2012, 2014, 2013, 2014],
        ...                    'sale': [55, 40, 84, 31]})
        >>> df
           month  year  sale
        0      1  2012    55
        1      4  2014    40
        2      7  2013    84
        3     10  2014    31
    
        Set the index to become the 'month' column:
    
        >>> df.set_index('month')
               year  sale
        month
        1      2012    55
        4      2014    40
        7      2013    84
        10     2014    31
    
        Create a MultiIndex using columns 'year' and 'month':
    
        >>> df.set_index(['year', 'month'])
                    sale
        year  month
        2012  1     55
        2014  4     40
        2013  7     84
        2014  10    31
    
        Create a MultiIndex using an Index and a column:
    
        >>> df.set_index([pd.Index([1, 2, 3, 4]), 'year'])
                 month  sale
           year
        1  2012  1      55
        2  2014  4      40
        3  2013  7      84
        4  2014  10     31
    
        Create a MultiIndex using two Series:
    
        >>> s = pd.Series([1, 2, 3, 4])
        >>> df.set_index([s, s**2])
              month  year  sale
        1 1       1  2012    55
        2 4       4  2014    40
        3 9       7  2013    84
        4 16     10  2014    31
        """
        inplace = validate_bool_kwarg(inplace, "inplace")
        self._check_inplace_and_allows_duplicate_labels(inplace)
        if not isinstance(keys, list):
            keys = [keys]
    
        err_msg = (
            'The parameter "keys" may be a column key, one-dimensional '
            "array, or a list containing only valid column keys and "
            "one-dimensional arrays."
        )
    
        missing: list[Hashable] = []
        for col in keys:
            if isinstance(col, (Index, Series, np.ndarray, list, abc.Iterator)):
                # arrays are fine as long as they are one-dimensional
                # iterators get converted to list below
                if getattr(col, "ndim", 1) != 1:
                    raise ValueError(err_msg)
            else:
                # everything else gets tried as a key; see GH 24969
                try:
                    found = col in self.columns
                except TypeError as err:
                    raise TypeError(
                        f"{err_msg}. Received column of type {type(col)}"
                    ) from err
                else:
                    if not found:
                        missing.append(col)
    
        if missing:
>           raise KeyError(f"None of {missing} are in the columns")
E           KeyError: "None of ['mac'] are in the columns"

.venv/lib/python3.11/site-packages/pandas/core/frame.py:6106: KeyError
______________________ TestAnalysisLogic.test_cluster_aps ______________________

self = <test_analysis.TestAnalysisLogic object at 0x7f59e51310>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f51967390>

    def test_cluster_aps(self, populated_state):
        """Test AP-Clustering."""
>       clustered_df = analysis.cluster_aps(populated_state, n_clusters=2)

pytest/test_analysis.py:166: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/analysis/logic.py:736: in cluster_aps
    df["cluster"] = kmeans.fit_predict(X_scaled)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1064: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1456: in fit
    self._check_params_vs_input(X)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1396: in _check_params_vs_input
    super()._check_params_vs_input(X, default_n_init=10)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = KMeans(n_clusters=2, random_state=42)
X = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])
default_n_init = 10

    def _check_params_vs_input(self, X, default_n_init=None):
        # n_clusters
        if X.shape[0] < self.n_clusters:
>           raise ValueError(
                f"n_samples={X.shape[0]} should be >= n_clusters={self.n_clusters}."
            )
E           ValueError: n_samples=1 should be >= n_clusters=2.

.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:871: ValueError
__________________ TestAnalysisLogic.test_profile_ap_clusters __________________

self = Index(['bssid', 'ssid', 'vendor', 'cluster', 'supports_11k', 'supports_11v',
       'supports_11r'],
      dtype='object')
key = 'channel'

    def get_loc(self, key):
        """
        Get integer location, slice or boolean mask for requested label.
    
        Parameters
        ----------
        key : label
    
        Returns
        -------
        int if unique index, slice if monotonic index, else mask
    
        Examples
        --------
        >>> unique_index = pd.Index(list('abc'))
        >>> unique_index.get_loc('b')
        1
    
        >>> monotonic_index = pd.Index(list('abbc'))
        >>> monotonic_index.get_loc('b')
        slice(1, 3, None)
    
        >>> non_monotonic_index = pd.Index(list('abcb'))
        >>> non_monotonic_index.get_loc('b')
        array([False,  True, False,  True])
        """
        casted_key = self._maybe_cast_indexer(key)
        try:
>           return self._engine.get_loc(casted_key)

.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3802: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
index.pyx:153: in pandas._libs.index.IndexEngine.get_loc
    ???
index.pyx:182: in pandas._libs.index.IndexEngine.get_loc
    ???
pandas/_libs/hashtable_class_helper.pxi:7081: in pandas._libs.hashtable.PyObjectHashTable.get_item
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   KeyError: 'channel'

pandas/_libs/hashtable_class_helper.pxi:7089: KeyError

The above exception was the direct cause of the following exception:

self = <test_analysis.TestAnalysisLogic object at 0x7f59e58710>

    def test_profile_ap_clusters(self):
        """Test AP-Cluster-Profilierung."""
        cluster_data = {
            'bssid': ['ap1', 'ap2'],
            'ssid': ['SSID1', 'SSID2'],
            'vendor': ['Vendor1', 'Vendor2'],
            'cluster': [0, 1],
            'supports_11k': [True, False],
            'supports_11v': [True, False],
            'supports_11r': [False, True]
        }
        clustered_df = pd.DataFrame(cluster_data)
    
>       profiles = analysis.profile_ap_clusters(clustered_df)

pytest/test_analysis.py:187: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/analysis/logic.py:766: in profile_ap_clusters
    "channels": cluster_data["channel"].value_counts().to_dict(),
.venv/lib/python3.11/site-packages/pandas/core/frame.py:4090: in __getitem__
    indexer = self.columns.get_loc(key)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Index(['bssid', 'ssid', 'vendor', 'cluster', 'supports_11k', 'supports_11v',
       'supports_11r'],
      dtype='object')
key = 'channel'

    def get_loc(self, key):
        """
        Get integer location, slice or boolean mask for requested label.
    
        Parameters
        ----------
        key : label
    
        Returns
        -------
        int if unique index, slice if monotonic index, else mask
    
        Examples
        --------
        >>> unique_index = pd.Index(list('abc'))
        >>> unique_index.get_loc('b')
        1
    
        >>> monotonic_index = pd.Index(list('abbc'))
        >>> monotonic_index.get_loc('b')
        slice(1, 3, None)
    
        >>> non_monotonic_index = pd.Index(list('abcb'))
        >>> non_monotonic_index.get_loc('b')
        array([False,  True, False,  True])
        """
        casted_key = self._maybe_cast_indexer(key)
        try:
            return self._engine.get_loc(casted_key)
        except KeyError as err:
            if isinstance(casted_key, slice) or (
                isinstance(casted_key, abc.Iterable)
                and any(isinstance(x, slice) for x in casted_key)
            ):
                raise InvalidIndexError(key)
>           raise KeyError(key) from err
E           KeyError: 'channel'

.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3809: KeyError
________ TestDeviceProfiler.test_create_device_fingerprint_empty_state _________

self = <test_analysis.TestDeviceProfiler object at 0x7f59e59a10>

    def test_create_device_fingerprint_empty_state(self):
        """Test Fingerprint mit leerem ClientState."""
        empty_client = ClientState(mac="aa:bb:cc:dd:ee:ff")
        fingerprint = create_device_fingerprint(empty_client)
    
>       assert fingerprint == ""  # Sollte leer sein für leeren State
E       AssertionError: assert 'd41d8cd98f00...00998ecf8427e' == ''
E         
E         + d41d8cd98f00b204e9800998ecf8427e

pytest/test_analysis.py:251: AssertionError
___________________ TestGraphExport.test_build_export_graph ____________________

self = <test_analysis.TestGraphExport object at 0x7f59e5b610>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f51e77fd0>

    def test_build_export_graph(self, populated_state):
        """Test Graph-Aufbau für Export."""
        # Erstelle Test-Daten
        ap_data = {
            'bssid': ['08:96:d7:1a:21:1c'],
            'ssid': ['MyTestWLAN'],
            'vendor': ['TestVendor'],
            'cluster': [0],
            'channel': [6],
            'rssi_mean': [-50.0],
            'supports_11k': [False],
            'supports_11v': [False],
            'supports_11r': [False]
        }
        clustered_ap_df = pd.DataFrame(ap_data)
    
        aps_to_export = {'08:96:d7:1a:21:1c': populated_state.aps['08:96:d7:1a:21:1c']}
        clients_to_export = {}
    
        graph = analysis._build_export_graph(
            populated_state,
            clustered_ap_df,
            aps_to_export,
            clients_to_export,
            include_clients=False,
            clustered_client_df=None
        )
    
        assert graph is not None
        assert graph.number_of_nodes() > 0
>       assert 'start' in graph.graph
E       AssertionError: assert 'start' in {'mode': 'dynamic', 'timeformat': 'datetime'}
E        +  where {'mode': 'dynamic', 'timeformat': 'datetime'} = <networkx.classes.graph.Graph object at 0x7f51e74b50>.graph

pytest/test_analysis.py:319: AssertionError
___________________ TestGraphExport.test_discover_attributes ___________________

self = <test_analysis.TestGraphExport object at 0x7f59e5bc10>

    def test_discover_attributes(self):
        """Test Attribut-Entdeckung für GEXF."""
        import networkx as nx
    
        G = nx.Graph()
        G.add_node("node1", type="AP", activity=10, vendor="Test")
        G.add_edge("node1", "node2", weight=1.5, kind="Association")
    
        node_attrs, edge_attrs = analysis._discover_attributes(G)
    
        assert isinstance(node_attrs, dict)
        assert isinstance(edge_attrs, dict)
        assert 'type' in node_attrs
        assert 'activity' in node_attrs
>       assert 'weight' in edge_attrs
E       AssertionError: assert 'weight' in {}

pytest/test_analysis.py:336: AssertionError
______________ TestAnalysisEdgeCases.test_single_client_analysis _______________

self = <test_analysis.TestAnalysisEdgeCases object at 0x7f59e61390>

    def test_single_client_analysis(self):
        """Test Analyse mit nur einem Client."""
        state = WifiAnalysisState()
        client = ClientState(mac="aa:bb:cc:dd:ee:ff")
>       client.all_packet_ts = np.array([time.time(), time.time() + 1])
E       NameError: name 'time' is not defined

pytest/test_analysis.py:379: NameError
_____________ TestAnalysisEdgeCases.test_malformed_event_handling ______________

self = <test_analysis.TestAnalysisEdgeCases object at 0x7f59e620d0>

    def test_malformed_event_handling(self):
        """Test Behandlung von fehlerhaften Events."""
        state = WifiAnalysisState()
    
        # Teste mit unvollständigem Event
>       malformed_event = {'ts': time.time(), 'type': 'beacon'}  # Fehlt bssid
E       NameError: name 'time' is not defined

pytest/test_analysis.py:406: NameError
________________ TestUtilsModule.test_intelligent_vendor_lookup ________________

self = <test_app.TestUtilsModule object at 0x7f59e6c090>

    def test_intelligent_vendor_lookup(self):
>       assert "Apple" in utils.lookup_vendor("a8:51:ab:0c:b9:e9")
E       TypeError: argument of type 'NoneType' is not iterable

pytest/test_app.py:71: TypeError
_____________ TestAnalysisModule.test_features_for_client_behavior _____________

self = <test_app.TestAnalysisModule object at 0x7f59e6dad0>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f51e777d0>

    def test_features_for_client_behavior(self, populated_state):
        client = populated_state.clients['a8:51:ab:0c:b9:e9']
>       features = analysis.features_for_client_behavior(client)
E       AttributeError: module 'wlan_tool.analysis' has no attribute 'features_for_client_behavior'

pytest/test_app.py:108: AttributeError
_________________ TestAnalysisModule.test_cluster_clients_runs _________________

self = <test_app.TestAnalysisModule object at 0x7f59e6e1d0>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f7becb690>

    def test_cluster_clients_runs(self, populated_state):
>       clustered_df, feature_df = analysis.cluster_clients(populated_state, algo="kmeans", n_clusters=2)
E       AttributeError: module 'wlan_tool.analysis' has no attribute 'cluster_clients'

pytest/test_app.py:117: AttributeError
___________________ TestAnalysisModule.test_profile_clusters ___________________

self = <test_app.TestAnalysisModule object at 0x7f59e6e7d0>

    def test_profile_clusters(self):
        feature_data = {'original_macs': ['mac1', 'mac2'], 'feature1': [10, 20], 'feature2': [1, 2]}
        feature_df = pd.DataFrame(feature_data)
        cluster_data = {'original_macs': ['mac1', 'mac2'], 'cluster': [0, 0]}
        clustered_df = pd.DataFrame(cluster_data)
>       profiles = analysis.profile_clusters(feature_df, clustered_df)
E       AttributeError: module 'wlan_tool.analysis' has no attribute 'profile_clusters'

pytest/test_app.py:128: AttributeError
_____________ TestPacketParsing.test_packet_to_event_probe_request _____________

self = <test_capture.TestPacketParsing object at 0x7f59e7e510>

    def test_packet_to_event_probe_request(self):
        """Test Probe-Request-Paket zu Event-Konvertierung."""
        rt_layer = RadioTap(
            present="Flags+Channel+dBm_AntSignal",
            Flags="",
            ChannelFrequency=2412,
            dBm_AntSignal=-60
        )
        dot11_layer = Dot11(
            type=0, subtype=4,
            addr1='ff:ff:ff:ff:ff:ff',  # Broadcast
            addr2='aa:bb:cc:dd:ee:ff'   # Client
        )
        ssid_ie = Dot11Elt(
            ID=0,
            info=b'TestSSID'
        )
    
        pkt = rt_layer / dot11_layer / ssid_ie
        pkt.time = time.time()
    
        event = capture.packet_to_event(pkt)
    
        assert event is not None
        assert event['type'] == 'probe_req'
        assert event['client'] == 'aa:bb:cc:dd:ee:ff'
        assert event['rssi'] == -60
        # SSID wird als Hex-String gespeichert, dann dekodiert
>       assert 'TestSSID' in event['probes']
E       KeyError: 'probes'

pytest/test_capture.py:63: KeyError
______________ TestPacketParsing.test_packet_to_event_data_frame _______________

self = <test_capture.TestPacketParsing object at 0x7f59e7e850>

    def test_packet_to_event_data_frame(self):
        """Test Data-Frame zu Event-Konvertierung."""
>       rt_layer = RadioTap(
            present="Flags+Channel+dBm_AntSignal+MCS_index",
            Flags="",
            ChannelFrequency=2412,
            dBm_AntSignal=-55,
            MCS_index=7
        )

pytest/test_capture.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.11/site-packages/scapy/base_classes.py:399: in __call__
    i.__init__(*args, **kargs)
.venv/lib/python3.11/site-packages/scapy/packet.py:178: in __init__
    self.get_field(fname).any2i(self, value)
.venv/lib/python3.11/site-packages/scapy/fields.py:3052: in any2i
    return self._fixup_val(super(FlagsField, self).any2i(pkt, x))
.venv/lib/python3.11/site-packages/scapy/fields.py:3048: in _fixup_val
    return FlagValue(x, self.names)
.venv/lib/python3.11/site-packages/scapy/fields.py:2835: in __init__
    self.value = self._fixvalue(value)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'FlagValue' object has no attribute 'value'") raised in repr()] FlagValue object at 0x7f51f3c100>
value = ['Flags', 'Channel', 'dBm_AntSignal', 'MCS_index']

    def _fixvalue(self, value):
        # type: (Any) -> int
        if not value:
            return 0
        if isinstance(value, six.string_types):
            value = value.split('+') if self.multi else list(value)
        if isinstance(value, list):
            y = 0
            for i in value:
>               y |= 1 << self.names.index(i)
E               ValueError: 'MCS_index' is not in list

.venv/lib/python3.11/site-packages/scapy/fields.py:2827: ValueError
_______________ TestPacketParsing.test_packet_to_event_with_dhcp _______________

self = <test_capture.TestPacketParsing object at 0x7f59e7f590>

    def test_packet_to_event_with_dhcp(self):
        """Test Paket mit DHCP-Informationen."""
        from scapy.layers.dhcp import DHCP, BOOTP
    
        rt_layer = RadioTap(
            present="Flags+Channel+dBm_AntSignal",
            Flags="",
            ChannelFrequency=2412,
            dBm_AntSignal=-50
        )
        dot11_layer = Dot11(
            type=2, subtype=0,
            addr1='aa:bb:cc:dd:ee:ff',
            addr2='11:22:33:44:55:66'
        )
        bootp_layer = BOOTP(chaddr=b'\x11\x22\x33\x44\x55\x66')
        dhcp_layer = DHCP(options=[(53, 3), (12, b'TestHostname')])  # DHCP Request mit Hostname
    
        pkt = rt_layer / dot11_layer / bootp_layer / dhcp_layer
        pkt.time = time.time()
    
        event = capture.packet_to_event(pkt)
    
        assert event is not None
        assert event['type'] == 'data'
>       assert event['hostname'] == 'TestHostname'
E       KeyError: 'hostname'

pytest/test_capture.py:155: KeyError
____________ TestChannelHopper.test_channel_hopper_command_failure _____________

self = <test_capture.TestChannelHopper object at 0x7f59e89650>
mock_run = <MagicMock name='run' id='547541182800'>

    @patch('subprocess.run')
    def test_channel_hopper_command_failure(self, mock_run):
        """Test ChannelHopper bei Kommando-Fehlern."""
>       mock_run.side_effect = subprocess.CalledProcessError(1, "iw")
E       NameError: name 'subprocess' is not defined

pytest/test_capture.py:235: NameError
______________________ TestIEExtraction.test_extract_seq _______________________

self = <test_capture.TestIEExtraction object at 0x7f59e8c690>

    def test_extract_seq(self):
        """Test Sequenznummer-Extraktion."""
        dot11 = Dot11(SC=0x1234)  # SC = 0x1234, >> 4 = 0x123
    
        seq = capture._extract_seq(dot11)
        assert seq == 0x123
    
        # Test mit None
        seq = capture._extract_seq(None)
>       assert seq is None
E       assert 0 is None

pytest/test_capture.py:379: AssertionError
____________ TestErrorHandling.test_packet_to_event_encoding_error _____________

self = <test_capture.TestErrorHandling object at 0x7f59e8d4d0>

    def test_packet_to_event_encoding_error(self):
        """Test mit Encoding-Fehlern."""
        rt_layer = RadioTap()
        dot11_layer = Dot11(type=0, subtype=8, addr3='aa:bb:cc:dd:ee:ff')
        beacon_layer = Dot11Beacon()
        # Erstelle IE mit ungültigem UTF-8
        ssid_ie = Dot11Elt(ID=0, info=b'\xff\xfe\xfd')
    
        pkt = rt_layer / dot11_layer / beacon_layer / ssid_ie
        pkt.time = time.time()
    
        # Sollte nicht crashen
        event = capture.packet_to_event(pkt)
        if event is not None:
>           assert event['ssid'] == "<binary>"  # Sollte als binary markiert werden
E           AssertionError: assert '<hidden>' == '<binary>'
E             
E             - <binary>
E             + <hidden>

pytest/test_capture.py:412: AssertionError
____________ TestCaptureController.test_select_interface_automatic _____________

self = <test_controllers.TestCaptureController object at 0x7f59e8fad0>
mock_find_interfaces = <MagicMock name='find_wlan_interfaces' id='546761280720'>
mock_console = <MagicMock id='546751061968'>

    @patch('wlan_tool.pre_run_checks.find_wlan_interfaces')
    def test_select_interface_automatic(self, mock_find_interfaces, mock_console):
        """Test automatische Interface-Auswahl."""
        mock_find_interfaces.return_value = ["wlan0", "wlan1"]
    
        args = MagicMock()
        args.iface = None
        config_data = {}
    
        controller = CaptureController(args, config_data, mock_console)
    
        with patch('rich.prompt.Prompt.ask', return_value="wlan0"):
>           iface = controller._select_interface()

pytest/test_controllers.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.controllers.CaptureController object at 0x7f516b7710>

    def _select_interface(self) -> Optional[str]:
        """Wählt das zu verwendende physische WLAN-Interface aus."""
        iface = self.args.iface
        if not iface:
            self.console.print(
                "[bold cyan]Kein Interface angegeben. Suche nach geeigneten WLAN-Interfaces...[/bold cyan]"
            )
>           suitable_ifaces = pre_run_checks.find_wlan_interfaces()
E           NameError: name 'pre_run_checks' is not defined

wlan_tool/controllers.py:124: NameError
__________ TestCaptureController.test_select_interface_no_interfaces ___________

self = <test_controllers.TestCaptureController object at 0x7f59e98110>
mock_find_interfaces = <MagicMock name='find_wlan_interfaces' id='546751056656'>
mock_console = <MagicMock id='546761291856'>

    @patch('wlan_tool.pre_run_checks.find_wlan_interfaces')
    def test_select_interface_no_interfaces(self, mock_find_interfaces, mock_console):
        """Test Interface-Auswahl ohne verfügbare Interfaces."""
        mock_find_interfaces.return_value = []
    
        args = MagicMock()
        args.iface = None
        config_data = {}
    
        controller = CaptureController(args, config_data, mock_console)
    
>       iface = controller._select_interface()

pytest/test_controllers.py:57: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.controllers.CaptureController object at 0x7f4ce37910>

    def _select_interface(self) -> Optional[str]:
        """Wählt das zu verwendende physische WLAN-Interface aus."""
        iface = self.args.iface
        if not iface:
            self.console.print(
                "[bold cyan]Kein Interface angegeben. Suche nach geeigneten WLAN-Interfaces...[/bold cyan]"
            )
>           suitable_ifaces = pre_run_checks.find_wlan_interfaces()
E           NameError: name 'pre_run_checks' is not defined

wlan_tool/controllers.py:124: NameError
____________ TestCaptureController.test_setup_monitor_mode_failure _____________

self = <test_controllers.TestCaptureController object at 0x7f59e993d0>
mock_run = <MagicMock name='run' id='546751187408'>
mock_console = <MagicMock id='546751667600'>

    @patch('subprocess.run')
    def test_setup_monitor_mode_failure(self, mock_run, mock_console):
        """Test Monitor-Mode-Setup (Fehler)."""
>       mock_run.side_effect = subprocess.CalledProcessError(1, "airmon-ng")
E       NameError: name 'subprocess' is not defined

pytest/test_controllers.py:89: NameError
________ TestAnalysisController.test_analysis_controller_initialization ________

self = <test_controllers.TestAnalysisController object at 0x7f59e9ae50>
mock_console = <MagicMock id='546826837072'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f4cefc810>

    def test_analysis_controller_initialization(self, mock_console, populated_state):
        """Test AnalysisController-Initialisierung."""
        args = MagicMock()
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
        assert controller.args == args
        assert controller.config_data == config_data
        assert controller.console == mock_console
        assert controller.plugins == plugins
>       assert controller.state == populated_state
E       AttributeError: 'AnalysisController' object has no attribute 'state'

pytest/test_controllers.py:201: AttributeError
__________________ TestAnalysisController.test_run_inference ___________________

self = <test_controllers.TestAnalysisController object at 0x7f59e8f010>
mock_score = <MagicMock name='score_pairs_with_recency_and_matching' id='546751779600'>
mock_console = <MagicMock id='546751631312'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f4cf03f90>

    @patch('wlan_tool.analysis.logic.score_pairs_with_recency_and_matching')
    def test_run_inference(self, mock_score, mock_console, populated_state):
        """Test Inferenz-Ausführung."""
        mock_score.return_value = []
    
        args = MagicMock()
        args.infer = True
        args.model = None
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       controller.run_inference()
E       AttributeError: 'AnalysisController' object has no attribute 'run_inference'

pytest/test_controllers.py:218: AttributeError
______________ TestAnalysisController.test_run_client_clustering _______________

self = <test_controllers.TestAnalysisController object at 0x7f59e991d0>
mock_cluster = <MagicMock name='cluster_clients' id='546751133904'>
mock_console = <MagicMock id='546823435472'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f4cf04d10>

    @patch('wlan_tool.analysis.logic.cluster_clients')
    def test_run_client_clustering(self, mock_cluster, mock_console, populated_state):
        """Test Client-Clustering."""
        mock_cluster.return_value = (None, None)
    
        args = MagicMock()
        args.cluster_clients = 2
        args.cluster_algo = "kmeans"
        args.no_mac_correlation = False
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       controller.run_client_clustering()
E       AttributeError: 'AnalysisController' object has no attribute 'run_client_clustering'

pytest/test_controllers.py:237: AttributeError
________________ TestAnalysisController.test_run_ap_clustering _________________

self = <test_controllers.TestAnalysisController object at 0x7f59e9b5d0>
mock_cluster = <MagicMock name='cluster_aps' id='546751008912'>
mock_console = <MagicMock id='546751190032'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f4ce90710>

    @patch('wlan_tool.analysis.logic.cluster_aps')
    def test_run_ap_clustering(self, mock_cluster, mock_console, populated_state):
        """Test AP-Clustering."""
        mock_cluster.return_value = None
    
        args = MagicMock()
        args.cluster_aps = 2
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       controller.run_ap_clustering()
E       AttributeError: 'AnalysisController' object has no attribute 'run_ap_clustering'

pytest/test_controllers.py:254: AttributeError
_________________ TestAnalysisController.test_run_graph_export _________________

self = <test_controllers.TestAnalysisController object at 0x7f59e9b950>
mock_export = <MagicMock name='export_ap_graph' id='546750967056'>
mock_console = <MagicMock id='546750886032'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f4ce59710>

    @patch('wlan_tool.analysis.logic.export_ap_graph')
    def test_run_graph_export(self, mock_export, mock_console, populated_state):
        """Test Graph-Export."""
        mock_export.return_value = True
    
        args = MagicMock()
        args.export_graph = "/tmp/test.gexf"
        args.cluster_aps = 2
        args.graph_include_clients = False
        args.graph_min_activity = 0
        args.graph_min_duration = 0
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       with patch.object(controller, 'run_ap_clustering', return_value=None):

pytest/test_controllers.py:275: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f4cd3d990>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <wlan_tool.controllers.AnalysisController object at 0x7f4cd3d9d0> does not have the attribute 'run_ap_clustering'

../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1419: AttributeError
_________________ TestAnalysisController.test_run_labeling_ui __________________

self = <test_controllers.TestAnalysisController object at 0x7f59e9bcd0>
mock_label_ui = <MagicMock name='interactive_label_ui' id='546751712272'>
mock_console = <MagicMock id='546751621968'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f4cf11cd0>

    @patch('wlan_tool.presentation.cli.interactive_label_ui')
    def test_run_labeling_ui(self, mock_label_ui, mock_console, populated_state):
        """Test Labeling-UI."""
        args = MagicMock()
        args.label_ui = True
        args.db = "test.db"
        args.label_db = "labels.db"
        args.model = "model.pkl"
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       controller.run_labeling_ui()
E       AttributeError: 'AnalysisController' object has no attribute 'run_labeling_ui'

pytest/test_controllers.py:294: AttributeError
______________ TestAnalysisController.test_run_client_labeling_ui ______________

self = <test_controllers.TestAnalysisController object at 0x7f59ca8090>
mock_client_label_ui = <MagicMock name='interactive_client_label_ui' id='546749831184'>
mock_console = <MagicMock id='546751333776'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f4cd2fad0>

    @patch('wlan_tool.presentation.cli.interactive_client_label_ui')
    def test_run_client_labeling_ui(self, mock_client_label_ui, mock_console, populated_state):
        """Test Client-Labeling-UI."""
        args = MagicMock()
        args.label_clients = True
        args.label_db = "labels.db"
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       controller.run_client_labeling_ui()
E       AttributeError: 'AnalysisController' object has no attribute 'run_client_labeling_ui'

pytest/test_controllers.py:310: AttributeError
_______________ TestAnalysisController.test_run_mac_correlation ________________

self = <test_controllers.TestAnalysisController object at 0x7f59ca85d0>
mock_correlate = <MagicMock name='correlate_devices_by_fingerprint' id='546750465872'>
mock_console = <MagicMock id='546750497040'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f4ce64950>

    @patch('wlan_tool.analysis.device_profiler.correlate_devices_by_fingerprint')
    def test_run_mac_correlation(self, mock_correlate, mock_console, populated_state):
        """Test MAC-Korrelation."""
        mock_correlate.return_value = {}
    
        args = MagicMock()
        args.correlate_macs = True
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       controller.run_mac_correlation()
E       AttributeError: 'AnalysisController' object has no attribute 'run_mac_correlation'

pytest/test_controllers.py:327: AttributeError
_____________ TestAnalysisController.test_run_analysis_no_actions ______________

self = <test_controllers.TestAnalysisController object at 0x7f59ca8c50>
mock_console = <MagicMock id='546751087888'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f4cdc0450>

    def test_run_analysis_no_actions(self, mock_console, populated_state):
        """Test Analyse ohne Aktionen."""
        args = MagicMock()
        args.infer = False
        args.cluster_clients = None
        args.cluster_aps = None
        args.export_graph = None
        args.label_ui = False
        args.label_clients = False
        args.correlate_macs = False
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
        # Sollte nicht crashen
>       controller.run_analysis()

pytest/test_controllers.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/controllers.py:339: in run_analysis
    self._run_profiling()  # Benötigt state, den es jetzt als self.state hat
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.controllers.AnalysisController object at 0x7f4cdc2e10>

    def _run_profiling(self):
        self.console.print(
            "\n[bold cyan]Starte automatisches Geräte-Profiling...[/bold cyan]"
        )
        device_map = {}
    
        # --- NEU: Versuch 1: TR-064 (FRITZ!Box) ---
        self.console.print(
            "[cyan]Versuch 1: Identifizierung über FRITZ!Box TR-064...[/cyan]"
        )
        # Passwort aus Argumenten oder interaktiv abfragen
        fritz_password = self.args.fritzbox_password
        if FritzHosts and not fritz_password:
            if (
                self.console.input(
                    "Haben Sie ein Passwort für Ihre FRITZ!Box gesetzt? (y/n): "
                ).lower()
                == "y"
            ):
                fritz_password = self.console.input(
                    "Bitte FRITZ!Box-Passwort eingeben: ", password=True
                )
    
        device_map = (
>           device_profiler.get_devices_from_fritzbox_tr064(password=fritz_password)
            or {}
        )
E       NameError: name 'device_profiler' is not defined

wlan_tool/controllers.py:487: NameError
__________ TestAnalysisController.test_run_analysis_multiple_actions ___________

self = <test_controllers.TestAnalysisController object at 0x7f59ca92d0>
mock_console = <MagicMock id='546750532112'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f4cdad6d0>

    def test_run_analysis_multiple_actions(self, mock_console, populated_state):
        """Test Analyse mit mehreren Aktionen."""
        args = MagicMock()
        args.infer = True
        args.cluster_clients = 2
        args.cluster_aps = 2
        args.export_graph = "/tmp/test.gexf"
        args.label_ui = False
        args.label_clients = False
        args.correlate_macs = False
        args.model = None
        args.cluster_algo = "kmeans"
        args.no_mac_correlation = False
        args.graph_include_clients = False
        args.graph_min_activity = 0
        args.graph_min_duration = 0
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       with patch.object(controller, 'run_inference'):

pytest/test_controllers.py:372: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f4cdaf310>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <wlan_tool.controllers.AnalysisController object at 0x7f51f8d850> does not have the attribute 'run_inference'

../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1419: AttributeError
_________ TestControllerEdgeCases.test_analysis_controller_empty_state _________

self = <test_controllers.TestControllerEdgeCases object at 0x7f59caab50>
mock_console = <MagicMock id='546750238800'>

    def test_analysis_controller_empty_state(self, mock_console):
        """Test AnalysisController mit leerem State."""
        args = MagicMock()
        args.infer = True
        args.model = None
        config_data = {}
        plugins = {}
        new_events = []
        empty_state = WifiAnalysisState()
    
        controller = AnalysisController(args, config_data, mock_console, plugins, empty_state, new_events)
    
        # Sollte nicht crashen
>       controller.run_inference()
E       AttributeError: 'AnalysisController' object has no attribute 'run_inference'

pytest/test_controllers.py:420: AttributeError
________ TestControllerEdgeCases.test_analysis_controller_with_plugins _________

self = <test_controllers.TestControllerEdgeCases object at 0x7f59cab2d0>
mock_console = <MagicMock id='546750714576'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f4cdcb510>

    def test_analysis_controller_with_plugins(self, mock_console, populated_state):
        """Test AnalysisController mit Plugins."""
        args = MagicMock()
        args.run_plugins = ["test_plugin"]
        config_data = {}
    
        mock_plugin = MagicMock()
        mock_plugin.run.return_value = None
        plugins = {"test_plugin": mock_plugin}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       controller.run_plugins()
E       AttributeError: 'AnalysisController' object has no attribute 'run_plugins'

pytest/test_controllers.py:435: AttributeError
____________ TestControllerIntegration.test_full_analysis_workflow _____________

self = <test_controllers.TestControllerIntegration object at 0x7f59cb4210>
mock_console = <MagicMock id='546750238224'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f4cda3450>

    def test_full_analysis_workflow(self, mock_console, populated_state):
        """Test vollständiger Analyse-Workflow."""
        args = MagicMock()
        args.infer = True
        args.cluster_clients = 2
        args.cluster_aps = 2
        args.export_graph = "/tmp/test.gexf"
        args.label_ui = False
        args.label_clients = False
        args.correlate_macs = False
        args.model = None
        args.cluster_algo = "kmeans"
        args.no_mac_correlation = False
        args.graph_include_clients = False
        args.graph_min_activity = 0
        args.graph_min_duration = 0
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       with patch.object(controller, 'run_inference'):

pytest/test_controllers.py:491: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f4ce00ed0>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <wlan_tool.controllers.AnalysisController object at 0x7f4ce00f50> does not have the attribute 'run_inference'

../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1419: AttributeError
_____________________ TestLoggingSystem.test_setup_logging _____________________

self = <test_error_handling.TestLoggingSystem object at 0x7f59d110d0>

    def test_setup_logging(self):
        """Test Logging-Setup."""
        logger = setup_logging(
            log_level="DEBUG",
            enable_console=True,
            enable_performance_logging=True,
            enable_error_tracking=True
        )
    
        assert logger is not None
        assert logger.name == "wlan_tool"
>       assert logger.level == logging.DEBUG
E       NameError: name 'logging' is not defined

pytest/test_error_handling.py:317: NameError
___________ TestDatabaseErrorHandling.test_database_connection_error ___________

self = <test_error_handling.TestDatabaseErrorHandling object at 0x7f59d122d0>

    def test_database_connection_error(self):
        """Test Datenbankverbindungs-Fehler."""
        with pytest.raises(DatabaseError) as exc_info:
            from wlan_tool.storage.database import db_conn_ctx
            with db_conn_ctx("/invalid/path/database.db"):
                pass
    
        assert "Cannot create database directory" in str(exc_info.value)
>       assert exc_info.value.error_code == "SQLITE_ERROR"
E       AssertionError: assert 'DB_UNEXPECTED_ERROR' == 'SQLITE_ERROR'
E         
E         - SQLITE_ERROR
E         + DB_UNEXPECTED_ERROR

pytest/test_error_handling.py:345: AssertionError
----------------------------- Captured stdout call -----------------------------
2025-10-19 11:40:27,361 | DEBUG    | Starting operation: database_connection
2025-10-19 11:40:27,362 | ERROR    | Error in database_connection: WLANToolError: Cannot create database directory: /invalid/path (Code: DB_DIR_CREATION_FAILED) | Details: {'directory': '/invalid/path', 'original_error': "[Errno 13] Permission denied: '/invalid'"} (Code: DB_DIR_CREATION_FAILED) | Details: {'directory': '/invalid/path', 'original_error': "[Errno 13] Permission denied: '/invalid'"}
2025-10-19 11:40:27,368 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/pathlib.py", line 1116, in mkdir
    os.mkdir(self, mode)
FileNotFoundError: [Errno 2] No such file or directory: '/invalid/path'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 81, in db_conn_ctx
    db_dir.mkdir(parents=True, exist_ok=True)
  File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/pathlib.py", line 1120, in mkdir
    self.parent.mkdir(parents=True, exist_ok=True)
  File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/pathlib.py", line 1116, in mkdir
    os.mkdir(self, mode)
PermissionError: [Errno 13] Permission denied: '/invalid'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 83, in db_conn_ctx
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Cannot create database directory: /invalid/path (Code: DB_DIR_CREATION_FAILED) | Details: {'directory': '/invalid/path', 'original_error': "[Errno 13] Permission denied: '/invalid'"}

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in database_connection: WLANToolError: Cannot create database directory: /invalid/path (Code: DB_DIR_CREATION_FAILED) | Details: {'directory': '/invalid/path', 'original_error': "[Errno 13] Permission denied: '/invalid'"} (Code: DB_DIR_CREATION_FAILED) | Details: {'directory': '/invalid/path', 'original_error': "[Errno 13] Permission denied: '/invalid'"}
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/pathlib.py", line 1116, in mkdir
    os.mkdir(self, mode)
FileNotFoundError: [Errno 2] No such file or directory: '/invalid/path'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 81, in db_conn_ctx
    db_dir.mkdir(parents=True, exist_ok=True)
  File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/pathlib.py", line 1120, in mkdir
    self.parent.mkdir(parents=True, exist_ok=True)
  File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/pathlib.py", line 1116, in mkdir
    os.mkdir(self, mode)
PermissionError: [Errno 13] Permission denied: '/invalid'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 83, in db_conn_ctx
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Cannot create database directory: /invalid/path (Code: DB_DIR_CREATION_FAILED) | Details: {'directory': '/invalid/path', 'original_error': "[Errno 13] Permission denied: '/invalid'"}
___________ TestDatabaseErrorHandling.test_database_migration_error ____________

self = <test_error_handling.TestDatabaseErrorHandling object at 0x7f59d128d0>

    def test_database_migration_error(self):
        """Test Datenbankmigrations-Fehler."""
        with tempfile.NamedTemporaryFile(suffix='.db', delete=False) as f:
            db_path = f.name
    
        try:
            # Erstelle ungültige Migration
            migrations_dir = Path("wlan_tool/assets/sql_data/versions")
            migrations_dir.mkdir(parents=True, exist_ok=True)
    
            invalid_migration = migrations_dir / "999_invalid.sql"
            invalid_migration.write_text("INVALID SQL SYNTAX")
    
>           with pytest.raises(DatabaseError):
E           Failed: DID NOT RAISE <class 'wlan_tool.exceptions.DatabaseError'>

pytest/test_error_handling.py:360: Failed
----------------------------- Captured stdout call -----------------------------
2025-10-19 11:40:27,406 | DEBUG    | Starting operation: database_migration
2025-10-19 11:40:27,407 | DEBUG    | Starting operation: database_connection
2025-10-19 11:40:27,423 | INFO     | Current DB version: 0. Looking for migrations...
2025-10-19 11:40:27,423 | INFO     | Applying migration: 001_initial_schema.sql (Version 1)
2025-10-19 11:40:27,435 | INFO     | DB successfully migrated to version 1
2025-10-19 11:40:27,435 | INFO     | Applying migration: 002_add_dns_table.sql (Version 2)
2025-10-19 11:40:27,436 | INFO     | DB successfully migrated to version 2
2025-10-19 11:40:27,437 | INFO     | Applying migration: 003_add_network_info.sql (Version 3)
2025-10-19 11:40:27,438 | INFO     | DB successfully migrated to version 3
2025-10-19 11:40:27,438 | INFO     | Applying migration: 004_add_indexes.sql (Version 4)
2025-10-19 11:40:27,440 | INFO     | DB successfully migrated to version 4
2025-10-19 11:40:27,440 | INFO     | Applying migration: 999_invalid.sql (Version 999)
2025-10-19 11:40:27,441 | ERROR    | Unexpected error during migration 999_invalid.sql: WLANToolError: Migration failed: 999_invalid.sql (Code: MIGRATION_EXECUTION_FAILED) | Details: {'migration_file': '999_invalid.sql', 'version': 999, 'sqlite_error': 'near "INVALID": syntax error'}
2025-10-19 11:40:27,461 | INFO     | Database is up to date.
------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_migration
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
INFO     wlan_tool.storage.database:database.py:157 Current DB version: 0. Looking for migrations...
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 001_initial_schema.sql (Version 1)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 1
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 002_add_dns_table.sql (Version 2)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 2
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 003_add_network_info.sql (Version 3)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 3
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 004_add_indexes.sql (Version 4)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 4
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 999_invalid.sql (Version 999)
ERROR    wlan_tool.storage.database:database.py:199 Unexpected error during migration 999_invalid.sql: WLANToolError: Migration failed: 999_invalid.sql (Code: MIGRATION_EXECUTION_FAILED) | Details: {'migration_file': '999_invalid.sql', 'version': 999, 'sqlite_error': 'near "INVALID": syntax error'}
INFO     wlan_tool.storage.database:database.py:204 Database is up to date.
__________ TestAnalysisErrorHandling.test_client_features_null_state ___________

self = <test_error_handling.TestAnalysisErrorHandling object at 0x7f59d13190>

    def test_client_features_null_state(self):
        """Test Client-Features mit None-State."""
        from wlan_tool.analysis.logic import features_for_client
    
>       with pytest.raises(ValidationError) as exc_info:
E       Failed: DID NOT RAISE <class 'wlan_tool.exceptions.ValidationError'>

pytest/test_error_handling.py:377: Failed
----------------------------- Captured stdout call -----------------------------
2025-10-19 11:40:27,493 | DEBUG    | Starting operation: client_features_extraction
2025-10-19 11:40:27,494 | ERROR    | Error in client_features_extraction: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'} (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}
2025-10-19 11:40:27,494 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 229, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}

2025-10-19 11:40:27,494 | ERROR    | Unexpected error in features_for_client: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}
2025-10-19 11:40:27,495 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 229, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_features_extraction
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in client_features_extraction: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'} (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 229, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}

ERROR    wlan_tool.analysis.logic:exceptions.py:165 Unexpected error in features_for_client: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}
DEBUG    wlan_tool.analysis.logic:exceptions.py:166 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 229, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}
_________ TestAnalysisErrorHandling.test_client_features_invalid_type __________

self = <test_error_handling.TestAnalysisErrorHandling object at 0x7f59d13790>

    def test_client_features_invalid_type(self):
        """Test Client-Features mit ungültigem Typ."""
        from wlan_tool.analysis.logic import features_for_client
    
>       with pytest.raises(ValidationError) as exc_info:
E       Failed: DID NOT RAISE <class 'wlan_tool.exceptions.ValidationError'>

pytest/test_error_handling.py:387: Failed
----------------------------- Captured stdout call -----------------------------
2025-10-19 11:40:27,524 | DEBUG    | Starting operation: client_features_extraction
2025-10-19 11:40:27,524 | ERROR    | Error in client_features_extraction: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"} (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}
2025-10-19 11:40:27,525 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 236, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}

2025-10-19 11:40:27,525 | ERROR    | Unexpected error in features_for_client: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}
2025-10-19 11:40:27,526 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 236, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_features_extraction
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in client_features_extraction: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"} (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 236, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}

ERROR    wlan_tool.analysis.logic:exceptions.py:165 Unexpected error in features_for_client: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}
DEBUG    wlan_tool.analysis.logic:exceptions.py:166 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 236, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}
_________ TestAnalysisErrorHandling.test_clustering_invalid_parameters _________

self = <test_error_handling.TestAnalysisErrorHandling object at 0x7f59d13d90>

    def test_clustering_invalid_parameters(self):
        """Test Clustering mit ungültigen Parametern."""
        from wlan_tool.analysis.logic import cluster_clients
        from wlan_tool.storage.state import WifiAnalysisState
    
        state = WifiAnalysisState()
    
        # Teste ungültige n_clusters
>       with pytest.raises(ValidationError) as exc_info:
E       Failed: DID NOT RAISE <class 'wlan_tool.exceptions.ValidationError'>

pytest/test_error_handling.py:401: Failed
----------------------------- Captured stdout call -----------------------------
2025-10-19 11:40:27,554 | DEBUG    | Starting operation: client_clustering
2025-10-19 11:40:27,555 | ERROR    | Error in client_clustering: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0} (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}
2025-10-19 11:40:27,555 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 495, in cluster_clients
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}

2025-10-19 11:40:27,555 | ERROR    | Unexpected error in cluster_clients: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}
2025-10-19 11:40:27,556 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 495, in cluster_clients
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_clustering
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in client_clustering: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0} (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 495, in cluster_clients
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}

ERROR    wlan_tool.analysis.logic:exceptions.py:165 Unexpected error in cluster_clients: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}
DEBUG    wlan_tool.analysis.logic:exceptions.py:166 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 495, in cluster_clients
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}
___________ TestFileSystemErrorHandling.test_csv_export_invalid_path ___________

self = <test_error_handling.TestFileSystemErrorHandling object at 0x7f59d1c610>

    def test_csv_export_invalid_path(self):
        """Test CSV-Export mit ungültigem Pfad."""
        from wlan_tool.storage.database import export_confirmed_to_csv
    
>       with pytest.raises(ValidationError) as exc_info:
E       Failed: DID NOT RAISE <class 'wlan_tool.exceptions.ValidationError'>

pytest/test_error_handling.py:422: Failed
----------------------------- Captured stdout call -----------------------------
2025-10-19 11:40:27,585 | DEBUG    | Starting operation: csv_export
2025-10-19 11:40:27,587 | ERROR    | Error in csv_export: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''} (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}
2025-10-19 11:40:27,588 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}

2025-10-19 11:40:27,588 | ERROR    | Error in export_confirmed_to_csv: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}
2025-10-19 11:40:27,589 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: csv_export
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in csv_export: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''} (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}

ERROR    wlan_tool.storage.database:exceptions.py:153 Error in export_confirmed_to_csv: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}
DEBUG    wlan_tool.storage.database:exceptions.py:154 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}
____________ TestFileSystemErrorHandling.test_csv_export_missing_db ____________

self = <test_error_handling.TestFileSystemErrorHandling object at 0x7f59d1cc10>

    def test_csv_export_missing_db(self):
        """Test CSV-Export mit fehlender Datenbank."""
        from wlan_tool.storage.database import export_confirmed_to_csv
    
>       with pytest.raises(FileSystemError) as exc_info:
E       Failed: DID NOT RAISE <class 'wlan_tool.exceptions.FileSystemError'>

pytest/test_error_handling.py:432: Failed
----------------------------- Captured stdout call -----------------------------
2025-10-19 11:40:27,618 | DEBUG    | Starting operation: csv_export
2025-10-19 11:40:27,618 | ERROR    | Error in csv_export: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'} (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}
2025-10-19 11:40:27,619 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}

2025-10-19 11:40:27,619 | ERROR    | Error in export_confirmed_to_csv: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}
2025-10-19 11:40:27,620 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: csv_export
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in csv_export: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'} (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}

ERROR    wlan_tool.storage.database:exceptions.py:153 Error in export_confirmed_to_csv: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}
DEBUG    wlan_tool.storage.database:exceptions.py:154 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}
____________ TestErrorHandlingEdgeCases.test_nested_error_contexts _____________

self = <test_error_handling.TestErrorHandlingEdgeCases object at 0x7f59d1e350>

    def test_nested_error_contexts(self):
        """Test verschachtelte Error-Contexts."""
        with ErrorContext("outer_operation", "OUTER_ERROR") as outer:
            with ErrorContext("inner_operation", "INNER_ERROR") as inner:
>               raise ValueError("Inner error")
E               ValueError: Inner error

pytest/test_error_handling.py:473: ValueError

The above exception was the direct cause of the following exception:

self = <test_error_handling.TestErrorHandlingEdgeCases object at 0x7f59d1e350>

    def test_nested_error_contexts(self):
        """Test verschachtelte Error-Contexts."""
        with ErrorContext("outer_operation", "OUTER_ERROR") as outer:
>           with ErrorContext("inner_operation", "INNER_ERROR") as inner:

pytest/test_error_handling.py:472: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.exceptions.ErrorContext object at 0x7f4cd8c150>
exc_type = <class 'ValueError'>, exc_val = ValueError('Inner error')
exc_tb = <traceback object at 0x7f4cd8c400>

    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type is not None:
            error_msg = f"Error in {self.operation}: {exc_val}"
    
            if isinstance(exc_val, WLANToolError):
                error_msg += f" (Code: {exc_val.error_code})"
                if exc_val.details:
                    error_msg += f" | Details: {exc_val.details}"
            else:
                error_msg += f" | Type: {exc_type.__name__}"
    
            self.logger.log(self.log_level, error_msg)
            self.logger.debug(f"Traceback: {traceback.format_exc()}")
    
            # Konvertiere zu WLANToolError falls nötig
            if not isinstance(exc_val, WLANToolError):
                wlan_error = WLANToolError(
                    message=str(exc_val),
                    error_code=self.error_code or "CONTEXT_ERROR",
                    details={
                        "operation": self.operation,
                        "original_type": exc_type.__name__,
                    },
                )
>               raise wlan_error from exc_val
E               wlan_tool.exceptions.WLANToolError: WLANToolError: Inner error (Code: INNER_ERROR) | Details: {'operation': 'inner_operation', 'original_type': 'ValueError'}

wlan_tool/exceptions.py:313: WLANToolError
----------------------------- Captured stdout call -----------------------------
2025-10-19 11:40:28,658 | DEBUG    | Starting operation: outer_operation
2025-10-19 11:40:28,658 | DEBUG    | Starting operation: inner_operation
2025-10-19 11:40:28,658 | ERROR    | Error in inner_operation: Inner error | Type: ValueError
2025-10-19 11:40:28,659 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/pytest/test_error_handling.py", line 473, in test_nested_error_contexts
    raise ValueError("Inner error")
ValueError: Inner error

2025-10-19 11:40:28,659 | ERROR    | Error in outer_operation: WLANToolError: Inner error (Code: INNER_ERROR) | Details: {'operation': 'inner_operation', 'original_type': 'ValueError'} (Code: INNER_ERROR) | Details: {'operation': 'inner_operation', 'original_type': 'ValueError'}
2025-10-19 11:40:28,660 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/pytest/test_error_handling.py", line 473, in test_nested_error_contexts
    raise ValueError("Inner error")
ValueError: Inner error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/pi/hacking/pytest/test_error_handling.py", line 472, in test_nested_error_contexts
    with ErrorContext("inner_operation", "INNER_ERROR") as inner:
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 313, in __exit__
    raise wlan_error from exc_val
wlan_tool.exceptions.WLANToolError: WLANToolError: Inner error (Code: INNER_ERROR) | Details: {'operation': 'inner_operation', 'original_type': 'ValueError'}

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: outer_operation
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: inner_operation
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in inner_operation: Inner error | Type: ValueError
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/pytest/test_error_handling.py", line 473, in test_nested_error_contexts
    raise ValueError("Inner error")
ValueError: Inner error

ERROR    wlan_tool.exceptions:exceptions.py:300 Error in outer_operation: WLANToolError: Inner error (Code: INNER_ERROR) | Details: {'operation': 'inner_operation', 'original_type': 'ValueError'} (Code: INNER_ERROR) | Details: {'operation': 'inner_operation', 'original_type': 'ValueError'}
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/pytest/test_error_handling.py", line 473, in test_nested_error_contexts
    raise ValueError("Inner error")
ValueError: Inner error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/pi/hacking/pytest/test_error_handling.py", line 472, in test_nested_error_contexts
    with ErrorContext("inner_operation", "INNER_ERROR") as inner:
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 313, in __exit__
    raise wlan_error from exc_val
wlan_tool.exceptions.WLANToolError: WLANToolError: Inner error (Code: INNER_ERROR) | Details: {'operation': 'inner_operation', 'original_type': 'ValueError'}
_____________ TestEndToEndWorkflow.test_complete_analysis_pipeline _____________

self = <test_integration.TestEndToEndWorkflow object at 0x7f59d1ff50>
sample_events = [{'beacon_interval': 102, 'bssid': '08:96:d7:1a:21:1c', 'cap': 17, 'channel': 6, ...}, {'client': 'a8:51:ab:0c:b9:e9',...-91, ...}, {'client': 'b2:87:23:15:7f:f2', 'ie_order_hash': 67890, 'ies': {0: ['MyOtherWLAN']}, 'rssi': -70, ...}, ...]
temp_db_file = '/tmp/tmp563tci02.db'

    def test_complete_analysis_pipeline(self, sample_events, temp_db_file):
        """Test kompletter Analyse-Pipeline."""
        # 1. Erstelle State aus Events
        state = WifiAnalysisState()
        state.build_from_events(sample_events)
    
        assert len(state.aps) > 0
        assert len(state.clients) > 0
    
        # 2. Führe Inferenz durch
        results = analysis.score_pairs_with_recency_and_matching(state)
        assert isinstance(results, list)
    
        # 3. Führe Client-Clustering durch
        clustered_df, feature_df = analysis.cluster_clients(state, n_clusters=2)
        if clustered_df is not None:
            assert len(clustered_df) > 0
    
        # 4. Führe AP-Clustering durch
>       ap_clustered_df = analysis.cluster_aps(state, n_clusters=2)

pytest/test_integration.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/analysis/logic.py:736: in cluster_aps
    df["cluster"] = kmeans.fit_predict(X_scaled)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1064: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1456: in fit
    self._check_params_vs_input(X)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1396: in _check_params_vs_input
    super()._check_params_vs_input(X, default_n_init=10)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = KMeans(n_clusters=2, random_state=42)
X = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])
default_n_init = 10

    def _check_params_vs_input(self, X, default_n_init=None):
        # n_clusters
        if X.shape[0] < self.n_clusters:
>           raise ValueError(
                f"n_samples={X.shape[0]} should be >= n_clusters={self.n_clusters}."
            )
E           ValueError: n_samples=1 should be >= n_clusters=2.

.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:871: ValueError
---------------------------- Captured stdout setup -----------------------------
2025-10-19 11:40:28,769 | DEBUG    | Starting operation: database_migration
2025-10-19 11:40:28,770 | DEBUG    | Starting operation: database_connection
2025-10-19 11:40:28,787 | INFO     | Current DB version: 0. Looking for migrations...
2025-10-19 11:40:28,787 | INFO     | Applying migration: 001_initial_schema.sql (Version 1)
2025-10-19 11:40:28,798 | INFO     | DB successfully migrated to version 1
2025-10-19 11:40:28,799 | INFO     | Applying migration: 002_add_dns_table.sql (Version 2)
2025-10-19 11:40:28,800 | INFO     | DB successfully migrated to version 2
2025-10-19 11:40:28,800 | INFO     | Applying migration: 003_add_network_info.sql (Version 3)
2025-10-19 11:40:28,802 | INFO     | DB successfully migrated to version 3
2025-10-19 11:40:28,802 | INFO     | Applying migration: 004_add_indexes.sql (Version 4)
2025-10-19 11:40:28,803 | INFO     | DB successfully migrated to version 4
2025-10-19 11:40:28,823 | INFO     | Database is up to date.
------------------------------ Captured log setup ------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_migration
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
INFO     wlan_tool.storage.database:database.py:157 Current DB version: 0. Looking for migrations...
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 001_initial_schema.sql (Version 1)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 1
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 002_add_dns_table.sql (Version 2)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 2
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 003_add_network_info.sql (Version 3)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 3
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 004_add_indexes.sql (Version 4)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 4
INFO     wlan_tool.storage.database:database.py:204 Database is up to date.
----------------------------- Captured stdout call -----------------------------
2025-10-19 11:40:28,825 | INFO     | Baue/Aktualisiere Zustand aus Event-Stream auf...
2025-10-19 11:40:28,825 | INFO     | Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
2025-10-19 11:40:28,836 | DEBUG    | Dynamische Normalisierungsfaktoren: {'beacon_count': 1.0, 'probe_resp_count': 1.0, 'supporting_clients': 1.0, 'seq_support': 1.0, 'rssi_std_max': 20.0}
2025-10-19 11:40:28,837 | DEBUG    | Starting operation: client_clustering
2025-10-19 11:40:28,837 | INFO     | Korreliere randomisierte MACs vor der Feature-Extraktion...
2025-10-19 11:40:28,837 | INFO     | Fand 0 Gruppen von potenziell zusammengehörigen randomisierten MACs.
2025-10-19 11:40:28,838 | DEBUG    | Starting operation: client_features_extraction
2025-10-19 11:40:28,838 | DEBUG    | Starting operation: client_features_extraction
2025-10-19 11:40:28,838 | DEBUG    | Starting operation: client_features_extraction
2025-10-19 11:40:28,853 | INFO     | Wende manuelle Feature-Gewichtungen für Standard-Clustering an...
2025-10-19 11:40:28,853 | DEBUG    | Gewichte Feature 'supports_11ax' mit Faktor 3.0.
2025-10-19 11:40:28,856 | DEBUG    | Gewichte Feature 'supports_11ac' mit Faktor 2.0.
2025-10-19 11:40:28,859 | DEBUG    | Gewichte Feature 'has_apple_ie' mit Faktor 2.5.
2025-10-19 11:40:28,862 | DEBUG    | Gewichte Feature 'has_ms_ie' mit Faktor 2.0.
2025-10-19 11:40:28,865 | DEBUG    | Gewichte Feature 'mimo_streams' mit Faktor 1.5.
2025-10-19 11:40:28,867 | DEBUG    | Gewichte Feature 'is_randomized_mac' mit Faktor 1.2.
2025-10-19 11:40:28,870 | DEBUG    | Gewichte Feature 'was_in_powersave' mit Faktor 1.2.
2025-10-19 11:40:28,873 | DEBUG    | Gewichte Feature 'probe_count' mit Faktor 1.0.
2025-10-19 11:40:28,876 | DEBUG    | Gewichte Feature 'seen_with_ap_count' mit Faktor 1.0.
2025-10-19 11:40:28,879 | INFO     | Verwende KMeans für das Clustering...
------------------------------ Captured log call -------------------------------
INFO     wlan_tool.storage.state:state.py:52 Baue/Aktualisiere Zustand aus Event-Stream auf...
INFO     wlan_tool.storage.state:state.py:57 Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
DEBUG    wlan_tool.analysis.logic:logic.py:148 Dynamische Normalisierungsfaktoren: {'beacon_count': 1.0, 'probe_resp_count': 1.0, 'supporting_clients': 1.0, 'seq_support': 1.0, 'rssi_std_max': 20.0}
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_clustering
INFO     wlan_tool.analysis.logic:logic.py:396 Korreliere randomisierte MACs vor der Feature-Extraktion...
INFO     wlan_tool.analysis.logic:logic.py:791 Fand 0 Gruppen von potenziell zusammengehörigen randomisierten MACs.
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_features_extraction
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_features_extraction
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_features_extraction
INFO     wlan_tool.analysis.logic:logic.py:584 Wende manuelle Feature-Gewichtungen für Standard-Clustering an...
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'supports_11ax' mit Faktor 3.0.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'supports_11ac' mit Faktor 2.0.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'has_apple_ie' mit Faktor 2.5.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'has_ms_ie' mit Faktor 2.0.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'mimo_streams' mit Faktor 1.5.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'is_randomized_mac' mit Faktor 1.2.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'was_in_powersave' mit Faktor 1.2.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'probe_count' mit Faktor 1.0.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'seen_with_ap_count' mit Faktor 1.0.
INFO     wlan_tool.analysis.logic:logic.py:609 Verwende KMeans für das Clustering...
________________ TestEndToEndWorkflow.test_database_integration ________________

self = <test_integration.TestEndToEndWorkflow object at 0x7f59d28350>
sample_events = [{'beacon_interval': 102, 'bssid': '08:96:d7:1a:21:1c', 'cap': 17, 'channel': 6, ...}, {'client': 'a8:51:ab:0c:b9:e9',...-91, ...}, {'client': 'b2:87:23:15:7f:f2', 'ie_order_hash': 67890, 'ies': {0: ['MyOtherWLAN']}, 'rssi': -70, ...}, ...]
temp_db_file = '/tmp/tmpu5q8t38r.db'

    def test_database_integration(self, sample_events, temp_db_file):
        """Test Datenbank-Integration."""
        # Schreibe Events in Datenbank
        with database.db_conn_ctx(temp_db_file) as conn:
            for event in sample_events:
>               database.add_event(conn, event)
E               AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

pytest/test_integration.py:64: AttributeError

The above exception was the direct cause of the following exception:

path = '/tmp/tmpu5q8t38r.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
>           with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):

wlan_tool/storage/database.py:68: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.exceptions.ErrorContext object at 0x7f4ca97950>
exc_type = <class 'AttributeError'>
exc_val = AttributeError("module 'wlan_tool.storage.database' has no attribute 'add_event'")
exc_tb = <traceback object at 0x7f4ca95500>

    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type is not None:
            error_msg = f"Error in {self.operation}: {exc_val}"
    
            if isinstance(exc_val, WLANToolError):
                error_msg += f" (Code: {exc_val.error_code})"
                if exc_val.details:
                    error_msg += f" | Details: {exc_val.details}"
            else:
                error_msg += f" | Type: {exc_type.__name__}"
    
            self.logger.log(self.log_level, error_msg)
            self.logger.debug(f"Traceback: {traceback.format_exc()}")
    
            # Konvertiere zu WLANToolError falls nötig
            if not isinstance(exc_val, WLANToolError):
                wlan_error = WLANToolError(
                    message=str(exc_val),
                    error_code=self.error_code or "CONTEXT_ERROR",
                    details={
                        "operation": self.operation,
                        "original_type": exc_type.__name__,
                    },
                )
>               raise wlan_error from exc_val
E               wlan_tool.exceptions.WLANToolError: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}

wlan_tool/exceptions.py:313: WLANToolError

The above exception was the direct cause of the following exception:

self = <test_integration.TestEndToEndWorkflow object at 0x7f59d28350>
sample_events = [{'beacon_interval': 102, 'bssid': '08:96:d7:1a:21:1c', 'cap': 17, 'channel': 6, ...}, {'client': 'a8:51:ab:0c:b9:e9',...-91, ...}, {'client': 'b2:87:23:15:7f:f2', 'ie_order_hash': 67890, 'ies': {0: ['MyOtherWLAN']}, 'rssi': -70, ...}, ...]
temp_db_file = '/tmp/tmpu5q8t38r.db'

    def test_database_integration(self, sample_events, temp_db_file):
        """Test Datenbank-Integration."""
        # Schreibe Events in Datenbank
>       with database.db_conn_ctx(temp_db_file) as conn:

pytest/test_integration.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/contextlib.py:158: in __exit__
    self.gen.throw(typ, value, traceback)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

path = '/tmp/tmpu5q8t38r.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
            with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):
                # Validiere Datenbankpfad
                if not _validate_file_path(path):
                    raise ValidationError(
                        f"Invalid database path: {path}",
                        error_code="INVALID_DB_PATH",
                        details={"db_path": path},
                    )
    
                # Erstelle Verzeichnis falls nötig
                db_dir = Path(path).parent
                if not db_dir.exists():
                    try:
                        db_dir.mkdir(parents=True, exist_ok=True)
                    except OSError as e:
                        raise FileSystemError(
                            f"Cannot create database directory: {db_dir}",
                            error_code="DB_DIR_CREATION_FAILED",
                            details={"directory": str(db_dir), "original_error": str(e)},
                        ) from e
    
                # Verbinde zur Datenbank
                conn = sqlite3.connect(path, timeout=Constants.DB_CONNECTION_TIMEOUT)
                conn.row_factory = sqlite3.Row
    
                # Setze pragmas für bessere Performance und Fehlerbehandlung
                conn.execute("PRAGMA foreign_keys = ON")
                conn.execute("PRAGMA journal_mode = WAL")
                conn.execute("PRAGMA synchronous = NORMAL")
                conn.execute("PRAGMA cache_size = 10000")
                conn.execute("PRAGMA temp_store = MEMORY")
    
                yield conn
    
        except sqlite3.Error as e:
            if conn:
                conn.rollback()
            raise DatabaseError(
                get_error_message(ErrorCodes.DB_CONNECTION_FAILED, details=str(e)),
                error_code=ErrorCodes.DB_CONNECTION_FAILED.value,
                details={"db_path": path, "sqlite_error": str(e)},
            ) from e
        except Exception as e:
            if conn:
                conn.rollback()
>           raise DatabaseError(
                f"Unexpected database error: {e}",
                error_code="DB_UNEXPECTED_ERROR",
                details={"db_path": path, "original_error": str(e)},
            ) from e
E           wlan_tool.exceptions.DatabaseError: WLANToolError: Unexpected database error: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'} (Code: DB_UNEXPECTED_ERROR) | Details: {'db_path': '/tmp/tmpu5q8t38r.db', 'original_error': "WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}"}

wlan_tool/storage/database.py:113: DatabaseError
---------------------------- Captured stdout setup -----------------------------
2025-10-19 11:40:29,160 | DEBUG    | Starting operation: database_migration
2025-10-19 11:40:29,161 | DEBUG    | Starting operation: database_connection
2025-10-19 11:40:29,180 | INFO     | Current DB version: 0. Looking for migrations...
2025-10-19 11:40:29,180 | INFO     | Applying migration: 001_initial_schema.sql (Version 1)
2025-10-19 11:40:29,187 | INFO     | DB successfully migrated to version 1
2025-10-19 11:40:29,188 | INFO     | Applying migration: 002_add_dns_table.sql (Version 2)
2025-10-19 11:40:29,189 | INFO     | DB successfully migrated to version 2
2025-10-19 11:40:29,189 | INFO     | Applying migration: 003_add_network_info.sql (Version 3)
2025-10-19 11:40:29,191 | INFO     | DB successfully migrated to version 3
2025-10-19 11:40:29,191 | INFO     | Applying migration: 004_add_indexes.sql (Version 4)
2025-10-19 11:40:29,192 | INFO     | DB successfully migrated to version 4
2025-10-19 11:40:29,215 | INFO     | Database is up to date.
------------------------------ Captured log setup ------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_migration
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
INFO     wlan_tool.storage.database:database.py:157 Current DB version: 0. Looking for migrations...
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 001_initial_schema.sql (Version 1)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 1
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 002_add_dns_table.sql (Version 2)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 2
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 003_add_network_info.sql (Version 3)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 3
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 004_add_indexes.sql (Version 4)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 4
INFO     wlan_tool.storage.database:database.py:204 Database is up to date.
----------------------------- Captured stdout call -----------------------------
2025-10-19 11:40:29,217 | DEBUG    | Starting operation: database_connection
2025-10-19 11:40:29,219 | ERROR    | Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
2025-10-19 11:40:29,220 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/hacking/pytest/test_integration.py", line 64, in test_database_integration
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/hacking/pytest/test_integration.py", line 64, in test_database_integration
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'
_________________ TestEndToEndWorkflow.test_config_integration _________________

self = <test_integration.TestEndToEndWorkflow object at 0x7f59d28690>

    def test_config_integration(self):
        """Test Konfigurations-Integration."""
        # Teste Konfigurations-Laden
>       config_data = utils.load_config()
E       TypeError: load_config() missing 1 required positional argument: 'profile'

pytest/test_integration.py:82: TypeError
_____________________ TestDataFlow.test_state_persistence ______________________

self = <test_integration.TestDataFlow object at 0x7f59d29510>
sample_events = [{'beacon_interval': 102, 'bssid': '08:96:d7:1a:21:1c', 'cap': 17, 'channel': 6, ...}, {'client': 'a8:51:ab:0c:b9:e9',...-91, ...}, {'client': 'b2:87:23:15:7f:f2', 'ie_order_hash': 67890, 'ies': {0: ['MyOtherWLAN']}, 'rssi': -70, ...}, ...]
temp_db_file = '/tmp/tmp02zt_hbd.db'

    def test_state_persistence(self, sample_events, temp_db_file):
        """Test State-Persistierung."""
        # Erstelle State
        state1 = WifiAnalysisState()
        state1.build_from_events(sample_events)
    
        # Schreibe in Datenbank
        with database.db_conn_ctx(temp_db_file) as conn:
            for event in sample_events:
>               database.add_event(conn, event)
E               AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

pytest/test_integration.py:130: AttributeError

The above exception was the direct cause of the following exception:

path = '/tmp/tmp02zt_hbd.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
>           with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):

wlan_tool/storage/database.py:68: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.exceptions.ErrorContext object at 0x7f4cb7a150>
exc_type = <class 'AttributeError'>
exc_val = AttributeError("module 'wlan_tool.storage.database' has no attribute 'add_event'")
exc_tb = <traceback object at 0x7f4cb78dc0>

    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type is not None:
            error_msg = f"Error in {self.operation}: {exc_val}"
    
            if isinstance(exc_val, WLANToolError):
                error_msg += f" (Code: {exc_val.error_code})"
                if exc_val.details:
                    error_msg += f" | Details: {exc_val.details}"
            else:
                error_msg += f" | Type: {exc_type.__name__}"
    
            self.logger.log(self.log_level, error_msg)
            self.logger.debug(f"Traceback: {traceback.format_exc()}")
    
            # Konvertiere zu WLANToolError falls nötig
            if not isinstance(exc_val, WLANToolError):
                wlan_error = WLANToolError(
                    message=str(exc_val),
                    error_code=self.error_code or "CONTEXT_ERROR",
                    details={
                        "operation": self.operation,
                        "original_type": exc_type.__name__,
                    },
                )
>               raise wlan_error from exc_val
E               wlan_tool.exceptions.WLANToolError: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}

wlan_tool/exceptions.py:313: WLANToolError

The above exception was the direct cause of the following exception:

self = <test_integration.TestDataFlow object at 0x7f59d29510>
sample_events = [{'beacon_interval': 102, 'bssid': '08:96:d7:1a:21:1c', 'cap': 17, 'channel': 6, ...}, {'client': 'a8:51:ab:0c:b9:e9',...-91, ...}, {'client': 'b2:87:23:15:7f:f2', 'ie_order_hash': 67890, 'ies': {0: ['MyOtherWLAN']}, 'rssi': -70, ...}, ...]
temp_db_file = '/tmp/tmp02zt_hbd.db'

    def test_state_persistence(self, sample_events, temp_db_file):
        """Test State-Persistierung."""
        # Erstelle State
        state1 = WifiAnalysisState()
        state1.build_from_events(sample_events)
    
        # Schreibe in Datenbank
>       with database.db_conn_ctx(temp_db_file) as conn:

pytest/test_integration.py:128: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/contextlib.py:158: in __exit__
    self.gen.throw(typ, value, traceback)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

path = '/tmp/tmp02zt_hbd.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
            with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):
                # Validiere Datenbankpfad
                if not _validate_file_path(path):
                    raise ValidationError(
                        f"Invalid database path: {path}",
                        error_code="INVALID_DB_PATH",
                        details={"db_path": path},
                    )
    
                # Erstelle Verzeichnis falls nötig
                db_dir = Path(path).parent
                if not db_dir.exists():
                    try:
                        db_dir.mkdir(parents=True, exist_ok=True)
                    except OSError as e:
                        raise FileSystemError(
                            f"Cannot create database directory: {db_dir}",
                            error_code="DB_DIR_CREATION_FAILED",
                            details={"directory": str(db_dir), "original_error": str(e)},
                        ) from e
    
                # Verbinde zur Datenbank
                conn = sqlite3.connect(path, timeout=Constants.DB_CONNECTION_TIMEOUT)
                conn.row_factory = sqlite3.Row
    
                # Setze pragmas für bessere Performance und Fehlerbehandlung
                conn.execute("PRAGMA foreign_keys = ON")
                conn.execute("PRAGMA journal_mode = WAL")
                conn.execute("PRAGMA synchronous = NORMAL")
                conn.execute("PRAGMA cache_size = 10000")
                conn.execute("PRAGMA temp_store = MEMORY")
    
                yield conn
    
        except sqlite3.Error as e:
            if conn:
                conn.rollback()
            raise DatabaseError(
                get_error_message(ErrorCodes.DB_CONNECTION_FAILED, details=str(e)),
                error_code=ErrorCodes.DB_CONNECTION_FAILED.value,
                details={"db_path": path, "sqlite_error": str(e)},
            ) from e
        except Exception as e:
            if conn:
                conn.rollback()
>           raise DatabaseError(
                f"Unexpected database error: {e}",
                error_code="DB_UNEXPECTED_ERROR",
                details={"db_path": path, "original_error": str(e)},
            ) from e
E           wlan_tool.exceptions.DatabaseError: WLANToolError: Unexpected database error: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'} (Code: DB_UNEXPECTED_ERROR) | Details: {'db_path': '/tmp/tmp02zt_hbd.db', 'original_error': "WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}"}

wlan_tool/storage/database.py:113: DatabaseError
---------------------------- Captured stdout setup -----------------------------
2025-10-19 11:40:30,283 | DEBUG    | Starting operation: database_migration
2025-10-19 11:40:30,284 | DEBUG    | Starting operation: database_connection
2025-10-19 11:40:30,301 | INFO     | Current DB version: 0. Looking for migrations...
2025-10-19 11:40:30,301 | INFO     | Applying migration: 001_initial_schema.sql (Version 1)
2025-10-19 11:40:30,308 | INFO     | DB successfully migrated to version 1
2025-10-19 11:40:30,309 | INFO     | Applying migration: 002_add_dns_table.sql (Version 2)
2025-10-19 11:40:30,310 | INFO     | DB successfully migrated to version 2
2025-10-19 11:40:30,310 | INFO     | Applying migration: 003_add_network_info.sql (Version 3)
2025-10-19 11:40:30,312 | INFO     | DB successfully migrated to version 3
2025-10-19 11:40:30,312 | INFO     | Applying migration: 004_add_indexes.sql (Version 4)
2025-10-19 11:40:30,314 | INFO     | DB successfully migrated to version 4
2025-10-19 11:40:30,335 | INFO     | Database is up to date.
------------------------------ Captured log setup ------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_migration
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
INFO     wlan_tool.storage.database:database.py:157 Current DB version: 0. Looking for migrations...
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 001_initial_schema.sql (Version 1)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 1
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 002_add_dns_table.sql (Version 2)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 2
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 003_add_network_info.sql (Version 3)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 3
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 004_add_indexes.sql (Version 4)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 4
INFO     wlan_tool.storage.database:database.py:204 Database is up to date.
----------------------------- Captured stdout call -----------------------------
2025-10-19 11:40:30,336 | INFO     | Baue/Aktualisiere Zustand aus Event-Stream auf...
2025-10-19 11:40:30,337 | INFO     | Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
2025-10-19 11:40:30,337 | DEBUG    | Starting operation: database_connection
2025-10-19 11:40:30,339 | ERROR    | Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
2025-10-19 11:40:30,340 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/hacking/pytest/test_integration.py", line 130, in test_state_persistence
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

------------------------------ Captured log call -------------------------------
INFO     wlan_tool.storage.state:state.py:52 Baue/Aktualisiere Zustand aus Event-Stream auf...
INFO     wlan_tool.storage.state:state.py:57 Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/hacking/pytest/test_integration.py", line 130, in test_state_persistence
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'
________________ TestLargeDataset.test_large_dataset_processing ________________

self = <test_integration.TestLargeDataset object at 0x7f59d29d50>

    def test_large_dataset_processing(self):
        """Test Verarbeitung großer Datensätze."""
        # Erstelle großen State
        state = WifiAnalysisState()
    
        # Erstelle 100 APs
        for i in range(100):
            bssid = f"08:96:d7:1a:21:{i:02x}"
>           ap = state.aps[bssid] = state.aps.get(bssid, type(state).__dict__['aps'].__class__())()
E           KeyError: 'aps'

pytest/test_integration.py:158: KeyError
_______________ TestErrorRecovery.test_malformed_event_handling ________________

self = <test_integration.TestErrorRecovery object at 0x7f59d2b3d0>

    def test_malformed_event_handling(self):
        """Test Behandlung fehlerhafter Events."""
        state = WifiAnalysisState()
    
        # Teste verschiedene fehlerhafte Events
        malformed_events = [
            {},  # Leeres Event
            {'ts': time.time()},  # Nur Zeitstempel
            {'ts': time.time(), 'type': 'invalid'},  # Ungültiger Typ
            {'ts': time.time(), 'type': 'beacon'},  # Beacon ohne BSSID
        ]
    
        for event in malformed_events:
            # Sollte nicht crashen
            try:
>               state.update_from_event(event)

pytest/test_integration.py:241: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f4cf03390>
ev = {}, detailed_ies = False

    def update_from_event(self, ev: dict, detailed_ies: bool = False):
>       ts, ev_type = ev["ts"], ev.get("type")
E       KeyError: 'ts'

wlan_tool/storage/state.py:66: KeyError

During handling of the above exception, another exception occurred:

self = <test_integration.TestErrorRecovery object at 0x7f59d2b3d0>

    def test_malformed_event_handling(self):
        """Test Behandlung fehlerhafter Events."""
        state = WifiAnalysisState()
    
        # Teste verschiedene fehlerhafte Events
        malformed_events = [
            {},  # Leeres Event
            {'ts': time.time()},  # Nur Zeitstempel
            {'ts': time.time(), 'type': 'invalid'},  # Ungültiger Typ
            {'ts': time.time(), 'type': 'beacon'},  # Beacon ohne BSSID
        ]
    
        for event in malformed_events:
            # Sollte nicht crashen
            try:
                state.update_from_event(event)
            except Exception as e:
>               pytest.fail(f"Malformed event should be handled gracefully: {e}")
E               Failed: Malformed event should be handled gracefully: 'ts'

pytest/test_integration.py:243: Failed
______________ TestMemoryManagement.test_memory_usage_large_state ______________

self = <test_integration.TestMemoryManagement object at 0x7f59d30890>

    def test_memory_usage_large_state(self):
        """Test Speicherverbrauch mit großem State."""
        import psutil
        import os
    
        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss
    
        # Erstelle großen State
        state = WifiAnalysisState()
    
        for i in range(1000):
            mac = f"aa:bb:cc:dd:ee:{i:04x}"
>           client = state.clients[mac] = state.clients.get(mac, type(state).__dict__['clients'].__class__())()
E           KeyError: 'clients'

pytest/test_integration.py:295: KeyError
____________ TestMemoryManagement.test_state_pruning_memory_release ____________

self = <test_integration.TestMemoryManagement object at 0x7f59d30e90>

    def test_state_pruning_memory_release(self):
        """Test Speicherfreigabe durch State-Pruning."""
        import psutil
        import os
    
        process = psutil.Process(os.getpid())
    
        # Erstelle State mit alten und neuen Daten
        state = WifiAnalysisState()
    
        # Alte Clients (werden gepruned)
        for i in range(100):
            mac = f"old:aa:bb:cc:dd:ee:{i:02x}"
>           client = state.clients[mac] = state.clients.get(mac, type(state).__dict__['clients'].__class__())()
E           KeyError: 'clients'

pytest/test_integration.py:321: KeyError
_____________ TestAnalysisPerformance.test_clustering_performance ______________

self = <test_performance.TestAnalysisPerformance object at 0x7f59d336d0>

    def test_clustering_performance(self):
        """Test Clustering-Performance."""
        # Erstelle State mit vielen Clients
        state = WifiAnalysisState()
    
        for i in range(200):
            mac = f"aa:bb:cc:dd:ee:{i:02x}"
>           client = state.clients[mac] = state.clients.get(mac, type(state).__dict__['clients'].__class__())()
E           KeyError: 'clients'

pytest/test_performance.py:147: KeyError
______________ TestAnalysisPerformance.test_inference_performance ______________

self = <test_performance.TestAnalysisPerformance object at 0x7f59d33cd0>

    def test_inference_performance(self):
        """Test Inferenz-Performance."""
        # Erstelle State mit APs und Clients
        state = WifiAnalysisState()
    
        # Erstelle 50 APs
        for i in range(50):
            bssid = f"08:96:d7:1a:21:{i:02x}"
>           ap = state.aps[bssid] = state.aps.get(bssid, type(state).__dict__['aps'].__class__())()
E           KeyError: 'aps'

pytest/test_performance.py:180: KeyError
_____________ TestMemoryPerformance.test_memory_usage_large_state ______________

self = <test_performance.TestMemoryPerformance object at 0x7f59d40590>

    def test_memory_usage_large_state(self):
        """Test Speicherverbrauch mit großem State."""
        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss
    
        # Erstelle großen State
        state = WifiAnalysisState()
    
        # 1000 Clients
        for i in range(1000):
            mac = f"aa:bb:cc:dd:ee:{i:04x}"
>           client = state.clients[mac] = state.clients.get(mac, type(state).__dict__['clients'].__class__())()
E           KeyError: 'clients'

pytest/test_performance.py:228: KeyError
___________ TestMemoryPerformance.test_memory_cleanup_after_pruning ____________

self = <test_performance.TestMemoryPerformance object at 0x7f59d40b90>

    def test_memory_cleanup_after_pruning(self):
        """Test Speicherbereinigung nach Pruning."""
        process = psutil.Process(os.getpid())
    
        # Erstelle State mit alten und neuen Daten
        state = WifiAnalysisState()
    
        # 500 alte Clients (werden gepruned)
        for i in range(500):
            mac = f"old:aa:bb:cc:dd:ee:{i:03x}"
>           client = state.clients[mac] = state.clients.get(mac, type(state).__dict__['clients'].__class__())()
E           KeyError: 'clients'

pytest/test_performance.py:269: KeyError
___________ TestDatabasePerformance.test_database_write_performance ____________

self = <test_performance.TestDatabasePerformance object at 0x7f59d41490>
temp_db_file = '/tmp/tmpe3kx05ud.db'

    def test_database_write_performance(self, temp_db_file):
        """Test Datenbank-Schreib-Performance."""
        # Erstelle Test-Events
        events = []
        for i in range(1000):
            event = {
                'ts': time.time() + i,
                'type': 'beacon' if i % 2 == 0 else 'probe_req',
                'bssid': f'08:96:d7:1a:21:{i % 100:02x}',
                'ssid': f'SSID_{i % 50}',
                'rssi': -50 - (i % 50),
                'channel': (i % 13) + 1
            }
            events.append(event)
    
        start_time = time.time()
    
        with database.db_conn_ctx(temp_db_file) as conn:
            for event in events:
>               database.add_event(conn, event)
E               AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

pytest/test_performance.py:325: AttributeError

The above exception was the direct cause of the following exception:

path = '/tmp/tmpe3kx05ud.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
>           with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):

wlan_tool/storage/database.py:68: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.exceptions.ErrorContext object at 0x7f4ce533d0>
exc_type = <class 'AttributeError'>
exc_val = AttributeError("module 'wlan_tool.storage.database' has no attribute 'add_event'")
exc_tb = <traceback object at 0x7f4ce52b00>

    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type is not None:
            error_msg = f"Error in {self.operation}: {exc_val}"
    
            if isinstance(exc_val, WLANToolError):
                error_msg += f" (Code: {exc_val.error_code})"
                if exc_val.details:
                    error_msg += f" | Details: {exc_val.details}"
            else:
                error_msg += f" | Type: {exc_type.__name__}"
    
            self.logger.log(self.log_level, error_msg)
            self.logger.debug(f"Traceback: {traceback.format_exc()}")
    
            # Konvertiere zu WLANToolError falls nötig
            if not isinstance(exc_val, WLANToolError):
                wlan_error = WLANToolError(
                    message=str(exc_val),
                    error_code=self.error_code or "CONTEXT_ERROR",
                    details={
                        "operation": self.operation,
                        "original_type": exc_type.__name__,
                    },
                )
>               raise wlan_error from exc_val
E               wlan_tool.exceptions.WLANToolError: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}

wlan_tool/exceptions.py:313: WLANToolError

The above exception was the direct cause of the following exception:

self = <test_performance.TestDatabasePerformance object at 0x7f59d41490>
temp_db_file = '/tmp/tmpe3kx05ud.db'

    def test_database_write_performance(self, temp_db_file):
        """Test Datenbank-Schreib-Performance."""
        # Erstelle Test-Events
        events = []
        for i in range(1000):
            event = {
                'ts': time.time() + i,
                'type': 'beacon' if i % 2 == 0 else 'probe_req',
                'bssid': f'08:96:d7:1a:21:{i % 100:02x}',
                'ssid': f'SSID_{i % 50}',
                'rssi': -50 - (i % 50),
                'channel': (i % 13) + 1
            }
            events.append(event)
    
        start_time = time.time()
    
>       with database.db_conn_ctx(temp_db_file) as conn:

pytest/test_performance.py:323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/contextlib.py:158: in __exit__
    self.gen.throw(typ, value, traceback)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

path = '/tmp/tmpe3kx05ud.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
            with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):
                # Validiere Datenbankpfad
                if not _validate_file_path(path):
                    raise ValidationError(
                        f"Invalid database path: {path}",
                        error_code="INVALID_DB_PATH",
                        details={"db_path": path},
                    )
    
                # Erstelle Verzeichnis falls nötig
                db_dir = Path(path).parent
                if not db_dir.exists():
                    try:
                        db_dir.mkdir(parents=True, exist_ok=True)
                    except OSError as e:
                        raise FileSystemError(
                            f"Cannot create database directory: {db_dir}",
                            error_code="DB_DIR_CREATION_FAILED",
                            details={"directory": str(db_dir), "original_error": str(e)},
                        ) from e
    
                # Verbinde zur Datenbank
                conn = sqlite3.connect(path, timeout=Constants.DB_CONNECTION_TIMEOUT)
                conn.row_factory = sqlite3.Row
    
                # Setze pragmas für bessere Performance und Fehlerbehandlung
                conn.execute("PRAGMA foreign_keys = ON")
                conn.execute("PRAGMA journal_mode = WAL")
                conn.execute("PRAGMA synchronous = NORMAL")
                conn.execute("PRAGMA cache_size = 10000")
                conn.execute("PRAGMA temp_store = MEMORY")
    
                yield conn
    
        except sqlite3.Error as e:
            if conn:
                conn.rollback()
            raise DatabaseError(
                get_error_message(ErrorCodes.DB_CONNECTION_FAILED, details=str(e)),
                error_code=ErrorCodes.DB_CONNECTION_FAILED.value,
                details={"db_path": path, "sqlite_error": str(e)},
            ) from e
        except Exception as e:
            if conn:
                conn.rollback()
>           raise DatabaseError(
                f"Unexpected database error: {e}",
                error_code="DB_UNEXPECTED_ERROR",
                details={"db_path": path, "original_error": str(e)},
            ) from e
E           wlan_tool.exceptions.DatabaseError: WLANToolError: Unexpected database error: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'} (Code: DB_UNEXPECTED_ERROR) | Details: {'db_path': '/tmp/tmpe3kx05ud.db', 'original_error': "WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}"}

wlan_tool/storage/database.py:113: DatabaseError
---------------------------- Captured stdout setup -----------------------------
2025-10-19 11:40:31,443 | DEBUG    | Starting operation: database_migration
2025-10-19 11:40:31,444 | DEBUG    | Starting operation: database_connection
2025-10-19 11:40:31,458 | INFO     | Current DB version: 0. Looking for migrations...
2025-10-19 11:40:31,459 | INFO     | Applying migration: 001_initial_schema.sql (Version 1)
2025-10-19 11:40:31,469 | INFO     | DB successfully migrated to version 1
2025-10-19 11:40:31,469 | INFO     | Applying migration: 002_add_dns_table.sql (Version 2)
2025-10-19 11:40:31,470 | INFO     | DB successfully migrated to version 2
2025-10-19 11:40:31,471 | INFO     | Applying migration: 003_add_network_info.sql (Version 3)
2025-10-19 11:40:31,472 | INFO     | DB successfully migrated to version 3
2025-10-19 11:40:31,473 | INFO     | Applying migration: 004_add_indexes.sql (Version 4)
2025-10-19 11:40:31,474 | INFO     | DB successfully migrated to version 4
2025-10-19 11:40:31,495 | INFO     | Database is up to date.
------------------------------ Captured log setup ------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_migration
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
INFO     wlan_tool.storage.database:database.py:157 Current DB version: 0. Looking for migrations...
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 001_initial_schema.sql (Version 1)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 1
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 002_add_dns_table.sql (Version 2)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 2
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 003_add_network_info.sql (Version 3)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 3
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 004_add_indexes.sql (Version 4)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 4
INFO     wlan_tool.storage.database:database.py:204 Database is up to date.
----------------------------- Captured stdout call -----------------------------
2025-10-19 11:40:31,501 | DEBUG    | Starting operation: database_connection
2025-10-19 11:40:31,503 | ERROR    | Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
2025-10-19 11:40:31,504 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/hacking/pytest/test_performance.py", line 325, in test_database_write_performance
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/hacking/pytest/test_performance.py", line 325, in test_database_write_performance
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'
____________ TestDatabasePerformance.test_database_read_performance ____________

self = <test_performance.TestDatabasePerformance object at 0x7f59d41b10>
temp_db_file = '/tmp/tmpoddy9x9c.db'

    def test_database_read_performance(self, temp_db_file):
        """Test Datenbank-Lese-Performance."""
        # Schreibe Test-Events
        events = []
        for i in range(1000):
            event = {
                'ts': time.time() + i,
                'type': 'beacon' if i % 2 == 0 else 'probe_req',
                'bssid': f'08:96:d7:1a:21:{i % 100:02x}',
                'ssid': f'SSID_{i % 50}',
                'rssi': -50 - (i % 50),
                'channel': (i % 13) + 1
            }
            events.append(event)
    
        with database.db_conn_ctx(temp_db_file) as conn:
            for event in events:
>               database.add_event(conn, event)
E               AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

pytest/test_performance.py:351: AttributeError

The above exception was the direct cause of the following exception:

path = '/tmp/tmpoddy9x9c.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
>           with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):

wlan_tool/storage/database.py:68: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.exceptions.ErrorContext object at 0x7f4cd8f510>
exc_type = <class 'AttributeError'>
exc_val = AttributeError("module 'wlan_tool.storage.database' has no attribute 'add_event'")
exc_tb = <traceback object at 0x7f4cd8c140>

    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type is not None:
            error_msg = f"Error in {self.operation}: {exc_val}"
    
            if isinstance(exc_val, WLANToolError):
                error_msg += f" (Code: {exc_val.error_code})"
                if exc_val.details:
                    error_msg += f" | Details: {exc_val.details}"
            else:
                error_msg += f" | Type: {exc_type.__name__}"
    
            self.logger.log(self.log_level, error_msg)
            self.logger.debug(f"Traceback: {traceback.format_exc()}")
    
            # Konvertiere zu WLANToolError falls nötig
            if not isinstance(exc_val, WLANToolError):
                wlan_error = WLANToolError(
                    message=str(exc_val),
                    error_code=self.error_code or "CONTEXT_ERROR",
                    details={
                        "operation": self.operation,
                        "original_type": exc_type.__name__,
                    },
                )
>               raise wlan_error from exc_val
E               wlan_tool.exceptions.WLANToolError: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}

wlan_tool/exceptions.py:313: WLANToolError

The above exception was the direct cause of the following exception:

self = <test_performance.TestDatabasePerformance object at 0x7f59d41b10>
temp_db_file = '/tmp/tmpoddy9x9c.db'

    def test_database_read_performance(self, temp_db_file):
        """Test Datenbank-Lese-Performance."""
        # Schreibe Test-Events
        events = []
        for i in range(1000):
            event = {
                'ts': time.time() + i,
                'type': 'beacon' if i % 2 == 0 else 'probe_req',
                'bssid': f'08:96:d7:1a:21:{i % 100:02x}',
                'ssid': f'SSID_{i % 50}',
                'rssi': -50 - (i % 50),
                'channel': (i % 13) + 1
            }
            events.append(event)
    
>       with database.db_conn_ctx(temp_db_file) as conn:

pytest/test_performance.py:349: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/contextlib.py:158: in __exit__
    self.gen.throw(typ, value, traceback)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

path = '/tmp/tmpoddy9x9c.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
            with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):
                # Validiere Datenbankpfad
                if not _validate_file_path(path):
                    raise ValidationError(
                        f"Invalid database path: {path}",
                        error_code="INVALID_DB_PATH",
                        details={"db_path": path},
                    )
    
                # Erstelle Verzeichnis falls nötig
                db_dir = Path(path).parent
                if not db_dir.exists():
                    try:
                        db_dir.mkdir(parents=True, exist_ok=True)
                    except OSError as e:
                        raise FileSystemError(
                            f"Cannot create database directory: {db_dir}",
                            error_code="DB_DIR_CREATION_FAILED",
                            details={"directory": str(db_dir), "original_error": str(e)},
                        ) from e
    
                # Verbinde zur Datenbank
                conn = sqlite3.connect(path, timeout=Constants.DB_CONNECTION_TIMEOUT)
                conn.row_factory = sqlite3.Row
    
                # Setze pragmas für bessere Performance und Fehlerbehandlung
                conn.execute("PRAGMA foreign_keys = ON")
                conn.execute("PRAGMA journal_mode = WAL")
                conn.execute("PRAGMA synchronous = NORMAL")
                conn.execute("PRAGMA cache_size = 10000")
                conn.execute("PRAGMA temp_store = MEMORY")
    
                yield conn
    
        except sqlite3.Error as e:
            if conn:
                conn.rollback()
            raise DatabaseError(
                get_error_message(ErrorCodes.DB_CONNECTION_FAILED, details=str(e)),
                error_code=ErrorCodes.DB_CONNECTION_FAILED.value,
                details={"db_path": path, "sqlite_error": str(e)},
            ) from e
        except Exception as e:
            if conn:
                conn.rollback()
>           raise DatabaseError(
                f"Unexpected database error: {e}",
                error_code="DB_UNEXPECTED_ERROR",
                details={"db_path": path, "original_error": str(e)},
            ) from e
E           wlan_tool.exceptions.DatabaseError: WLANToolError: Unexpected database error: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'} (Code: DB_UNEXPECTED_ERROR) | Details: {'db_path': '/tmp/tmpoddy9x9c.db', 'original_error': "WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}"}

wlan_tool/storage/database.py:113: DatabaseError
---------------------------- Captured stdout setup -----------------------------
2025-10-19 11:40:31,666 | DEBUG    | Starting operation: database_migration
2025-10-19 11:40:31,667 | DEBUG    | Starting operation: database_connection
2025-10-19 11:40:31,682 | INFO     | Current DB version: 0. Looking for migrations...
2025-10-19 11:40:31,682 | INFO     | Applying migration: 001_initial_schema.sql (Version 1)
2025-10-19 11:40:31,693 | INFO     | DB successfully migrated to version 1
2025-10-19 11:40:31,693 | INFO     | Applying migration: 002_add_dns_table.sql (Version 2)
2025-10-19 11:40:31,694 | INFO     | DB successfully migrated to version 2
2025-10-19 11:40:31,695 | INFO     | Applying migration: 003_add_network_info.sql (Version 3)
2025-10-19 11:40:31,696 | INFO     | DB successfully migrated to version 3
2025-10-19 11:40:31,697 | INFO     | Applying migration: 004_add_indexes.sql (Version 4)
2025-10-19 11:40:31,698 | INFO     | DB successfully migrated to version 4
2025-10-19 11:40:31,719 | INFO     | Database is up to date.
------------------------------ Captured log setup ------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_migration
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
INFO     wlan_tool.storage.database:database.py:157 Current DB version: 0. Looking for migrations...
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 001_initial_schema.sql (Version 1)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 1
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 002_add_dns_table.sql (Version 2)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 2
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 003_add_network_info.sql (Version 3)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 3
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 004_add_indexes.sql (Version 4)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 4
INFO     wlan_tool.storage.database:database.py:204 Database is up to date.
----------------------------- Captured stdout call -----------------------------
2025-10-19 11:40:31,725 | DEBUG    | Starting operation: database_connection
2025-10-19 11:40:31,728 | ERROR    | Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
2025-10-19 11:40:31,729 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/hacking/pytest/test_performance.py", line 351, in test_database_read_performance
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/hacking/pytest/test_performance.py", line 351, in test_database_read_performance
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'
________ TestScalabilityPerformance.test_scalability_with_dataset_size _________

self = <test_performance.TestScalabilityPerformance object at 0x7f59d42bd0>

    def test_scalability_with_dataset_size(self):
        """Test Skalierbarkeit mit Datensatz-Größe."""
        dataset_sizes = [100, 500, 1000]
        processing_times = []
    
        for size in dataset_sizes:
            # Erstelle State mit gegebener Größe
            state = WifiAnalysisState()
    
            for i in range(size):
                mac = f"aa:bb:cc:dd:ee:{i:04x}"
>               client = state.clients[mac] = state.clients.get(mac, type(state).__dict__['clients'].__class__())()
E               KeyError: 'clients'

pytest/test_performance.py:440: KeyError
_______________ TestCLIModule.test_print_client_cluster_results ________________

self = <test_presentation.TestCLIModule object at 0x7f59d33ad0>
mock_console = <MagicMock id='546750348496'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f4cd464d0>

    def test_print_client_cluster_results(self, mock_console, populated_state):
        """Test Client-Cluster-Ergebnis-Ausgabe."""
        from wlan_tool.analysis import logic as analysis
    
        # Erstelle Test-Cluster-Daten
        clustered_df, feature_df = analysis.cluster_clients(populated_state, n_clusters=2)
    
        if clustered_df is not None and not clustered_df.empty:
            # Mock args
            args = MagicMock()
            args.cluster_clients = 2
            args.cluster_algo = "kmeans"
            args.no_mac_correlation = False
    
            # Sollte nicht crashen
>           cli.print_client_cluster_results(args, populated_state, mock_console)

pytest/test_presentation.py:38: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = <MagicMock id='546750543440'>
state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f4cd464d0>
console = <MagicMock id='546750348496'>

    def print_client_cluster_results(args, state, console):
        """Führt das Client-Clustering aus und gibt die Ergebnisse formatiert aus."""
        clustered_df, feature_df = analysis.cluster_clients(
            state,
            n_clusters=args.cluster_clients,
            algo_name=args.cluster_algo,
            use_correlation=(not args.no_mac_correlation),
        )
        """Gibt die Ergebnisse des Client-Clusterings formatiert aus."""
        if clustered_df is not None and not clustered_df.empty:
            console.print(
                "[yellow]Keine Client-Daten für das Clustering gefunden.[/yellow]"
            )
            return
    
>       title_correlation_str = "& Korrelation" if use_correlation else "& ohne Korrelation"
E       NameError: name 'use_correlation' is not defined

wlan_tool/presentation/cli.py:34: NameError
---------------------------- Captured stdout setup -----------------------------
2025-10-19 11:40:31,989 | INFO     | Baue/Aktualisiere Zustand aus Event-Stream auf...
2025-10-19 11:40:31,990 | INFO     | Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
------------------------------ Captured log setup ------------------------------
INFO     wlan_tool.storage.state:state.py:52 Baue/Aktualisiere Zustand aus Event-Stream auf...
INFO     wlan_tool.storage.state:state.py:57 Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
----------------------------- Captured stdout call -----------------------------
2025-10-19 11:40:31,991 | DEBUG    | Starting operation: client_clustering
2025-10-19 11:40:31,991 | INFO     | Korreliere randomisierte MACs vor der Feature-Extraktion...
2025-10-19 11:40:31,992 | INFO     | Fand 0 Gruppen von potenziell zusammengehörigen randomisierten MACs.
2025-10-19 11:40:31,992 | DEBUG    | Starting operation: client_features_extraction
2025-10-19 11:40:31,992 | DEBUG    | Starting operation: client_features_extraction
2025-10-19 11:40:31,992 | DEBUG    | Starting operation: client_features_extraction
2025-10-19 11:40:32,005 | INFO     | Wende manuelle Feature-Gewichtungen für Standard-Clustering an...
2025-10-19 11:40:32,006 | DEBUG    | Gewichte Feature 'supports_11ax' mit Faktor 3.0.
2025-10-19 11:40:32,009 | DEBUG    | Gewichte Feature 'supports_11ac' mit Faktor 2.0.
2025-10-19 11:40:32,012 | DEBUG    | Gewichte Feature 'has_apple_ie' mit Faktor 2.5.
2025-10-19 11:40:32,015 | DEBUG    | Gewichte Feature 'has_ms_ie' mit Faktor 2.0.
2025-10-19 11:40:32,017 | DEBUG    | Gewichte Feature 'mimo_streams' mit Faktor 1.5.
2025-10-19 11:40:32,020 | DEBUG    | Gewichte Feature 'is_randomized_mac' mit Faktor 1.2.
2025-10-19 11:40:32,023 | DEBUG    | Gewichte Feature 'was_in_powersave' mit Faktor 1.2.
2025-10-19 11:40:32,026 | DEBUG    | Gewichte Feature 'probe_count' mit Faktor 1.0.
2025-10-19 11:40:32,029 | DEBUG    | Gewichte Feature 'seen_with_ap_count' mit Faktor 1.0.
2025-10-19 11:40:32,032 | INFO     | Verwende KMeans für das Clustering...
2025-10-19 11:40:32,040 | ERROR    | Unexpected error in cluster_clients: cluster_clients() got an unexpected keyword argument 'algo_name'
2025-10-19 11:40:32,041 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
TypeError: cluster_clients() got an unexpected keyword argument 'algo_name'

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_clustering
INFO     wlan_tool.analysis.logic:logic.py:396 Korreliere randomisierte MACs vor der Feature-Extraktion...
INFO     wlan_tool.analysis.logic:logic.py:791 Fand 0 Gruppen von potenziell zusammengehörigen randomisierten MACs.
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_features_extraction
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_features_extraction
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_features_extraction
INFO     wlan_tool.analysis.logic:logic.py:584 Wende manuelle Feature-Gewichtungen für Standard-Clustering an...
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'supports_11ax' mit Faktor 3.0.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'supports_11ac' mit Faktor 2.0.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'has_apple_ie' mit Faktor 2.5.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'has_ms_ie' mit Faktor 2.0.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'mimo_streams' mit Faktor 1.5.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'is_randomized_mac' mit Faktor 1.2.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'was_in_powersave' mit Faktor 1.2.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'probe_count' mit Faktor 1.0.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'seen_with_ap_count' mit Faktor 1.0.
INFO     wlan_tool.analysis.logic:logic.py:609 Verwende KMeans für das Clustering...
ERROR    wlan_tool.analysis.logic:exceptions.py:165 Unexpected error in cluster_clients: cluster_clients() got an unexpected keyword argument 'algo_name'
DEBUG    wlan_tool.analysis.logic:exceptions.py:166 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
TypeError: cluster_clients() got an unexpected keyword argument 'algo_name'
_________________ TestCLIModule.test_print_ap_cluster_results __________________

self = <test_presentation.TestCLIModule object at 0x7f59d50d10>
mock_console = <MagicMock id='546750144656'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f4cdd7050>

    def test_print_ap_cluster_results(self, mock_console, populated_state):
        """Test AP-Cluster-Ergebnis-Ausgabe."""
        from wlan_tool.analysis import logic as analysis
    
        # Erstelle Test-AP-Cluster-Daten
>       clustered_df = analysis.cluster_aps(populated_state, n_clusters=2)

pytest/test_presentation.py:48: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/analysis/logic.py:736: in cluster_aps
    df["cluster"] = kmeans.fit_predict(X_scaled)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1064: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1456: in fit
    self._check_params_vs_input(X)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1396: in _check_params_vs_input
    super()._check_params_vs_input(X, default_n_init=10)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = KMeans(n_clusters=2, random_state=42)
X = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])
default_n_init = 10

    def _check_params_vs_input(self, X, default_n_init=None):
        # n_clusters
        if X.shape[0] < self.n_clusters:
>           raise ValueError(
                f"n_samples={X.shape[0]} should be >= n_clusters={self.n_clusters}."
            )
E           ValueError: n_samples=1 should be >= n_clusters=2.

.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:871: ValueError
---------------------------- Captured stdout setup -----------------------------
2025-10-19 11:40:32,086 | INFO     | Baue/Aktualisiere Zustand aus Event-Stream auf...
2025-10-19 11:40:32,087 | INFO     | Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
------------------------------ Captured log setup ------------------------------
INFO     wlan_tool.storage.state:state.py:52 Baue/Aktualisiere Zustand aus Event-Stream auf...
INFO     wlan_tool.storage.state:state.py:57 Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
________ TestCLIEdgeCases.test_print_client_cluster_results_empty_data _________

self = <test_presentation.TestCLIEdgeCases object at 0x7f59d557d0>
mock_console = <MagicMock id='547539988880'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f7bed3b10>

    def test_print_client_cluster_results_empty_data(self, mock_console, populated_state):
        """Test Client-Cluster-Ausgabe mit leeren Daten."""
        # Erstelle leeren State
        empty_state = WifiAnalysisState()
    
        args = MagicMock()
        args.cluster_clients = 2
        args.cluster_algo = "kmeans"
        args.no_mac_correlation = False
    
        # Sollte nicht crashen
>       cli.print_client_cluster_results(args, empty_state, mock_console)

pytest/test_presentation.py:281: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = <MagicMock id='547539990544'>
state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f7bed2c50>
console = <MagicMock id='547539988880'>

    def print_client_cluster_results(args, state, console):
        """Führt das Client-Clustering aus und gibt die Ergebnisse formatiert aus."""
        clustered_df, feature_df = analysis.cluster_clients(
            state,
            n_clusters=args.cluster_clients,
            algo_name=args.cluster_algo,
            use_correlation=(not args.no_mac_correlation),
        )
        """Gibt die Ergebnisse des Client-Clusterings formatiert aus."""
        if clustered_df is not None and not clustered_df.empty:
            console.print(
                "[yellow]Keine Client-Daten für das Clustering gefunden.[/yellow]"
            )
            return
    
>       title_correlation_str = "& Korrelation" if use_correlation else "& ohne Korrelation"
E       NameError: name 'use_correlation' is not defined

wlan_tool/presentation/cli.py:34: NameError
---------------------------- Captured stdout setup -----------------------------
2025-10-19 11:40:32,503 | INFO     | Baue/Aktualisiere Zustand aus Event-Stream auf...
2025-10-19 11:40:32,503 | INFO     | Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
------------------------------ Captured log setup ------------------------------
INFO     wlan_tool.storage.state:state.py:52 Baue/Aktualisiere Zustand aus Event-Stream auf...
INFO     wlan_tool.storage.state:state.py:57 Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
----------------------------- Captured stdout call -----------------------------
2025-10-19 11:40:32,505 | ERROR    | Unexpected error in cluster_clients: cluster_clients() got an unexpected keyword argument 'algo_name'
2025-10-19 11:40:32,506 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
TypeError: cluster_clients() got an unexpected keyword argument 'algo_name'

------------------------------ Captured log call -------------------------------
ERROR    wlan_tool.analysis.logic:exceptions.py:165 Unexpected error in cluster_clients: cluster_clients() got an unexpected keyword argument 'algo_name'
DEBUG    wlan_tool.analysis.logic:exceptions.py:166 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
TypeError: cluster_clients() got an unexpected keyword argument 'algo_name'
_________________ TestPerformance.test_large_dataset_handling __________________

self = <test_presentation.TestPerformance object at 0x7f59d57c90>
mock_console = <MagicMock id='546751567504'>

    def test_large_dataset_handling(self, mock_console):
        """Test mit großen Datensätzen."""
        # Erstelle State mit vielen Clients
        state = WifiAnalysisState()
    
        for i in range(100):
            client = ClientState(mac=f"aa:bb:cc:dd:ee:{i:02x}")
            client.probes = {f"SSID_{i}"}
            client.all_packet_ts = np.array([time.time() - 100, time.time()])
>           client.rssi_w = Welford()
E           NameError: name 'Welford' is not defined

pytest/test_presentation.py:366: NameError
_____________ TestClientState.test_client_state_update_from_event ______________

self = <test_storage.TestClientState object at 0x7f59d66450>

    def test_client_state_update_from_event(self):
        """Test ClientState-Update aus Event."""
        client = ClientState(mac="aa:bb:cc:dd:ee:ff")
        event = {
            'ts': time.time(),
            'type': 'probe_req',
            'client': 'aa:bb:cc:dd:ee:ff',
            'rssi': -50,
            'ies': {'probes': ['TestSSID']}
        }
    
        client.update_from_event(event)
        assert client.count == 1
>       assert 'TestSSID' in client.probes
E       AssertionError: assert 'TestSSID' in set()
E        +  where set() = ClientState(mac='aa:bb:cc:dd:ee:ff', first_seen=1760866832.6590343, last_seen=1760866832.6590343, count=1, probes=set(..., hostname=None, mcs_rates=Counter(), noise_w=Welford(n=0, mean=0.0, M2=0.0), fcs_error_count=0, ie_order_hashes=set()).probes

pytest/test_storage.py:97: AssertionError
_________________ TestAPState.test_ap_state_update_from_beacon _________________

self = <test_storage.TestAPState object at 0x7f59d67890>

    def test_ap_state_update_from_beacon(self):
        """Test APState-Update aus Beacon."""
        ap = APState(bssid="aa:bb:cc:dd:ee:ff", ssid="TestAP")
        event = {
            'ts': time.time(),
            'type': 'beacon',
            'bssid': 'aa:bb:cc:dd:ee:ff',
            'ssid': 'TestAP',
            'rssi': -50,
            'channel': 6,
            'beacon_interval': 102
        }
    
>       ap.update_from_event(event)
E       AttributeError: 'APState' object has no attribute 'update_from_event'

pytest/test_storage.py:141: AttributeError
___________________ TestWifiAnalysisState.test_state_pruning ___________________

self = <test_storage.TestWifiAnalysisState object at 0x7f59d75b90>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f514b4090>

    def test_state_pruning(self, populated_state):
        """Test State-Pruning."""
        state = populated_state
        assert 'DE:AD:BE:EF:00:00' in state.clients
    
        pruned_count = state.prune_state(time.time(), threshold_s=7200)
    
        assert pruned_count > 0
        assert 'DE:AD:BE:EF:00:00' not in state.clients
>       assert 'a8:51:ab:0c:b9:e9' in state.clients  # Sollte bleiben
E       AssertionError: assert 'a8:51:ab:0c:b9:e9' in {}
E        +  where {} = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f514b4090>.clients

pytest/test_storage.py:203: AssertionError
---------------------------- Captured stdout setup -----------------------------
2025-10-19 11:40:32,728 | INFO     | Baue/Aktualisiere Zustand aus Event-Stream auf...
2025-10-19 11:40:32,728 | INFO     | Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
------------------------------ Captured log setup ------------------------------
INFO     wlan_tool.storage.state:state.py:52 Baue/Aktualisiere Zustand aus Event-Stream auf...
INFO     wlan_tool.storage.state:state.py:57 Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
----------------------------- Captured stdout call -----------------------------
2025-10-19 11:40:32,729 | INFO     | Zustand bereinigt: 1 APs, 3 Clients, 0 Seq-Einträge und 1 SSIDs entfernt.
------------------------------ Captured log call -------------------------------
INFO     wlan_tool.storage.state:state.py:237 Zustand bereinigt: 1 APs, 3 Clients, 0 Seq-Einträge und 1 SSIDs entfernt.
________________ TestWifiAnalysisState.test_state_ssid_mapping _________________

self = <test_storage.TestWifiAnalysisState object at 0x7f59d653d0>
sample_events = [{'beacon_interval': 102, 'bssid': '08:96:d7:1a:21:1c', 'cap': 17, 'channel': 6, ...}, {'client': 'a8:51:ab:0c:b9:e9',...-91, ...}, {'client': 'b2:87:23:15:7f:f2', 'ie_order_hash': 67890, 'ies': {0: ['MyOtherWLAN']}, 'rssi': -70, ...}, ...]

    def test_state_ssid_mapping(self, sample_events):
        """Test SSID-Mapping-Funktionalität."""
        state = WifiAnalysisState()
        state.build_from_events(sample_events)
    
        # Teste SSID-Map
        assert 'MyTestWLAN' in state.ssid_map
        ssid_info = state.ssid_map['MyTestWLAN']
        assert '08:96:d7:1a:21:1c' in ssid_info['bssids']
>       assert 'a8:51:ab:0c:b9:e9' in ssid_info['sources']['probe_req']
E       AssertionError: assert 'a8:51:ab:0c:b9:e9' in set()

pytest/test_storage.py:214: AssertionError
----------------------------- Captured stdout call -----------------------------
2025-10-19 11:40:32,755 | INFO     | Baue/Aktualisiere Zustand aus Event-Stream auf...
2025-10-19 11:40:32,756 | INFO     | Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
------------------------------ Captured log call -------------------------------
INFO     wlan_tool.storage.state:state.py:52 Baue/Aktualisiere Zustand aus Event-Stream auf...
INFO     wlan_tool.storage.state:state.py:57 Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
_____________________ TestDatabaseModule.test_fetch_events _____________________

self = <test_storage.TestDatabaseModule object at 0x7f59d762d0>
in_memory_db = <sqlite3.Connection object at 0x7f7bfd0c70>
sample_events = [{'beacon_interval': 102, 'bssid': '08:96:d7:1a:21:1c', 'cap': 17, 'channel': 6, ...}, {'client': 'a8:51:ab:0c:b9:e9',...-91, ...}, {'client': 'b2:87:23:15:7f:f2', 'ie_order_hash': 67890, 'ies': {0: ['MyOtherWLAN']}, 'rssi': -70, ...}, ...]

    def test_fetch_events(self, in_memory_db, sample_events):
        """Test Event-Abruf."""
        conn = in_memory_db
    
        # Schreibe Test-Events
        for event in sample_events[:2]:
>           database.add_event(conn, event)
E           AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

pytest/test_storage.py:260: AttributeError
______________________ TestDatabaseModule.test_add_label _______________________

self = <test_storage.TestDatabaseModule object at 0x7f59d766d0>
in_memory_db = <sqlite3.Connection object at 0x7f7bfd27a0>

    def test_add_label(self, in_memory_db):
        """Test Label-Hinzufügung."""
        conn = in_memory_db
    
        database.add_label(conn, "TestSSID", "aa:bb:cc:dd:ee:ff", 1)
    
        cursor = conn.execute("SELECT * FROM labels WHERE ssid = ? AND bssid = ?",
                            ("TestSSID", "aa:bb:cc:dd:ee:ff"))
        result = cursor.fetchone()
        assert result is not None
>       assert result[2] == 1  # label = 1
E       AssertionError: assert 'aa:bb:cc:dd:ee:ff' == 1

pytest/test_storage.py:277: AssertionError
----------------------------- Captured stdout call -----------------------------
2025-10-19 11:40:33,486 | DEBUG    | Starting operation: add_label
2025-10-19 11:40:33,487 | DEBUG    | Added label: TestSSID -> aa:bb:cc:dd:ee:ff = 1 (source: ui)
------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: add_label
DEBUG    wlan_tool.storage.database:database.py:618 Added label: TestSSID -> aa:bb:cc:dd:ee:ff = 1 (source: ui)
________________ TestOUIFunctions.test_lookup_vendor_apple_mac _________________

self = <test_utils.TestOUIFunctions object at 0x7f59d7e150>

    def test_lookup_vendor_apple_mac(self):
        """Test Vendor-Lookup für Apple-MAC."""
        # Apple MAC-Adresse
        mac = "a8:51:ab:0c:b9:e9"
        vendor = utils.lookup_vendor(mac)
    
>       assert vendor is not None
E       assert None is not None

pytest/test_utils.py:26: AssertionError
_______________ TestOUIFunctions.test_lookup_vendor_unknown_mac ________________

self = <test_utils.TestOUIFunctions object at 0x7f59d7ed50>

    def test_lookup_vendor_unknown_mac(self):
        """Test Vendor-Lookup für unbekannte MAC."""
        # Unbekannte MAC-Adresse
        mac = "ff:ff:ff:ff:ff:ff"
        vendor = utils.lookup_vendor(mac)
    
        # Sollte None oder "Unknown" zurückgeben
>       assert vendor is None or vendor == "Unknown"
E       AssertionError: assert ('(Lokal / Randomisiert)' is None or '(Lokal / Randomisiert)' == 'Unknown'
E         
E         - Unknown
E         + (Lokal / Randomisiert))

pytest/test_utils.py:45: AssertionError
_________________ TestIEParsing.test_parse_ies_vendor_specific _________________

self = <test_utils.TestIEParsing object at 0x7f59d88ad0>

    def test_parse_ies_vendor_specific(self):
        """Test Vendor-spezifische IE-Parsing."""
        ies = {221: ['0017f20a010103040507080c']}  # Apple IE
        parsed = utils.parse_ies(ies, detailed=True)
    
        assert isinstance(parsed, dict)
        assert "vendor_specific" in parsed
>       assert "Apple" in parsed["vendor_specific"]
E       AssertionError: assert 'Apple' in {}

pytest/test_utils.py:131: AssertionError
_________________ TestIEParsing.test_parse_ies_ht_capabilities _________________

self = <test_utils.TestIEParsing object at 0x7f59d88e50>

    def test_parse_ies_ht_capabilities(self):
        """Test HT-Capabilities-Parsing."""
        ies = {45: ['1f']}  # HT Capabilities
        parsed = utils.parse_ies(ies, detailed=True)
    
        assert isinstance(parsed, dict)
        assert "ht_caps" in parsed
>       assert "streams" in parsed["ht_caps"]
E       AssertionError: assert 'streams' in {'40mhz_support': True}

pytest/test_utils.py:140: AssertionError
_________________ TestUtilityFunctions.test_is_local_admin_mac _________________

self = <test_utils.TestUtilityFunctions object at 0x7f59d89e90>

    def test_is_local_admin_mac(self):
        """Test lokale Admin-MAC-Erkennung."""
        # Lokale Admin-MAC
        assert utils.is_local_admin_mac("02:00:00:00:00:00") is True
        assert utils.is_local_admin_mac("06:00:00:00:00:00") is True
    
        # Globale MAC
        assert utils.is_local_admin_mac("00:00:00:00:00:00") is False
>       assert utils.is_local_admin_mac("aa:bb:cc:dd:ee:ff") is False
E       AssertionError: assert True is False
E        +  where True = <function is_local_admin_mac at 0x7f90d8c180>('aa:bb:cc:dd:ee:ff')
E        +    where <function is_local_admin_mac at 0x7f90d8c180> = utils.is_local_admin_mac

pytest/test_utils.py:171: AssertionError
___________________ TestUtilityFunctions.test_is_valid_bssid ___________________

self = <test_utils.TestUtilityFunctions object at 0x7f59d8a490>

    def test_is_valid_bssid(self):
        """Test BSSID-Validierung."""
        # Gültige BSSID
        assert utils.is_valid_bssid("aa:bb:cc:dd:ee:ff") is True
        assert utils.is_valid_bssid("00:11:22:33:44:55") is True
    
        # Ungültige BSSID
        assert utils.is_valid_bssid("") is False
        assert utils.is_valid_bssid("invalid") is False
>       assert utils.is_valid_bssid("aa:bb:cc:dd:ee") is False  # Zu kurz
E       AssertionError: assert True is False
E        +  where True = <function is_valid_bssid at 0x7f90d8c220>('aa:bb:cc:dd:ee')
E        +    where <function is_valid_bssid at 0x7f90d8c220> = utils.is_valid_bssid

pytest/test_utils.py:182: AssertionError
________________ TestUtilityFunctions.test_ie_fingerprint_hash _________________

self = <test_utils.TestUtilityFunctions object at 0x7f59d8aa90>

    def test_ie_fingerprint_hash(self):
        """Test IE-Fingerprint-Hash."""
        ies = {
            0: ['TestSSID'],
            1: ['82848b96'],
            48: ['0100000fac040100000fac020100000fac028c00']
        }
    
        hash_value = utils.ie_fingerprint_hash(ies)
    
        assert isinstance(hash_value, str)
>       assert len(hash_value) == 32  # MD5-Hash-Länge
E       AssertionError: assert 40 == 32
E        +  where 40 = len('fb3a54a0b7ca1a713fd927a194ff191b7de45566')

pytest/test_utils.py:196: AssertionError
_____________ TestUtilityFunctions.test_ie_fingerprint_hash_empty ______________

self = <test_utils.TestUtilityFunctions object at 0x7f59d8b0d0>

    def test_ie_fingerprint_hash_empty(self):
        """Test IE-Fingerprint-Hash mit leeren IEs."""
        ies = {}
    
        hash_value = utils.ie_fingerprint_hash(ies)
    
>       assert hash_value is None or hash_value == ""
E       AssertionError: assert ('da39a3ee5e6b4b0d3255bfef95601890afd80709' is None or 'da39a3ee5e6b...01890afd80709' == ''
E         
E         + da39a3ee5e6b4b0d3255bfef95601890afd80709)

pytest/test_utils.py:205: AssertionError
_________________ TestConfigFunctions.test_load_config_default _________________

self = <test_utils.TestConfigFunctions object at 0x7f59d8bf50>

    def test_load_config_default(self):
        """Test Konfigurations-Laden (Standard)."""
>       config_data = utils.load_config()
E       TypeError: load_config() missing 1 required positional argument: 'profile'

pytest/test_utils.py:226: TypeError
____________ TestConfigFunctions.test_load_config_specific_profile _____________

self = <test_utils.TestConfigFunctions object at 0x7f59d9c590>

    def test_load_config_specific_profile(self):
        """Test Konfigurations-Laden (spezifisches Profil)."""
        # Erstelle temporäre Konfigurationsdatei
        test_config = {
            "capture": {"interface": "test0", "duration": 60},
            "database": {"path": "test.db"}
        }
    
        with tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False) as f:
            yaml.dump(test_config, f)
            config_path = f.name
    
        try:
>           with patch('wlan_tool.utils.CONFIG_PATH', config_path):

pytest/test_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f52fa7a10>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'wlan_tool.utils' from '/home/pi/hacking/wlan_tool/utils.py'> does not have the attribute 'CONFIG_PATH'

../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1419: AttributeError
______________ TestConfigFunctions.test_load_config_missing_file _______________

self = <test_utils.TestConfigFunctions object at 0x7f59d9cb90>

    def test_load_config_missing_file(self):
        """Test Konfigurations-Laden (fehlende Datei)."""
>       with patch('wlan_tool.utils.CONFIG_PATH', Path("/nonexistent/config.yaml")):

pytest/test_utils.py:255: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f58b90c50>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'wlan_tool.utils' from '/home/pi/hacking/wlan_tool/utils.py'> does not have the attribute 'CONFIG_PATH'

../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1419: AttributeError
________________ TestEdgeCases.test_ie_fingerprint_hash_unicode ________________

self = <test_utils.TestEdgeCases object at 0x7f59d9f710>

    def test_ie_fingerprint_hash_unicode(self):
        """Test IE-Fingerprint-Hash mit Unicode-Daten."""
        ies = {0: ['TestSSID_äöü']}  # Unicode-Zeichen
    
        hash_value = utils.ie_fingerprint_hash(ies)
    
        assert isinstance(hash_value, str)
>       assert len(hash_value) == 32
E       AssertionError: assert 40 == 32
E        +  where 40 = len('758ed0819e647ff1683744b0bc9b1ff7470f6d37')

pytest/test_utils.py:356: AssertionError
_____________ TestEdgeCases.test_config_loading_with_invalid_yaml ______________

self = <test_utils.TestEdgeCases object at 0x7f59d89c90>

    def test_config_loading_with_invalid_yaml(self):
        """Test Konfigurations-Laden mit ungültigem YAML."""
        invalid_yaml = "invalid: yaml: content: ["
    
        with tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False) as f:
            f.write(invalid_yaml)
            config_path = f.name
    
        try:
>           with patch('wlan_tool.utils.CONFIG_PATH', config_path):

pytest/test_utils.py:378: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f4cda0690>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'wlan_tool.utils' from '/home/pi/hacking/wlan_tool/utils.py'> does not have the attribute 'CONFIG_PATH'

../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1419: AttributeError
__________ TestEndToEndWorkflow.test_complete_wifi_analysis_workflow ___________

self = <test_end_to_end.TestEndToEndWorkflow object at 0x7f58ce6390>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]
temp_dir = PosixPath('/tmp/tmpwk4f7di0')

    @pytest.mark.integration
    @pytest.mark.slow
    def test_complete_wifi_analysis_workflow(self, large_dataset, temp_dir):
        """Test des kompletten WLAN-Analyse-Workflows."""
        # 1. Datenverarbeitung
        processor = WiFiDataProcessor()
        processed_data = processor.process_data(large_dataset)
    
        assert len(processed_data) == len(large_dataset)
        assert "processed_timestamp" in processed_data.columns
    
        # 2. Feature-Extraktion
        extractor = FeatureExtractor()
        features = extractor.extract_features(processed_data)
    
        assert features.shape[0] == len(processed_data)
        assert features.shape[1] > 0
    
        # 3. Clustering-Analyse
        analyzer = ClusteringAnalyzer()
>       labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)

tests/integration/test_end_to_end.py:42: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1064: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1446: in fit
    X = validate_data(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2944: in validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1107: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:120: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[-1.15579349,  0.        ,  0.        , ...,  0.        ,
         0.15614176, -0.97725852],
       [-1.1557934...176, -0.97725852],
       [ 1.35680105,  0.        ,  0.        , ...,  0.        ,
         0.15614176,  1.02327069]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:169: ValueError
____________ TestEndToEndWorkflow.test_plugin_integration_workflow _____________

self = <test_end_to_end.TestEndToEndWorkflow object at 0x7f58ce6a90>
sample_wifi_data =               timestamp device_id  ...  packet_count  bytes_transferred
0   2024-01-01 00:00:00  device_3  ...        ...15         206.754596
999 2024-01-01 16:39:00  device_1  ...           103         554.365485

[1000 rows x 11 columns]
temp_dir = PosixPath('/tmp/tmp_ir40npa')

    @pytest.mark.integration
    def test_plugin_integration_workflow(self, sample_wifi_data, temp_dir):
        """Test der Plugin-Integration im Workflow."""
        from plugins import load_all_plugins
    
        # Plugins laden
        plugin_dir = Path("plugins")
        plugins = load_all_plugins(plugin_dir)
    
        assert len(plugins) > 0
    
        # Features extrahieren
        extractor = FeatureExtractor()
        features = extractor.extract_features(sample_wifi_data)
    
        # Jedes Plugin testen
        for plugin in plugins:
            # Plugin-Dependencies prüfen
>           if not plugin.validate_dependencies():
E           AttributeError: 'str' object has no attribute 'validate_dependencies'

tests/integration/test_end_to_end.py:101: AttributeError
----------------------------- Captured stdout call -----------------------------
2025-10-19 11:40:35,704 | INFO     | Plugin 'Advanced Clustering' v1.0.0 geladen
2025-10-19 11:40:35,710 | INFO     | Plugin 'Ensemble Models' v1.0.0 geladen
2025-10-19 11:40:35,713 | WARNING  | Dependencies ['umap-learn'] für Plugin 'UMAP Plot' nicht verfügbar
2025-10-19 11:40:35,713 | WARNING  | Plugin umap_plot hat fehlende Dependencies
2025-10-19 11:40:35,715 | INFO     | Plugin 'Sankey Diagram' v1.0.0 geladen
2025-10-19 11:40:35,719 | WARNING  | PyTorch oder Gym nicht verfügbar: No module named 'gym'
2025-10-19 11:40:35,723 | WARNING  | Dependencies ['gym'] für Plugin 'Reinforcement Learning' nicht verfügbar
2025-10-19 11:40:35,723 | WARNING  | Plugin reinforcement_learning hat fehlende Dependencies
2025-10-19 11:40:35,725 | INFO     | Plugin 'Example_Plugin' v1.0.0 geladen
------------------------------ Captured log call -------------------------------
INFO     plugins:__init__.py:120 Plugin 'Advanced Clustering' v1.0.0 geladen
INFO     plugins:__init__.py:120 Plugin 'Ensemble Models' v1.0.0 geladen
WARNING  plugins:__init__.py:68 Dependencies ['umap-learn'] für Plugin 'UMAP Plot' nicht verfügbar
WARNING  plugins:__init__.py:97 Plugin umap_plot hat fehlende Dependencies
INFO     plugins:__init__.py:120 Plugin 'Sankey Diagram' v1.0.0 geladen
WARNING  root:plugin.py:28 PyTorch oder Gym nicht verfügbar: No module named 'gym'
WARNING  plugins:__init__.py:68 Dependencies ['gym'] für Plugin 'Reinforcement Learning' nicht verfügbar
WARNING  plugins:__init__.py:97 Plugin reinforcement_learning hat fehlende Dependencies
INFO     plugins:__init__.py:120 Plugin 'Example_Plugin' v1.0.0 geladen
_____________ TestEndToEndWorkflow.test_data_pipeline_with_file_io _____________

self = <test_end_to_end.TestEndToEndWorkflow object at 0x7f58ce7190>
temp_dir = PosixPath('/tmp/tmpao2wm8c_')

    @pytest.mark.integration
    def test_data_pipeline_with_file_io(self, temp_dir):
        """Test der Datenpipeline mit Datei-I/O."""
        # Test-Daten generieren
        n_samples = 1000
        test_data = pd.DataFrame(
            {
                "timestamp": pd.date_range(
                    "2024-01-01", periods=n_samples, freq="1min"
                ),
                "device_id": np.random.choice(
                    ["device_1", "device_2", "device_3"], n_samples
                ),
                "signal_strength": np.random.normal(-50, 10, n_samples),
                "frequency": np.random.choice([2.4, 5.0], n_samples),
                "channel": np.random.randint(1, 14, n_samples),
                "mac_address": [f"00:11:22:33:44:{i:02x}" for i in range(n_samples)],
                "ssid": np.random.choice(
                    ["WiFi_Home", "WiFi_Office", "Public_WiFi"], n_samples
                ),
                "encryption": np.random.choice(["WPA2", "WPA3", "Open"], n_samples),
                "data_rate": np.random.normal(54, 10, n_samples),
                "packet_count": np.random.poisson(100, n_samples),
                "bytes_transferred": np.random.exponential(1000, n_samples),
            }
        )
    
        # 1. Daten in CSV speichern
        input_file = temp_dir / "input_data.csv"
        test_data.to_csv(input_file, index=False)
    
        # 2. Daten laden und verarbeiten
        loaded_data = pd.read_csv(input_file)
        processor = WiFiDataProcessor()
        processed_data = processor.process_data(loaded_data)
    
        # 3. Features extrahieren
        extractor = FeatureExtractor()
        features = extractor.extract_features(processed_data)
    
        # 4. Clustering
        analyzer = ClusteringAnalyzer()
>       labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=3)

tests/integration/test_end_to_end.py:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1064: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1446: in fit
    X = validate_data(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2944: in validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1107: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:120: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[-1.62859019,  0.        ,  0.        , ...,  0.        ,
         0.        , -0.9900495 ],
       [-1.6285901...   ,  1.0100505 ],
       [ 1.69506325,  0.        ,  0.        , ...,  0.        ,
         0.        ,  1.0100505 ]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:169: ValueError
____________ TestEndToEndWorkflow.test_error_handling_and_recovery _____________

self = <test_end_to_end.TestEndToEndWorkflow object at 0x7f58ce78d0>
temp_dir = PosixPath('/tmp/tmpjxcgg4s6')

    @pytest.mark.integration
    def test_error_handling_and_recovery(self, temp_dir):
        """Test der Fehlerbehandlung und Wiederherstellung."""
        processor = WiFiDataProcessor()
        extractor = FeatureExtractor()
        analyzer = ClusteringAnalyzer()
    
        # Test mit ungültigen Daten
        invalid_data = pd.DataFrame(
            {
                "timestamp": ["invalid_date", "2024-01-01", "2024-01-02"],
                "signal_strength": [np.nan, -50, -60],
                "frequency": [1.0, 2.4, 5.0],  # Ungültige Frequenz
                "device_id": ["device_1", "device_2", "device_3"],
                "mac_address": [
                    "00:11:22:33:44:01",
                    "00:11:22:33:44:02",
                    "00:11:22:33:44:03",
                ],
                "ssid": ["WiFi_Home", "WiFi_Office", "Public_WiFi"],
                "encryption": ["WPA2", "WPA3", "Open"],
                "channel": [1, 6, 11],
                "data_rate": [54, 100, 54],
                "packet_count": [100, 200, 150],
                "bytes_transferred": [1000, 2000, 1500],
            }
        )
    
        # Verarbeitung sollte Fehler behandeln
        try:
>           processed_data = processor.process_data(invalid_data)

tests/integration/test_end_to_end.py:203: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/data_processing/wifi_processor.py:45: in process_data
    processed_data['processed_timestamp'] = pd.to_datetime(processed_data['timestamp'])
.venv/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:1067: in to_datetime
    values = convert_listlike(arg._values, format)
.venv/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:435: in _convert_listlike_datetimes
    result, tz_parsed = objects_to_datetime64(
.venv/lib/python3.11/site-packages/pandas/core/arrays/datetimes.py:2398: in objects_to_datetime64
    result, tz_parsed = tslib.array_to_datetime(
tslib.pyx:414: in pandas._libs.tslib.array_to_datetime
    ???
tslib.pyx:596: in pandas._libs.tslib.array_to_datetime
    ???
tslib.pyx:553: in pandas._libs.tslib.array_to_datetime
    ???
conversion.pyx:641: in pandas._libs.tslibs.conversion.convert_str_to_tsobject
    ???
parsing.pyx:336: in pandas._libs.tslibs.parsing.parse_datetime_string
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   pandas._libs.tslibs.parsing.DateParseError: Unknown datetime string format, unable to parse: invalid_date, at position 0

parsing.pyx:666: DateParseError

During handling of the above exception, another exception occurred:

self = <test_end_to_end.TestEndToEndWorkflow object at 0x7f58ce78d0>
temp_dir = PosixPath('/tmp/tmpjxcgg4s6')

    @pytest.mark.integration
    def test_error_handling_and_recovery(self, temp_dir):
        """Test der Fehlerbehandlung und Wiederherstellung."""
        processor = WiFiDataProcessor()
        extractor = FeatureExtractor()
        analyzer = ClusteringAnalyzer()
    
        # Test mit ungültigen Daten
        invalid_data = pd.DataFrame(
            {
                "timestamp": ["invalid_date", "2024-01-01", "2024-01-02"],
                "signal_strength": [np.nan, -50, -60],
                "frequency": [1.0, 2.4, 5.0],  # Ungültige Frequenz
                "device_id": ["device_1", "device_2", "device_3"],
                "mac_address": [
                    "00:11:22:33:44:01",
                    "00:11:22:33:44:02",
                    "00:11:22:33:44:03",
                ],
                "ssid": ["WiFi_Home", "WiFi_Office", "Public_WiFi"],
                "encryption": ["WPA2", "WPA3", "Open"],
                "channel": [1, 6, 11],
                "data_rate": [54, 100, 54],
                "packet_count": [100, 200, 150],
                "bytes_transferred": [1000, 2000, 1500],
            }
        )
    
        # Verarbeitung sollte Fehler behandeln
        try:
            processed_data = processor.process_data(invalid_data)
            # Wenn erfolgreich, sollten ungültige Daten bereinigt sein
            assert len(processed_data) <= len(invalid_data)
        except Exception as e:
            # Fehler sollten informativ sein
>           assert "Invalid" in str(e) or "Missing" in str(e)
E           AssertionError: assert ('Invalid' in 'Unknown datetime string format, unable to parse: invalid_date, at position 0' or 'Missing' in 'Unknown datetime string format, unable to parse: invalid_date, at position 0')
E            +  where 'Unknown datetime string format, unable to parse: invalid_date, at position 0' = str(DateParseError('Unknown datetime string format, unable to parse: invalid_date, at position 0'))
E            +  and   'Unknown datetime string format, unable to parse: invalid_date, at position 0' = str(DateParseError('Unknown datetime string format, unable to parse: invalid_date, at position 0'))

tests/integration/test_end_to_end.py:208: AssertionError
_______________ TestEndToEndWorkflow.test_performance_under_load _______________

self = <test_end_to_end.TestEndToEndWorkflow object at 0x7f58ce7fd0>
temp_dir = PosixPath('/tmp/tmpulbt39c5')

    @pytest.mark.integration
    def test_performance_under_load(self, temp_dir):
        """Test der Performance unter Last."""
        import time
    
        # Große Datenmenge
        n_samples = 50000
        large_data = pd.DataFrame(
            {
                "timestamp": pd.date_range("2024-01-01", periods=n_samples, freq="1s"),
                "device_id": np.random.choice(
                    [f"device_{i}" for i in range(100)], n_samples
                ),
                "signal_strength": np.random.normal(-50, 10, n_samples),
                "frequency": np.random.choice([2.4, 5.0], n_samples),
                "channel": np.random.randint(1, 14, n_samples),
                "mac_address": [f"00:11:22:33:44:{i:02x}" for i in range(n_samples)],
                "ssid": np.random.choice(
                    ["WiFi_Home", "WiFi_Office", "Public_WiFi"], n_samples
                ),
                "encryption": np.random.choice(["WPA2", "WPA3", "Open"], n_samples),
                "data_rate": np.random.normal(54, 10, n_samples),
                "packet_count": np.random.poisson(100, n_samples),
                "bytes_transferred": np.random.exponential(1000, n_samples),
            }
        )
    
        processor = WiFiDataProcessor()
        extractor = FeatureExtractor()
        analyzer = ClusteringAnalyzer()
    
        # Performance-Messung
        start_time = time.time()
    
        # Verarbeitung
        processed_data = processor.process_data(large_data)
        features = extractor.extract_features(processed_data)
>       labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)

tests/integration/test_end_to_end.py:259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1064: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1446: in fit
    X = validate_data(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2944: in validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1107: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:120: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[-1.6100241 ,  0.        ,  0.        , ...,  0.        ,
         0.        , -1.00344594],
       [-1.6100241...   ,  0.9965659 ],
       [ 1.63599223,  0.        ,  0.        , ...,  0.        ,
         0.        , -1.00344594]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:169: ValueError
_______________ TestEndToEndWorkflow.test_concurrent_processing ________________

self = <test_end_to_end.TestEndToEndWorkflow object at 0x7f58cec710>
temp_dir = PosixPath('/tmp/tmpsd4oe9ll')

    @pytest.mark.integration
    def test_concurrent_processing(self, temp_dir):
        """Test der parallelen Verarbeitung."""
        import threading
        from concurrent.futures import ThreadPoolExecutor
    
        def process_chunk(chunk_data):
            """Verarbeitet einen Daten-Chunk."""
            processor = WiFiDataProcessor()
            extractor = FeatureExtractor()
            analyzer = ClusteringAnalyzer()
    
            processed_data = processor.process_data(chunk_data)
            features = extractor.extract_features(processed_data)
            labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=3)
    
            return {
                "chunk_id": threading.current_thread().ident,
                "n_samples": len(chunk_data),
                "n_clusters": len(np.unique(labels)),
            }
    
        # Daten in Chunks aufteilen
        n_chunks = 4
        chunk_size = 1000
        n_samples = n_chunks * chunk_size
    
        test_data = pd.DataFrame(
            {
                "timestamp": pd.date_range(
                    "2024-01-01", periods=n_samples, freq="1min"
                ),
                "device_id": np.random.choice(
                    [f"device_{i}" for i in range(50)], n_samples
                ),
                "signal_strength": np.random.normal(-50, 10, n_samples),
                "frequency": np.random.choice([2.4, 5.0], n_samples),
                "channel": np.random.randint(1, 14, n_samples),
                "mac_address": [f"00:11:22:33:44:{i:02x}" for i in range(n_samples)],
                "ssid": np.random.choice(
                    ["WiFi_Home", "WiFi_Office", "Public_WiFi"], n_samples
                ),
                "encryption": np.random.choice(["WPA2", "WPA3", "Open"], n_samples),
                "data_rate": np.random.normal(54, 10, n_samples),
                "packet_count": np.random.poisson(100, n_samples),
                "bytes_transferred": np.random.exponential(1000, n_samples),
            }
        )
    
        chunks = [
            test_data.iloc[i * chunk_size : (i + 1) * chunk_size]
            for i in range(n_chunks)
        ]
    
        # Parallele Verarbeitung
        with ThreadPoolExecutor(max_workers=n_chunks) as executor:
            futures = [executor.submit(process_chunk, chunk) for chunk in chunks]
>           results = [future.result() for future in futures]

tests/integration/test_end_to_end.py:328: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/integration/test_end_to_end.py:328: in <listcomp>
    results = [future.result() for future in futures]
../.pyenv/versions/3.11.9/lib/python3.11/concurrent/futures/_base.py:456: in result
    return self.__get_result()
../.pyenv/versions/3.11.9/lib/python3.11/concurrent/futures/_base.py:401: in __get_result
    raise self._exception
../.pyenv/versions/3.11.9/lib/python3.11/concurrent/futures/thread.py:58: in run
    result = self.fn(*self.args, **self.kwargs)
tests/integration/test_end_to_end.py:285: in process_chunk
    labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=3)
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1064: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1446: in fit
    X = validate_data(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2944: in validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1107: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:120: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[-1.62859019,  0.        ,  0.        , ...,  0.11020775,
        -0.38663966, -1.06832936],
       [-1.6285901...14 ,  0.93604092],
       [ 1.69506325,  0.        ,  0.        , ...,  0.11020775,
         0.31126587,  0.93604092]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:169: ValueError
_______________ TestClusteringBenchmarks.test_kmeans_performance _______________

self = <test_benchmarks.TestClusteringBenchmarks object at 0x7f58d09050>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f4cf23c50>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_kmeans_performance(self, benchmark, large_dataset):
        """Benchmark für K-Means Clustering."""
        analyzer = ClusteringAnalyzer()
    
        # Features extrahieren
        feature_extractor = FeatureExtractor()
        features = feature_extractor.extract_features(large_dataset)
    
        def clustering_func():
            return analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)
    
>       result = benchmark(clustering_func)

tests/performance/test_benchmarks.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:156: in __call__
    return self._raw(function_to_benchmark, *args, **kwargs)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:180: in _raw
    duration, iterations, loops_range = self._calibrate_timer(runner)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:318: in _calibrate_timer
    duration = runner(loops_range)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:109: in runner
    function_to_benchmark(*args, **kwargs)
tests/performance/test_benchmarks.py:29: in clustering_func
    return analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1064: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1446: in fit
    X = validate_data(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2944: in validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1107: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:120: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176, -0.97725852],
       [ 0.       ...176, -0.97725852],
       [ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176,  1.02327069]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:169: ValueError
_______________ TestClusteringBenchmarks.test_dbscan_performance _______________

self = <test_benchmarks.TestClusteringBenchmarks object at 0x7f58d09650>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f4c860790>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_dbscan_performance(self, benchmark, large_dataset):
        """Benchmark für DBSCAN Clustering."""
        analyzer = ClusteringAnalyzer()
    
        feature_extractor = FeatureExtractor()
        features = feature_extractor.extract_features(large_dataset)
    
        def clustering_func():
            return analyzer.cluster_data(
                features, algorithm="dbscan", eps=0.5, min_samples=5
            )
    
>       result = benchmark(clustering_func)

tests/performance/test_benchmarks.py:51: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:156: in __call__
    return self._raw(function_to_benchmark, *args, **kwargs)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:180: in _raw
    duration, iterations, loops_range = self._calibrate_timer(runner)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:318: in _calibrate_timer
    duration = runner(loops_range)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:109: in runner
    function_to_benchmark(*args, **kwargs)
tests/performance/test_benchmarks.py:47: in clustering_func
    return analyzer.cluster_data(
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1064: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1446: in fit
    X = validate_data(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2944: in validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1107: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:120: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176, -0.97725852],
       [ 0.       ...176, -0.97725852],
       [ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176,  1.02327069]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:169: ValueError
____________ TestClusteringBenchmarks.test_hierarchical_performance ____________

self = <test_benchmarks.TestClusteringBenchmarks object at 0x7f58ce6550>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f50fb0b50>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_hierarchical_performance(self, benchmark, large_dataset):
        """Benchmark für Hierarchical Clustering."""
        analyzer = ClusteringAnalyzer()
    
        feature_extractor = FeatureExtractor()
        features = feature_extractor.extract_features(large_dataset)
    
        def clustering_func():
            return analyzer.cluster_data(
                features, algorithm="hierarchical", n_clusters=5
            )
    
>       result = benchmark(clustering_func)

tests/performance/test_benchmarks.py:71: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:156: in __call__
    return self._raw(function_to_benchmark, *args, **kwargs)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:180: in _raw
    duration, iterations, loops_range = self._calibrate_timer(runner)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:318: in _calibrate_timer
    duration = runner(loops_range)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:109: in runner
    function_to_benchmark(*args, **kwargs)
tests/performance/test_benchmarks.py:67: in clustering_func
    return analyzer.cluster_data(
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1064: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1446: in fit
    X = validate_data(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2944: in validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1107: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:120: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176, -0.97725852],
       [ 0.       ...176, -0.97725852],
       [ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176,  1.02327069]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:169: ValueError
_____________ TestClusteringBenchmarks.test_clustering_scalability _____________

self = <test_benchmarks.TestClusteringBenchmarks object at 0x7f58d09b90>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f4e1eb550>

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_clustering_scalability(self, benchmark):
        """Test Skalierbarkeit mit verschiedenen Datengrößen."""
        sizes = [1000, 5000, 10000, 20000]
        times = []
    
        for size in sizes:
            # Generiere Test-Daten
            X = np.random.randn(size, 20)
            analyzer = ClusteringAnalyzer()
    
            def clustering_func():
                return analyzer.cluster_data(X, algorithm="kmeans", n_clusters=5)
    
            result = benchmark(clustering_func)
>           times.append(result.stats.mean)
E           AttributeError: 'numpy.ndarray' object has no attribute 'stats'

tests/performance/test_benchmarks.py:93: AttributeError
________ TestDataProcessingBenchmarks.test_data_processing_performance _________

self = <test_benchmarks.TestDataProcessingBenchmarks object at 0x7f58d09f50>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f50f8a8d0>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_data_processing_performance(self, benchmark, large_dataset):
        """Benchmark für Datenverarbeitung."""
        processor = WiFiDataProcessor()
    
        def processing_func():
            return processor.process_data(large_dataset)
    
        result = benchmark(processing_func)
    
        # Datenverarbeitung sollte schnell sein
>       assert result.stats.mean < 1.0

tests/performance/test_benchmarks.py:121: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self =                timestamp  device_id  ...  bytes_transferred  processed_timestamp
0    2024-01-01 00:00:00  device_51  ...01 02:46:38
9999 2024-01-01 02:46:39   device_7  ...         594.132395  2024-01-01 02:46:39

[10000 rows x 12 columns]
name = 'stats'

    @final
    def __getattr__(self, name: str):
        """
        After regular attribute access, try looking up the name
        This allows simpler access to columns for interactive use.
        """
        # Note: obj.x will always call obj.__getattribute__('x') prior to
        # calling obj.__getattr__('x').
        if (
            name not in self._internal_names_set
            and name not in self._metadata
            and name not in self._accessors
            and self._info_axis._can_hold_identifiers_and_holds_name(name)
        ):
            return self[name]
>       return object.__getattribute__(self, name)
E       AttributeError: 'DataFrame' object has no attribute 'stats'

.venv/lib/python3.11/site-packages/pandas/core/generic.py:6293: AttributeError
_______ TestDataProcessingBenchmarks.test_feature_extraction_performance _______

self = <test_benchmarks.TestDataProcessingBenchmarks object at 0x7f58d0a2d0>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f514e81d0>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_feature_extraction_performance(self, benchmark, large_dataset):
        """Benchmark für Feature-Extraktion."""
        extractor = FeatureExtractor()
    
        def extraction_func():
            return extractor.extract_features(large_dataset)
    
        result = benchmark(extraction_func)
    
        # Feature-Extraktion sollte effizient sein
>       assert result.stats.mean < 2.0
E       AttributeError: 'numpy.ndarray' object has no attribute 'stats'

tests/performance/test_benchmarks.py:136: AttributeError
________ TestDataProcessingBenchmarks.test_feature_scaling_performance _________

self = <test_benchmarks.TestDataProcessingBenchmarks object at 0x7f58d0a7d0>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f4ce99c90>

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_feature_scaling_performance(self, benchmark):
        """Benchmark für Feature-Skalierung."""
        extractor = FeatureExtractor()
    
        # Große Feature-Matrix
        features = np.random.randn(50000, 100)
    
        def scaling_func():
            return extractor.scale_features(features)
    
        result = benchmark(scaling_func)
    
        # Skalierung sollte sehr schnell sein
>       assert result.stats.mean < 0.5
E       AttributeError: 'numpy.ndarray' object has no attribute 'stats'

tests/performance/test_benchmarks.py:154: AttributeError
_________ TestClassificationBenchmarks.test_random_forest_performance __________

self = <test_benchmarks.TestClassificationBenchmarks object at 0x7f58d0aed0>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f4ce91c10>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_random_forest_performance(self, benchmark, large_dataset):
        """Benchmark für Random Forest Klassifikation."""
        classifier = DeviceClassifier()
    
        # Features und Labels generieren
        feature_extractor = FeatureExtractor()
        features = feature_extractor.extract_features(large_dataset)
        labels = np.random.randint(0, 5, len(features))
    
        def classification_func():
            classifier.train(features, labels)
            return classifier.predict(features)
    
        result = benchmark(classification_func)
    
        # Random Forest sollte effizient sein
>       assert result.stats.mean < 3.0
E       AttributeError: 'numpy.ndarray' object has no attribute 'stats'

tests/performance/test_benchmarks.py:179: AttributeError
______________ TestClassificationBenchmarks.test_svm_performance _______________

self = <test_benchmarks.TestClassificationBenchmarks object at 0x7f58d0b4d0>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f4ca9e0d0>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_svm_performance(self, benchmark, large_dataset):
        """Benchmark für SVM Klassifikation."""
        classifier = DeviceClassifier(algorithm="svm")
    
        feature_extractor = FeatureExtractor()
        features = feature_extractor.extract_features(large_dataset)
        labels = np.random.randint(0, 5, len(features))
    
        def classification_func():
            classifier.train(features, labels)
            return classifier.predict(features)
    
>       result = benchmark(classification_func)

tests/performance/test_benchmarks.py:196: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:156: in __call__
    return self._raw(function_to_benchmark, *args, **kwargs)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:180: in _raw
    duration, iterations, loops_range = self._calibrate_timer(runner)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:318: in _calibrate_timer
    duration = runner(loops_range)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:109: in runner
    function_to_benchmark(*args, **kwargs)
tests/performance/test_benchmarks.py:193: in classification_func
    classifier.train(features, labels)
wlan_tool/analysis/device_classification.py:64: in train
    self.model.fit(X, y)
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/svm/_base.py:196: in fit
    X, y = validate_data(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2961: in validate_data
    X, y = check_X_y(X, y, **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1370: in check_X_y
    X = check_array(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1107: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:120: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176, -0.97725852],
       [ 0.       ...176, -0.97725852],
       [ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176,  1.02327069]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           SVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:169: ValueError
______________ TestMemoryBenchmarks.test_memory_usage_clustering _______________

self = <test_benchmarks.TestMemoryBenchmarks object at 0x7f58d0bc50>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f4ce9bf50>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    @pytest.mark.memory
    def test_memory_usage_clustering(self, benchmark, large_dataset):
        """Benchmark für Speichernutzung beim Clustering."""
        analyzer = ClusteringAnalyzer()
        feature_extractor = FeatureExtractor()
    
        def memory_intensive_func():
            # Features extrahieren
            features = feature_extractor.extract_features(large_dataset)
    
            # Clustering durchführen
            labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)
    
            # Zusätzliche Berechnungen
            unique_labels = np.unique(labels)
            cluster_sizes = [np.sum(labels == label) for label in unique_labels]
    
            return {
                "n_clusters": len(unique_labels),
                "cluster_sizes": cluster_sizes,
                "features_shape": features.shape,
            }
    
>       result = benchmark(memory_intensive_func)

tests/performance/test_benchmarks.py:231: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:156: in __call__
    return self._raw(function_to_benchmark, *args, **kwargs)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:180: in _raw
    duration, iterations, loops_range = self._calibrate_timer(runner)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:318: in _calibrate_timer
    duration = runner(loops_range)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:109: in runner
    function_to_benchmark(*args, **kwargs)
tests/performance/test_benchmarks.py:219: in memory_intensive_func
    labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1064: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1446: in fit
    X = validate_data(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2944: in validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1107: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:120: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176, -0.97725852],
       [ 0.       ...176, -0.97725852],
       [ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176,  1.02327069]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:169: ValueError
_____________ TestMemoryBenchmarks.test_memory_usage_large_dataset _____________

self = <test_benchmarks.TestMemoryBenchmarks object at 0x7f58d142d0>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f50f98ad0>

    @pytest.mark.benchmark
    @pytest.mark.performance
    @pytest.mark.memory
    def test_memory_usage_large_dataset(self, benchmark):
        """Benchmark für Speichernutzung mit sehr großen Datensätzen."""
        # Sehr großer Datensatz
        n_samples = 100000
        n_features = 50
    
        def large_dataset_func():
            # Große Daten generieren
            X = np.random.randn(n_samples, n_features)
    
            # Clustering mit reduzierter Komplexität
            from sklearn.cluster import MiniBatchKMeans
    
            kmeans = MiniBatchKMeans(n_clusters=10, batch_size=1000)
            labels = kmeans.fit_predict(X)
    
            return {
                "n_samples": n_samples,
                "n_features": n_features,
                "n_clusters": len(np.unique(labels)),
            }
    
        result = benchmark(large_dataset_func)
    
        # Auch bei großen Datensätzen sollte es in angemessener Zeit laufen
>       assert result.stats.mean < 10.0
E       AttributeError: 'dict' object has no attribute 'stats'

tests/performance/test_benchmarks.py:265: AttributeError
________ TestConcurrentBenchmarks.test_parallel_processing_performance _________

self = <test_benchmarks.TestConcurrentBenchmarks object at 0x7f58d14990>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f4e19f5d0>

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_parallel_processing_performance(self, benchmark):
        """Benchmark für parallele Verarbeitung."""
        import threading
        from concurrent.futures import ThreadPoolExecutor
    
        def process_chunk(chunk_data):
            """Verarbeitet einen Daten-Chunk."""
            analyzer = ClusteringAnalyzer()
            return analyzer.cluster_data(chunk_data, algorithm="kmeans", n_clusters=3)
    
        def parallel_processing_func():
            # Daten in Chunks aufteilen
            n_chunks = 4
            chunk_size = 2500
            X = np.random.randn(n_chunks * chunk_size, 20)
            chunks = [X[i * chunk_size : (i + 1) * chunk_size] for i in range(n_chunks)]
    
            # Parallele Verarbeitung
            with ThreadPoolExecutor(max_workers=n_chunks) as executor:
                futures = [executor.submit(process_chunk, chunk) for chunk in chunks]
                results = [future.result() for future in futures]
    
            return results
    
        result = benchmark(parallel_processing_func)
    
        # Parallele Verarbeitung sollte effizienter sein
>       assert result.stats.mean < 3.0
E       AttributeError: 'list' object has no attribute 'stats'

tests/performance/test_benchmarks.py:301: AttributeError
__________________ TestIOBenchmarks.test_file_io_performance ___________________

self = <test_benchmarks.TestIOBenchmarks object at 0x7f58d15110>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f515c6990>
temp_dir = PosixPath('/tmp/tmp_dx_3_fi')

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_file_io_performance(self, benchmark, temp_dir):
        """Benchmark für Datei-I/O."""
        import pickle
    
        # Große Daten generieren
        large_data = np.random.randn(10000, 50)
        file_path = temp_dir / "test_data.pkl"
    
        def io_func():
            # Speichern
            with open(file_path, "wb") as f:
                pickle.dump(large_data, f)
    
            # Laden
            with open(file_path, "rb") as f:
                loaded_data = pickle.load(f)
    
            return loaded_data.shape
    
        result = benchmark(io_func)
    
        # I/O sollte schnell sein
>       assert result.stats.mean < 1.0
E       AttributeError: 'tuple' object has no attribute 'stats'

tests/performance/test_benchmarks.py:332: AttributeError
___________________ TestIOBenchmarks.test_csv_io_performance ___________________

self = <test_benchmarks.TestIOBenchmarks object at 0x7f58d15710>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f4e1c5890>
temp_dir = PosixPath('/tmp/tmp77fbr_w2')
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_csv_io_performance(self, benchmark, temp_dir, large_dataset):
        """Benchmark für CSV-I/O."""
        csv_path = temp_dir / "test_data.csv"
    
        def csv_io_func():
            # Speichern
            large_dataset.to_csv(csv_path, index=False)
    
            # Laden
            loaded_data = pd.read_csv(csv_path)
    
            return loaded_data.shape
    
        result = benchmark(csv_io_func)
    
        # CSV-I/O kann langsamer sein
>       assert result.stats.mean < 2.0
E       AttributeError: 'tuple' object has no attribute 'stats'

tests/performance/test_benchmarks.py:353: AttributeError
_________________ TestMemoryUsage.test_memory_usage_clustering _________________

self = <test_memory_profiling.TestMemoryUsage object at 0x7f58d3ad90>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.memory
    @pytest.mark.performance
    def test_memory_usage_clustering(self, large_dataset):
        """Test Speichernutzung beim Clustering."""
        process = psutil.Process(os.getpid())
        memory_before = process.memory_info().rss / 1024 / 1024
    
        analyzer = ClusteringAnalyzer()
        feature_extractor = FeatureExtractor()
    
        # Features extrahieren
        features = feature_extractor.extract_features(large_dataset)
        memory_after_features = process.memory_info().rss / 1024 / 1024
    
        # Clustering durchführen
>       labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)

tests/performance/test_memory_profiling.py:77: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1064: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1446: in fit
    X = validate_data(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2944: in validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1107: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:120: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176, -0.97725852],
       [ 0.       ...176, -0.97725852],
       [ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176,  1.02327069]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:169: ValueError
______________ TestMemoryProfiling.test_detailed_memory_profiling ______________

self = <test_memory_profiling.TestMemoryProfiling object at 0x7f58d440d0>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.memory
    @pytest.mark.performance
    def test_detailed_memory_profiling(self, large_dataset):
        """Detailliertes Memory-Profiling der WLAN-Analyse."""
        from memory_profiler import memory_usage
    
        def analyze_wifi_data():
            """WLAN-Datenanalyse mit Memory-Tracking."""
            processor = WiFiDataProcessor()
            extractor = FeatureExtractor()
            analyzer = ClusteringAnalyzer()
    
            # 1. Daten verarbeiten
            processed_data = processor.process_data(large_dataset)
    
            # 2. Features extrahieren
            features = extractor.extract_features(processed_data)
    
            # 3. Clustering
            labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)
    
            # 4. Ergebnisse zusammenfassen
            unique_labels = np.unique(labels)
            cluster_sizes = [np.sum(labels == label) for label in unique_labels]
    
            return {
                "n_clusters": len(unique_labels),
                "cluster_sizes": cluster_sizes,
                "features_shape": features.shape,
            }
    
        # Memory-Usage während der Ausführung messen
>       mem_usage = memory_usage(analyze_wifi_data, interval=0.1)

tests/performance/test_memory_profiling.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.11/site-packages/memory_profiler.py:379: in memory_usage
    returned = f(*args, **kw)
tests/performance/test_memory_profiling.py:208: in analyze_wifi_data
    labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1064: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1446: in fit
    X = validate_data(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2944: in validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1107: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:120: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[-1.15579349,  0.        ,  0.        , ...,  0.        ,
         0.15614176, -0.97725852],
       [-1.1557934...176, -0.97725852],
       [ 1.35680105,  0.        ,  0.        , ...,  0.        ,
         0.15614176,  1.02327069]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:169: ValueError
_____________ TestMemoryOptimization.test_memory_usage_data_types ______________

self = <test_memory_profiling.TestMemoryOptimization object at 0x7f58d45cd0>

    @pytest.mark.memory
    @pytest.mark.performance
    def test_memory_usage_data_types(self):
        """Test Speichernutzung verschiedener Datentypen."""
        process = psutil.Process(os.getpid())
    
        # Test verschiedene Datentypen
        data_types = [
            ("float32", np.float32),
            ("float64", np.float64),
            ("int32", np.int32),
            ("int64", np.int64),
        ]
    
        memory_usage = {}
    
        for dtype_name, dtype in data_types:
            memory_before = process.memory_info().rss / 1024 / 1024
    
            # Große Array mit spezifischem Datentyp
            array = np.random.randn(10000, 100).astype(dtype)
    
            memory_after = process.memory_info().rss / 1024 / 1024
            memory_usage[dtype_name] = memory_after - memory_before
    
        # float32 sollte weniger Speicher verwenden als float64
>       assert memory_usage["float32"] < memory_usage["float64"]
E       assert 7.50390625 < 7.50390625

tests/performance/test_memory_profiling.py:405: AssertionError
__________________ TestDataValidator.test_validate_valid_data __________________

self = <test_data_processing.TestDataValidator object at 0x7f58d611d0>
sample_wifi_data =               timestamp device_id  ...  packet_count  bytes_transferred
0   2024-01-01 00:00:00  device_3  ...        ...15         206.754596
999 2024-01-01 16:39:00  device_1  ...           103         554.365485

[1000 rows x 11 columns]

    def test_validate_valid_data(self, sample_wifi_data):
        """Test Validierung gültiger Daten."""
        validator = DataValidator()
        is_valid, errors = validator.validate(sample_wifi_data)
    
>       assert is_valid
E       assert False

tests/unit/test_data_processing.py:178: AssertionError
_____________________ TestClusteringModel.test_fit_kmeans ______________________

self = <test_ml_models.TestClusteringModel object at 0x7f58943890>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])

    def test_fit_kmeans(self, sample_features):
        """Test K-Means Clustering."""
        model = ClusteringModel(algorithm="kmeans", n_clusters=3)
>       model.fit(sample_features)

tests/unit/test_ml_models.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/clustering_model.py:53: in fit
    self.model = self._create_model()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.clustering_model.ClusteringModel object at 0x7f4cef89d0>
n_clusters = 3

    def _create_model(self, n_clusters: Optional[int] = None) -> Any:
        """Erstellt das Clustering-Modell."""
        if self.algorithm == 'kmeans':
            n_clusters = n_clusters or self.kwargs.get('n_clusters', 5)
>           return KMeans(n_clusters=n_clusters, random_state=42, **self.kwargs)
E           TypeError: sklearn.cluster._kmeans.KMeans() got multiple values for keyword argument 'n_clusters'

wlan_tool/ml_models/clustering_model.py:36: TypeError
__________________ TestClusteringModel.test_predict_after_fit __________________

self = <test_ml_models.TestClusteringModel object at 0x7f58950b10>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])

    def test_predict_after_fit(self, sample_features):
        """Test Vorhersage nach Training."""
        model = ClusteringModel(algorithm="kmeans", n_clusters=3)
>       model.fit(sample_features)

tests/unit/test_ml_models.py:52: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/clustering_model.py:53: in fit
    self.model = self._create_model()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.clustering_model.ClusteringModel object at 0x7f4cee94d0>
n_clusters = 3

    def _create_model(self, n_clusters: Optional[int] = None) -> Any:
        """Erstellt das Clustering-Modell."""
        if self.algorithm == 'kmeans':
            n_clusters = n_clusters or self.kwargs.get('n_clusters', 5)
>           return KMeans(n_clusters=n_clusters, random_state=42, **self.kwargs)
E           TypeError: sklearn.cluster._kmeans.KMeans() got multiple values for keyword argument 'n_clusters'

wlan_tool/ml_models/clustering_model.py:36: TypeError
_________________ TestClusteringModel.test_get_cluster_centers _________________

self = <test_ml_models.TestClusteringModel object at 0x7f58951250>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])

    def test_get_cluster_centers(self, sample_features):
        """Test Cluster-Zentren abrufen."""
        model = ClusteringModel(algorithm="kmeans", n_clusters=3)
>       model.fit(sample_features)

tests/unit/test_ml_models.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/clustering_model.py:53: in fit
    self.model = self._create_model()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.clustering_model.ClusteringModel object at 0x7f59e9a610>
n_clusters = 3

    def _create_model(self, n_clusters: Optional[int] = None) -> Any:
        """Erstellt das Clustering-Modell."""
        if self.algorithm == 'kmeans':
            n_clusters = n_clusters or self.kwargs.get('n_clusters', 5)
>           return KMeans(n_clusters=n_clusters, random_state=42, **self.kwargs)
E           TypeError: sklearn.cluster._kmeans.KMeans() got multiple values for keyword argument 'n_clusters'

wlan_tool/ml_models/clustering_model.py:36: TypeError
_________________ TestClusteringModel.test_evaluate_clustering _________________

self = <test_ml_models.TestClusteringModel object at 0x7f58951990>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])

    def test_evaluate_clustering(self, sample_features):
        """Test Clustering-Evaluation."""
        model = ClusteringModel(algorithm="kmeans", n_clusters=3)
>       model.fit(sample_features)

tests/unit/test_ml_models.py:73: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/clustering_model.py:53: in fit
    self.model = self._create_model()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.clustering_model.ClusteringModel object at 0x7f4cee9210>
n_clusters = 3

    def _create_model(self, n_clusters: Optional[int] = None) -> Any:
        """Erstellt das Clustering-Modell."""
        if self.algorithm == 'kmeans':
            n_clusters = n_clusters or self.kwargs.get('n_clusters', 5)
>           return KMeans(n_clusters=n_clusters, random_state=42, **self.kwargs)
E           TypeError: sklearn.cluster._kmeans.KMeans() got multiple values for keyword argument 'n_clusters'

wlan_tool/ml_models/clustering_model.py:36: TypeError
__________________ TestClusteringModel.test_invalid_algorithm __________________

self = <test_ml_models.TestClusteringModel object at 0x7f58943110>

    def test_invalid_algorithm(self):
        """Test mit ungültigem Algorithmus."""
>       with pytest.raises(ValueError, match="Unsupported algorithm"):
E       Failed: DID NOT RAISE <class 'ValueError'>

tests/unit/test_ml_models.py:86: Failed
______________ TestClusteringModel.test_hyperparameter_validation ______________

self = <test_ml_models.TestClusteringModel object at 0x7f58951e90>

    def test_hyperparameter_validation(self):
        """Test Hyperparameter-Validierung."""
        # Ungültige n_clusters
>       with pytest.raises(ValueError, match="n_clusters must be positive"):
E       Failed: DID NOT RAISE <class 'ValueError'>

tests/unit/test_ml_models.py:92: Failed
________________ TestClassificationModel.test_cross_validation _________________

self = <test_ml_models.TestClassificationModel object at 0x7f58964ed0>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
sample_labels = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])

    def test_cross_validation(self, sample_features, sample_labels):
        """Test Cross-Validation."""
        model = ClassificationModel(algorithm="random_forest", n_estimators=10)
    
>       cv_scores = model.cross_validate(sample_features, sample_labels, cv=3)

tests/unit/test_ml_models.py:177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f4ce5bd90>
X = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
y = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])
cv = 3

    def cross_validate(self, X: np.ndarray, y: np.ndarray, cv: int = 5) -> Dict[str, List[float]]:
        """Führt Cross-Validation durch."""
        if not self.is_fitted:
>           raise ValueError("Model must be fitted first")
E           ValueError: Model must be fitted first

wlan_tool/ml_models/classification_model.py:103: ValueError
_________________ TestEnsembleModel.test_fit_voting_classifier _________________

self = <test_ml_models.TestEnsembleModel object at 0x7f58966410>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
sample_labels = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])

    def test_fit_voting_classifier(self, sample_features, sample_labels):
        """Test Voting Classifier Training."""
        model = EnsembleModel(
            algorithm="voting",
            estimators=[
                ("rf", ClassificationModel(algorithm="random_forest")),
                ("svm", ClassificationModel(algorithm="svm")),
            ],
        )
>       model.fit(sample_features, sample_labels)

tests/unit/test_ml_models.py:215: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/ensemble_model.py:62: in fit
    self.model = self._create_model(estimators=estimators)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.ensemble_model.EnsembleModel object at 0x7f4ca2df90>
base_estimator = None
estimators = [('rf', <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f4ca2d590>), ('svm', <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f4ca2cb90>)]

    def _create_model(self, base_estimator=None, estimators=None) -> Any:
        """Erstellt das Ensemble-Modell."""
        if self.algorithm == 'voting':
            if estimators is None:
                raise ValueError("Voting requires estimators list")
>           return VotingClassifier(estimators=estimators, **self.kwargs)
E           TypeError: sklearn.ensemble._voting.VotingClassifier() got multiple values for keyword argument 'estimators'

wlan_tool/ml_models/ensemble_model.py:36: TypeError
______________________ TestEnsembleModel.test_fit_bagging ______________________

self = <test_ml_models.TestEnsembleModel object at 0x7f58966b10>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
sample_labels = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])

    def test_fit_bagging(self, sample_features, sample_labels):
        """Test Bagging Training."""
        model = EnsembleModel(
            algorithm="bagging",
            base_estimator=ClassificationModel(algorithm="random_forest"),
            n_estimators=5,
        )
>       model.fit(sample_features, sample_labels)

tests/unit/test_ml_models.py:227: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/ensemble_model.py:67: in fit
    self.model = self._create_model(base_estimator=base_estimator)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.ensemble_model.EnsembleModel object at 0x7f4ce59a50>
base_estimator = <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f4ce5b8d0>
estimators = None

    def _create_model(self, base_estimator=None, estimators=None) -> Any:
        """Erstellt das Ensemble-Modell."""
        if self.algorithm == 'voting':
            if estimators is None:
                raise ValueError("Voting requires estimators list")
            return VotingClassifier(estimators=estimators, **self.kwargs)
        elif self.algorithm == 'bagging':
            if base_estimator is None:
                raise ValueError("Bagging requires base_estimator")
>           return BaggingClassifier(base_estimator=base_estimator, **self.kwargs)
E           TypeError: sklearn.ensemble._bagging.BaggingClassifier() got multiple values for keyword argument 'base_estimator'

wlan_tool/ml_models/ensemble_model.py:40: TypeError
_____________________ TestEnsembleModel.test_fit_boosting ______________________

self = <test_ml_models.TestEnsembleModel object at 0x7f58967250>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
sample_labels = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])

    def test_fit_boosting(self, sample_features, sample_labels):
        """Test Boosting Training."""
        model = EnsembleModel(
            algorithm="boosting",
            base_estimator=ClassificationModel(algorithm="random_forest"),
            n_estimators=5,
        )
>       model.fit(sample_features, sample_labels)

tests/unit/test_ml_models.py:239: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/ensemble_model.py:67: in fit
    self.model = self._create_model(base_estimator=base_estimator)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.ensemble_model.EnsembleModel object at 0x7f4d7da010>
base_estimator = <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f4d7d8650>
estimators = None

    def _create_model(self, base_estimator=None, estimators=None) -> Any:
        """Erstellt das Ensemble-Modell."""
        if self.algorithm == 'voting':
            if estimators is None:
                raise ValueError("Voting requires estimators list")
            return VotingClassifier(estimators=estimators, **self.kwargs)
        elif self.algorithm == 'bagging':
            if base_estimator is None:
                raise ValueError("Bagging requires base_estimator")
            return BaggingClassifier(base_estimator=base_estimator, **self.kwargs)
        elif self.algorithm == 'boosting':
            if base_estimator is None:
                raise ValueError("Boosting requires base_estimator")
>           return AdaBoostClassifier(base_estimator=base_estimator, **self.kwargs)
E           TypeError: sklearn.ensemble._weight_boosting.AdaBoostClassifier() got multiple values for keyword argument 'base_estimator'

wlan_tool/ml_models/ensemble_model.py:44: TypeError
___________________ TestEnsembleModel.test_predict_ensemble ____________________

self = <test_ml_models.TestEnsembleModel object at 0x7f58967950>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
sample_labels = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])

    def test_predict_ensemble(self, sample_features, sample_labels):
        """Test Ensemble-Vorhersage."""
        model = EnsembleModel(
            algorithm="voting",
            estimators=[
                ("rf", ClassificationModel(algorithm="random_forest")),
                ("svm", ClassificationModel(algorithm="svm")),
            ],
        )
>       model.fit(sample_features, sample_labels)

tests/unit/test_ml_models.py:253: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/ensemble_model.py:62: in fit
    self.model = self._create_model(estimators=estimators)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.ensemble_model.EnsembleModel object at 0x7f4cdda8d0>
base_estimator = None
estimators = [('rf', <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f4cdd8bd0>), ('svm', <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f4cdd8ed0>)]

    def _create_model(self, base_estimator=None, estimators=None) -> Any:
        """Erstellt das Ensemble-Modell."""
        if self.algorithm == 'voting':
            if estimators is None:
                raise ValueError("Voting requires estimators list")
>           return VotingClassifier(estimators=estimators, **self.kwargs)
E           TypeError: sklearn.ensemble._voting.VotingClassifier() got multiple values for keyword argument 'estimators'

wlan_tool/ml_models/ensemble_model.py:36: TypeError
___________________ TestEnsembleModel.test_evaluate_ensemble ___________________

self = <test_ml_models.TestEnsembleModel object at 0x7f58968090>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
sample_labels = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])

    def test_evaluate_ensemble(self, sample_features, sample_labels):
        """Test Ensemble-Evaluation."""
        model = EnsembleModel(
            algorithm="voting",
            estimators=[
                ("rf", ClassificationModel(algorithm="random_forest")),
                ("svm", ClassificationModel(algorithm="svm")),
            ],
        )
>       model.fit(sample_features, sample_labels)

tests/unit/test_ml_models.py:269: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/ensemble_model.py:62: in fit
    self.model = self._create_model(estimators=estimators)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.ensemble_model.EnsembleModel object at 0x7f4ced6290>
base_estimator = None
estimators = [('rf', <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f4ced6250>), ('svm', <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f4ced42d0>)]

    def _create_model(self, base_estimator=None, estimators=None) -> Any:
        """Erstellt das Ensemble-Modell."""
        if self.algorithm == 'voting':
            if estimators is None:
                raise ValueError("Voting requires estimators list")
>           return VotingClassifier(estimators=estimators, **self.kwargs)
E           TypeError: sklearn.ensemble._voting.VotingClassifier() got multiple values for keyword argument 'estimators'

wlan_tool/ml_models/ensemble_model.py:36: TypeError
___________ TestEnsembleModel.test_individual_estimator_performance ____________

self = <test_ml_models.TestEnsembleModel object at 0x7f58968790>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
sample_labels = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])

    def test_individual_estimator_performance(self, sample_features, sample_labels):
        """Test Performance einzelner Estimators."""
        model = EnsembleModel(
            algorithm="voting",
            estimators=[
                ("rf", ClassificationModel(algorithm="random_forest")),
                ("svm", ClassificationModel(algorithm="svm")),
            ],
        )
>       model.fit(sample_features, sample_labels)

tests/unit/test_ml_models.py:287: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/ensemble_model.py:62: in fit
    self.model = self._create_model(estimators=estimators)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.ensemble_model.EnsembleModel object at 0x7f4d7d8c10>
base_estimator = None
estimators = [('rf', <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f4d7db490>), ('svm', <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f4d7da050>)]

    def _create_model(self, base_estimator=None, estimators=None) -> Any:
        """Erstellt das Ensemble-Modell."""
        if self.algorithm == 'voting':
            if estimators is None:
                raise ValueError("Voting requires estimators list")
>           return VotingClassifier(estimators=estimators, **self.kwargs)
E           TypeError: sklearn.ensemble._voting.VotingClassifier() got multiple values for keyword argument 'estimators'

wlan_tool/ml_models/ensemble_model.py:36: TypeError
___________________ TestEnsembleModel.test_invalid_algorithm ___________________

self = <test_ml_models.TestEnsembleModel object at 0x7f58968e50>

    def test_invalid_algorithm(self):
        """Test mit ungültigem Ensemble-Algorithmus."""
>       with pytest.raises(ValueError, match="Unsupported ensemble algorithm"):
E       Failed: DID NOT RAISE <class 'ValueError'>

tests/unit/test_ml_models.py:298: Failed
___________________ TestEnsembleModel.test_empty_estimators ____________________

self = <test_ml_models.TestEnsembleModel object at 0x7f58969510>

    def test_empty_estimators(self):
        """Test mit leerer Estimator-Liste."""
>       with pytest.raises(ValueError, match="At least one estimator required"):
E       Failed: DID NOT RAISE <class 'ValueError'>

tests/unit/test_ml_models.py:303: Failed
__________________ TestModelPersistence.test_save_load_model ___________________

self = <test_ml_models.TestModelPersistence object at 0x7f58966810>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
sample_labels = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])
temp_dir = PosixPath('/tmp/tmp0f9w1uyz')

    def test_save_load_model(self, sample_features, sample_labels, temp_dir):
        """Test Speichern und Laden von Modellen."""
        # Training
        model = ClassificationModel(algorithm="random_forest", n_estimators=10)
        model.fit(sample_features, sample_labels)
    
        # Speichern
        model_path = temp_dir / "test_model.pkl"
>       model.save(model_path)
E       AttributeError: 'ClassificationModel' object has no attribute 'save'

tests/unit/test_ml_models.py:318: AttributeError
_________________ TestModelPersistence.test_save_load_ensemble _________________

self = <test_ml_models.TestModelPersistence object at 0x7f58953610>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
sample_labels = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])
temp_dir = PosixPath('/tmp/tmppbfaok6u')

    def test_save_load_ensemble(self, sample_features, sample_labels, temp_dir):
        """Test Speichern und Laden von Ensemble-Modellen."""
        # Training
        model = EnsembleModel(
            algorithm="voting",
            estimators=[
                ("rf", ClassificationModel(algorithm="random_forest")),
                ("svm", ClassificationModel(algorithm="svm")),
            ],
        )
>       model.fit(sample_features, sample_labels)

tests/unit/test_ml_models.py:344: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/ensemble_model.py:62: in fit
    self.model = self._create_model(estimators=estimators)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.ensemble_model.EnsembleModel object at 0x7f4ceedc50>
base_estimator = None
estimators = [('rf', <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f4ceeed50>), ('svm', <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f4ceee010>)]

    def _create_model(self, base_estimator=None, estimators=None) -> Any:
        """Erstellt das Ensemble-Modell."""
        if self.algorithm == 'voting':
            if estimators is None:
                raise ValueError("Voting requires estimators list")
>           return VotingClassifier(estimators=estimators, **self.kwargs)
E           TypeError: sklearn.ensemble._voting.VotingClassifier() got multiple values for keyword argument 'estimators'

wlan_tool/ml_models/ensemble_model.py:36: TypeError
=============================== warnings summary ===============================
tests/conftest.py:12
  /home/pi/hacking/tests/conftest.py:12: DeprecationWarning: 
  Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),
  (to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)
  but was not found to be installed on your system.
  If this would cause problems for you,
  please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466
          
    import pandas as pd

pytest/test_integration.py:192
  /home/pi/hacking/pytest/test_integration.py:192: PytestUnknownMarkWarning: Unknown pytest.mark.network - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.network

plugins/clustering_advanced/tests/test_clustering_advanced.py::TestAdvancedClusteringPlugin::test_optics_clustering
  /home/pi/hacking/.venv/lib/python3.11/site-packages/sklearn/cluster/_optics.py:664: UserWarning: All reachability values are inf. Set a larger max_eps or all data will be considered outliers.
    warnings.warn(

plugins/clustering_advanced/tests/test_clustering_advanced.py::TestAdvancedClusteringPlugin::test_hdbscan_clustering
plugins/clustering_advanced/tests/test_clustering_advanced.py::TestAdvancedClusteringPlugin::test_hdbscan_clustering
  /home/pi/hacking/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.
    warnings.warn(

plugins/clustering_advanced/tests/test_clustering_advanced.py::TestAdvancedClusteringPlugin::test_plugin_run_with_sufficient_data
  /home/pi/hacking/.venv/lib/python3.11/site-packages/sklearn/cluster/_optics.py:664: UserWarning:
  
  All reachability values are inf. Set a larger max_eps or all data will be considered outliers.

plugins/clustering_advanced/tests/test_clustering_advanced.py::TestAdvancedClusteringPlugin::test_plugin_run_with_sufficient_data
plugins/clustering_advanced/tests/test_clustering_advanced.py::TestAdvancedClusteringPlugin::test_plugin_run_with_sufficient_data
  /home/pi/hacking/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:
  
  'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.

plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_model_performance_evaluation
  /home/pi/hacking/.venv/lib/python3.11/site-packages/sklearn/model_selection/_split.py:805: UserWarning:
  
  The least populated class in y has only 4 members, which is less than n_splits=5.

plugins/ensemble_models/tests/test_ensemble_models.py: 66 warnings
  /home/pi/hacking/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:451: DeprecationWarning:
  
  scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.

plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_model_performance_evaluation
plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_model_performance_evaluation
plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_model_performance_evaluation
plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_model_performance_evaluation
plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_model_performance_evaluation
plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_model_performance_evaluation
  /home/pi/hacking/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:
  
  lbfgs failed to converge (status=1):
  STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.
  
  Increase the number of iterations (max_iter) or scale the data as shown in:
      https://scikit-learn.org/stable/modules/preprocessing.html
  Please also refer to the documentation for alternative solver options:
      https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

plugins/ensemble_models/tests/test_ensemble_models.py: 40 warnings
  /home/pi/hacking/.venv/lib/python3.11/site-packages/sklearn/model_selection/_split.py:805: UserWarning:
  
  The least populated class in y has only 3 members, which is less than n_splits=5.

plugins/ensemble_models/tests/test_ensemble_models.py: 24 warnings
  /home/pi/hacking/.venv/lib/python3.11/site-packages/sklearn/model_selection/_split.py:805: UserWarning:
  
  The least populated class in y has only 2 members, which is less than n_splits=5.

pytest/test_capture.py::TestSniffingIntegration::test_sniff_with_writer_mock
  /home/pi/hacking/.venv/lib/python3.11/site-packages/_pytest/threadexception.py:77: PytestUnhandledThreadExceptionWarning:
  
  Exception in thread ChannelHopper
  
  Traceback (most recent call last):
    File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/threading.py", line 1045, in _bootstrap_inner
      self.run()
    File "/home/pi/hacking/wlan_tool/capture/sniffer.py", line 207, in run
      subprocess.run(command, check=True, capture_output=True, text=True)
    File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/subprocess.py", line 550, in run
      stdout, stderr = process.communicate(input, timeout=timeout)
      ^^^^^^^^^^^^^^
  ValueError: not enough values to unpack (expected 2, got 0)

tests/integration/test_end_to_end.py::TestEndToEndWorkflow::test_error_handling_and_recovery
  /home/pi/hacking/wlan_tool/data_processing/wifi_processor.py:45: UserWarning:
  
  Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html

-------------------------------------------------------------------------------------------------- benchmark: 9 tests --------------------------------------------------------------------------------------------------
Name (time in ms)                               Min                   Max                  Mean              StdDev                Median                 IQR            Outliers      OPS            Rounds  Iterations
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
test_file_io_performance                    22.7457 (1.0)        192.5190 (3.60)       138.9650 (2.62)      25.5245 (160.58)     134.6340 (2.54)      14.2307 (63.07)       14;11   7.1961 (0.38)         55           1
test_feature_extraction_performance         52.9147 (2.33)        53.4108 (1.0)         53.1087 (1.0)        0.1589 (1.0)         53.0918 (1.0)        0.2256 (1.0)           6;0  18.8293 (1.0)          16           1
test_data_processing_performance            61.7063 (2.71)       564.1093 (10.56)       92.1036 (1.73)     121.6350 (765.25)      62.2530 (1.17)       1.4630 (6.48)          1;1  10.8573 (0.58)         17           1
test_clustering_scalability                 90.1540 (3.96)       104.7145 (1.96)        97.3566 (1.83)       5.3066 (33.39)       98.2979 (1.85)      10.0916 (44.73)         6;0  10.2715 (0.55)         11           1
test_feature_scaling_performance           150.3077 (6.61)       152.8172 (2.86)       150.9212 (2.84)       1.0715 (6.74)       150.4787 (2.83)       0.9122 (4.04)          1;1   6.6260 (0.35)          5           1
test_parallel_processing_performance       183.4883 (8.07)       224.9166 (4.21)       203.5215 (3.83)      17.9388 (112.86)     203.6089 (3.84)      34.5718 (153.22)        3;0   4.9135 (0.26)          7           1
test_csv_io_performance                    328.3187 (14.43)      329.0878 (6.16)       328.5942 (6.19)       0.3450 (2.17)       328.4134 (6.19)       0.5646 (2.50)          1;0   3.0433 (0.16)          5           1
test_memory_usage_large_dataset            467.8356 (20.57)      842.2049 (15.77)      658.7405 (12.40)    153.7957 (967.59)     709.6061 (13.37)    247.2175 (>1000.0)       2;0   1.5180 (0.08)          5           1
test_random_forest_performance           8,122.9101 (357.12)   8,151.4984 (152.62)   8,141.0817 (153.29)    11.1508 (70.15)    8,142.4280 (153.36)    13.5373 (60.00)         1;0   0.1228 (0.01)          5           1
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Legend:
  Outliers: 1 Standard Deviation from Mean; 1.5 IQR (InterQuartile Range) from 1st Quartile and 3rd Quartile.
  OPS: Operations Per Second, computed as 1 / Mean
=========================== short test summary info ============================
FAILED plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_performance_visualization_creation
FAILED plugins/reinforcement_learning/tests/test_reinforcement_learning.py::TestReinforcementLearningPlugin::test_environment_observation
FAILED plugins/reinforcement_learning/tests/test_reinforcement_learning.py::TestReinforcementLearningPlugin::test_plugin_run_with_sufficient_data
FAILED plugins/reinforcement_learning/tests/test_reinforcement_learning.py::TestReinforcementLearningPlugin::test_plugin_run_without_pytorch
FAILED pytest/test_analysis.py::TestAnalysisLogic::test_profile_clusters - Ke...
FAILED pytest/test_analysis.py::TestAnalysisLogic::test_cluster_aps - ValueEr...
FAILED pytest/test_analysis.py::TestAnalysisLogic::test_profile_ap_clusters
FAILED pytest/test_analysis.py::TestDeviceProfiler::test_create_device_fingerprint_empty_state
FAILED pytest/test_analysis.py::TestGraphExport::test_build_export_graph - As...
FAILED pytest/test_analysis.py::TestGraphExport::test_discover_attributes - A...
FAILED pytest/test_analysis.py::TestAnalysisEdgeCases::test_single_client_analysis
FAILED pytest/test_analysis.py::TestAnalysisEdgeCases::test_malformed_event_handling
FAILED pytest/test_app.py::TestUtilsModule::test_intelligent_vendor_lookup - ...
FAILED pytest/test_app.py::TestAnalysisModule::test_features_for_client_behavior
FAILED pytest/test_app.py::TestAnalysisModule::test_cluster_clients_runs - At...
FAILED pytest/test_app.py::TestAnalysisModule::test_profile_clusters - Attrib...
FAILED pytest/test_capture.py::TestPacketParsing::test_packet_to_event_probe_request
FAILED pytest/test_capture.py::TestPacketParsing::test_packet_to_event_data_frame
FAILED pytest/test_capture.py::TestPacketParsing::test_packet_to_event_with_dhcp
FAILED pytest/test_capture.py::TestChannelHopper::test_channel_hopper_command_failure
FAILED pytest/test_capture.py::TestIEExtraction::test_extract_seq - assert 0 ...
FAILED pytest/test_capture.py::TestErrorHandling::test_packet_to_event_encoding_error
FAILED pytest/test_controllers.py::TestCaptureController::test_select_interface_automatic
FAILED pytest/test_controllers.py::TestCaptureController::test_select_interface_no_interfaces
FAILED pytest/test_controllers.py::TestCaptureController::test_setup_monitor_mode_failure
FAILED pytest/test_controllers.py::TestAnalysisController::test_analysis_controller_initialization
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_inference
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_client_clustering
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_ap_clustering
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_graph_export
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_labeling_ui
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_client_labeling_ui
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_mac_correlation
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_analysis_no_actions
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_analysis_multiple_actions
FAILED pytest/test_controllers.py::TestControllerEdgeCases::test_analysis_controller_empty_state
FAILED pytest/test_controllers.py::TestControllerEdgeCases::test_analysis_controller_with_plugins
FAILED pytest/test_controllers.py::TestControllerIntegration::test_full_analysis_workflow
FAILED pytest/test_error_handling.py::TestLoggingSystem::test_setup_logging
FAILED pytest/test_error_handling.py::TestDatabaseErrorHandling::test_database_connection_error
FAILED pytest/test_error_handling.py::TestDatabaseErrorHandling::test_database_migration_error
FAILED pytest/test_error_handling.py::TestAnalysisErrorHandling::test_client_features_null_state
FAILED pytest/test_error_handling.py::TestAnalysisErrorHandling::test_client_features_invalid_type
FAILED pytest/test_error_handling.py::TestAnalysisErrorHandling::test_clustering_invalid_parameters
FAILED pytest/test_error_handling.py::TestFileSystemErrorHandling::test_csv_export_invalid_path
FAILED pytest/test_error_handling.py::TestFileSystemErrorHandling::test_csv_export_missing_db
FAILED pytest/test_error_handling.py::TestErrorHandlingEdgeCases::test_nested_error_contexts
FAILED pytest/test_integration.py::TestEndToEndWorkflow::test_complete_analysis_pipeline
FAILED pytest/test_integration.py::TestEndToEndWorkflow::test_database_integration
FAILED pytest/test_integration.py::TestEndToEndWorkflow::test_config_integration
FAILED pytest/test_integration.py::TestDataFlow::test_state_persistence - wla...
FAILED pytest/test_integration.py::TestLargeDataset::test_large_dataset_processing
FAILED pytest/test_integration.py::TestErrorRecovery::test_malformed_event_handling
FAILED pytest/test_integration.py::TestMemoryManagement::test_memory_usage_large_state
FAILED pytest/test_integration.py::TestMemoryManagement::test_state_pruning_memory_release
FAILED pytest/test_performance.py::TestAnalysisPerformance::test_clustering_performance
FAILED pytest/test_performance.py::TestAnalysisPerformance::test_inference_performance
FAILED pytest/test_performance.py::TestMemoryPerformance::test_memory_usage_large_state
FAILED pytest/test_performance.py::TestMemoryPerformance::test_memory_cleanup_after_pruning
FAILED pytest/test_performance.py::TestDatabasePerformance::test_database_write_performance
FAILED pytest/test_performance.py::TestDatabasePerformance::test_database_read_performance
FAILED pytest/test_performance.py::TestScalabilityPerformance::test_scalability_with_dataset_size
FAILED pytest/test_presentation.py::TestCLIModule::test_print_client_cluster_results
FAILED pytest/test_presentation.py::TestCLIModule::test_print_ap_cluster_results
FAILED pytest/test_presentation.py::TestCLIEdgeCases::test_print_client_cluster_results_empty_data
FAILED pytest/test_presentation.py::TestPerformance::test_large_dataset_handling
FAILED pytest/test_storage.py::TestClientState::test_client_state_update_from_event
FAILED pytest/test_storage.py::TestAPState::test_ap_state_update_from_beacon
FAILED pytest/test_storage.py::TestWifiAnalysisState::test_state_pruning - As...
FAILED pytest/test_storage.py::TestWifiAnalysisState::test_state_ssid_mapping
FAILED pytest/test_storage.py::TestDatabaseModule::test_fetch_events - Attrib...
FAILED pytest/test_storage.py::TestDatabaseModule::test_add_label - Assertion...
FAILED pytest/test_utils.py::TestOUIFunctions::test_lookup_vendor_apple_mac
FAILED pytest/test_utils.py::TestOUIFunctions::test_lookup_vendor_unknown_mac
FAILED pytest/test_utils.py::TestIEParsing::test_parse_ies_vendor_specific - ...
FAILED pytest/test_utils.py::TestIEParsing::test_parse_ies_ht_capabilities - ...
FAILED pytest/test_utils.py::TestUtilityFunctions::test_is_local_admin_mac - ...
FAILED pytest/test_utils.py::TestUtilityFunctions::test_is_valid_bssid - Asse...
FAILED pytest/test_utils.py::TestUtilityFunctions::test_ie_fingerprint_hash
FAILED pytest/test_utils.py::TestUtilityFunctions::test_ie_fingerprint_hash_empty
FAILED pytest/test_utils.py::TestConfigFunctions::test_load_config_default - ...
FAILED pytest/test_utils.py::TestConfigFunctions::test_load_config_specific_profile
FAILED pytest/test_utils.py::TestConfigFunctions::test_load_config_missing_file
FAILED pytest/test_utils.py::TestEdgeCases::test_ie_fingerprint_hash_unicode
FAILED pytest/test_utils.py::TestEdgeCases::test_config_loading_with_invalid_yaml
FAILED tests/integration/test_end_to_end.py::TestEndToEndWorkflow::test_complete_wifi_analysis_workflow
FAILED tests/integration/test_end_to_end.py::TestEndToEndWorkflow::test_plugin_integration_workflow
FAILED tests/integration/test_end_to_end.py::TestEndToEndWorkflow::test_data_pipeline_with_file_io
FAILED tests/integration/test_end_to_end.py::TestEndToEndWorkflow::test_error_handling_and_recovery
FAILED tests/integration/test_end_to_end.py::TestEndToEndWorkflow::test_performance_under_load
FAILED tests/integration/test_end_to_end.py::TestEndToEndWorkflow::test_concurrent_processing
FAILED tests/performance/test_benchmarks.py::TestClusteringBenchmarks::test_kmeans_performance
FAILED tests/performance/test_benchmarks.py::TestClusteringBenchmarks::test_dbscan_performance
FAILED tests/performance/test_benchmarks.py::TestClusteringBenchmarks::test_hierarchical_performance
FAILED tests/performance/test_benchmarks.py::TestClusteringBenchmarks::test_clustering_scalability
FAILED tests/performance/test_benchmarks.py::TestDataProcessingBenchmarks::test_data_processing_performance
FAILED tests/performance/test_benchmarks.py::TestDataProcessingBenchmarks::test_feature_extraction_performance
FAILED tests/performance/test_benchmarks.py::TestDataProcessingBenchmarks::test_feature_scaling_performance
FAILED tests/performance/test_benchmarks.py::TestClassificationBenchmarks::test_random_forest_performance
FAILED tests/performance/test_benchmarks.py::TestClassificationBenchmarks::test_svm_performance
FAILED tests/performance/test_benchmarks.py::TestMemoryBenchmarks::test_memory_usage_clustering
FAILED tests/performance/test_benchmarks.py::TestMemoryBenchmarks::test_memory_usage_large_dataset
FAILED tests/performance/test_benchmarks.py::TestConcurrentBenchmarks::test_parallel_processing_performance
FAILED tests/performance/test_benchmarks.py::TestIOBenchmarks::test_file_io_performance
FAILED tests/performance/test_benchmarks.py::TestIOBenchmarks::test_csv_io_performance
FAILED tests/performance/test_memory_profiling.py::TestMemoryUsage::test_memory_usage_clustering
FAILED tests/performance/test_memory_profiling.py::TestMemoryProfiling::test_detailed_memory_profiling
FAILED tests/performance/test_memory_profiling.py::TestMemoryOptimization::test_memory_usage_data_types
FAILED tests/unit/test_data_processing.py::TestDataValidator::test_validate_valid_data
FAILED tests/unit/test_ml_models.py::TestClusteringModel::test_fit_kmeans - T...
FAILED tests/unit/test_ml_models.py::TestClusteringModel::test_predict_after_fit
FAILED tests/unit/test_ml_models.py::TestClusteringModel::test_get_cluster_centers
FAILED tests/unit/test_ml_models.py::TestClusteringModel::test_evaluate_clustering
FAILED tests/unit/test_ml_models.py::TestClusteringModel::test_invalid_algorithm
FAILED tests/unit/test_ml_models.py::TestClusteringModel::test_hyperparameter_validation
FAILED tests/unit/test_ml_models.py::TestClassificationModel::test_cross_validation
FAILED tests/unit/test_ml_models.py::TestEnsembleModel::test_fit_voting_classifier
FAILED tests/unit/test_ml_models.py::TestEnsembleModel::test_fit_bagging - Ty...
FAILED tests/unit/test_ml_models.py::TestEnsembleModel::test_fit_boosting - T...
FAILED tests/unit/test_ml_models.py::TestEnsembleModel::test_predict_ensemble
FAILED tests/unit/test_ml_models.py::TestEnsembleModel::test_evaluate_ensemble
FAILED tests/unit/test_ml_models.py::TestEnsembleModel::test_individual_estimator_performance
FAILED tests/unit/test_ml_models.py::TestEnsembleModel::test_invalid_algorithm
FAILED tests/unit/test_ml_models.py::TestEnsembleModel::test_empty_estimators
FAILED tests/unit/test_ml_models.py::TestModelPersistence::test_save_load_model
FAILED tests/unit/test_ml_models.py::TestModelPersistence::test_save_load_ensemble
========== 126 failed, 234 passed, 147 warnings in 941.40s (0:15:41) ===========
============================= test session starts ==============================
platform linux -- Python 3.11.9, pytest-8.2.0, pluggy-1.6.0
benchmark: 5.1.0 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)
rootdir: /home/pi/hacking
configfile: pytest.ini
plugins: xdist-3.8.0, hypothesis-6.142.1, cov-7.0.0, mock-3.12.0, html-4.1.1, benchmark-5.1.0, Faker-37.11.0, metadata-3.1.1, json-report-1.5.0
collected 360 items

plugins/clustering_advanced/tests/test_clustering_advanced.py .......... [  2%]
.....                                                                    [  4%]
plugins/ensemble_models/tests/test_ensemble_models.py ..........         [  6%]
plugins/example_plugin/tests/test_example_plugin.py ..                   [  7%]
plugins/reinforcement_learning/tests/test_reinforcement_learning.py .... [  8%]
.F............                                                           [ 12%]
plugins/sankey/tests/test_sankey.py ......                               [ 14%]
plugins/umap_plot/tests/test_umap_plot.py ........                       [ 16%]
pytest/test_analysis.py ..........................                       [ 23%]
pytest/test_app.py ..F...FFF..                                           [ 26%]
pytest/test_capture.py .FF..F....F......F.F.                             [ 32%]
pytest/test_controllers.py .FF..F...FFFFFFFFFF..FF.F                     [ 39%]
pytest/test_error_handling.py ......................F..FFFFFFF..F...     [ 50%]
pytest/test_integration.py .FF.FF..F..FF                                 [ 53%]
pytest/test_performance.py ....FFFFFF.F                                  [ 56%]
pytest/test_presentation.py F............F....F.                         [ 62%]
pytest/test_storage.py ......F..F....FF..FF...                           [ 68%]
pytest/test_utils.py F.F......FF..FFFF.FFF.....F.F                       [ 76%]
tests/integration/test_end_to_end.py FFFFFF                              [ 78%]
tests/performance/test_benchmarks.py FFFFFFFFFFFFFF                      [ 82%]
tests/performance/test_memory_profiling.py ..F...F.F..F                  [ 85%]
tests/unit/test_data_processing.py ................F.....                [ 91%]
tests/unit/test_ml_models.py .F..FFFFF.......F..FFFFFFFFFF               [100%]

=================================== FAILURES ===================================
_________ TestReinforcementLearningPlugin.test_environment_observation _________

self = <plugins.reinforcement_learning.tests.test_reinforcement_learning.TestReinforcementLearningPlugin object at 0x7f9339acd0>
plugin = <plugins.reinforcement_learning.plugin.Plugin object at 0x7f68e03cd0>
mock_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f68e01510>
mock_events = [{'client': 'aa:bb:cc:dd:ee:00', 'ts': 1000.0, 'type': 'probe_req'}, {'client': 'aa:bb:cc:dd:ee:01', 'ts': 1001.0, 'type': 'probe_req'}]

    def test_environment_observation(self, plugin, mock_state, mock_events):
        """Test Environment Observation."""
        env = plugin._WiFiScanningEnvironment(mock_state, mock_events)
        obs = env._get_observation()
    
        assert len(obs) == 10
        assert all(0 <= val <= 1 for val in obs)  # Normalisierte Werte
>       assert obs[0] == 1.0 / 48.0  # current_channel normalisiert
E       assert 0.020833334 == (1.0 / 48.0)

plugins/reinforcement_learning/tests/test_reinforcement_learning.py:141: AssertionError
________________ TestUtilsModule.test_intelligent_vendor_lookup ________________

self = <test_app.TestUtilsModule object at 0x7f712b8610>

    def test_intelligent_vendor_lookup(self):
>       assert "Apple" in utils.lookup_vendor("a8:51:ab:0c:b9:e9")
E       TypeError: argument of type 'NoneType' is not iterable

pytest/test_app.py:71: TypeError
_____________ TestAnalysisModule.test_features_for_client_behavior _____________

self = <test_app.TestAnalysisModule object at 0x7f71298f50>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f694d66d0>

    def test_features_for_client_behavior(self, populated_state):
        client = populated_state.clients['a8:51:ab:0c:b9:e9']
>       features = analysis.features_for_client_behavior(client)
E       AttributeError: module 'wlan_tool.analysis' has no attribute 'features_for_client_behavior'

pytest/test_app.py:108: AttributeError
_________________ TestAnalysisModule.test_cluster_clients_runs _________________

self = <test_app.TestAnalysisModule object at 0x7f71298ed0>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f68e99050>

    def test_cluster_clients_runs(self, populated_state):
>       clustered_df, feature_df = analysis.cluster_clients(populated_state, algo="kmeans", n_clusters=2)
E       AttributeError: module 'wlan_tool.analysis' has no attribute 'cluster_clients'

pytest/test_app.py:117: AttributeError
___________________ TestAnalysisModule.test_profile_clusters ___________________

self = <test_app.TestAnalysisModule object at 0x7f7129b250>

    def test_profile_clusters(self):
        feature_data = {'original_macs': ['mac1', 'mac2'], 'feature1': [10, 20], 'feature2': [1, 2]}
        feature_df = pd.DataFrame(feature_data)
        cluster_data = {'original_macs': ['mac1', 'mac2'], 'cluster': [0, 0]}
        clustered_df = pd.DataFrame(cluster_data)
>       profiles = analysis.profile_clusters(feature_df, clustered_df)
E       AttributeError: module 'wlan_tool.analysis' has no attribute 'profile_clusters'

pytest/test_app.py:128: AttributeError
_____________ TestPacketParsing.test_packet_to_event_probe_request _____________

self = <test_capture.TestPacketParsing object at 0x7f7128c150>

    def test_packet_to_event_probe_request(self):
        """Test Probe-Request-Paket zu Event-Konvertierung."""
        rt_layer = RadioTap(
            present="Flags+Channel+dBm_AntSignal",
            Flags="",
            ChannelFrequency=2412,
            dBm_AntSignal=-60
        )
        dot11_layer = Dot11(
            type=0, subtype=4,
            addr1='ff:ff:ff:ff:ff:ff',  # Broadcast
            addr2='aa:bb:cc:dd:ee:ff'   # Client
        )
        ssid_ie = Dot11Elt(
            ID=0,
            info=b'TestSSID'
        )
    
        pkt = rt_layer / dot11_layer / ssid_ie
        pkt.time = time.time()
    
        event = capture.packet_to_event(pkt)
    
        assert event is not None
        assert event['type'] == 'probe_req'
        assert event['client'] == 'aa:bb:cc:dd:ee:ff'
        assert event['rssi'] == -60
        # SSID wird als Hex-String gespeichert, dann dekodiert
>       assert 'TestSSID' in event['probes']
E       KeyError: 'probes'

pytest/test_capture.py:63: KeyError
______________ TestPacketParsing.test_packet_to_event_data_frame _______________

self = <test_capture.TestPacketParsing object at 0x7f7128cc50>

    def test_packet_to_event_data_frame(self):
        """Test Data-Frame zu Event-Konvertierung."""
>       rt_layer = RadioTap(
            present="Flags+Channel+dBm_AntSignal+MCS_index",
            Flags="",
            ChannelFrequency=2412,
            dBm_AntSignal=-55,
            MCS_index=7
        )

pytest/test_capture.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.11/site-packages/scapy/base_classes.py:399: in __call__
    i.__init__(*args, **kargs)
.venv/lib/python3.11/site-packages/scapy/packet.py:178: in __init__
    self.get_field(fname).any2i(self, value)
.venv/lib/python3.11/site-packages/scapy/fields.py:3052: in any2i
    return self._fixup_val(super(FlagsField, self).any2i(pkt, x))
.venv/lib/python3.11/site-packages/scapy/fields.py:3048: in _fixup_val
    return FlagValue(x, self.names)
.venv/lib/python3.11/site-packages/scapy/fields.py:2835: in __init__
    self.value = self._fixvalue(value)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'FlagValue' object has no attribute 'value'") raised in repr()] FlagValue object at 0x7f68f77fc0>
value = ['Flags', 'Channel', 'dBm_AntSignal', 'MCS_index']

    def _fixvalue(self, value):
        # type: (Any) -> int
        if not value:
            return 0
        if isinstance(value, six.string_types):
            value = value.split('+') if self.multi else list(value)
        if isinstance(value, list):
            y = 0
            for i in value:
>               y |= 1 << self.names.index(i)
E               ValueError: 'MCS_index' is not in list

.venv/lib/python3.11/site-packages/scapy/fields.py:2827: ValueError
_______________ TestPacketParsing.test_packet_to_event_with_dhcp _______________

self = <test_capture.TestPacketParsing object at 0x7f7128df90>

    def test_packet_to_event_with_dhcp(self):
        """Test Paket mit DHCP-Informationen."""
        from scapy.layers.dhcp import DHCP, BOOTP
    
        rt_layer = RadioTap(
            present="Flags+Channel+dBm_AntSignal",
            Flags="",
            ChannelFrequency=2412,
            dBm_AntSignal=-50
        )
        dot11_layer = Dot11(
            type=2, subtype=0,
            addr1='aa:bb:cc:dd:ee:ff',
            addr2='11:22:33:44:55:66'
        )
        bootp_layer = BOOTP(chaddr=b'\x11\x22\x33\x44\x55\x66')
        dhcp_layer = DHCP(options=[(53, 3), (12, b'TestHostname')])  # DHCP Request mit Hostname
    
        pkt = rt_layer / dot11_layer / bootp_layer / dhcp_layer
        pkt.time = time.time()
    
        event = capture.packet_to_event(pkt)
    
        assert event is not None
        assert event['type'] == 'data'
>       assert event['hostname'] == 'TestHostname'
E       KeyError: 'hostname'

pytest/test_capture.py:155: KeyError
____________ TestChannelHopper.test_channel_hopper_command_failure _____________

self = <test_capture.TestChannelHopper object at 0x7f712aa750>
mock_run = <MagicMock name='run' id='547230511568'>

    @patch('subprocess.run')
    def test_channel_hopper_command_failure(self, mock_run):
        """Test ChannelHopper bei Kommando-Fehlern."""
>       mock_run.side_effect = subprocess.CalledProcessError(1, "iw")
E       NameError: name 'subprocess' is not defined

pytest/test_capture.py:235: NameError
______________________ TestIEExtraction.test_extract_seq _______________________

self = <test_capture.TestIEExtraction object at 0x7f7129bed0>

    def test_extract_seq(self):
        """Test Sequenznummer-Extraktion."""
        dot11 = Dot11(SC=0x1234)  # SC = 0x1234, >> 4 = 0x123
    
        seq = capture._extract_seq(dot11)
        assert seq == 0x123
    
        # Test mit None
        seq = capture._extract_seq(None)
>       assert seq is None
E       assert 0 is None

pytest/test_capture.py:379: AssertionError
____________ TestErrorHandling.test_packet_to_event_encoding_error _____________

self = <test_capture.TestErrorHandling object at 0x7f712a8fd0>

    def test_packet_to_event_encoding_error(self):
        """Test mit Encoding-Fehlern."""
        rt_layer = RadioTap()
        dot11_layer = Dot11(type=0, subtype=8, addr3='aa:bb:cc:dd:ee:ff')
        beacon_layer = Dot11Beacon()
        # Erstelle IE mit ungültigem UTF-8
        ssid_ie = Dot11Elt(ID=0, info=b'\xff\xfe\xfd')
    
        pkt = rt_layer / dot11_layer / beacon_layer / ssid_ie
        pkt.time = time.time()
    
        # Sollte nicht crashen
        event = capture.packet_to_event(pkt)
        if event is not None:
>           assert event['ssid'] == "<binary>"  # Sollte als binary markiert werden
E           AssertionError: assert '<hidden>' == '<binary>'
E             
E             - <binary>
E             + <hidden>

pytest/test_capture.py:412: AssertionError
____________ TestCaptureController.test_select_interface_automatic _____________

self = <test_controllers.TestCaptureController object at 0x7f71476e10>
mock_find_interfaces = <MagicMock name='find_wlan_interfaces' id='547204626640'>
mock_console = <MagicMock id='547169660880'>

    @patch('wlan_tool.pre_run_checks.find_wlan_interfaces')
    def test_select_interface_automatic(self, mock_find_interfaces, mock_console):
        """Test automatische Interface-Auswahl."""
        mock_find_interfaces.return_value = ["wlan0", "wlan1"]
    
        args = MagicMock()
        args.iface = None
        config_data = {}
    
        controller = CaptureController(args, config_data, mock_console)
    
        with patch('rich.prompt.Prompt.ask', return_value="wlan0"):
>           iface = controller._select_interface()

pytest/test_controllers.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.controllers.CaptureController object at 0x7f67ef9fd0>

    def _select_interface(self) -> Optional[str]:
        """Wählt das zu verwendende physische WLAN-Interface aus."""
        iface = self.args.iface
        if not iface:
            self.console.print(
                "[bold cyan]Kein Interface angegeben. Suche nach geeigneten WLAN-Interfaces...[/bold cyan]"
            )
>           suitable_ifaces = pre_run_checks.find_wlan_interfaces()
E           NameError: name 'pre_run_checks' is not defined

wlan_tool/controllers.py:124: NameError
__________ TestCaptureController.test_select_interface_no_interfaces ___________

self = <test_controllers.TestCaptureController object at 0x7f71476a10>
mock_find_interfaces = <MagicMock name='find_wlan_interfaces' id='547204619152'>
mock_console = <MagicMock id='547169662352'>

    @patch('wlan_tool.pre_run_checks.find_wlan_interfaces')
    def test_select_interface_no_interfaces(self, mock_find_interfaces, mock_console):
        """Test Interface-Auswahl ohne verfügbare Interfaces."""
        mock_find_interfaces.return_value = []
    
        args = MagicMock()
        args.iface = None
        config_data = {}
    
        controller = CaptureController(args, config_data, mock_console)
    
>       iface = controller._select_interface()

pytest/test_controllers.py:57: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.controllers.CaptureController object at 0x7f67f0ca50>

    def _select_interface(self) -> Optional[str]:
        """Wählt das zu verwendende physische WLAN-Interface aus."""
        iface = self.args.iface
        if not iface:
            self.console.print(
                "[bold cyan]Kein Interface angegeben. Suche nach geeigneten WLAN-Interfaces...[/bold cyan]"
            )
>           suitable_ifaces = pre_run_checks.find_wlan_interfaces()
E           NameError: name 'pre_run_checks' is not defined

wlan_tool/controllers.py:124: NameError
____________ TestCaptureController.test_setup_monitor_mode_failure _____________

self = <test_controllers.TestCaptureController object at 0x7f7147fa90>
mock_run = <MagicMock name='run' id='547203951952'>
mock_console = <MagicMock id='547220127568'>

    @patch('subprocess.run')
    def test_setup_monitor_mode_failure(self, mock_run, mock_console):
        """Test Monitor-Mode-Setup (Fehler)."""
>       mock_run.side_effect = subprocess.CalledProcessError(1, "airmon-ng")
E       NameError: name 'subprocess' is not defined

pytest/test_controllers.py:89: NameError
________ TestAnalysisController.test_analysis_controller_initialization ________

self = <test_controllers.TestAnalysisController object at 0x7f7147d150>
mock_console = <MagicMock id='547203970896'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f67ee7410>

    def test_analysis_controller_initialization(self, mock_console, populated_state):
        """Test AnalysisController-Initialisierung."""
        args = MagicMock()
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
        assert controller.args == args
        assert controller.config_data == config_data
        assert controller.console == mock_console
        assert controller.plugins == plugins
>       assert controller.state == populated_state
E       AttributeError: 'AnalysisController' object has no attribute 'state'

pytest/test_controllers.py:201: AttributeError
__________________ TestAnalysisController.test_run_inference ___________________

self = <test_controllers.TestAnalysisController object at 0x7f7147d410>
mock_score = <MagicMock name='score_pairs_with_recency_and_matching' id='547203965776'>
mock_console = <MagicMock id='547203937616'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f67e5fc10>

    @patch('wlan_tool.analysis.logic.score_pairs_with_recency_and_matching')
    def test_run_inference(self, mock_score, mock_console, populated_state):
        """Test Inferenz-Ausführung."""
        mock_score.return_value = []
    
        args = MagicMock()
        args.infer = True
        args.model = None
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       controller.run_inference()
E       AttributeError: 'AnalysisController' object has no attribute 'run_inference'

pytest/test_controllers.py:218: AttributeError
______________ TestAnalysisController.test_run_client_clustering _______________

self = <test_controllers.TestAnalysisController object at 0x7f7147ce50>
mock_cluster = <MagicMock name='cluster_clients' id='547203997264'>
mock_console = <MagicMock id='547204262288'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f67e64a90>

    @patch('wlan_tool.analysis.logic.cluster_clients')
    def test_run_client_clustering(self, mock_cluster, mock_console, populated_state):
        """Test Client-Clustering."""
        mock_cluster.return_value = (None, None)
    
        args = MagicMock()
        args.cluster_clients = 2
        args.cluster_algo = "kmeans"
        args.no_mac_correlation = False
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       controller.run_client_clustering()
E       AttributeError: 'AnalysisController' object has no attribute 'run_client_clustering'

pytest/test_controllers.py:237: AttributeError
________________ TestAnalysisController.test_run_ap_clustering _________________

self = <test_controllers.TestAnalysisController object at 0x7f7147db50>
mock_cluster = <MagicMock name='cluster_aps' id='547204493840'>
mock_console = <MagicMock id='547204176016'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f67edfc10>

    @patch('wlan_tool.analysis.logic.cluster_aps')
    def test_run_ap_clustering(self, mock_cluster, mock_console, populated_state):
        """Test AP-Clustering."""
        mock_cluster.return_value = None
    
        args = MagicMock()
        args.cluster_aps = 2
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       controller.run_ap_clustering()
E       AttributeError: 'AnalysisController' object has no attribute 'run_ap_clustering'

pytest/test_controllers.py:254: AttributeError
_________________ TestAnalysisController.test_run_graph_export _________________

self = <test_controllers.TestAnalysisController object at 0x7f7147ea90>
mock_export = <MagicMock name='export_ap_graph' id='547205548752'>
mock_console = <MagicMock id='547205683600'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f67fe1410>

    @patch('wlan_tool.analysis.logic.export_ap_graph')
    def test_run_graph_export(self, mock_export, mock_console, populated_state):
        """Test Graph-Export."""
        mock_export.return_value = True
    
        args = MagicMock()
        args.export_graph = "/tmp/test.gexf"
        args.cluster_aps = 2
        args.graph_include_clients = False
        args.graph_min_activity = 0
        args.graph_min_duration = 0
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       with patch.object(controller, 'run_ap_clustering', return_value=None):

pytest/test_controllers.py:275: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f67e6e0d0>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <wlan_tool.controllers.AnalysisController object at 0x7f67fe0210> does not have the attribute 'run_ap_clustering'

../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1419: AttributeError
_________________ TestAnalysisController.test_run_labeling_ui __________________

self = <test_controllers.TestAnalysisController object at 0x7f7147e890>
mock_label_ui = <MagicMock name='interactive_label_ui' id='547204177616'>
mock_console = <MagicMock id='547205678480'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f67f0af10>

    @patch('wlan_tool.presentation.cli.interactive_label_ui')
    def test_run_labeling_ui(self, mock_label_ui, mock_console, populated_state):
        """Test Labeling-UI."""
        args = MagicMock()
        args.label_ui = True
        args.db = "test.db"
        args.label_db = "labels.db"
        args.model = "model.pkl"
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       controller.run_labeling_ui()
E       AttributeError: 'AnalysisController' object has no attribute 'run_labeling_ui'

pytest/test_controllers.py:294: AttributeError
______________ TestAnalysisController.test_run_client_labeling_ui ______________

self = <test_controllers.TestAnalysisController object at 0x7f7147ed10>
mock_client_label_ui = <MagicMock name='interactive_client_label_ui' id='547204206288'>
mock_console = <MagicMock id='547204488784'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f67e98c10>

    @patch('wlan_tool.presentation.cli.interactive_client_label_ui')
    def test_run_client_labeling_ui(self, mock_client_label_ui, mock_console, populated_state):
        """Test Client-Labeling-UI."""
        args = MagicMock()
        args.label_clients = True
        args.label_db = "labels.db"
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       controller.run_client_labeling_ui()
E       AttributeError: 'AnalysisController' object has no attribute 'run_client_labeling_ui'

pytest/test_controllers.py:310: AttributeError
_______________ TestAnalysisController.test_run_mac_correlation ________________

self = <test_controllers.TestAnalysisController object at 0x7f7147eed0>
mock_correlate = <MagicMock name='correlate_devices_by_fingerprint' id='547204178832'>
mock_console = <MagicMock id='547204146064'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f67e91090>

    @patch('wlan_tool.analysis.device_profiler.correlate_devices_by_fingerprint')
    def test_run_mac_correlation(self, mock_correlate, mock_console, populated_state):
        """Test MAC-Korrelation."""
        mock_correlate.return_value = {}
    
        args = MagicMock()
        args.correlate_macs = True
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       controller.run_mac_correlation()
E       AttributeError: 'AnalysisController' object has no attribute 'run_mac_correlation'

pytest/test_controllers.py:327: AttributeError
_____________ TestAnalysisController.test_run_analysis_no_actions ______________

self = <test_controllers.TestAnalysisController object at 0x7f7147f410>
mock_console = <MagicMock id='547204674448'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f67e4a390>

    def test_run_analysis_no_actions(self, mock_console, populated_state):
        """Test Analyse ohne Aktionen."""
        args = MagicMock()
        args.infer = False
        args.cluster_clients = None
        args.cluster_aps = None
        args.export_graph = None
        args.label_ui = False
        args.label_clients = False
        args.correlate_macs = False
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
        # Sollte nicht crashen
>       controller.run_analysis()

pytest/test_controllers.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/controllers.py:339: in run_analysis
    self._run_profiling()  # Benötigt state, den es jetzt als self.state hat
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.controllers.AnalysisController object at 0x7f67e48710>

    def _run_profiling(self):
        self.console.print(
            "\n[bold cyan]Starte automatisches Geräte-Profiling...[/bold cyan]"
        )
        device_map = {}
    
        # --- NEU: Versuch 1: TR-064 (FRITZ!Box) ---
        self.console.print(
            "[cyan]Versuch 1: Identifizierung über FRITZ!Box TR-064...[/cyan]"
        )
        # Passwort aus Argumenten oder interaktiv abfragen
        fritz_password = self.args.fritzbox_password
        if FritzHosts and not fritz_password:
            if (
                self.console.input(
                    "Haben Sie ein Passwort für Ihre FRITZ!Box gesetzt? (y/n): "
                ).lower()
                == "y"
            ):
                fritz_password = self.console.input(
                    "Bitte FRITZ!Box-Passwort eingeben: ", password=True
                )
    
        device_map = (
>           device_profiler.get_devices_from_fritzbox_tr064(password=fritz_password)
            or {}
        )
E       NameError: name 'device_profiler' is not defined

wlan_tool/controllers.py:487: NameError
__________ TestAnalysisController.test_run_analysis_multiple_actions ___________

self = <test_controllers.TestAnalysisController object at 0x7f71454110>
mock_console = <MagicMock id='547205810960'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f6800e450>

    def test_run_analysis_multiple_actions(self, mock_console, populated_state):
        """Test Analyse mit mehreren Aktionen."""
        args = MagicMock()
        args.infer = True
        args.cluster_clients = 2
        args.cluster_aps = 2
        args.export_graph = "/tmp/test.gexf"
        args.label_ui = False
        args.label_clients = False
        args.correlate_macs = False
        args.model = None
        args.cluster_algo = "kmeans"
        args.no_mac_correlation = False
        args.graph_include_clients = False
        args.graph_min_activity = 0
        args.graph_min_duration = 0
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       with patch.object(controller, 'run_inference'):

pytest/test_controllers.py:372: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f6800ebd0>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <wlan_tool.controllers.AnalysisController object at 0x7f6800ec50> does not have the attribute 'run_inference'

../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1419: AttributeError
_________ TestControllerEdgeCases.test_analysis_controller_empty_state _________

self = <test_controllers.TestControllerEdgeCases object at 0x7f71455790>
mock_console = <MagicMock id='547229050384'>

    def test_analysis_controller_empty_state(self, mock_console):
        """Test AnalysisController mit leerem State."""
        args = MagicMock()
        args.infer = True
        args.model = None
        config_data = {}
        plugins = {}
        new_events = []
        empty_state = WifiAnalysisState()
    
        controller = AnalysisController(args, config_data, mock_console, plugins, empty_state, new_events)
    
        # Sollte nicht crashen
>       controller.run_inference()
E       AttributeError: 'AnalysisController' object has no attribute 'run_inference'

pytest/test_controllers.py:420: AttributeError
________ TestControllerEdgeCases.test_analysis_controller_with_plugins _________

self = <test_controllers.TestControllerEdgeCases object at 0x7f71455e90>
mock_console = <MagicMock id='547934951440'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f93827cd0>

    def test_analysis_controller_with_plugins(self, mock_console, populated_state):
        """Test AnalysisController mit Plugins."""
        args = MagicMock()
        args.run_plugins = ["test_plugin"]
        config_data = {}
    
        mock_plugin = MagicMock()
        mock_plugin.run.return_value = None
        plugins = {"test_plugin": mock_plugin}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       controller.run_plugins()
E       AttributeError: 'AnalysisController' object has no attribute 'run_plugins'

pytest/test_controllers.py:435: AttributeError
____________ TestControllerIntegration.test_full_analysis_workflow _____________

self = <test_controllers.TestControllerIntegration object at 0x7f714572d0>
mock_console = <MagicMock id='547935523280'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f9377f510>

    def test_full_analysis_workflow(self, mock_console, populated_state):
        """Test vollständiger Analyse-Workflow."""
        args = MagicMock()
        args.infer = True
        args.cluster_clients = 2
        args.cluster_aps = 2
        args.export_graph = "/tmp/test.gexf"
        args.label_ui = False
        args.label_clients = False
        args.correlate_macs = False
        args.model = None
        args.cluster_algo = "kmeans"
        args.no_mac_correlation = False
        args.graph_include_clients = False
        args.graph_min_activity = 0
        args.graph_min_duration = 0
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       with patch.object(controller, 'run_inference'):

pytest/test_controllers.py:491: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f9377ed10>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <wlan_tool.controllers.AnalysisController object at 0x7f67e62510> does not have the attribute 'run_inference'

../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1419: AttributeError
_____________________ TestLoggingSystem.test_setup_logging _____________________

self = <test_error_handling.TestLoggingSystem object at 0x7f7142f050>

    def test_setup_logging(self):
        """Test Logging-Setup."""
        logger = setup_logging(
            log_level="DEBUG",
            enable_console=True,
            enable_performance_logging=True,
            enable_error_tracking=True
        )
    
        assert logger is not None
        assert logger.name == "wlan_tool"
>       assert logger.level == logging.DEBUG
E       NameError: name 'logging' is not defined

pytest/test_error_handling.py:317: NameError
___________ TestDatabaseErrorHandling.test_database_connection_error ___________

self = <test_error_handling.TestDatabaseErrorHandling object at 0x7f7142c310>

    def test_database_connection_error(self):
        """Test Datenbankverbindungs-Fehler."""
        with pytest.raises(DatabaseError) as exc_info:
            from wlan_tool.storage.database import db_conn_ctx
            with db_conn_ctx("/invalid/path/database.db"):
                pass
    
        assert "Cannot create database directory" in str(exc_info.value)
>       assert exc_info.value.error_code == "SQLITE_ERROR"
E       AssertionError: assert 'DB_UNEXPECTED_ERROR' == 'SQLITE_ERROR'
E         
E         - SQLITE_ERROR
E         + DB_UNEXPECTED_ERROR

pytest/test_error_handling.py:345: AssertionError
----------------------------- Captured stdout call -----------------------------
2025-10-19 12:55:48,637 | DEBUG    | Starting operation: database_connection
2025-10-19 12:55:48,638 | ERROR    | Error in database_connection: WLANToolError: Cannot create database directory: /invalid/path (Code: DB_DIR_CREATION_FAILED) | Details: {'directory': '/invalid/path', 'original_error': "[Errno 13] Permission denied: '/invalid'"} (Code: DB_DIR_CREATION_FAILED) | Details: {'directory': '/invalid/path', 'original_error': "[Errno 13] Permission denied: '/invalid'"}
2025-10-19 12:55:48,644 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/pathlib.py", line 1116, in mkdir
    os.mkdir(self, mode)
FileNotFoundError: [Errno 2] No such file or directory: '/invalid/path'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 81, in db_conn_ctx
    db_dir.mkdir(parents=True, exist_ok=True)
  File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/pathlib.py", line 1120, in mkdir
    self.parent.mkdir(parents=True, exist_ok=True)
  File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/pathlib.py", line 1116, in mkdir
    os.mkdir(self, mode)
PermissionError: [Errno 13] Permission denied: '/invalid'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 83, in db_conn_ctx
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Cannot create database directory: /invalid/path (Code: DB_DIR_CREATION_FAILED) | Details: {'directory': '/invalid/path', 'original_error': "[Errno 13] Permission denied: '/invalid'"}

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in database_connection: WLANToolError: Cannot create database directory: /invalid/path (Code: DB_DIR_CREATION_FAILED) | Details: {'directory': '/invalid/path', 'original_error': "[Errno 13] Permission denied: '/invalid'"} (Code: DB_DIR_CREATION_FAILED) | Details: {'directory': '/invalid/path', 'original_error': "[Errno 13] Permission denied: '/invalid'"}
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/pathlib.py", line 1116, in mkdir
    os.mkdir(self, mode)
FileNotFoundError: [Errno 2] No such file or directory: '/invalid/path'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 81, in db_conn_ctx
    db_dir.mkdir(parents=True, exist_ok=True)
  File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/pathlib.py", line 1120, in mkdir
    self.parent.mkdir(parents=True, exist_ok=True)
  File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/pathlib.py", line 1116, in mkdir
    os.mkdir(self, mode)
PermissionError: [Errno 13] Permission denied: '/invalid'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 83, in db_conn_ctx
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Cannot create database directory: /invalid/path (Code: DB_DIR_CREATION_FAILED) | Details: {'directory': '/invalid/path', 'original_error': "[Errno 13] Permission denied: '/invalid'"}
___________ TestDatabaseErrorHandling.test_database_migration_error ____________

self = <test_error_handling.TestDatabaseErrorHandling object at 0x7f7142c490>

    def test_database_migration_error(self):
        """Test Datenbankmigrations-Fehler."""
        with tempfile.NamedTemporaryFile(suffix='.db', delete=False) as f:
            db_path = f.name
    
        try:
            # Erstelle ungültige Migration
            migrations_dir = Path("wlan_tool/assets/sql_data/versions")
            migrations_dir.mkdir(parents=True, exist_ok=True)
    
            invalid_migration = migrations_dir / "999_invalid.sql"
            invalid_migration.write_text("INVALID SQL SYNTAX")
    
>           with pytest.raises(DatabaseError):
E           Failed: DID NOT RAISE <class 'wlan_tool.exceptions.DatabaseError'>

pytest/test_error_handling.py:360: Failed
----------------------------- Captured stdout call -----------------------------
2025-10-19 12:55:48,689 | DEBUG    | Starting operation: database_migration
2025-10-19 12:55:48,690 | DEBUG    | Starting operation: database_connection
2025-10-19 12:55:48,709 | INFO     | Current DB version: 0. Looking for migrations...
2025-10-19 12:55:48,710 | INFO     | Applying migration: 001_initial_schema.sql (Version 1)
2025-10-19 12:55:48,718 | INFO     | DB successfully migrated to version 1
2025-10-19 12:55:48,719 | INFO     | Applying migration: 002_add_dns_table.sql (Version 2)
2025-10-19 12:55:48,720 | INFO     | DB successfully migrated to version 2
2025-10-19 12:55:48,720 | INFO     | Applying migration: 003_add_network_info.sql (Version 3)
2025-10-19 12:55:48,722 | INFO     | DB successfully migrated to version 3
2025-10-19 12:55:48,722 | INFO     | Applying migration: 004_add_indexes.sql (Version 4)
2025-10-19 12:55:48,724 | INFO     | DB successfully migrated to version 4
2025-10-19 12:55:48,724 | INFO     | Applying migration: 999_invalid.sql (Version 999)
2025-10-19 12:55:48,724 | ERROR    | Unexpected error during migration 999_invalid.sql: WLANToolError: Migration failed: 999_invalid.sql (Code: MIGRATION_EXECUTION_FAILED) | Details: {'migration_file': '999_invalid.sql', 'version': 999, 'sqlite_error': 'near "INVALID": syntax error'}
2025-10-19 12:55:48,746 | INFO     | Database is up to date.
------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_migration
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
INFO     wlan_tool.storage.database:database.py:157 Current DB version: 0. Looking for migrations...
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 001_initial_schema.sql (Version 1)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 1
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 002_add_dns_table.sql (Version 2)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 2
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 003_add_network_info.sql (Version 3)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 3
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 004_add_indexes.sql (Version 4)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 4
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 999_invalid.sql (Version 999)
ERROR    wlan_tool.storage.database:database.py:199 Unexpected error during migration 999_invalid.sql: WLANToolError: Migration failed: 999_invalid.sql (Code: MIGRATION_EXECUTION_FAILED) | Details: {'migration_file': '999_invalid.sql', 'version': 999, 'sqlite_error': 'near "INVALID": syntax error'}
INFO     wlan_tool.storage.database:database.py:204 Database is up to date.
__________ TestAnalysisErrorHandling.test_client_features_null_state ___________

self = <test_error_handling.TestAnalysisErrorHandling object at 0x7f7142ce10>

    def test_client_features_null_state(self):
        """Test Client-Features mit None-State."""
        from wlan_tool.analysis.logic import features_for_client
    
>       with pytest.raises(ValidationError) as exc_info:
E       Failed: DID NOT RAISE <class 'wlan_tool.exceptions.ValidationError'>

pytest/test_error_handling.py:377: Failed
----------------------------- Captured stdout call -----------------------------
2025-10-19 12:55:48,777 | DEBUG    | Starting operation: client_features_extraction
2025-10-19 12:55:48,777 | ERROR    | Error in client_features_extraction: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'} (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}
2025-10-19 12:55:48,778 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 229, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}

2025-10-19 12:55:48,778 | ERROR    | Unexpected error in features_for_client: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}
2025-10-19 12:55:48,779 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 229, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_features_extraction
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in client_features_extraction: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'} (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 229, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}

ERROR    wlan_tool.analysis.logic:exceptions.py:165 Unexpected error in features_for_client: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}
DEBUG    wlan_tool.analysis.logic:exceptions.py:166 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 229, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}
_________ TestAnalysisErrorHandling.test_client_features_invalid_type __________

self = <test_error_handling.TestAnalysisErrorHandling object at 0x7f7142c910>

    def test_client_features_invalid_type(self):
        """Test Client-Features mit ungültigem Typ."""
        from wlan_tool.analysis.logic import features_for_client
    
>       with pytest.raises(ValidationError) as exc_info:
E       Failed: DID NOT RAISE <class 'wlan_tool.exceptions.ValidationError'>

pytest/test_error_handling.py:387: Failed
----------------------------- Captured stdout call -----------------------------
2025-10-19 12:55:48,809 | DEBUG    | Starting operation: client_features_extraction
2025-10-19 12:55:48,810 | ERROR    | Error in client_features_extraction: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"} (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}
2025-10-19 12:55:48,810 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 236, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}

2025-10-19 12:55:48,811 | ERROR    | Unexpected error in features_for_client: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}
2025-10-19 12:55:48,811 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 236, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_features_extraction
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in client_features_extraction: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"} (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 236, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}

ERROR    wlan_tool.analysis.logic:exceptions.py:165 Unexpected error in features_for_client: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}
DEBUG    wlan_tool.analysis.logic:exceptions.py:166 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 236, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}
_________ TestAnalysisErrorHandling.test_clustering_invalid_parameters _________

self = <test_error_handling.TestAnalysisErrorHandling object at 0x7f71654990>

    def test_clustering_invalid_parameters(self):
        """Test Clustering mit ungültigen Parametern."""
        from wlan_tool.analysis.logic import cluster_clients
        from wlan_tool.storage.state import WifiAnalysisState
    
        state = WifiAnalysisState()
    
        # Teste ungültige n_clusters
>       with pytest.raises(ValidationError) as exc_info:
E       Failed: DID NOT RAISE <class 'wlan_tool.exceptions.ValidationError'>

pytest/test_error_handling.py:401: Failed
----------------------------- Captured stdout call -----------------------------
2025-10-19 12:55:48,840 | DEBUG    | Starting operation: client_clustering
2025-10-19 12:55:48,841 | ERROR    | Error in client_clustering: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0} (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}
2025-10-19 12:55:48,841 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 495, in cluster_clients
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}

2025-10-19 12:55:48,842 | ERROR    | Unexpected error in cluster_clients: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}
2025-10-19 12:55:48,842 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 495, in cluster_clients
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_clustering
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in client_clustering: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0} (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 495, in cluster_clients
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}

ERROR    wlan_tool.analysis.logic:exceptions.py:165 Unexpected error in cluster_clients: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}
DEBUG    wlan_tool.analysis.logic:exceptions.py:166 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 495, in cluster_clients
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}
___________ TestFileSystemErrorHandling.test_csv_export_invalid_path ___________

self = <test_error_handling.TestFileSystemErrorHandling object at 0x7f71655c10>

    def test_csv_export_invalid_path(self):
        """Test CSV-Export mit ungültigem Pfad."""
        from wlan_tool.storage.database import export_confirmed_to_csv
    
>       with pytest.raises(ValidationError) as exc_info:
E       Failed: DID NOT RAISE <class 'wlan_tool.exceptions.ValidationError'>

pytest/test_error_handling.py:422: Failed
----------------------------- Captured stdout call -----------------------------
2025-10-19 12:55:48,872 | DEBUG    | Starting operation: csv_export
2025-10-19 12:55:48,872 | ERROR    | Error in csv_export: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''} (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}
2025-10-19 12:55:48,873 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}

2025-10-19 12:55:48,873 | ERROR    | Error in export_confirmed_to_csv: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}
2025-10-19 12:55:48,874 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: csv_export
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in csv_export: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''} (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}

ERROR    wlan_tool.storage.database:exceptions.py:153 Error in export_confirmed_to_csv: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}
DEBUG    wlan_tool.storage.database:exceptions.py:154 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}
____________ TestFileSystemErrorHandling.test_csv_export_missing_db ____________

self = <test_error_handling.TestFileSystemErrorHandling object at 0x7f71656010>

    def test_csv_export_missing_db(self):
        """Test CSV-Export mit fehlender Datenbank."""
        from wlan_tool.storage.database import export_confirmed_to_csv
    
>       with pytest.raises(FileSystemError) as exc_info:
E       Failed: DID NOT RAISE <class 'wlan_tool.exceptions.FileSystemError'>

pytest/test_error_handling.py:432: Failed
----------------------------- Captured stdout call -----------------------------
2025-10-19 12:55:48,904 | DEBUG    | Starting operation: csv_export
2025-10-19 12:55:48,905 | ERROR    | Error in csv_export: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'} (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}
2025-10-19 12:55:48,905 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}

2025-10-19 12:55:48,906 | ERROR    | Error in export_confirmed_to_csv: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}
2025-10-19 12:55:48,906 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: csv_export
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in csv_export: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'} (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}

ERROR    wlan_tool.storage.database:exceptions.py:153 Error in export_confirmed_to_csv: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}
DEBUG    wlan_tool.storage.database:exceptions.py:154 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}
____________ TestErrorHandlingEdgeCases.test_nested_error_contexts _____________

self = <test_error_handling.TestErrorHandlingEdgeCases object at 0x7f71656750>

    def test_nested_error_contexts(self):
        """Test verschachtelte Error-Contexts."""
        with ErrorContext("outer_operation", "OUTER_ERROR") as outer:
            with ErrorContext("inner_operation", "INNER_ERROR") as inner:
>               raise ValueError("Inner error")
E               ValueError: Inner error

pytest/test_error_handling.py:473: ValueError

The above exception was the direct cause of the following exception:

self = <test_error_handling.TestErrorHandlingEdgeCases object at 0x7f71656750>

    def test_nested_error_contexts(self):
        """Test verschachtelte Error-Contexts."""
        with ErrorContext("outer_operation", "OUTER_ERROR") as outer:
>           with ErrorContext("inner_operation", "INNER_ERROR") as inner:

pytest/test_error_handling.py:472: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.exceptions.ErrorContext object at 0x7f704a0650>
exc_type = <class 'ValueError'>, exc_val = ValueError('Inner error')
exc_tb = <traceback object at 0x7f704a0980>

    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type is not None:
            error_msg = f"Error in {self.operation}: {exc_val}"
    
            if isinstance(exc_val, WLANToolError):
                error_msg += f" (Code: {exc_val.error_code})"
                if exc_val.details:
                    error_msg += f" | Details: {exc_val.details}"
            else:
                error_msg += f" | Type: {exc_type.__name__}"
    
            self.logger.log(self.log_level, error_msg)
            self.logger.debug(f"Traceback: {traceback.format_exc()}")
    
            # Konvertiere zu WLANToolError falls nötig
            if not isinstance(exc_val, WLANToolError):
                wlan_error = WLANToolError(
                    message=str(exc_val),
                    error_code=self.error_code or "CONTEXT_ERROR",
                    details={
                        "operation": self.operation,
                        "original_type": exc_type.__name__,
                    },
                )
>               raise wlan_error from exc_val
E               wlan_tool.exceptions.WLANToolError: WLANToolError: Inner error (Code: INNER_ERROR) | Details: {'operation': 'inner_operation', 'original_type': 'ValueError'}

wlan_tool/exceptions.py:313: WLANToolError
----------------------------- Captured stdout call -----------------------------
2025-10-19 12:55:49,944 | DEBUG    | Starting operation: outer_operation
2025-10-19 12:55:49,944 | DEBUG    | Starting operation: inner_operation
2025-10-19 12:55:49,944 | ERROR    | Error in inner_operation: Inner error | Type: ValueError
2025-10-19 12:55:49,945 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/pytest/test_error_handling.py", line 473, in test_nested_error_contexts
    raise ValueError("Inner error")
ValueError: Inner error

2025-10-19 12:55:49,945 | ERROR    | Error in outer_operation: WLANToolError: Inner error (Code: INNER_ERROR) | Details: {'operation': 'inner_operation', 'original_type': 'ValueError'} (Code: INNER_ERROR) | Details: {'operation': 'inner_operation', 'original_type': 'ValueError'}
2025-10-19 12:55:49,946 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/pytest/test_error_handling.py", line 473, in test_nested_error_contexts
    raise ValueError("Inner error")
ValueError: Inner error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/pi/hacking/pytest/test_error_handling.py", line 472, in test_nested_error_contexts
    with ErrorContext("inner_operation", "INNER_ERROR") as inner:
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 313, in __exit__
    raise wlan_error from exc_val
wlan_tool.exceptions.WLANToolError: WLANToolError: Inner error (Code: INNER_ERROR) | Details: {'operation': 'inner_operation', 'original_type': 'ValueError'}

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: outer_operation
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: inner_operation
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in inner_operation: Inner error | Type: ValueError
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/pytest/test_error_handling.py", line 473, in test_nested_error_contexts
    raise ValueError("Inner error")
ValueError: Inner error

ERROR    wlan_tool.exceptions:exceptions.py:300 Error in outer_operation: WLANToolError: Inner error (Code: INNER_ERROR) | Details: {'operation': 'inner_operation', 'original_type': 'ValueError'} (Code: INNER_ERROR) | Details: {'operation': 'inner_operation', 'original_type': 'ValueError'}
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/pytest/test_error_handling.py", line 473, in test_nested_error_contexts
    raise ValueError("Inner error")
ValueError: Inner error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/pi/hacking/pytest/test_error_handling.py", line 472, in test_nested_error_contexts
    with ErrorContext("inner_operation", "INNER_ERROR") as inner:
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 313, in __exit__
    raise wlan_error from exc_val
wlan_tool.exceptions.WLANToolError: WLANToolError: Inner error (Code: INNER_ERROR) | Details: {'operation': 'inner_operation', 'original_type': 'ValueError'}
________________ TestEndToEndWorkflow.test_database_integration ________________

self = <test_integration.TestEndToEndWorkflow object at 0x7f71410210>
sample_events = [{'beacon_interval': 102, 'bssid': '08:96:d7:1a:21:1c', 'cap': 17, 'channel': 6, ...}, {'client': 'a8:51:ab:0c:b9:e9',...-91, ...}, {'client': 'b2:87:23:15:7f:f2', 'ie_order_hash': 67890, 'ies': {0: ['MyOtherWLAN']}, 'rssi': -70, ...}, ...]
temp_db_file = '/tmp/tmphkce858a.db'

    def test_database_integration(self, sample_events, temp_db_file):
        """Test Datenbank-Integration."""
        # Schreibe Events in Datenbank
        with database.db_conn_ctx(temp_db_file) as conn:
            for event in sample_events:
>               database.add_event(conn, event)
E               AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

pytest/test_integration.py:64: AttributeError

The above exception was the direct cause of the following exception:

path = '/tmp/tmphkce858a.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
>           with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):

wlan_tool/storage/database.py:68: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.exceptions.ErrorContext object at 0x7f692a16d0>
exc_type = <class 'AttributeError'>
exc_val = AttributeError("module 'wlan_tool.storage.database' has no attribute 'add_event'")
exc_tb = <traceback object at 0x7f692a12c0>

    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type is not None:
            error_msg = f"Error in {self.operation}: {exc_val}"
    
            if isinstance(exc_val, WLANToolError):
                error_msg += f" (Code: {exc_val.error_code})"
                if exc_val.details:
                    error_msg += f" | Details: {exc_val.details}"
            else:
                error_msg += f" | Type: {exc_type.__name__}"
    
            self.logger.log(self.log_level, error_msg)
            self.logger.debug(f"Traceback: {traceback.format_exc()}")
    
            # Konvertiere zu WLANToolError falls nötig
            if not isinstance(exc_val, WLANToolError):
                wlan_error = WLANToolError(
                    message=str(exc_val),
                    error_code=self.error_code or "CONTEXT_ERROR",
                    details={
                        "operation": self.operation,
                        "original_type": exc_type.__name__,
                    },
                )
>               raise wlan_error from exc_val
E               wlan_tool.exceptions.WLANToolError: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}

wlan_tool/exceptions.py:313: WLANToolError

The above exception was the direct cause of the following exception:

self = <test_integration.TestEndToEndWorkflow object at 0x7f71410210>
sample_events = [{'beacon_interval': 102, 'bssid': '08:96:d7:1a:21:1c', 'cap': 17, 'channel': 6, ...}, {'client': 'a8:51:ab:0c:b9:e9',...-91, ...}, {'client': 'b2:87:23:15:7f:f2', 'ie_order_hash': 67890, 'ies': {0: ['MyOtherWLAN']}, 'rssi': -70, ...}, ...]
temp_db_file = '/tmp/tmphkce858a.db'

    def test_database_integration(self, sample_events, temp_db_file):
        """Test Datenbank-Integration."""
        # Schreibe Events in Datenbank
>       with database.db_conn_ctx(temp_db_file) as conn:

pytest/test_integration.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/contextlib.py:158: in __exit__
    self.gen.throw(typ, value, traceback)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

path = '/tmp/tmphkce858a.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
            with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):
                # Validiere Datenbankpfad
                if not _validate_file_path(path):
                    raise ValidationError(
                        f"Invalid database path: {path}",
                        error_code="INVALID_DB_PATH",
                        details={"db_path": path},
                    )
    
                # Erstelle Verzeichnis falls nötig
                db_dir = Path(path).parent
                if not db_dir.exists():
                    try:
                        db_dir.mkdir(parents=True, exist_ok=True)
                    except OSError as e:
                        raise FileSystemError(
                            f"Cannot create database directory: {db_dir}",
                            error_code="DB_DIR_CREATION_FAILED",
                            details={"directory": str(db_dir), "original_error": str(e)},
                        ) from e
    
                # Verbinde zur Datenbank
                conn = sqlite3.connect(path, timeout=Constants.DB_CONNECTION_TIMEOUT)
                conn.row_factory = sqlite3.Row
    
                # Setze pragmas für bessere Performance und Fehlerbehandlung
                conn.execute("PRAGMA foreign_keys = ON")
                conn.execute("PRAGMA journal_mode = WAL")
                conn.execute("PRAGMA synchronous = NORMAL")
                conn.execute("PRAGMA cache_size = 10000")
                conn.execute("PRAGMA temp_store = MEMORY")
    
                yield conn
    
        except sqlite3.Error as e:
            if conn:
                conn.rollback()
            raise DatabaseError(
                get_error_message(ErrorCodes.DB_CONNECTION_FAILED, details=str(e)),
                error_code=ErrorCodes.DB_CONNECTION_FAILED.value,
                details={"db_path": path, "sqlite_error": str(e)},
            ) from e
        except Exception as e:
            if conn:
                conn.rollback()
>           raise DatabaseError(
                f"Unexpected database error: {e}",
                error_code="DB_UNEXPECTED_ERROR",
                details={"db_path": path, "original_error": str(e)},
            ) from e
E           wlan_tool.exceptions.DatabaseError: WLANToolError: Unexpected database error: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'} (Code: DB_UNEXPECTED_ERROR) | Details: {'db_path': '/tmp/tmphkce858a.db', 'original_error': "WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}"}

wlan_tool/storage/database.py:113: DatabaseError
---------------------------- Captured stdout setup -----------------------------
2025-10-19 12:55:50,236 | DEBUG    | Starting operation: database_migration
2025-10-19 12:55:50,236 | DEBUG    | Starting operation: database_connection
2025-10-19 12:55:50,257 | INFO     | Current DB version: 0. Looking for migrations...
2025-10-19 12:55:50,257 | INFO     | Applying migration: 001_initial_schema.sql (Version 1)
2025-10-19 12:55:50,265 | INFO     | DB successfully migrated to version 1
2025-10-19 12:55:50,265 | INFO     | Applying migration: 002_add_dns_table.sql (Version 2)
2025-10-19 12:55:50,267 | INFO     | DB successfully migrated to version 2
2025-10-19 12:55:50,267 | INFO     | Applying migration: 003_add_network_info.sql (Version 3)
2025-10-19 12:55:50,268 | INFO     | DB successfully migrated to version 3
2025-10-19 12:55:50,269 | INFO     | Applying migration: 004_add_indexes.sql (Version 4)
2025-10-19 12:55:50,270 | INFO     | DB successfully migrated to version 4
2025-10-19 12:55:50,293 | INFO     | Database is up to date.
------------------------------ Captured log setup ------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_migration
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
INFO     wlan_tool.storage.database:database.py:157 Current DB version: 0. Looking for migrations...
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 001_initial_schema.sql (Version 1)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 1
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 002_add_dns_table.sql (Version 2)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 2
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 003_add_network_info.sql (Version 3)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 3
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 004_add_indexes.sql (Version 4)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 4
INFO     wlan_tool.storage.database:database.py:204 Database is up to date.
----------------------------- Captured stdout call -----------------------------
2025-10-19 12:55:50,294 | DEBUG    | Starting operation: database_connection
2025-10-19 12:55:50,296 | ERROR    | Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
2025-10-19 12:55:50,297 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/hacking/pytest/test_integration.py", line 64, in test_database_integration
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/hacking/pytest/test_integration.py", line 64, in test_database_integration
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'
_________________ TestEndToEndWorkflow.test_config_integration _________________

self = <test_integration.TestEndToEndWorkflow object at 0x7f714123d0>

    def test_config_integration(self):
        """Test Konfigurations-Integration."""
        # Teste Konfigurations-Laden
>       config_data = utils.load_config()
E       TypeError: load_config() missing 1 required positional argument: 'profile'

pytest/test_integration.py:82: TypeError
_____________________ TestDataFlow.test_state_persistence ______________________

self = <test_integration.TestDataFlow object at 0x7f71411d10>
sample_events = [{'beacon_interval': 102, 'bssid': '08:96:d7:1a:21:1c', 'cap': 17, 'channel': 6, ...}, {'client': 'a8:51:ab:0c:b9:e9',...-91, ...}, {'client': 'b2:87:23:15:7f:f2', 'ie_order_hash': 67890, 'ies': {0: ['MyOtherWLAN']}, 'rssi': -70, ...}, ...]
temp_db_file = '/tmp/tmp7h_4m9cw.db'

    def test_state_persistence(self, sample_events, temp_db_file):
        """Test State-Persistierung."""
        # Erstelle State
        state1 = WifiAnalysisState()
        state1.build_from_events(sample_events)
    
        # Schreibe in Datenbank
        with database.db_conn_ctx(temp_db_file) as conn:
            for event in sample_events:
>               database.add_event(conn, event)
E               AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

pytest/test_integration.py:130: AttributeError

The above exception was the direct cause of the following exception:

path = '/tmp/tmp7h_4m9cw.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
>           with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):

wlan_tool/storage/database.py:68: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.exceptions.ErrorContext object at 0x7f68d491d0>
exc_type = <class 'AttributeError'>
exc_val = AttributeError("module 'wlan_tool.storage.database' has no attribute 'add_event'")
exc_tb = <traceback object at 0x7f68d48600>

    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type is not None:
            error_msg = f"Error in {self.operation}: {exc_val}"
    
            if isinstance(exc_val, WLANToolError):
                error_msg += f" (Code: {exc_val.error_code})"
                if exc_val.details:
                    error_msg += f" | Details: {exc_val.details}"
            else:
                error_msg += f" | Type: {exc_type.__name__}"
    
            self.logger.log(self.log_level, error_msg)
            self.logger.debug(f"Traceback: {traceback.format_exc()}")
    
            # Konvertiere zu WLANToolError falls nötig
            if not isinstance(exc_val, WLANToolError):
                wlan_error = WLANToolError(
                    message=str(exc_val),
                    error_code=self.error_code or "CONTEXT_ERROR",
                    details={
                        "operation": self.operation,
                        "original_type": exc_type.__name__,
                    },
                )
>               raise wlan_error from exc_val
E               wlan_tool.exceptions.WLANToolError: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}

wlan_tool/exceptions.py:313: WLANToolError

The above exception was the direct cause of the following exception:

self = <test_integration.TestDataFlow object at 0x7f71411d10>
sample_events = [{'beacon_interval': 102, 'bssid': '08:96:d7:1a:21:1c', 'cap': 17, 'channel': 6, ...}, {'client': 'a8:51:ab:0c:b9:e9',...-91, ...}, {'client': 'b2:87:23:15:7f:f2', 'ie_order_hash': 67890, 'ies': {0: ['MyOtherWLAN']}, 'rssi': -70, ...}, ...]
temp_db_file = '/tmp/tmp7h_4m9cw.db'

    def test_state_persistence(self, sample_events, temp_db_file):
        """Test State-Persistierung."""
        # Erstelle State
        state1 = WifiAnalysisState()
        state1.build_from_events(sample_events)
    
        # Schreibe in Datenbank
>       with database.db_conn_ctx(temp_db_file) as conn:

pytest/test_integration.py:128: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/contextlib.py:158: in __exit__
    self.gen.throw(typ, value, traceback)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

path = '/tmp/tmp7h_4m9cw.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
            with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):
                # Validiere Datenbankpfad
                if not _validate_file_path(path):
                    raise ValidationError(
                        f"Invalid database path: {path}",
                        error_code="INVALID_DB_PATH",
                        details={"db_path": path},
                    )
    
                # Erstelle Verzeichnis falls nötig
                db_dir = Path(path).parent
                if not db_dir.exists():
                    try:
                        db_dir.mkdir(parents=True, exist_ok=True)
                    except OSError as e:
                        raise FileSystemError(
                            f"Cannot create database directory: {db_dir}",
                            error_code="DB_DIR_CREATION_FAILED",
                            details={"directory": str(db_dir), "original_error": str(e)},
                        ) from e
    
                # Verbinde zur Datenbank
                conn = sqlite3.connect(path, timeout=Constants.DB_CONNECTION_TIMEOUT)
                conn.row_factory = sqlite3.Row
    
                # Setze pragmas für bessere Performance und Fehlerbehandlung
                conn.execute("PRAGMA foreign_keys = ON")
                conn.execute("PRAGMA journal_mode = WAL")
                conn.execute("PRAGMA synchronous = NORMAL")
                conn.execute("PRAGMA cache_size = 10000")
                conn.execute("PRAGMA temp_store = MEMORY")
    
                yield conn
    
        except sqlite3.Error as e:
            if conn:
                conn.rollback()
            raise DatabaseError(
                get_error_message(ErrorCodes.DB_CONNECTION_FAILED, details=str(e)),
                error_code=ErrorCodes.DB_CONNECTION_FAILED.value,
                details={"db_path": path, "sqlite_error": str(e)},
            ) from e
        except Exception as e:
            if conn:
                conn.rollback()
>           raise DatabaseError(
                f"Unexpected database error: {e}",
                error_code="DB_UNEXPECTED_ERROR",
                details={"db_path": path, "original_error": str(e)},
            ) from e
E           wlan_tool.exceptions.DatabaseError: WLANToolError: Unexpected database error: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'} (Code: DB_UNEXPECTED_ERROR) | Details: {'db_path': '/tmp/tmp7h_4m9cw.db', 'original_error': "WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}"}

wlan_tool/storage/database.py:113: DatabaseError
---------------------------- Captured stdout setup -----------------------------
2025-10-19 12:55:50,535 | DEBUG    | Starting operation: database_migration
2025-10-19 12:55:50,535 | DEBUG    | Starting operation: database_connection
2025-10-19 12:55:50,550 | INFO     | Current DB version: 0. Looking for migrations...
2025-10-19 12:55:50,551 | INFO     | Applying migration: 001_initial_schema.sql (Version 1)
2025-10-19 12:55:50,559 | INFO     | DB successfully migrated to version 1
2025-10-19 12:55:50,560 | INFO     | Applying migration: 002_add_dns_table.sql (Version 2)
2025-10-19 12:55:50,561 | INFO     | DB successfully migrated to version 2
2025-10-19 12:55:50,561 | INFO     | Applying migration: 003_add_network_info.sql (Version 3)
2025-10-19 12:55:50,563 | INFO     | DB successfully migrated to version 3
2025-10-19 12:55:50,563 | INFO     | Applying migration: 004_add_indexes.sql (Version 4)
2025-10-19 12:55:50,565 | INFO     | DB successfully migrated to version 4
2025-10-19 12:55:50,587 | INFO     | Database is up to date.
------------------------------ Captured log setup ------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_migration
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
INFO     wlan_tool.storage.database:database.py:157 Current DB version: 0. Looking for migrations...
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 001_initial_schema.sql (Version 1)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 1
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 002_add_dns_table.sql (Version 2)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 2
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 003_add_network_info.sql (Version 3)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 3
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 004_add_indexes.sql (Version 4)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 4
INFO     wlan_tool.storage.database:database.py:204 Database is up to date.
----------------------------- Captured stdout call -----------------------------
2025-10-19 12:55:50,589 | INFO     | Baue/Aktualisiere Zustand aus Event-Stream auf...
2025-10-19 12:55:50,590 | INFO     | Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
2025-10-19 12:55:50,590 | DEBUG    | Starting operation: database_connection
2025-10-19 12:55:50,592 | ERROR    | Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
2025-10-19 12:55:50,593 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/hacking/pytest/test_integration.py", line 130, in test_state_persistence
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

------------------------------ Captured log call -------------------------------
INFO     wlan_tool.storage.state:state.py:52 Baue/Aktualisiere Zustand aus Event-Stream auf...
INFO     wlan_tool.storage.state:state.py:57 Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/hacking/pytest/test_integration.py", line 130, in test_state_persistence
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'
________________ TestLargeDataset.test_large_dataset_processing ________________

self = <test_integration.TestLargeDataset object at 0x7f71412690>

    def test_large_dataset_processing(self):
        """Test Verarbeitung großer Datensätze."""
        # Erstelle großen State
        state = WifiAnalysisState()
    
        # Erstelle 100 APs
        for i in range(100):
            bssid = f"08:96:d7:1a:21:{i:02x}"
>           ap = state.aps[bssid] = state.aps.get(bssid, type(state).__dict__['aps'].__class__())()
E           KeyError: 'aps'

pytest/test_integration.py:158: KeyError
_______________ TestErrorRecovery.test_malformed_event_handling ________________

self = <test_integration.TestErrorRecovery object at 0x7f7141c790>

    def test_malformed_event_handling(self):
        """Test Behandlung fehlerhafter Events."""
        state = WifiAnalysisState()
    
        # Teste verschiedene fehlerhafte Events
        malformed_events = [
            {},  # Leeres Event
            {'ts': time.time()},  # Nur Zeitstempel
            {'ts': time.time(), 'type': 'invalid'},  # Ungültiger Typ
            {'ts': time.time(), 'type': 'beacon'},  # Beacon ohne BSSID
        ]
    
        for event in malformed_events:
            # Sollte nicht crashen
            try:
>               state.update_from_event(event)

pytest/test_integration.py:241: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f68d05c10>
ev = {}, detailed_ies = False

    def update_from_event(self, ev: dict, detailed_ies: bool = False):
>       ts, ev_type = ev["ts"], ev.get("type")
E       KeyError: 'ts'

wlan_tool/storage/state.py:66: KeyError

During handling of the above exception, another exception occurred:

self = <test_integration.TestErrorRecovery object at 0x7f7141c790>

    def test_malformed_event_handling(self):
        """Test Behandlung fehlerhafter Events."""
        state = WifiAnalysisState()
    
        # Teste verschiedene fehlerhafte Events
        malformed_events = [
            {},  # Leeres Event
            {'ts': time.time()},  # Nur Zeitstempel
            {'ts': time.time(), 'type': 'invalid'},  # Ungültiger Typ
            {'ts': time.time(), 'type': 'beacon'},  # Beacon ohne BSSID
        ]
    
        for event in malformed_events:
            # Sollte nicht crashen
            try:
                state.update_from_event(event)
            except Exception as e:
>               pytest.fail(f"Malformed event should be handled gracefully: {e}")
E               Failed: Malformed event should be handled gracefully: 'ts'

pytest/test_integration.py:243: Failed
______________ TestMemoryManagement.test_memory_usage_large_state ______________

self = <test_integration.TestMemoryManagement object at 0x7f7141ec90>

    def test_memory_usage_large_state(self):
        """Test Speicherverbrauch mit großem State."""
        import psutil
        import os
    
        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss
    
        # Erstelle großen State
        state = WifiAnalysisState()
    
        for i in range(1000):
            mac = f"aa:bb:cc:dd:ee:{i:04x}"
>           client = state.clients[mac] = state.clients.get(mac, type(state).__dict__['clients'].__class__())()
E           KeyError: 'clients'

pytest/test_integration.py:295: KeyError
____________ TestMemoryManagement.test_state_pruning_memory_release ____________

self = <test_integration.TestMemoryManagement object at 0x7f7141f450>

    def test_state_pruning_memory_release(self):
        """Test Speicherfreigabe durch State-Pruning."""
        import psutil
        import os
    
        process = psutil.Process(os.getpid())
    
        # Erstelle State mit alten und neuen Daten
        state = WifiAnalysisState()
    
        # Alte Clients (werden gepruned)
        for i in range(100):
            mac = f"old:aa:bb:cc:dd:ee:{i:02x}"
>           client = state.clients[mac] = state.clients.get(mac, type(state).__dict__['clients'].__class__())()
E           KeyError: 'clients'

pytest/test_integration.py:321: KeyError
_____________ TestAnalysisPerformance.test_clustering_performance ______________

self = <test_performance.TestAnalysisPerformance object at 0x7f71401790>

    def test_clustering_performance(self):
        """Test Clustering-Performance."""
        # Erstelle State mit vielen Clients
        state = WifiAnalysisState()
    
        for i in range(200):
            mac = f"aa:bb:cc:dd:ee:{i:02x}"
>           client = state.clients[mac] = state.clients.get(mac, type(state).__dict__['clients'].__class__())()
E           KeyError: 'clients'

pytest/test_performance.py:147: KeyError
______________ TestAnalysisPerformance.test_inference_performance ______________

self = <test_performance.TestAnalysisPerformance object at 0x7f71402190>

    def test_inference_performance(self):
        """Test Inferenz-Performance."""
        # Erstelle State mit APs und Clients
        state = WifiAnalysisState()
    
        # Erstelle 50 APs
        for i in range(50):
            bssid = f"08:96:d7:1a:21:{i:02x}"
>           ap = state.aps[bssid] = state.aps.get(bssid, type(state).__dict__['aps'].__class__())()
E           KeyError: 'aps'

pytest/test_performance.py:180: KeyError
_____________ TestMemoryPerformance.test_memory_usage_large_state ______________

self = <test_performance.TestMemoryPerformance object at 0x7f71402910>

    def test_memory_usage_large_state(self):
        """Test Speicherverbrauch mit großem State."""
        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss
    
        # Erstelle großen State
        state = WifiAnalysisState()
    
        # 1000 Clients
        for i in range(1000):
            mac = f"aa:bb:cc:dd:ee:{i:04x}"
>           client = state.clients[mac] = state.clients.get(mac, type(state).__dict__['clients'].__class__())()
E           KeyError: 'clients'

pytest/test_performance.py:228: KeyError
___________ TestMemoryPerformance.test_memory_cleanup_after_pruning ____________

self = <test_performance.TestMemoryPerformance object at 0x7f71402510>

    def test_memory_cleanup_after_pruning(self):
        """Test Speicherbereinigung nach Pruning."""
        process = psutil.Process(os.getpid())
    
        # Erstelle State mit alten und neuen Daten
        state = WifiAnalysisState()
    
        # 500 alte Clients (werden gepruned)
        for i in range(500):
            mac = f"old:aa:bb:cc:dd:ee:{i:03x}"
>           client = state.clients[mac] = state.clients.get(mac, type(state).__dict__['clients'].__class__())()
E           KeyError: 'clients'

pytest/test_performance.py:269: KeyError
___________ TestDatabasePerformance.test_database_write_performance ____________

self = <test_performance.TestDatabasePerformance object at 0x7f71403590>
temp_db_file = '/tmp/tmplvasky16.db'

    def test_database_write_performance(self, temp_db_file):
        """Test Datenbank-Schreib-Performance."""
        # Erstelle Test-Events
        events = []
        for i in range(1000):
            event = {
                'ts': time.time() + i,
                'type': 'beacon' if i % 2 == 0 else 'probe_req',
                'bssid': f'08:96:d7:1a:21:{i % 100:02x}',
                'ssid': f'SSID_{i % 50}',
                'rssi': -50 - (i % 50),
                'channel': (i % 13) + 1
            }
            events.append(event)
    
        start_time = time.time()
    
        with database.db_conn_ctx(temp_db_file) as conn:
            for event in events:
>               database.add_event(conn, event)
E               AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

pytest/test_performance.py:325: AttributeError

The above exception was the direct cause of the following exception:

path = '/tmp/tmplvasky16.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
>           with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):

wlan_tool/storage/database.py:68: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.exceptions.ErrorContext object at 0x7f68f10410>
exc_type = <class 'AttributeError'>
exc_val = AttributeError("module 'wlan_tool.storage.database' has no attribute 'add_event'")
exc_tb = <traceback object at 0x7f68f13dc0>

    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type is not None:
            error_msg = f"Error in {self.operation}: {exc_val}"
    
            if isinstance(exc_val, WLANToolError):
                error_msg += f" (Code: {exc_val.error_code})"
                if exc_val.details:
                    error_msg += f" | Details: {exc_val.details}"
            else:
                error_msg += f" | Type: {exc_type.__name__}"
    
            self.logger.log(self.log_level, error_msg)
            self.logger.debug(f"Traceback: {traceback.format_exc()}")
    
            # Konvertiere zu WLANToolError falls nötig
            if not isinstance(exc_val, WLANToolError):
                wlan_error = WLANToolError(
                    message=str(exc_val),
                    error_code=self.error_code or "CONTEXT_ERROR",
                    details={
                        "operation": self.operation,
                        "original_type": exc_type.__name__,
                    },
                )
>               raise wlan_error from exc_val
E               wlan_tool.exceptions.WLANToolError: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}

wlan_tool/exceptions.py:313: WLANToolError

The above exception was the direct cause of the following exception:

self = <test_performance.TestDatabasePerformance object at 0x7f71403590>
temp_db_file = '/tmp/tmplvasky16.db'

    def test_database_write_performance(self, temp_db_file):
        """Test Datenbank-Schreib-Performance."""
        # Erstelle Test-Events
        events = []
        for i in range(1000):
            event = {
                'ts': time.time() + i,
                'type': 'beacon' if i % 2 == 0 else 'probe_req',
                'bssid': f'08:96:d7:1a:21:{i % 100:02x}',
                'ssid': f'SSID_{i % 50}',
                'rssi': -50 - (i % 50),
                'channel': (i % 13) + 1
            }
            events.append(event)
    
        start_time = time.time()
    
>       with database.db_conn_ctx(temp_db_file) as conn:

pytest/test_performance.py:323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/contextlib.py:158: in __exit__
    self.gen.throw(typ, value, traceback)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

path = '/tmp/tmplvasky16.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
            with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):
                # Validiere Datenbankpfad
                if not _validate_file_path(path):
                    raise ValidationError(
                        f"Invalid database path: {path}",
                        error_code="INVALID_DB_PATH",
                        details={"db_path": path},
                    )
    
                # Erstelle Verzeichnis falls nötig
                db_dir = Path(path).parent
                if not db_dir.exists():
                    try:
                        db_dir.mkdir(parents=True, exist_ok=True)
                    except OSError as e:
                        raise FileSystemError(
                            f"Cannot create database directory: {db_dir}",
                            error_code="DB_DIR_CREATION_FAILED",
                            details={"directory": str(db_dir), "original_error": str(e)},
                        ) from e
    
                # Verbinde zur Datenbank
                conn = sqlite3.connect(path, timeout=Constants.DB_CONNECTION_TIMEOUT)
                conn.row_factory = sqlite3.Row
    
                # Setze pragmas für bessere Performance und Fehlerbehandlung
                conn.execute("PRAGMA foreign_keys = ON")
                conn.execute("PRAGMA journal_mode = WAL")
                conn.execute("PRAGMA synchronous = NORMAL")
                conn.execute("PRAGMA cache_size = 10000")
                conn.execute("PRAGMA temp_store = MEMORY")
    
                yield conn
    
        except sqlite3.Error as e:
            if conn:
                conn.rollback()
            raise DatabaseError(
                get_error_message(ErrorCodes.DB_CONNECTION_FAILED, details=str(e)),
                error_code=ErrorCodes.DB_CONNECTION_FAILED.value,
                details={"db_path": path, "sqlite_error": str(e)},
            ) from e
        except Exception as e:
            if conn:
                conn.rollback()
>           raise DatabaseError(
                f"Unexpected database error: {e}",
                error_code="DB_UNEXPECTED_ERROR",
                details={"db_path": path, "original_error": str(e)},
            ) from e
E           wlan_tool.exceptions.DatabaseError: WLANToolError: Unexpected database error: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'} (Code: DB_UNEXPECTED_ERROR) | Details: {'db_path': '/tmp/tmplvasky16.db', 'original_error': "WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}"}

wlan_tool/storage/database.py:113: DatabaseError
---------------------------- Captured stdout setup -----------------------------
2025-10-19 12:55:51,733 | DEBUG    | Starting operation: database_migration
2025-10-19 12:55:51,734 | DEBUG    | Starting operation: database_connection
2025-10-19 12:55:51,751 | INFO     | Current DB version: 0. Looking for migrations...
2025-10-19 12:55:51,751 | INFO     | Applying migration: 001_initial_schema.sql (Version 1)
2025-10-19 12:55:51,763 | INFO     | DB successfully migrated to version 1
2025-10-19 12:55:51,763 | INFO     | Applying migration: 002_add_dns_table.sql (Version 2)
2025-10-19 12:55:51,764 | INFO     | DB successfully migrated to version 2
2025-10-19 12:55:51,765 | INFO     | Applying migration: 003_add_network_info.sql (Version 3)
2025-10-19 12:55:51,766 | INFO     | DB successfully migrated to version 3
2025-10-19 12:55:51,766 | INFO     | Applying migration: 004_add_indexes.sql (Version 4)
2025-10-19 12:55:51,768 | INFO     | DB successfully migrated to version 4
2025-10-19 12:55:51,792 | INFO     | Database is up to date.
------------------------------ Captured log setup ------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_migration
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
INFO     wlan_tool.storage.database:database.py:157 Current DB version: 0. Looking for migrations...
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 001_initial_schema.sql (Version 1)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 1
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 002_add_dns_table.sql (Version 2)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 2
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 003_add_network_info.sql (Version 3)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 3
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 004_add_indexes.sql (Version 4)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 4
INFO     wlan_tool.storage.database:database.py:204 Database is up to date.
----------------------------- Captured stdout call -----------------------------
2025-10-19 12:55:51,798 | DEBUG    | Starting operation: database_connection
2025-10-19 12:55:51,800 | ERROR    | Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
2025-10-19 12:55:51,801 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/hacking/pytest/test_performance.py", line 325, in test_database_write_performance
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/hacking/pytest/test_performance.py", line 325, in test_database_write_performance
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'
____________ TestDatabasePerformance.test_database_read_performance ____________

self = <test_performance.TestDatabasePerformance object at 0x7f71403ad0>
temp_db_file = '/tmp/tmpj_hdd4fy.db'

    def test_database_read_performance(self, temp_db_file):
        """Test Datenbank-Lese-Performance."""
        # Schreibe Test-Events
        events = []
        for i in range(1000):
            event = {
                'ts': time.time() + i,
                'type': 'beacon' if i % 2 == 0 else 'probe_req',
                'bssid': f'08:96:d7:1a:21:{i % 100:02x}',
                'ssid': f'SSID_{i % 50}',
                'rssi': -50 - (i % 50),
                'channel': (i % 13) + 1
            }
            events.append(event)
    
        with database.db_conn_ctx(temp_db_file) as conn:
            for event in events:
>               database.add_event(conn, event)
E               AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

pytest/test_performance.py:351: AttributeError

The above exception was the direct cause of the following exception:

path = '/tmp/tmpj_hdd4fy.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
>           with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):

wlan_tool/storage/database.py:68: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.exceptions.ErrorContext object at 0x7f6a4b5a10>
exc_type = <class 'AttributeError'>
exc_val = AttributeError("module 'wlan_tool.storage.database' has no attribute 'add_event'")
exc_tb = <traceback object at 0x7f6a585c80>

    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type is not None:
            error_msg = f"Error in {self.operation}: {exc_val}"
    
            if isinstance(exc_val, WLANToolError):
                error_msg += f" (Code: {exc_val.error_code})"
                if exc_val.details:
                    error_msg += f" | Details: {exc_val.details}"
            else:
                error_msg += f" | Type: {exc_type.__name__}"
    
            self.logger.log(self.log_level, error_msg)
            self.logger.debug(f"Traceback: {traceback.format_exc()}")
    
            # Konvertiere zu WLANToolError falls nötig
            if not isinstance(exc_val, WLANToolError):
                wlan_error = WLANToolError(
                    message=str(exc_val),
                    error_code=self.error_code or "CONTEXT_ERROR",
                    details={
                        "operation": self.operation,
                        "original_type": exc_type.__name__,
                    },
                )
>               raise wlan_error from exc_val
E               wlan_tool.exceptions.WLANToolError: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}

wlan_tool/exceptions.py:313: WLANToolError

The above exception was the direct cause of the following exception:

self = <test_performance.TestDatabasePerformance object at 0x7f71403ad0>
temp_db_file = '/tmp/tmpj_hdd4fy.db'

    def test_database_read_performance(self, temp_db_file):
        """Test Datenbank-Lese-Performance."""
        # Schreibe Test-Events
        events = []
        for i in range(1000):
            event = {
                'ts': time.time() + i,
                'type': 'beacon' if i % 2 == 0 else 'probe_req',
                'bssid': f'08:96:d7:1a:21:{i % 100:02x}',
                'ssid': f'SSID_{i % 50}',
                'rssi': -50 - (i % 50),
                'channel': (i % 13) + 1
            }
            events.append(event)
    
>       with database.db_conn_ctx(temp_db_file) as conn:

pytest/test_performance.py:349: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/contextlib.py:158: in __exit__
    self.gen.throw(typ, value, traceback)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

path = '/tmp/tmpj_hdd4fy.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
            with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):
                # Validiere Datenbankpfad
                if not _validate_file_path(path):
                    raise ValidationError(
                        f"Invalid database path: {path}",
                        error_code="INVALID_DB_PATH",
                        details={"db_path": path},
                    )
    
                # Erstelle Verzeichnis falls nötig
                db_dir = Path(path).parent
                if not db_dir.exists():
                    try:
                        db_dir.mkdir(parents=True, exist_ok=True)
                    except OSError as e:
                        raise FileSystemError(
                            f"Cannot create database directory: {db_dir}",
                            error_code="DB_DIR_CREATION_FAILED",
                            details={"directory": str(db_dir), "original_error": str(e)},
                        ) from e
    
                # Verbinde zur Datenbank
                conn = sqlite3.connect(path, timeout=Constants.DB_CONNECTION_TIMEOUT)
                conn.row_factory = sqlite3.Row
    
                # Setze pragmas für bessere Performance und Fehlerbehandlung
                conn.execute("PRAGMA foreign_keys = ON")
                conn.execute("PRAGMA journal_mode = WAL")
                conn.execute("PRAGMA synchronous = NORMAL")
                conn.execute("PRAGMA cache_size = 10000")
                conn.execute("PRAGMA temp_store = MEMORY")
    
                yield conn
    
        except sqlite3.Error as e:
            if conn:
                conn.rollback()
            raise DatabaseError(
                get_error_message(ErrorCodes.DB_CONNECTION_FAILED, details=str(e)),
                error_code=ErrorCodes.DB_CONNECTION_FAILED.value,
                details={"db_path": path, "sqlite_error": str(e)},
            ) from e
        except Exception as e:
            if conn:
                conn.rollback()
>           raise DatabaseError(
                f"Unexpected database error: {e}",
                error_code="DB_UNEXPECTED_ERROR",
                details={"db_path": path, "original_error": str(e)},
            ) from e
E           wlan_tool.exceptions.DatabaseError: WLANToolError: Unexpected database error: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'} (Code: DB_UNEXPECTED_ERROR) | Details: {'db_path': '/tmp/tmpj_hdd4fy.db', 'original_error': "WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}"}

wlan_tool/storage/database.py:113: DatabaseError
---------------------------- Captured stdout setup -----------------------------
2025-10-19 12:55:52,435 | DEBUG    | Starting operation: database_migration
2025-10-19 12:55:52,436 | DEBUG    | Starting operation: database_connection
2025-10-19 12:55:52,453 | INFO     | Current DB version: 0. Looking for migrations...
2025-10-19 12:55:52,453 | INFO     | Applying migration: 001_initial_schema.sql (Version 1)
2025-10-19 12:55:52,462 | INFO     | DB successfully migrated to version 1
2025-10-19 12:55:52,462 | INFO     | Applying migration: 002_add_dns_table.sql (Version 2)
2025-10-19 12:55:52,464 | INFO     | DB successfully migrated to version 2
2025-10-19 12:55:52,464 | INFO     | Applying migration: 003_add_network_info.sql (Version 3)
2025-10-19 12:55:52,465 | INFO     | DB successfully migrated to version 3
2025-10-19 12:55:52,466 | INFO     | Applying migration: 004_add_indexes.sql (Version 4)
2025-10-19 12:55:52,467 | INFO     | DB successfully migrated to version 4
2025-10-19 12:55:52,489 | INFO     | Database is up to date.
------------------------------ Captured log setup ------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_migration
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
INFO     wlan_tool.storage.database:database.py:157 Current DB version: 0. Looking for migrations...
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 001_initial_schema.sql (Version 1)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 1
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 002_add_dns_table.sql (Version 2)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 2
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 003_add_network_info.sql (Version 3)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 3
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 004_add_indexes.sql (Version 4)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 4
INFO     wlan_tool.storage.database:database.py:204 Database is up to date.
----------------------------- Captured stdout call -----------------------------
2025-10-19 12:55:52,496 | DEBUG    | Starting operation: database_connection
2025-10-19 12:55:52,498 | ERROR    | Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
2025-10-19 12:55:52,499 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/hacking/pytest/test_performance.py", line 351, in test_database_read_performance
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/hacking/pytest/test_performance.py", line 351, in test_database_read_performance
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'
________ TestScalabilityPerformance.test_scalability_with_dataset_size _________

self = <test_performance.TestScalabilityPerformance object at 0x7f71400cd0>

    def test_scalability_with_dataset_size(self):
        """Test Skalierbarkeit mit Datensatz-Größe."""
        dataset_sizes = [100, 500, 1000]
        processing_times = []
    
        for size in dataset_sizes:
            # Erstelle State mit gegebener Größe
            state = WifiAnalysisState()
    
            for i in range(size):
                mac = f"aa:bb:cc:dd:ee:{i:04x}"
>               client = state.clients[mac] = state.clients.get(mac, type(state).__dict__['clients'].__class__())()
E               KeyError: 'clients'

pytest/test_performance.py:440: KeyError
_______________ TestCLIModule.test_print_client_cluster_results ________________

self = <test_presentation.TestCLIModule object at 0x7f713e9b50>
mock_console = <MagicMock id='547230512784'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f70187ed0>

    def test_print_client_cluster_results(self, mock_console, populated_state):
        """Test Client-Cluster-Ergebnis-Ausgabe."""
        from wlan_tool.analysis import logic as analysis
    
        # Erstelle Test-Cluster-Daten
        clustered_df, feature_df = analysis.cluster_clients(populated_state, n_clusters=2)
    
        if clustered_df is not None and not clustered_df.empty:
            # Mock args
            args = MagicMock()
            args.cluster_clients = 2
            args.cluster_algo = "kmeans"
            args.no_mac_correlation = False
    
            # Sollte nicht crashen
>           cli.print_client_cluster_results(args, populated_state, mock_console)

pytest/test_presentation.py:38: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = <MagicMock id='547348177872'>
state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f70187ed0>
console = <MagicMock id='547230512784'>

    def print_client_cluster_results(args, state, console):
        """Führt das Client-Clustering aus und gibt die Ergebnisse formatiert aus."""
        clustered_df, feature_df = analysis.cluster_clients(
            state,
            n_clusters=args.cluster_clients,
            algo_name=args.cluster_algo,
            use_correlation=(not args.no_mac_correlation),
        )
        """Gibt die Ergebnisse des Client-Clusterings formatiert aus."""
        if clustered_df is not None and not clustered_df.empty:
            console.print(
                "[yellow]Keine Client-Daten für das Clustering gefunden.[/yellow]"
            )
            return
    
>       title_correlation_str = "& Korrelation" if use_correlation else "& ohne Korrelation"
E       NameError: name 'use_correlation' is not defined

wlan_tool/presentation/cli.py:34: NameError
---------------------------- Captured stdout setup -----------------------------
2025-10-19 12:55:52,741 | INFO     | Baue/Aktualisiere Zustand aus Event-Stream auf...
2025-10-19 12:55:52,742 | INFO     | Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
------------------------------ Captured log setup ------------------------------
INFO     wlan_tool.storage.state:state.py:52 Baue/Aktualisiere Zustand aus Event-Stream auf...
INFO     wlan_tool.storage.state:state.py:57 Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
----------------------------- Captured stdout call -----------------------------
2025-10-19 12:55:52,743 | DEBUG    | Starting operation: client_clustering
2025-10-19 12:55:52,744 | INFO     | Korreliere randomisierte MACs vor der Feature-Extraktion...
2025-10-19 12:55:52,744 | INFO     | Fand 0 Gruppen von potenziell zusammengehörigen randomisierten MACs.
2025-10-19 12:55:52,744 | DEBUG    | Starting operation: client_features_extraction
2025-10-19 12:55:52,744 | DEBUG    | Starting operation: client_features_extraction
2025-10-19 12:55:52,744 | DEBUG    | Starting operation: client_features_extraction
2025-10-19 12:55:52,757 | INFO     | Wende manuelle Feature-Gewichtungen für Standard-Clustering an...
2025-10-19 12:55:52,758 | DEBUG    | Gewichte Feature 'supports_11ax' mit Faktor 3.0.
2025-10-19 12:55:52,761 | DEBUG    | Gewichte Feature 'supports_11ac' mit Faktor 2.0.
2025-10-19 12:55:52,764 | DEBUG    | Gewichte Feature 'has_apple_ie' mit Faktor 2.5.
2025-10-19 12:55:52,767 | DEBUG    | Gewichte Feature 'has_ms_ie' mit Faktor 2.0.
2025-10-19 12:55:52,769 | DEBUG    | Gewichte Feature 'mimo_streams' mit Faktor 1.5.
2025-10-19 12:55:52,772 | DEBUG    | Gewichte Feature 'is_randomized_mac' mit Faktor 1.2.
2025-10-19 12:55:52,775 | DEBUG    | Gewichte Feature 'was_in_powersave' mit Faktor 1.2.
2025-10-19 12:55:52,778 | DEBUG    | Gewichte Feature 'probe_count' mit Faktor 1.0.
2025-10-19 12:55:52,781 | DEBUG    | Gewichte Feature 'seen_with_ap_count' mit Faktor 1.0.
2025-10-19 12:55:52,784 | INFO     | Verwende KMeans für das Clustering...
2025-10-19 12:55:52,793 | ERROR    | Unexpected error in cluster_clients: cluster_clients() got an unexpected keyword argument 'algo_name'
2025-10-19 12:55:52,794 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
TypeError: cluster_clients() got an unexpected keyword argument 'algo_name'

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_clustering
INFO     wlan_tool.analysis.logic:logic.py:396 Korreliere randomisierte MACs vor der Feature-Extraktion...
INFO     wlan_tool.analysis.logic:logic.py:801 Fand 0 Gruppen von potenziell zusammengehörigen randomisierten MACs.
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_features_extraction
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_features_extraction
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_features_extraction
INFO     wlan_tool.analysis.logic:logic.py:584 Wende manuelle Feature-Gewichtungen für Standard-Clustering an...
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'supports_11ax' mit Faktor 3.0.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'supports_11ac' mit Faktor 2.0.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'has_apple_ie' mit Faktor 2.5.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'has_ms_ie' mit Faktor 2.0.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'mimo_streams' mit Faktor 1.5.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'is_randomized_mac' mit Faktor 1.2.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'was_in_powersave' mit Faktor 1.2.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'probe_count' mit Faktor 1.0.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'seen_with_ap_count' mit Faktor 1.0.
INFO     wlan_tool.analysis.logic:logic.py:609 Verwende KMeans für das Clustering...
ERROR    wlan_tool.analysis.logic:exceptions.py:165 Unexpected error in cluster_clients: cluster_clients() got an unexpected keyword argument 'algo_name'
DEBUG    wlan_tool.analysis.logic:exceptions.py:166 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
TypeError: cluster_clients() got an unexpected keyword argument 'algo_name'
________ TestCLIEdgeCases.test_print_client_cluster_results_empty_data _________

self = <test_presentation.TestCLIEdgeCases object at 0x7f713f4310>
mock_console = <MagicMock id='547220469136'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f69591710>

    def test_print_client_cluster_results_empty_data(self, mock_console, populated_state):
        """Test Client-Cluster-Ausgabe mit leeren Daten."""
        # Erstelle leeren State
        empty_state = WifiAnalysisState()
    
        args = MagicMock()
        args.cluster_clients = 2
        args.cluster_algo = "kmeans"
        args.no_mac_correlation = False
    
        # Sollte nicht crashen
>       cli.print_client_cluster_results(args, empty_state, mock_console)

pytest/test_presentation.py:281: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = <MagicMock id='547935014352'>
state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f69592fd0>
console = <MagicMock id='547220469136'>

    def print_client_cluster_results(args, state, console):
        """Führt das Client-Clustering aus und gibt die Ergebnisse formatiert aus."""
        clustered_df, feature_df = analysis.cluster_clients(
            state,
            n_clusters=args.cluster_clients,
            algo_name=args.cluster_algo,
            use_correlation=(not args.no_mac_correlation),
        )
        """Gibt die Ergebnisse des Client-Clusterings formatiert aus."""
        if clustered_df is not None and not clustered_df.empty:
            console.print(
                "[yellow]Keine Client-Daten für das Clustering gefunden.[/yellow]"
            )
            return
    
>       title_correlation_str = "& Korrelation" if use_correlation else "& ohne Korrelation"
E       NameError: name 'use_correlation' is not defined

wlan_tool/presentation/cli.py:34: NameError
---------------------------- Captured stdout setup -----------------------------
2025-10-19 12:55:53,053 | INFO     | Baue/Aktualisiere Zustand aus Event-Stream auf...
2025-10-19 12:55:53,054 | INFO     | Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
------------------------------ Captured log setup ------------------------------
INFO     wlan_tool.storage.state:state.py:52 Baue/Aktualisiere Zustand aus Event-Stream auf...
INFO     wlan_tool.storage.state:state.py:57 Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
----------------------------- Captured stdout call -----------------------------
2025-10-19 12:55:53,057 | ERROR    | Unexpected error in cluster_clients: cluster_clients() got an unexpected keyword argument 'algo_name'
2025-10-19 12:55:53,058 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
TypeError: cluster_clients() got an unexpected keyword argument 'algo_name'

------------------------------ Captured log call -------------------------------
ERROR    wlan_tool.analysis.logic:exceptions.py:165 Unexpected error in cluster_clients: cluster_clients() got an unexpected keyword argument 'algo_name'
DEBUG    wlan_tool.analysis.logic:exceptions.py:166 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
TypeError: cluster_clients() got an unexpected keyword argument 'algo_name'
_________________ TestPerformance.test_large_dataset_handling __________________

self = <test_presentation.TestPerformance object at 0x7f713f6ed0>
mock_console = <MagicMock id='547220988432'>

    def test_large_dataset_handling(self, mock_console):
        """Test mit großen Datensätzen."""
        # Erstelle State mit vielen Clients
        state = WifiAnalysisState()
    
        for i in range(100):
            client = ClientState(mac=f"aa:bb:cc:dd:ee:{i:02x}")
            client.probes = {f"SSID_{i}"}
            client.all_packet_ts = np.array([time.time() - 100, time.time()])
>           client.rssi_w = Welford()
E           NameError: name 'Welford' is not defined

pytest/test_presentation.py:366: NameError
_____________ TestClientState.test_client_state_update_from_event ______________

self = <test_storage.TestClientState object at 0x7f713c9210>

    def test_client_state_update_from_event(self):
        """Test ClientState-Update aus Event."""
        client = ClientState(mac="aa:bb:cc:dd:ee:ff")
        event = {
            'ts': time.time(),
            'type': 'probe_req',
            'client': 'aa:bb:cc:dd:ee:ff',
            'rssi': -50,
            'ies': {'probes': ['TestSSID']}
        }
    
        client.update_from_event(event)
        assert client.count == 1
>       assert 'TestSSID' in client.probes
E       AssertionError: assert 'TestSSID' in set()
E        +  where set() = ClientState(mac='aa:bb:cc:dd:ee:ff', first_seen=1760871353.211379, last_seen=1760871353.211379, count=1, probes=set(),..., hostname=None, mcs_rates=Counter(), noise_w=Welford(n=0, mean=0.0, M2=0.0), fcs_error_count=0, ie_order_hashes=set()).probes

pytest/test_storage.py:97: AssertionError
_________________ TestAPState.test_ap_state_update_from_beacon _________________

self = <test_storage.TestAPState object at 0x7f713cb0d0>

    def test_ap_state_update_from_beacon(self):
        """Test APState-Update aus Beacon."""
        ap = APState(bssid="aa:bb:cc:dd:ee:ff", ssid="TestAP")
        event = {
            'ts': time.time(),
            'type': 'beacon',
            'bssid': 'aa:bb:cc:dd:ee:ff',
            'ssid': 'TestAP',
            'rssi': -50,
            'channel': 6,
            'beacon_interval': 102
        }
    
>       ap.update_from_event(event)
E       AttributeError: 'APState' object has no attribute 'update_from_event'

pytest/test_storage.py:141: AttributeError
___________________ TestWifiAnalysisState.test_state_pruning ___________________

self = <test_storage.TestWifiAnalysisState object at 0x7f713d4d50>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f936805d0>

    def test_state_pruning(self, populated_state):
        """Test State-Pruning."""
        state = populated_state
        assert 'DE:AD:BE:EF:00:00' in state.clients
    
        pruned_count = state.prune_state(time.time(), threshold_s=7200)
    
        assert pruned_count > 0
        assert 'DE:AD:BE:EF:00:00' not in state.clients
>       assert 'a8:51:ab:0c:b9:e9' in state.clients  # Sollte bleiben
E       AssertionError: assert 'a8:51:ab:0c:b9:e9' in {}
E        +  where {} = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f936805d0>.clients

pytest/test_storage.py:203: AssertionError
---------------------------- Captured stdout setup -----------------------------
2025-10-19 12:55:53,280 | INFO     | Baue/Aktualisiere Zustand aus Event-Stream auf...
2025-10-19 12:55:53,281 | INFO     | Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
------------------------------ Captured log setup ------------------------------
INFO     wlan_tool.storage.state:state.py:52 Baue/Aktualisiere Zustand aus Event-Stream auf...
INFO     wlan_tool.storage.state:state.py:57 Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
----------------------------- Captured stdout call -----------------------------
2025-10-19 12:55:53,282 | INFO     | Zustand bereinigt: 1 APs, 3 Clients, 0 Seq-Einträge und 1 SSIDs entfernt.
------------------------------ Captured log call -------------------------------
INFO     wlan_tool.storage.state:state.py:237 Zustand bereinigt: 1 APs, 3 Clients, 0 Seq-Einträge und 1 SSIDs entfernt.
________________ TestWifiAnalysisState.test_state_ssid_mapping _________________

self = <test_storage.TestWifiAnalysisState object at 0x7f713d5650>
sample_events = [{'beacon_interval': 102, 'bssid': '08:96:d7:1a:21:1c', 'cap': 17, 'channel': 6, ...}, {'client': 'a8:51:ab:0c:b9:e9',...-91, ...}, {'client': 'b2:87:23:15:7f:f2', 'ie_order_hash': 67890, 'ies': {0: ['MyOtherWLAN']}, 'rssi': -70, ...}, ...]

    def test_state_ssid_mapping(self, sample_events):
        """Test SSID-Mapping-Funktionalität."""
        state = WifiAnalysisState()
        state.build_from_events(sample_events)
    
        # Teste SSID-Map
        assert 'MyTestWLAN' in state.ssid_map
        ssid_info = state.ssid_map['MyTestWLAN']
        assert '08:96:d7:1a:21:1c' in ssid_info['bssids']
>       assert 'a8:51:ab:0c:b9:e9' in ssid_info['sources']['probe_req']
E       AssertionError: assert 'a8:51:ab:0c:b9:e9' in set()

pytest/test_storage.py:214: AssertionError
----------------------------- Captured stdout call -----------------------------
2025-10-19 12:55:53,308 | INFO     | Baue/Aktualisiere Zustand aus Event-Stream auf...
2025-10-19 12:55:53,309 | INFO     | Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
------------------------------ Captured log call -------------------------------
INFO     wlan_tool.storage.state:state.py:52 Baue/Aktualisiere Zustand aus Event-Stream auf...
INFO     wlan_tool.storage.state:state.py:57 Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
_____________________ TestDatabaseModule.test_fetch_events _____________________

self = <test_storage.TestDatabaseModule object at 0x7f713d6e90>
in_memory_db = <sqlite3.Connection object at 0x7f6a233b50>
sample_events = [{'beacon_interval': 102, 'bssid': '08:96:d7:1a:21:1c', 'cap': 17, 'channel': 6, ...}, {'client': 'a8:51:ab:0c:b9:e9',...-91, ...}, {'client': 'b2:87:23:15:7f:f2', 'ie_order_hash': 67890, 'ies': {0: ['MyOtherWLAN']}, 'rssi': -70, ...}, ...]

    def test_fetch_events(self, in_memory_db, sample_events):
        """Test Event-Abruf."""
        conn = in_memory_db
    
        # Schreibe Test-Events
        for event in sample_events[:2]:
>           database.add_event(conn, event)
E           AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

pytest/test_storage.py:260: AttributeError
______________________ TestDatabaseModule.test_add_label _______________________

self = <test_storage.TestDatabaseModule object at 0x7f713c9550>
in_memory_db = <sqlite3.Connection object at 0x7f68e35990>

    def test_add_label(self, in_memory_db):
        """Test Label-Hinzufügung."""
        conn = in_memory_db
    
        database.add_label(conn, "TestSSID", "aa:bb:cc:dd:ee:ff", 1)
    
        cursor = conn.execute("SELECT * FROM labels WHERE ssid = ? AND bssid = ?",
                            ("TestSSID", "aa:bb:cc:dd:ee:ff"))
        result = cursor.fetchone()
        assert result is not None
>       assert result[2] == 1  # label = 1
E       AssertionError: assert 'aa:bb:cc:dd:ee:ff' == 1

pytest/test_storage.py:277: AssertionError
----------------------------- Captured stdout call -----------------------------
2025-10-19 12:55:54,022 | DEBUG    | Starting operation: add_label
2025-10-19 12:55:54,023 | DEBUG    | Added label: TestSSID -> aa:bb:cc:dd:ee:ff = 1 (source: ui)
------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: add_label
DEBUG    wlan_tool.storage.database:database.py:618 Added label: TestSSID -> aa:bb:cc:dd:ee:ff = 1 (source: ui)
________________ TestOUIFunctions.test_lookup_vendor_apple_mac _________________

self = <test_utils.TestOUIFunctions object at 0x7f713ace90>

    def test_lookup_vendor_apple_mac(self):
        """Test Vendor-Lookup für Apple-MAC."""
        # Apple MAC-Adresse
        mac = "a8:51:ab:0c:b9:e9"
        vendor = utils.lookup_vendor(mac)
    
>       assert vendor is not None
E       assert None is not None

pytest/test_utils.py:26: AssertionError
_______________ TestOUIFunctions.test_lookup_vendor_unknown_mac ________________

self = <test_utils.TestOUIFunctions object at 0x7f713adad0>

    def test_lookup_vendor_unknown_mac(self):
        """Test Vendor-Lookup für unbekannte MAC."""
        # Unbekannte MAC-Adresse
        mac = "ff:ff:ff:ff:ff:ff"
        vendor = utils.lookup_vendor(mac)
    
        # Sollte None oder "Unknown" zurückgeben
>       assert vendor is None or vendor == "Unknown"
E       AssertionError: assert ('(Lokal / Randomisiert)' is None or '(Lokal / Randomisiert)' == 'Unknown'
E         
E         - Unknown
E         + (Lokal / Randomisiert))

pytest/test_utils.py:45: AssertionError
_________________ TestIEParsing.test_parse_ies_vendor_specific _________________

self = <test_utils.TestIEParsing object at 0x7f713b8050>

    def test_parse_ies_vendor_specific(self):
        """Test Vendor-spezifische IE-Parsing."""
        ies = {221: ['0017f20a010103040507080c']}  # Apple IE
        parsed = utils.parse_ies(ies, detailed=True)
    
        assert isinstance(parsed, dict)
        assert "vendor_specific" in parsed
>       assert "Apple" in parsed["vendor_specific"]
E       AssertionError: assert 'Apple' in {}

pytest/test_utils.py:131: AssertionError
_________________ TestIEParsing.test_parse_ies_ht_capabilities _________________

self = <test_utils.TestIEParsing object at 0x7f713b8450>

    def test_parse_ies_ht_capabilities(self):
        """Test HT-Capabilities-Parsing."""
        ies = {45: ['1f']}  # HT Capabilities
        parsed = utils.parse_ies(ies, detailed=True)
    
        assert isinstance(parsed, dict)
        assert "ht_caps" in parsed
>       assert "streams" in parsed["ht_caps"]
E       AssertionError: assert 'streams' in {'40mhz_support': True}

pytest/test_utils.py:140: AssertionError
_________________ TestUtilityFunctions.test_is_local_admin_mac _________________

self = <test_utils.TestUtilityFunctions object at 0x7f713b8f50>

    def test_is_local_admin_mac(self):
        """Test lokale Admin-MAC-Erkennung."""
        # Lokale Admin-MAC
        assert utils.is_local_admin_mac("02:00:00:00:00:00") is True
        assert utils.is_local_admin_mac("06:00:00:00:00:00") is True
    
        # Globale MAC
        assert utils.is_local_admin_mac("00:00:00:00:00:00") is False
>       assert utils.is_local_admin_mac("aa:bb:cc:dd:ee:ff") is False
E       AssertionError: assert True is False
E        +  where True = <function is_local_admin_mac at 0x7fa856c0e0>('aa:bb:cc:dd:ee:ff')
E        +    where <function is_local_admin_mac at 0x7fa856c0e0> = utils.is_local_admin_mac

pytest/test_utils.py:171: AssertionError
___________________ TestUtilityFunctions.test_is_valid_bssid ___________________

self = <test_utils.TestUtilityFunctions object at 0x7f713ba450>

    def test_is_valid_bssid(self):
        """Test BSSID-Validierung."""
        # Gültige BSSID
        assert utils.is_valid_bssid("aa:bb:cc:dd:ee:ff") is True
        assert utils.is_valid_bssid("00:11:22:33:44:55") is True
    
        # Ungültige BSSID
        assert utils.is_valid_bssid("") is False
        assert utils.is_valid_bssid("invalid") is False
>       assert utils.is_valid_bssid("aa:bb:cc:dd:ee") is False  # Zu kurz
E       AssertionError: assert True is False
E        +  where True = <function is_valid_bssid at 0x7fa856c180>('aa:bb:cc:dd:ee')
E        +    where <function is_valid_bssid at 0x7fa856c180> = utils.is_valid_bssid

pytest/test_utils.py:182: AssertionError
________________ TestUtilityFunctions.test_ie_fingerprint_hash _________________

self = <test_utils.TestUtilityFunctions object at 0x7f713b97d0>

    def test_ie_fingerprint_hash(self):
        """Test IE-Fingerprint-Hash."""
        ies = {
            0: ['TestSSID'],
            1: ['82848b96'],
            48: ['0100000fac040100000fac020100000fac028c00']
        }
    
        hash_value = utils.ie_fingerprint_hash(ies)
    
        assert isinstance(hash_value, str)
>       assert len(hash_value) == 32  # MD5-Hash-Länge
E       AssertionError: assert 40 == 32
E        +  where 40 = len('fb3a54a0b7ca1a713fd927a194ff191b7de45566')

pytest/test_utils.py:196: AssertionError
_____________ TestUtilityFunctions.test_ie_fingerprint_hash_empty ______________

self = <test_utils.TestUtilityFunctions object at 0x7f713b9390>

    def test_ie_fingerprint_hash_empty(self):
        """Test IE-Fingerprint-Hash mit leeren IEs."""
        ies = {}
    
        hash_value = utils.ie_fingerprint_hash(ies)
    
>       assert hash_value is None or hash_value == ""
E       AssertionError: assert ('da39a3ee5e6b4b0d3255bfef95601890afd80709' is None or 'da39a3ee5e6b...01890afd80709' == ''
E         
E         + da39a3ee5e6b4b0d3255bfef95601890afd80709)

pytest/test_utils.py:205: AssertionError
_________________ TestConfigFunctions.test_load_config_default _________________

self = <test_utils.TestConfigFunctions object at 0x7f713ba550>

    def test_load_config_default(self):
        """Test Konfigurations-Laden (Standard)."""
>       config_data = utils.load_config()
E       TypeError: load_config() missing 1 required positional argument: 'profile'

pytest/test_utils.py:226: TypeError
____________ TestConfigFunctions.test_load_config_specific_profile _____________

self = <test_utils.TestConfigFunctions object at 0x7f713ba2d0>

    def test_load_config_specific_profile(self):
        """Test Konfigurations-Laden (spezifisches Profil)."""
        # Erstelle temporäre Konfigurationsdatei
        test_config = {
            "capture": {"interface": "test0", "duration": 60},
            "database": {"path": "test.db"}
        }
    
        with tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False) as f:
            yaml.dump(test_config, f)
            config_path = f.name
    
        try:
>           with patch('wlan_tool.utils.CONFIG_PATH', config_path):

pytest/test_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f93683890>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'wlan_tool.utils' from '/home/pi/hacking/wlan_tool/utils.py'> does not have the attribute 'CONFIG_PATH'

../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1419: AttributeError
______________ TestConfigFunctions.test_load_config_missing_file _______________

self = <test_utils.TestConfigFunctions object at 0x7f713bb2d0>

    def test_load_config_missing_file(self):
        """Test Konfigurations-Laden (fehlende Datei)."""
>       with patch('wlan_tool.utils.CONFIG_PATH', Path("/nonexistent/config.yaml")):

pytest/test_utils.py:255: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f6914ebd0>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'wlan_tool.utils' from '/home/pi/hacking/wlan_tool/utils.py'> does not have the attribute 'CONFIG_PATH'

../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1419: AttributeError
________________ TestEdgeCases.test_ie_fingerprint_hash_unicode ________________

self = <test_utils.TestEdgeCases object at 0x7f713a2610>

    def test_ie_fingerprint_hash_unicode(self):
        """Test IE-Fingerprint-Hash mit Unicode-Daten."""
        ies = {0: ['TestSSID_äöü']}  # Unicode-Zeichen
    
        hash_value = utils.ie_fingerprint_hash(ies)
    
        assert isinstance(hash_value, str)
>       assert len(hash_value) == 32
E       AssertionError: assert 40 == 32
E        +  where 40 = len('758ed0819e647ff1683744b0bc9b1ff7470f6d37')

pytest/test_utils.py:356: AssertionError
_____________ TestEdgeCases.test_config_loading_with_invalid_yaml ______________

self = <test_utils.TestEdgeCases object at 0x7f713a1e50>

    def test_config_loading_with_invalid_yaml(self):
        """Test Konfigurations-Laden mit ungültigem YAML."""
        invalid_yaml = "invalid: yaml: content: ["
    
        with tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False) as f:
            f.write(invalid_yaml)
            config_path = f.name
    
        try:
>           with patch('wlan_tool.utils.CONFIG_PATH', config_path):

pytest/test_utils.py:378: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f68c69090>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'wlan_tool.utils' from '/home/pi/hacking/wlan_tool/utils.py'> does not have the attribute 'CONFIG_PATH'

../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1419: AttributeError
__________ TestEndToEndWorkflow.test_complete_wifi_analysis_workflow ___________

self = <test_end_to_end.TestEndToEndWorkflow object at 0x7f7107f210>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]
temp_dir = PosixPath('/tmp/tmpk3jkkfcx')

    @pytest.mark.integration
    @pytest.mark.slow
    def test_complete_wifi_analysis_workflow(self, large_dataset, temp_dir):
        """Test des kompletten WLAN-Analyse-Workflows."""
        # 1. Datenverarbeitung
        processor = WiFiDataProcessor()
        processed_data = processor.process_data(large_dataset)
    
        assert len(processed_data) == len(large_dataset)
        assert "processed_timestamp" in processed_data.columns
    
        # 2. Feature-Extraktion
        extractor = FeatureExtractor()
        features = extractor.extract_features(processed_data)
    
        assert features.shape[0] == len(processed_data)
        assert features.shape[1] > 0
    
        # 3. Clustering-Analyse
        analyzer = ClusteringAnalyzer()
>       labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)

tests/integration/test_end_to_end.py:42: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1064: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1446: in fit
    X = validate_data(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2944: in validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1107: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:120: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[-1.15579349,  0.        ,  0.        , ...,  0.        ,
         0.15614176, -0.97725852],
       [-1.1557934...176, -0.97725852],
       [ 1.35680105,  0.        ,  0.        , ...,  0.        ,
         0.15614176,  1.02327069]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:169: ValueError
____________ TestEndToEndWorkflow.test_plugin_integration_workflow _____________

self = <test_end_to_end.TestEndToEndWorkflow object at 0x7f704c71d0>
sample_wifi_data =               timestamp device_id  ...  packet_count  bytes_transferred
0   2024-01-01 00:00:00  device_3  ...        ...15         206.754596
999 2024-01-01 16:39:00  device_1  ...           103         554.365485

[1000 rows x 11 columns]
temp_dir = PosixPath('/tmp/tmpumyn1_tb')

    @pytest.mark.integration
    def test_plugin_integration_workflow(self, sample_wifi_data, temp_dir):
        """Test der Plugin-Integration im Workflow."""
        from plugins import load_all_plugins
    
        # Plugins laden
        plugin_dir = Path("plugins")
        plugins = load_all_plugins(plugin_dir)
    
        assert len(plugins) > 0
    
        # Features extrahieren
        extractor = FeatureExtractor()
        features = extractor.extract_features(sample_wifi_data)
    
        # Jedes Plugin testen
        for plugin in plugins:
            # Plugin-Dependencies prüfen
>           if not plugin.validate_dependencies():
E           AttributeError: 'str' object has no attribute 'validate_dependencies'

tests/integration/test_end_to_end.py:101: AttributeError
----------------------------- Captured stdout call -----------------------------
2025-10-19 12:55:56,216 | INFO     | Plugin 'Advanced Clustering' v1.0.0 geladen
2025-10-19 12:55:56,221 | INFO     | Plugin 'Ensemble Models' v1.0.0 geladen
2025-10-19 12:55:56,224 | WARNING  | Dependencies ['umap-learn'] für Plugin 'UMAP Plot' nicht verfügbar
2025-10-19 12:55:56,225 | WARNING  | Plugin umap_plot hat fehlende Dependencies
2025-10-19 12:55:56,227 | INFO     | Plugin 'Sankey Diagram' v1.0.0 geladen
2025-10-19 12:55:56,230 | WARNING  | PyTorch oder Gym nicht verfügbar: No module named 'gym'
2025-10-19 12:55:56,235 | WARNING  | Dependencies ['gym'] für Plugin 'Reinforcement Learning' nicht verfügbar
2025-10-19 12:55:56,235 | WARNING  | Plugin reinforcement_learning hat fehlende Dependencies
2025-10-19 12:55:56,237 | INFO     | Plugin 'Example_Plugin' v1.0.0 geladen
------------------------------ Captured log call -------------------------------
INFO     plugins:__init__.py:120 Plugin 'Advanced Clustering' v1.0.0 geladen
INFO     plugins:__init__.py:120 Plugin 'Ensemble Models' v1.0.0 geladen
WARNING  plugins:__init__.py:68 Dependencies ['umap-learn'] für Plugin 'UMAP Plot' nicht verfügbar
WARNING  plugins:__init__.py:97 Plugin umap_plot hat fehlende Dependencies
INFO     plugins:__init__.py:120 Plugin 'Sankey Diagram' v1.0.0 geladen
WARNING  root:plugin.py:28 PyTorch oder Gym nicht verfügbar: No module named 'gym'
WARNING  plugins:__init__.py:68 Dependencies ['gym'] für Plugin 'Reinforcement Learning' nicht verfügbar
WARNING  plugins:__init__.py:97 Plugin reinforcement_learning hat fehlende Dependencies
INFO     plugins:__init__.py:120 Plugin 'Example_Plugin' v1.0.0 geladen
_____________ TestEndToEndWorkflow.test_data_pipeline_with_file_io _____________

self = <test_end_to_end.TestEndToEndWorkflow object at 0x7f7105a610>
temp_dir = PosixPath('/tmp/tmpvt5ytn49')

    @pytest.mark.integration
    def test_data_pipeline_with_file_io(self, temp_dir):
        """Test der Datenpipeline mit Datei-I/O."""
        # Test-Daten generieren
        n_samples = 1000
        test_data = pd.DataFrame(
            {
                "timestamp": pd.date_range(
                    "2024-01-01", periods=n_samples, freq="1min"
                ),
                "device_id": np.random.choice(
                    ["device_1", "device_2", "device_3"], n_samples
                ),
                "signal_strength": np.random.normal(-50, 10, n_samples),
                "frequency": np.random.choice([2.4, 5.0], n_samples),
                "channel": np.random.randint(1, 14, n_samples),
                "mac_address": [f"00:11:22:33:44:{i:02x}" for i in range(n_samples)],
                "ssid": np.random.choice(
                    ["WiFi_Home", "WiFi_Office", "Public_WiFi"], n_samples
                ),
                "encryption": np.random.choice(["WPA2", "WPA3", "Open"], n_samples),
                "data_rate": np.random.normal(54, 10, n_samples),
                "packet_count": np.random.poisson(100, n_samples),
                "bytes_transferred": np.random.exponential(1000, n_samples),
            }
        )
    
        # 1. Daten in CSV speichern
        input_file = temp_dir / "input_data.csv"
        test_data.to_csv(input_file, index=False)
    
        # 2. Daten laden und verarbeiten
        loaded_data = pd.read_csv(input_file)
        processor = WiFiDataProcessor()
        processed_data = processor.process_data(loaded_data)
    
        # 3. Features extrahieren
        extractor = FeatureExtractor()
        features = extractor.extract_features(processed_data)
    
        # 4. Clustering
        analyzer = ClusteringAnalyzer()
>       labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=3)

tests/integration/test_end_to_end.py:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1064: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1446: in fit
    X = validate_data(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2944: in validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1107: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:120: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[-1.62859019,  0.        ,  0.        , ...,  0.        ,
         0.        , -0.9900495 ],
       [-1.6285901...   ,  1.0100505 ],
       [ 1.69506325,  0.        ,  0.        , ...,  0.        ,
         0.        ,  1.0100505 ]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:169: ValueError
____________ TestEndToEndWorkflow.test_error_handling_and_recovery _____________

self = <test_end_to_end.TestEndToEndWorkflow object at 0x7f704c7bd0>
temp_dir = PosixPath('/tmp/tmpe8yno1px')

    @pytest.mark.integration
    def test_error_handling_and_recovery(self, temp_dir):
        """Test der Fehlerbehandlung und Wiederherstellung."""
        processor = WiFiDataProcessor()
        extractor = FeatureExtractor()
        analyzer = ClusteringAnalyzer()
    
        # Test mit ungültigen Daten
        invalid_data = pd.DataFrame(
            {
                "timestamp": ["invalid_date", "2024-01-01", "2024-01-02"],
                "signal_strength": [np.nan, -50, -60],
                "frequency": [1.0, 2.4, 5.0],  # Ungültige Frequenz
                "device_id": ["device_1", "device_2", "device_3"],
                "mac_address": [
                    "00:11:22:33:44:01",
                    "00:11:22:33:44:02",
                    "00:11:22:33:44:03",
                ],
                "ssid": ["WiFi_Home", "WiFi_Office", "Public_WiFi"],
                "encryption": ["WPA2", "WPA3", "Open"],
                "channel": [1, 6, 11],
                "data_rate": [54, 100, 54],
                "packet_count": [100, 200, 150],
                "bytes_transferred": [1000, 2000, 1500],
            }
        )
    
        # Verarbeitung sollte Fehler behandeln
        try:
>           processed_data = processor.process_data(invalid_data)

tests/integration/test_end_to_end.py:203: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/data_processing/wifi_processor.py:45: in process_data
    processed_data['processed_timestamp'] = pd.to_datetime(processed_data['timestamp'])
.venv/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:1067: in to_datetime
    values = convert_listlike(arg._values, format)
.venv/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:435: in _convert_listlike_datetimes
    result, tz_parsed = objects_to_datetime64(
.venv/lib/python3.11/site-packages/pandas/core/arrays/datetimes.py:2398: in objects_to_datetime64
    result, tz_parsed = tslib.array_to_datetime(
tslib.pyx:414: in pandas._libs.tslib.array_to_datetime
    ???
tslib.pyx:596: in pandas._libs.tslib.array_to_datetime
    ???
tslib.pyx:553: in pandas._libs.tslib.array_to_datetime
    ???
conversion.pyx:641: in pandas._libs.tslibs.conversion.convert_str_to_tsobject
    ???
parsing.pyx:336: in pandas._libs.tslibs.parsing.parse_datetime_string
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   pandas._libs.tslibs.parsing.DateParseError: Unknown datetime string format, unable to parse: invalid_date, at position 0

parsing.pyx:666: DateParseError

During handling of the above exception, another exception occurred:

self = <test_end_to_end.TestEndToEndWorkflow object at 0x7f704c7bd0>
temp_dir = PosixPath('/tmp/tmpe8yno1px')

    @pytest.mark.integration
    def test_error_handling_and_recovery(self, temp_dir):
        """Test der Fehlerbehandlung und Wiederherstellung."""
        processor = WiFiDataProcessor()
        extractor = FeatureExtractor()
        analyzer = ClusteringAnalyzer()
    
        # Test mit ungültigen Daten
        invalid_data = pd.DataFrame(
            {
                "timestamp": ["invalid_date", "2024-01-01", "2024-01-02"],
                "signal_strength": [np.nan, -50, -60],
                "frequency": [1.0, 2.4, 5.0],  # Ungültige Frequenz
                "device_id": ["device_1", "device_2", "device_3"],
                "mac_address": [
                    "00:11:22:33:44:01",
                    "00:11:22:33:44:02",
                    "00:11:22:33:44:03",
                ],
                "ssid": ["WiFi_Home", "WiFi_Office", "Public_WiFi"],
                "encryption": ["WPA2", "WPA3", "Open"],
                "channel": [1, 6, 11],
                "data_rate": [54, 100, 54],
                "packet_count": [100, 200, 150],
                "bytes_transferred": [1000, 2000, 1500],
            }
        )
    
        # Verarbeitung sollte Fehler behandeln
        try:
            processed_data = processor.process_data(invalid_data)
            # Wenn erfolgreich, sollten ungültige Daten bereinigt sein
            assert len(processed_data) <= len(invalid_data)
        except Exception as e:
            # Fehler sollten informativ sein
>           assert "Invalid" in str(e) or "Missing" in str(e)
E           AssertionError: assert ('Invalid' in 'Unknown datetime string format, unable to parse: invalid_date, at position 0' or 'Missing' in 'Unknown datetime string format, unable to parse: invalid_date, at position 0')
E            +  where 'Unknown datetime string format, unable to parse: invalid_date, at position 0' = str(DateParseError('Unknown datetime string format, unable to parse: invalid_date, at position 0'))
E            +  and   'Unknown datetime string format, unable to parse: invalid_date, at position 0' = str(DateParseError('Unknown datetime string format, unable to parse: invalid_date, at position 0'))

tests/integration/test_end_to_end.py:208: AssertionError
_______________ TestEndToEndWorkflow.test_performance_under_load _______________

self = <test_end_to_end.TestEndToEndWorkflow object at 0x7f704d81d0>
temp_dir = PosixPath('/tmp/tmpbm6iw03g')

    @pytest.mark.integration
    def test_performance_under_load(self, temp_dir):
        """Test der Performance unter Last."""
        import time
    
        # Große Datenmenge
        n_samples = 50000
        large_data = pd.DataFrame(
            {
                "timestamp": pd.date_range("2024-01-01", periods=n_samples, freq="1s"),
                "device_id": np.random.choice(
                    [f"device_{i}" for i in range(100)], n_samples
                ),
                "signal_strength": np.random.normal(-50, 10, n_samples),
                "frequency": np.random.choice([2.4, 5.0], n_samples),
                "channel": np.random.randint(1, 14, n_samples),
                "mac_address": [f"00:11:22:33:44:{i:02x}" for i in range(n_samples)],
                "ssid": np.random.choice(
                    ["WiFi_Home", "WiFi_Office", "Public_WiFi"], n_samples
                ),
                "encryption": np.random.choice(["WPA2", "WPA3", "Open"], n_samples),
                "data_rate": np.random.normal(54, 10, n_samples),
                "packet_count": np.random.poisson(100, n_samples),
                "bytes_transferred": np.random.exponential(1000, n_samples),
            }
        )
    
        processor = WiFiDataProcessor()
        extractor = FeatureExtractor()
        analyzer = ClusteringAnalyzer()
    
        # Performance-Messung
        start_time = time.time()
    
        # Verarbeitung
        processed_data = processor.process_data(large_data)
        features = extractor.extract_features(processed_data)
>       labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)

tests/integration/test_end_to_end.py:259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1064: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1446: in fit
    X = validate_data(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2944: in validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1107: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:120: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[-1.6100241 ,  0.        ,  0.        , ...,  0.        ,
         0.        , -1.00344594],
       [-1.6100241...   ,  0.9965659 ],
       [ 1.63599223,  0.        ,  0.        , ...,  0.        ,
         0.        , -1.00344594]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:169: ValueError
_______________ TestEndToEndWorkflow.test_concurrent_processing ________________

self = <test_end_to_end.TestEndToEndWorkflow object at 0x7f704d88d0>
temp_dir = PosixPath('/tmp/tmpfue0vn5a')

    @pytest.mark.integration
    def test_concurrent_processing(self, temp_dir):
        """Test der parallelen Verarbeitung."""
        import threading
        from concurrent.futures import ThreadPoolExecutor
    
        def process_chunk(chunk_data):
            """Verarbeitet einen Daten-Chunk."""
            processor = WiFiDataProcessor()
            extractor = FeatureExtractor()
            analyzer = ClusteringAnalyzer()
    
            processed_data = processor.process_data(chunk_data)
            features = extractor.extract_features(processed_data)
            labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=3)
    
            return {
                "chunk_id": threading.current_thread().ident,
                "n_samples": len(chunk_data),
                "n_clusters": len(np.unique(labels)),
            }
    
        # Daten in Chunks aufteilen
        n_chunks = 4
        chunk_size = 1000
        n_samples = n_chunks * chunk_size
    
        test_data = pd.DataFrame(
            {
                "timestamp": pd.date_range(
                    "2024-01-01", periods=n_samples, freq="1min"
                ),
                "device_id": np.random.choice(
                    [f"device_{i}" for i in range(50)], n_samples
                ),
                "signal_strength": np.random.normal(-50, 10, n_samples),
                "frequency": np.random.choice([2.4, 5.0], n_samples),
                "channel": np.random.randint(1, 14, n_samples),
                "mac_address": [f"00:11:22:33:44:{i:02x}" for i in range(n_samples)],
                "ssid": np.random.choice(
                    ["WiFi_Home", "WiFi_Office", "Public_WiFi"], n_samples
                ),
                "encryption": np.random.choice(["WPA2", "WPA3", "Open"], n_samples),
                "data_rate": np.random.normal(54, 10, n_samples),
                "packet_count": np.random.poisson(100, n_samples),
                "bytes_transferred": np.random.exponential(1000, n_samples),
            }
        )
    
        chunks = [
            test_data.iloc[i * chunk_size : (i + 1) * chunk_size]
            for i in range(n_chunks)
        ]
    
        # Parallele Verarbeitung
        with ThreadPoolExecutor(max_workers=n_chunks) as executor:
            futures = [executor.submit(process_chunk, chunk) for chunk in chunks]
>           results = [future.result() for future in futures]

tests/integration/test_end_to_end.py:328: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/integration/test_end_to_end.py:328: in <listcomp>
    results = [future.result() for future in futures]
../.pyenv/versions/3.11.9/lib/python3.11/concurrent/futures/_base.py:456: in result
    return self.__get_result()
../.pyenv/versions/3.11.9/lib/python3.11/concurrent/futures/_base.py:401: in __get_result
    raise self._exception
../.pyenv/versions/3.11.9/lib/python3.11/concurrent/futures/thread.py:58: in run
    result = self.fn(*self.args, **self.kwargs)
tests/integration/test_end_to_end.py:285: in process_chunk
    labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=3)
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1064: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1446: in fit
    X = validate_data(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2944: in validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1107: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:120: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[-1.62859019,  0.        ,  0.        , ...,  0.11020775,
        -0.38663966, -1.06832936],
       [-1.6285901...14 ,  0.93604092],
       [ 1.69506325,  0.        ,  0.        , ...,  0.11020775,
         0.31126587,  0.93604092]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:169: ValueError
_______________ TestClusteringBenchmarks.test_kmeans_performance _______________

self = <test_benchmarks.TestClusteringBenchmarks object at 0x7f704ed150>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f675249d0>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_kmeans_performance(self, benchmark, large_dataset):
        """Benchmark für K-Means Clustering."""
        analyzer = ClusteringAnalyzer()
    
        # Features extrahieren
        feature_extractor = FeatureExtractor()
        features = feature_extractor.extract_features(large_dataset)
    
        def clustering_func():
            return analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)
    
>       result = benchmark(clustering_func)

tests/performance/test_benchmarks.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:156: in __call__
    return self._raw(function_to_benchmark, *args, **kwargs)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:180: in _raw
    duration, iterations, loops_range = self._calibrate_timer(runner)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:318: in _calibrate_timer
    duration = runner(loops_range)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:109: in runner
    function_to_benchmark(*args, **kwargs)
tests/performance/test_benchmarks.py:29: in clustering_func
    return analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1064: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1446: in fit
    X = validate_data(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2944: in validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1107: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:120: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176, -0.97725852],
       [ 0.       ...176, -0.97725852],
       [ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176,  1.02327069]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:169: ValueError
_______________ TestClusteringBenchmarks.test_dbscan_performance _______________

self = <test_benchmarks.TestClusteringBenchmarks object at 0x7f704ed750>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f67e30ed0>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_dbscan_performance(self, benchmark, large_dataset):
        """Benchmark für DBSCAN Clustering."""
        analyzer = ClusteringAnalyzer()
    
        feature_extractor = FeatureExtractor()
        features = feature_extractor.extract_features(large_dataset)
    
        def clustering_func():
            return analyzer.cluster_data(
                features, algorithm="dbscan", eps=0.5, min_samples=5
            )
    
>       result = benchmark(clustering_func)

tests/performance/test_benchmarks.py:51: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:156: in __call__
    return self._raw(function_to_benchmark, *args, **kwargs)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:180: in _raw
    duration, iterations, loops_range = self._calibrate_timer(runner)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:318: in _calibrate_timer
    duration = runner(loops_range)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:109: in runner
    function_to_benchmark(*args, **kwargs)
tests/performance/test_benchmarks.py:47: in clustering_func
    return analyzer.cluster_data(
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1064: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1446: in fit
    X = validate_data(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2944: in validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1107: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:120: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176, -0.97725852],
       [ 0.       ...176, -0.97725852],
       [ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176,  1.02327069]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:169: ValueError
____________ TestClusteringBenchmarks.test_hierarchical_performance ____________

self = <test_benchmarks.TestClusteringBenchmarks object at 0x7f704edd50>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f67526450>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_hierarchical_performance(self, benchmark, large_dataset):
        """Benchmark für Hierarchical Clustering."""
        analyzer = ClusteringAnalyzer()
    
        feature_extractor = FeatureExtractor()
        features = feature_extractor.extract_features(large_dataset)
    
        def clustering_func():
            return analyzer.cluster_data(
                features, algorithm="hierarchical", n_clusters=5
            )
    
>       result = benchmark(clustering_func)

tests/performance/test_benchmarks.py:71: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:156: in __call__
    return self._raw(function_to_benchmark, *args, **kwargs)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:180: in _raw
    duration, iterations, loops_range = self._calibrate_timer(runner)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:318: in _calibrate_timer
    duration = runner(loops_range)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:109: in runner
    function_to_benchmark(*args, **kwargs)
tests/performance/test_benchmarks.py:67: in clustering_func
    return analyzer.cluster_data(
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1064: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1446: in fit
    X = validate_data(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2944: in validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1107: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:120: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176, -0.97725852],
       [ 0.       ...176, -0.97725852],
       [ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176,  1.02327069]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:169: ValueError
_____________ TestClusteringBenchmarks.test_clustering_scalability _____________

self = <test_benchmarks.TestClusteringBenchmarks object at 0x7f704ee3d0>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f68c6a690>

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_clustering_scalability(self, benchmark):
        """Test Skalierbarkeit mit verschiedenen Datengrößen."""
        sizes = [1000, 5000, 10000, 20000]
        times = []
    
        for size in sizes:
            # Generiere Test-Daten
            X = np.random.randn(size, 20)
            analyzer = ClusteringAnalyzer()
    
            def clustering_func():
                return analyzer.cluster_data(X, algorithm="kmeans", n_clusters=5)
    
            result = benchmark(clustering_func)
>           times.append(result.stats.mean)
E           AttributeError: 'numpy.ndarray' object has no attribute 'stats'

tests/performance/test_benchmarks.py:93: AttributeError
________ TestDataProcessingBenchmarks.test_data_processing_performance _________

self = <test_benchmarks.TestDataProcessingBenchmarks object at 0x7f704eea50>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f6555a2d0>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_data_processing_performance(self, benchmark, large_dataset):
        """Benchmark für Datenverarbeitung."""
        processor = WiFiDataProcessor()
    
        def processing_func():
            return processor.process_data(large_dataset)
    
        result = benchmark(processing_func)
    
        # Datenverarbeitung sollte schnell sein
>       assert result.stats.mean < 1.0

tests/performance/test_benchmarks.py:121: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self =                timestamp  device_id  ...  bytes_transferred  processed_timestamp
0    2024-01-01 00:00:00  device_51  ...01 02:46:38
9999 2024-01-01 02:46:39   device_7  ...         594.132395  2024-01-01 02:46:39

[10000 rows x 12 columns]
name = 'stats'

    @final
    def __getattr__(self, name: str):
        """
        After regular attribute access, try looking up the name
        This allows simpler access to columns for interactive use.
        """
        # Note: obj.x will always call obj.__getattribute__('x') prior to
        # calling obj.__getattr__('x').
        if (
            name not in self._internal_names_set
            and name not in self._metadata
            and name not in self._accessors
            and self._info_axis._can_hold_identifiers_and_holds_name(name)
        ):
            return self[name]
>       return object.__getattribute__(self, name)
E       AttributeError: 'DataFrame' object has no attribute 'stats'

.venv/lib/python3.11/site-packages/pandas/core/generic.py:6293: AttributeError
_______ TestDataProcessingBenchmarks.test_feature_extraction_performance _______

self = <test_benchmarks.TestDataProcessingBenchmarks object at 0x7f704ef0d0>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f937d4e90>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_feature_extraction_performance(self, benchmark, large_dataset):
        """Benchmark für Feature-Extraktion."""
        extractor = FeatureExtractor()
    
        def extraction_func():
            return extractor.extract_features(large_dataset)
    
        result = benchmark(extraction_func)
    
        # Feature-Extraktion sollte effizient sein
>       assert result.stats.mean < 2.0
E       AttributeError: 'numpy.ndarray' object has no attribute 'stats'

tests/performance/test_benchmarks.py:136: AttributeError
________ TestDataProcessingBenchmarks.test_feature_scaling_performance _________

self = <test_benchmarks.TestDataProcessingBenchmarks object at 0x7f704eee10>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f6a5dd850>

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_feature_scaling_performance(self, benchmark):
        """Benchmark für Feature-Skalierung."""
        extractor = FeatureExtractor()
    
        # Große Feature-Matrix
        features = np.random.randn(50000, 100)
    
        def scaling_func():
            return extractor.scale_features(features)
    
        result = benchmark(scaling_func)
    
        # Skalierung sollte sehr schnell sein
>       assert result.stats.mean < 0.5
E       AttributeError: 'numpy.ndarray' object has no attribute 'stats'

tests/performance/test_benchmarks.py:154: AttributeError
_________ TestClassificationBenchmarks.test_random_forest_performance __________

self = <test_benchmarks.TestClassificationBenchmarks object at 0x7f704ef690>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f6613c710>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_random_forest_performance(self, benchmark, large_dataset):
        """Benchmark für Random Forest Klassifikation."""
        classifier = DeviceClassifier()
    
        # Features und Labels generieren
        feature_extractor = FeatureExtractor()
        features = feature_extractor.extract_features(large_dataset)
        labels = np.random.randint(0, 5, len(features))
    
        def classification_func():
            classifier.train(features, labels)
            return classifier.predict(features)
    
        result = benchmark(classification_func)
    
        # Random Forest sollte effizient sein
>       assert result.stats.mean < 3.0
E       AttributeError: 'numpy.ndarray' object has no attribute 'stats'

tests/performance/test_benchmarks.py:179: AttributeError
______________ TestClassificationBenchmarks.test_svm_performance _______________

self = <test_benchmarks.TestClassificationBenchmarks object at 0x7f704efa10>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f6911f2d0>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_svm_performance(self, benchmark, large_dataset):
        """Benchmark für SVM Klassifikation."""
        classifier = DeviceClassifier(algorithm="svm")
    
        feature_extractor = FeatureExtractor()
        features = feature_extractor.extract_features(large_dataset)
        labels = np.random.randint(0, 5, len(features))
    
        def classification_func():
            classifier.train(features, labels)
            return classifier.predict(features)
    
>       result = benchmark(classification_func)

tests/performance/test_benchmarks.py:196: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:156: in __call__
    return self._raw(function_to_benchmark, *args, **kwargs)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:180: in _raw
    duration, iterations, loops_range = self._calibrate_timer(runner)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:318: in _calibrate_timer
    duration = runner(loops_range)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:109: in runner
    function_to_benchmark(*args, **kwargs)
tests/performance/test_benchmarks.py:193: in classification_func
    classifier.train(features, labels)
wlan_tool/analysis/device_classification.py:64: in train
    self.model.fit(X, y)
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/svm/_base.py:196: in fit
    X, y = validate_data(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2961: in validate_data
    X, y = check_X_y(X, y, **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1370: in check_X_y
    X = check_array(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1107: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:120: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176, -0.97725852],
       [ 0.       ...176, -0.97725852],
       [ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176,  1.02327069]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           SVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:169: ValueError
______________ TestMemoryBenchmarks.test_memory_usage_clustering _______________

self = <test_benchmarks.TestMemoryBenchmarks object at 0x7f704f8050>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f691ed2d0>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    @pytest.mark.memory
    def test_memory_usage_clustering(self, benchmark, large_dataset):
        """Benchmark für Speichernutzung beim Clustering."""
        analyzer = ClusteringAnalyzer()
        feature_extractor = FeatureExtractor()
    
        def memory_intensive_func():
            # Features extrahieren
            features = feature_extractor.extract_features(large_dataset)
    
            # Clustering durchführen
            labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)
    
            # Zusätzliche Berechnungen
            unique_labels = np.unique(labels)
            cluster_sizes = [np.sum(labels == label) for label in unique_labels]
    
            return {
                "n_clusters": len(unique_labels),
                "cluster_sizes": cluster_sizes,
                "features_shape": features.shape,
            }
    
>       result = benchmark(memory_intensive_func)

tests/performance/test_benchmarks.py:231: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:156: in __call__
    return self._raw(function_to_benchmark, *args, **kwargs)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:180: in _raw
    duration, iterations, loops_range = self._calibrate_timer(runner)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:318: in _calibrate_timer
    duration = runner(loops_range)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:109: in runner
    function_to_benchmark(*args, **kwargs)
tests/performance/test_benchmarks.py:219: in memory_intensive_func
    labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1064: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1446: in fit
    X = validate_data(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2944: in validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1107: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:120: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176, -0.97725852],
       [ 0.       ...176, -0.97725852],
       [ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176,  1.02327069]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:169: ValueError
_____________ TestMemoryBenchmarks.test_memory_usage_large_dataset _____________

self = <test_benchmarks.TestMemoryBenchmarks object at 0x7f704f8490>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f69180090>

    @pytest.mark.benchmark
    @pytest.mark.performance
    @pytest.mark.memory
    def test_memory_usage_large_dataset(self, benchmark):
        """Benchmark für Speichernutzung mit sehr großen Datensätzen."""
        # Sehr großer Datensatz
        n_samples = 100000
        n_features = 50
    
        def large_dataset_func():
            # Große Daten generieren
            X = np.random.randn(n_samples, n_features)
    
            # Clustering mit reduzierter Komplexität
            from sklearn.cluster import MiniBatchKMeans
    
            kmeans = MiniBatchKMeans(n_clusters=10, batch_size=1000)
            labels = kmeans.fit_predict(X)
    
            return {
                "n_samples": n_samples,
                "n_features": n_features,
                "n_clusters": len(np.unique(labels)),
            }
    
        result = benchmark(large_dataset_func)
    
        # Auch bei großen Datensätzen sollte es in angemessener Zeit laufen
>       assert result.stats.mean < 10.0
E       AttributeError: 'dict' object has no attribute 'stats'

tests/performance/test_benchmarks.py:265: AttributeError
________ TestConcurrentBenchmarks.test_parallel_processing_performance _________

self = <test_benchmarks.TestConcurrentBenchmarks object at 0x7f704f8c10>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f6920fdd0>

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_parallel_processing_performance(self, benchmark):
        """Benchmark für parallele Verarbeitung."""
        import threading
        from concurrent.futures import ThreadPoolExecutor
    
        def process_chunk(chunk_data):
            """Verarbeitet einen Daten-Chunk."""
            analyzer = ClusteringAnalyzer()
            return analyzer.cluster_data(chunk_data, algorithm="kmeans", n_clusters=3)
    
        def parallel_processing_func():
            # Daten in Chunks aufteilen
            n_chunks = 4
            chunk_size = 2500
            X = np.random.randn(n_chunks * chunk_size, 20)
            chunks = [X[i * chunk_size : (i + 1) * chunk_size] for i in range(n_chunks)]
    
            # Parallele Verarbeitung
            with ThreadPoolExecutor(max_workers=n_chunks) as executor:
                futures = [executor.submit(process_chunk, chunk) for chunk in chunks]
                results = [future.result() for future in futures]
    
            return results
    
        result = benchmark(parallel_processing_func)
    
        # Parallele Verarbeitung sollte effizienter sein
>       assert result.stats.mean < 3.0
E       AttributeError: 'list' object has no attribute 'stats'

tests/performance/test_benchmarks.py:301: AttributeError
__________________ TestIOBenchmarks.test_file_io_performance ___________________

self = <test_benchmarks.TestIOBenchmarks object at 0x7f704f9350>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f661b3950>
temp_dir = PosixPath('/tmp/tmpnl62swag')

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_file_io_performance(self, benchmark, temp_dir):
        """Benchmark für Datei-I/O."""
        import pickle
    
        # Große Daten generieren
        large_data = np.random.randn(10000, 50)
        file_path = temp_dir / "test_data.pkl"
    
        def io_func():
            # Speichern
            with open(file_path, "wb") as f:
                pickle.dump(large_data, f)
    
            # Laden
            with open(file_path, "rb") as f:
                loaded_data = pickle.load(f)
    
            return loaded_data.shape
    
        result = benchmark(io_func)
    
        # I/O sollte schnell sein
>       assert result.stats.mean < 1.0
E       AttributeError: 'tuple' object has no attribute 'stats'

tests/performance/test_benchmarks.py:332: AttributeError
___________________ TestIOBenchmarks.test_csv_io_performance ___________________

self = <test_benchmarks.TestIOBenchmarks object at 0x7f704f9950>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f69174250>
temp_dir = PosixPath('/tmp/tmpd6ufd_0c')
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_csv_io_performance(self, benchmark, temp_dir, large_dataset):
        """Benchmark für CSV-I/O."""
        csv_path = temp_dir / "test_data.csv"
    
        def csv_io_func():
            # Speichern
            large_dataset.to_csv(csv_path, index=False)
    
            # Laden
            loaded_data = pd.read_csv(csv_path)
    
            return loaded_data.shape
    
        result = benchmark(csv_io_func)
    
        # CSV-I/O kann langsamer sein
>       assert result.stats.mean < 2.0
E       AttributeError: 'tuple' object has no attribute 'stats'

tests/performance/test_benchmarks.py:353: AttributeError
_________________ TestMemoryUsage.test_memory_usage_clustering _________________

self = <test_memory_profiling.TestMemoryUsage object at 0x7f70517790>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.memory
    @pytest.mark.performance
    def test_memory_usage_clustering(self, large_dataset):
        """Test Speichernutzung beim Clustering."""
        process = psutil.Process(os.getpid())
        memory_before = process.memory_info().rss / 1024 / 1024
    
        analyzer = ClusteringAnalyzer()
        feature_extractor = FeatureExtractor()
    
        # Features extrahieren
        features = feature_extractor.extract_features(large_dataset)
        memory_after_features = process.memory_info().rss / 1024 / 1024
    
        # Clustering durchführen
>       labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)

tests/performance/test_memory_profiling.py:77: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1064: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1446: in fit
    X = validate_data(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2944: in validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1107: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:120: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176, -0.97725852],
       [ 0.       ...176, -0.97725852],
       [ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176,  1.02327069]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:169: ValueError
______________ TestMemoryProfiling.test_detailed_memory_profiling ______________

self = <test_memory_profiling.TestMemoryProfiling object at 0x7f705251d0>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.memory
    @pytest.mark.performance
    def test_detailed_memory_profiling(self, large_dataset):
        """Detailliertes Memory-Profiling der WLAN-Analyse."""
        from memory_profiler import memory_usage
    
        def analyze_wifi_data():
            """WLAN-Datenanalyse mit Memory-Tracking."""
            processor = WiFiDataProcessor()
            extractor = FeatureExtractor()
            analyzer = ClusteringAnalyzer()
    
            # 1. Daten verarbeiten
            processed_data = processor.process_data(large_dataset)
    
            # 2. Features extrahieren
            features = extractor.extract_features(processed_data)
    
            # 3. Clustering
            labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)
    
            # 4. Ergebnisse zusammenfassen
            unique_labels = np.unique(labels)
            cluster_sizes = [np.sum(labels == label) for label in unique_labels]
    
            return {
                "n_clusters": len(unique_labels),
                "cluster_sizes": cluster_sizes,
                "features_shape": features.shape,
            }
    
        # Memory-Usage während der Ausführung messen
>       mem_usage = memory_usage(analyze_wifi_data, interval=0.1)

tests/performance/test_memory_profiling.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.11/site-packages/memory_profiler.py:379: in memory_usage
    returned = f(*args, **kw)
tests/performance/test_memory_profiling.py:208: in analyze_wifi_data
    labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1064: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1446: in fit
    X = validate_data(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2944: in validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1107: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:120: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[-1.15579349,  0.        ,  0.        , ...,  0.        ,
         0.15614176, -0.97725852],
       [-1.1557934...176, -0.97725852],
       [ 1.35680105,  0.        ,  0.        , ...,  0.        ,
         0.15614176,  1.02327069]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:169: ValueError
_________ TestMemoryProfiling.test_memory_profiling_garbage_collection _________

self = <test_memory_profiling.TestMemoryProfiling object at 0x7f70525d50>

    @pytest.mark.memory
    @pytest.mark.performance
    def test_memory_profiling_garbage_collection(self):
        """Test Memory-Profiling mit Garbage Collection."""
        import gc
    
        process = psutil.Process(os.getpid())
    
        def create_large_objects():
            """Erstellt große Objekte und führt Garbage Collection durch."""
            # Große Objekte erstellen
            large_arrays = [np.random.randn(1000, 100) for _ in range(10)]
    
            # Memory vor GC
            memory_before_gc = process.memory_info().rss / 1024 / 1024
    
            # Garbage Collection
            gc.collect()
    
            # Memory nach GC
            memory_after_gc = process.memory_info().rss / 1024 / 1024
    
            return memory_before_gc, memory_after_gc
    
        memory_before, memory_after = create_large_objects()
        memory_freed = memory_before - memory_after
    
        # Garbage Collection sollte Speicher freigeben
>       assert memory_freed > 0, "Garbage Collection hat keinen Speicher freigegeben"
E       AssertionError: Garbage Collection hat keinen Speicher freigegeben
E       assert 0.0 > 0

tests/performance/test_memory_profiling.py:302: AssertionError
_____________ TestMemoryOptimization.test_memory_usage_data_types ______________

self = <test_memory_profiling.TestMemoryOptimization object at 0x7f70526410>

    @pytest.mark.memory
    @pytest.mark.performance
    def test_memory_usage_data_types(self):
        """Test Speichernutzung verschiedener Datentypen."""
        process = psutil.Process(os.getpid())
    
        # Test verschiedene Datentypen
        data_types = [
            ("float32", np.float32),
            ("float64", np.float64),
            ("int32", np.int32),
            ("int64", np.int64),
        ]
    
        memory_usage = {}
    
        for dtype_name, dtype in data_types:
            memory_before = process.memory_info().rss / 1024 / 1024
    
            # Große Array mit spezifischem Datentyp
            array = np.random.randn(10000, 100).astype(dtype)
    
            memory_after = process.memory_info().rss / 1024 / 1024
            memory_usage[dtype_name] = memory_after - memory_before
    
        # float32 sollte weniger Speicher verwenden als float64
        assert memory_usage["float32"] < memory_usage["float64"]
    
        # int32 sollte weniger Speicher verwenden als int64
>       assert memory_usage["int32"] < memory_usage["int64"]
E       assert 0.0 < 0.0

tests/performance/test_memory_profiling.py:408: AssertionError
__________________ TestDataValidator.test_validate_valid_data __________________

self = <test_data_processing.TestDataValidator object at 0x7f70549550>
sample_wifi_data =               timestamp device_id  ...  packet_count  bytes_transferred
0   2024-01-01 00:00:00  device_3  ...        ...15         206.754596
999 2024-01-01 16:39:00  device_1  ...           103         554.365485

[1000 rows x 11 columns]

    def test_validate_valid_data(self, sample_wifi_data):
        """Test Validierung gültiger Daten."""
        validator = DataValidator()
        is_valid, errors = validator.validate(sample_wifi_data)
    
>       assert is_valid
E       assert False

tests/unit/test_data_processing.py:178: AssertionError
_____________________ TestClusteringModel.test_fit_kmeans ______________________

self = <test_ml_models.TestClusteringModel object at 0x7f7011f850>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])

    def test_fit_kmeans(self, sample_features):
        """Test K-Means Clustering."""
        model = ClusteringModel(algorithm="kmeans", n_clusters=3)
>       model.fit(sample_features)

tests/unit/test_ml_models.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/clustering_model.py:53: in fit
    self.model = self._create_model()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.clustering_model.ClusteringModel object at 0x7f65a83390>
n_clusters = 3

    def _create_model(self, n_clusters: Optional[int] = None) -> Any:
        """Erstellt das Clustering-Modell."""
        if self.algorithm == 'kmeans':
            n_clusters = n_clusters or self.kwargs.get('n_clusters', 5)
>           return KMeans(n_clusters=n_clusters, random_state=42, **self.kwargs)
E           TypeError: sklearn.cluster._kmeans.KMeans() got multiple values for keyword argument 'n_clusters'

wlan_tool/ml_models/clustering_model.py:36: TypeError
__________________ TestClusteringModel.test_predict_after_fit __________________

self = <test_ml_models.TestClusteringModel object at 0x7f70130a10>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])

    def test_predict_after_fit(self, sample_features):
        """Test Vorhersage nach Training."""
        model = ClusteringModel(algorithm="kmeans", n_clusters=3)
>       model.fit(sample_features)

tests/unit/test_ml_models.py:52: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/clustering_model.py:53: in fit
    self.model = self._create_model()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.clustering_model.ClusteringModel object at 0x7f66e68d90>
n_clusters = 3

    def _create_model(self, n_clusters: Optional[int] = None) -> Any:
        """Erstellt das Clustering-Modell."""
        if self.algorithm == 'kmeans':
            n_clusters = n_clusters or self.kwargs.get('n_clusters', 5)
>           return KMeans(n_clusters=n_clusters, random_state=42, **self.kwargs)
E           TypeError: sklearn.cluster._kmeans.KMeans() got multiple values for keyword argument 'n_clusters'

wlan_tool/ml_models/clustering_model.py:36: TypeError
_________________ TestClusteringModel.test_get_cluster_centers _________________

self = <test_ml_models.TestClusteringModel object at 0x7f70131150>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])

    def test_get_cluster_centers(self, sample_features):
        """Test Cluster-Zentren abrufen."""
        model = ClusteringModel(algorithm="kmeans", n_clusters=3)
>       model.fit(sample_features)

tests/unit/test_ml_models.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/clustering_model.py:53: in fit
    self.model = self._create_model()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.clustering_model.ClusteringModel object at 0x7f68f74210>
n_clusters = 3

    def _create_model(self, n_clusters: Optional[int] = None) -> Any:
        """Erstellt das Clustering-Modell."""
        if self.algorithm == 'kmeans':
            n_clusters = n_clusters or self.kwargs.get('n_clusters', 5)
>           return KMeans(n_clusters=n_clusters, random_state=42, **self.kwargs)
E           TypeError: sklearn.cluster._kmeans.KMeans() got multiple values for keyword argument 'n_clusters'

wlan_tool/ml_models/clustering_model.py:36: TypeError
_________________ TestClusteringModel.test_evaluate_clustering _________________

self = <test_ml_models.TestClusteringModel object at 0x7f70131890>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])

    def test_evaluate_clustering(self, sample_features):
        """Test Clustering-Evaluation."""
        model = ClusteringModel(algorithm="kmeans", n_clusters=3)
>       model.fit(sample_features)

tests/unit/test_ml_models.py:73: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/clustering_model.py:53: in fit
    self.model = self._create_model()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.clustering_model.ClusteringModel object at 0x7f6a319c50>
n_clusters = 3

    def _create_model(self, n_clusters: Optional[int] = None) -> Any:
        """Erstellt das Clustering-Modell."""
        if self.algorithm == 'kmeans':
            n_clusters = n_clusters or self.kwargs.get('n_clusters', 5)
>           return KMeans(n_clusters=n_clusters, random_state=42, **self.kwargs)
E           TypeError: sklearn.cluster._kmeans.KMeans() got multiple values for keyword argument 'n_clusters'

wlan_tool/ml_models/clustering_model.py:36: TypeError
__________________ TestClusteringModel.test_invalid_algorithm __________________

self = <test_ml_models.TestClusteringModel object at 0x7f70131f50>

    def test_invalid_algorithm(self):
        """Test mit ungültigem Algorithmus."""
>       with pytest.raises(ValueError, match="Unsupported algorithm"):
E       Failed: DID NOT RAISE <class 'ValueError'>

tests/unit/test_ml_models.py:86: Failed
______________ TestClusteringModel.test_hyperparameter_validation ______________

self = <test_ml_models.TestClusteringModel object at 0x7f70132610>

    def test_hyperparameter_validation(self):
        """Test Hyperparameter-Validierung."""
        # Ungültige n_clusters
>       with pytest.raises(ValueError, match="n_clusters must be positive"):
E       Failed: DID NOT RAISE <class 'ValueError'>

tests/unit/test_ml_models.py:92: Failed
________________ TestClassificationModel.test_cross_validation _________________

self = <test_ml_models.TestClassificationModel object at 0x7f70145e90>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
sample_labels = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])

    def test_cross_validation(self, sample_features, sample_labels):
        """Test Cross-Validation."""
        model = ClassificationModel(algorithm="random_forest", n_estimators=10)
    
>       cv_scores = model.cross_validate(sample_features, sample_labels, cv=3)

tests/unit/test_ml_models.py:177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f6920ec10>
X = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
y = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])
cv = 3

    def cross_validate(self, X: np.ndarray, y: np.ndarray, cv: int = 5) -> Dict[str, List[float]]:
        """Führt Cross-Validation durch."""
        if not self.is_fitted:
>           raise ValueError("Model must be fitted first")
E           ValueError: Model must be fitted first

wlan_tool/ml_models/classification_model.py:103: ValueError
_________________ TestEnsembleModel.test_fit_voting_classifier _________________

self = <test_ml_models.TestEnsembleModel object at 0x7f70146290>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
sample_labels = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])

    def test_fit_voting_classifier(self, sample_features, sample_labels):
        """Test Voting Classifier Training."""
        model = EnsembleModel(
            algorithm="voting",
            estimators=[
                ("rf", ClassificationModel(algorithm="random_forest")),
                ("svm", ClassificationModel(algorithm="svm")),
            ],
        )
>       model.fit(sample_features, sample_labels)

tests/unit/test_ml_models.py:215: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/ensemble_model.py:62: in fit
    self.model = self._create_model(estimators=estimators)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.ensemble_model.EnsembleModel object at 0x7f67edb410>
base_estimator = None
estimators = [('rf', <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f67ed8190>), ('svm', <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f67edbcd0>)]

    def _create_model(self, base_estimator=None, estimators=None) -> Any:
        """Erstellt das Ensemble-Modell."""
        if self.algorithm == 'voting':
            if estimators is None:
                raise ValueError("Voting requires estimators list")
>           return VotingClassifier(estimators=estimators, **self.kwargs)
E           TypeError: sklearn.ensemble._voting.VotingClassifier() got multiple values for keyword argument 'estimators'

wlan_tool/ml_models/ensemble_model.py:36: TypeError
______________________ TestEnsembleModel.test_fit_bagging ______________________

self = <test_ml_models.TestEnsembleModel object at 0x7f70145490>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
sample_labels = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])

    def test_fit_bagging(self, sample_features, sample_labels):
        """Test Bagging Training."""
        model = EnsembleModel(
            algorithm="bagging",
            base_estimator=ClassificationModel(algorithm="random_forest"),
            n_estimators=5,
        )
>       model.fit(sample_features, sample_labels)

tests/unit/test_ml_models.py:227: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/ensemble_model.py:67: in fit
    self.model = self._create_model(base_estimator=base_estimator)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.ensemble_model.EnsembleModel object at 0x7f66189490>
base_estimator = <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f6618a2d0>
estimators = None

    def _create_model(self, base_estimator=None, estimators=None) -> Any:
        """Erstellt das Ensemble-Modell."""
        if self.algorithm == 'voting':
            if estimators is None:
                raise ValueError("Voting requires estimators list")
            return VotingClassifier(estimators=estimators, **self.kwargs)
        elif self.algorithm == 'bagging':
            if base_estimator is None:
                raise ValueError("Bagging requires base_estimator")
>           return BaggingClassifier(base_estimator=base_estimator, **self.kwargs)
E           TypeError: sklearn.ensemble._bagging.BaggingClassifier() got multiple values for keyword argument 'base_estimator'

wlan_tool/ml_models/ensemble_model.py:40: TypeError
_____________________ TestEnsembleModel.test_fit_boosting ______________________

self = <test_ml_models.TestEnsembleModel object at 0x7f70146790>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
sample_labels = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])

    def test_fit_boosting(self, sample_features, sample_labels):
        """Test Boosting Training."""
        model = EnsembleModel(
            algorithm="boosting",
            base_estimator=ClassificationModel(algorithm="random_forest"),
            n_estimators=5,
        )
>       model.fit(sample_features, sample_labels)

tests/unit/test_ml_models.py:239: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/ensemble_model.py:67: in fit
    self.model = self._create_model(base_estimator=base_estimator)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.ensemble_model.EnsembleModel object at 0x7f68d4b9d0>
base_estimator = <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f68d49e50>
estimators = None

    def _create_model(self, base_estimator=None, estimators=None) -> Any:
        """Erstellt das Ensemble-Modell."""
        if self.algorithm == 'voting':
            if estimators is None:
                raise ValueError("Voting requires estimators list")
            return VotingClassifier(estimators=estimators, **self.kwargs)
        elif self.algorithm == 'bagging':
            if base_estimator is None:
                raise ValueError("Bagging requires base_estimator")
            return BaggingClassifier(base_estimator=base_estimator, **self.kwargs)
        elif self.algorithm == 'boosting':
            if base_estimator is None:
                raise ValueError("Boosting requires base_estimator")
>           return AdaBoostClassifier(base_estimator=base_estimator, **self.kwargs)
E           TypeError: sklearn.ensemble._weight_boosting.AdaBoostClassifier() got multiple values for keyword argument 'base_estimator'

wlan_tool/ml_models/ensemble_model.py:44: TypeError
___________________ TestEnsembleModel.test_predict_ensemble ____________________

self = <test_ml_models.TestEnsembleModel object at 0x7f70146b10>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
sample_labels = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])

    def test_predict_ensemble(self, sample_features, sample_labels):
        """Test Ensemble-Vorhersage."""
        model = EnsembleModel(
            algorithm="voting",
            estimators=[
                ("rf", ClassificationModel(algorithm="random_forest")),
                ("svm", ClassificationModel(algorithm="svm")),
            ],
        )
>       model.fit(sample_features, sample_labels)

tests/unit/test_ml_models.py:253: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/ensemble_model.py:62: in fit
    self.model = self._create_model(estimators=estimators)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.ensemble_model.EnsembleModel object at 0x7f69352650>
base_estimator = None
estimators = [('rf', <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f6a4f7110>), ('svm', <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f6a4f6f10>)]

    def _create_model(self, base_estimator=None, estimators=None) -> Any:
        """Erstellt das Ensemble-Modell."""
        if self.algorithm == 'voting':
            if estimators is None:
                raise ValueError("Voting requires estimators list")
>           return VotingClassifier(estimators=estimators, **self.kwargs)
E           TypeError: sklearn.ensemble._voting.VotingClassifier() got multiple values for keyword argument 'estimators'

wlan_tool/ml_models/ensemble_model.py:36: TypeError
___________________ TestEnsembleModel.test_evaluate_ensemble ___________________

self = <test_ml_models.TestEnsembleModel object at 0x7f70146e90>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
sample_labels = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])

    def test_evaluate_ensemble(self, sample_features, sample_labels):
        """Test Ensemble-Evaluation."""
        model = EnsembleModel(
            algorithm="voting",
            estimators=[
                ("rf", ClassificationModel(algorithm="random_forest")),
                ("svm", ClassificationModel(algorithm="svm")),
            ],
        )
>       model.fit(sample_features, sample_labels)

tests/unit/test_ml_models.py:269: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/ensemble_model.py:62: in fit
    self.model = self._create_model(estimators=estimators)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.ensemble_model.EnsembleModel object at 0x7f68d77350>
base_estimator = None
estimators = [('rf', <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f68d741d0>), ('svm', <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f68d77390>)]

    def _create_model(self, base_estimator=None, estimators=None) -> Any:
        """Erstellt das Ensemble-Modell."""
        if self.algorithm == 'voting':
            if estimators is None:
                raise ValueError("Voting requires estimators list")
>           return VotingClassifier(estimators=estimators, **self.kwargs)
E           TypeError: sklearn.ensemble._voting.VotingClassifier() got multiple values for keyword argument 'estimators'

wlan_tool/ml_models/ensemble_model.py:36: TypeError
___________ TestEnsembleModel.test_individual_estimator_performance ____________

self = <test_ml_models.TestEnsembleModel object at 0x7f70147390>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
sample_labels = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])

    def test_individual_estimator_performance(self, sample_features, sample_labels):
        """Test Performance einzelner Estimators."""
        model = EnsembleModel(
            algorithm="voting",
            estimators=[
                ("rf", ClassificationModel(algorithm="random_forest")),
                ("svm", ClassificationModel(algorithm="svm")),
            ],
        )
>       model.fit(sample_features, sample_labels)

tests/unit/test_ml_models.py:287: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/ensemble_model.py:62: in fit
    self.model = self._create_model(estimators=estimators)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.ensemble_model.EnsembleModel object at 0x7f68d4a390>
base_estimator = None
estimators = [('rf', <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f68d49f90>), ('svm', <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f68d49450>)]

    def _create_model(self, base_estimator=None, estimators=None) -> Any:
        """Erstellt das Ensemble-Modell."""
        if self.algorithm == 'voting':
            if estimators is None:
                raise ValueError("Voting requires estimators list")
>           return VotingClassifier(estimators=estimators, **self.kwargs)
E           TypeError: sklearn.ensemble._voting.VotingClassifier() got multiple values for keyword argument 'estimators'

wlan_tool/ml_models/ensemble_model.py:36: TypeError
___________________ TestEnsembleModel.test_invalid_algorithm ___________________

self = <test_ml_models.TestEnsembleModel object at 0x7f70147990>

    def test_invalid_algorithm(self):
        """Test mit ungültigem Ensemble-Algorithmus."""
>       with pytest.raises(ValueError, match="Unsupported ensemble algorithm"):
E       Failed: DID NOT RAISE <class 'ValueError'>

tests/unit/test_ml_models.py:298: Failed
___________________ TestEnsembleModel.test_empty_estimators ____________________

self = <test_ml_models.TestEnsembleModel object at 0x7f70147f90>

    def test_empty_estimators(self):
        """Test mit leerer Estimator-Liste."""
>       with pytest.raises(ValueError, match="At least one estimator required"):
E       Failed: DID NOT RAISE <class 'ValueError'>

tests/unit/test_ml_models.py:303: Failed
__________________ TestModelPersistence.test_save_load_model ___________________

self = <test_ml_models.TestModelPersistence object at 0x7f70148710>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
sample_labels = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])
temp_dir = PosixPath('/tmp/tmp1rvzl51o')

    def test_save_load_model(self, sample_features, sample_labels, temp_dir):
        """Test Speichern und Laden von Modellen."""
        # Training
        model = ClassificationModel(algorithm="random_forest", n_estimators=10)
        model.fit(sample_features, sample_labels)
    
        # Speichern
        model_path = temp_dir / "test_model.pkl"
>       model.save(model_path)
E       AttributeError: 'ClassificationModel' object has no attribute 'save'

tests/unit/test_ml_models.py:318: AttributeError
_________________ TestModelPersistence.test_save_load_ensemble _________________

self = <test_ml_models.TestModelPersistence object at 0x7f70148d50>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
sample_labels = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])
temp_dir = PosixPath('/tmp/tmpny45qwmn')

    def test_save_load_ensemble(self, sample_features, sample_labels, temp_dir):
        """Test Speichern und Laden von Ensemble-Modellen."""
        # Training
        model = EnsembleModel(
            algorithm="voting",
            estimators=[
                ("rf", ClassificationModel(algorithm="random_forest")),
                ("svm", ClassificationModel(algorithm="svm")),
            ],
        )
>       model.fit(sample_features, sample_labels)

tests/unit/test_ml_models.py:344: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/ensemble_model.py:62: in fit
    self.model = self._create_model(estimators=estimators)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.ensemble_model.EnsembleModel object at 0x7f691ede90>
base_estimator = None
estimators = [('rf', <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f691ee290>), ('svm', <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f691edcd0>)]

    def _create_model(self, base_estimator=None, estimators=None) -> Any:
        """Erstellt das Ensemble-Modell."""
        if self.algorithm == 'voting':
            if estimators is None:
                raise ValueError("Voting requires estimators list")
>           return VotingClassifier(estimators=estimators, **self.kwargs)
E           TypeError: sklearn.ensemble._voting.VotingClassifier() got multiple values for keyword argument 'estimators'

wlan_tool/ml_models/ensemble_model.py:36: TypeError
=============================== warnings summary ===============================
tests/conftest.py:12
  /home/pi/hacking/tests/conftest.py:12: DeprecationWarning: 
  Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),
  (to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)
  but was not found to be installed on your system.
  If this would cause problems for you,
  please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466
          
    import pandas as pd

pytest/test_integration.py:192
  /home/pi/hacking/pytest/test_integration.py:192: PytestUnknownMarkWarning: Unknown pytest.mark.network - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.network

plugins/clustering_advanced/tests/test_clustering_advanced.py::TestAdvancedClusteringPlugin::test_optics_clustering
  /home/pi/hacking/.venv/lib/python3.11/site-packages/sklearn/cluster/_optics.py:664: UserWarning: All reachability values are inf. Set a larger max_eps or all data will be considered outliers.
    warnings.warn(

plugins/clustering_advanced/tests/test_clustering_advanced.py::TestAdvancedClusteringPlugin::test_hdbscan_clustering
plugins/clustering_advanced/tests/test_clustering_advanced.py::TestAdvancedClusteringPlugin::test_hdbscan_clustering
  /home/pi/hacking/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.
    warnings.warn(

plugins/clustering_advanced/tests/test_clustering_advanced.py::TestAdvancedClusteringPlugin::test_plugin_run_with_sufficient_data
  /home/pi/hacking/.venv/lib/python3.11/site-packages/sklearn/cluster/_optics.py:664: UserWarning:
  
  All reachability values are inf. Set a larger max_eps or all data will be considered outliers.

plugins/clustering_advanced/tests/test_clustering_advanced.py::TestAdvancedClusteringPlugin::test_plugin_run_with_sufficient_data
plugins/clustering_advanced/tests/test_clustering_advanced.py::TestAdvancedClusteringPlugin::test_plugin_run_with_sufficient_data
  /home/pi/hacking/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:
  
  'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.

plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_model_performance_evaluation
  /home/pi/hacking/.venv/lib/python3.11/site-packages/sklearn/model_selection/_split.py:805: UserWarning:
  
  The least populated class in y has only 4 members, which is less than n_splits=5.

plugins/ensemble_models/tests/test_ensemble_models.py: 66 warnings
  /home/pi/hacking/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:451: DeprecationWarning:
  
  scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.

plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_model_performance_evaluation
plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_model_performance_evaluation
plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_model_performance_evaluation
plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_model_performance_evaluation
plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_model_performance_evaluation
plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_model_performance_evaluation
  /home/pi/hacking/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:
  
  lbfgs failed to converge (status=1):
  STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.
  
  Increase the number of iterations (max_iter) or scale the data as shown in:
      https://scikit-learn.org/stable/modules/preprocessing.html
  Please also refer to the documentation for alternative solver options:
      https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

plugins/ensemble_models/tests/test_ensemble_models.py: 40 warnings
  /home/pi/hacking/.venv/lib/python3.11/site-packages/sklearn/model_selection/_split.py:805: UserWarning:
  
  The least populated class in y has only 3 members, which is less than n_splits=5.

plugins/ensemble_models/tests/test_ensemble_models.py: 24 warnings
  /home/pi/hacking/.venv/lib/python3.11/site-packages/sklearn/model_selection/_split.py:805: UserWarning:
  
  The least populated class in y has only 2 members, which is less than n_splits=5.

pytest/test_capture.py::TestSniffingIntegration::test_sniff_with_writer_mock
  /home/pi/hacking/.venv/lib/python3.11/site-packages/_pytest/threadexception.py:77: PytestUnhandledThreadExceptionWarning:
  
  Exception in thread ChannelHopper
  
  Traceback (most recent call last):
    File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/threading.py", line 1045, in _bootstrap_inner
      self.run()
    File "/home/pi/hacking/wlan_tool/capture/sniffer.py", line 207, in run
      subprocess.run(command, check=True, capture_output=True, text=True)
    File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/subprocess.py", line 550, in run
      stdout, stderr = process.communicate(input, timeout=timeout)
      ^^^^^^^^^^^^^^
  ValueError: not enough values to unpack (expected 2, got 0)

tests/integration/test_end_to_end.py::TestEndToEndWorkflow::test_error_handling_and_recovery
  /home/pi/hacking/wlan_tool/data_processing/wifi_processor.py:45: UserWarning:
  
  Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html

-------------------------------------------------------------------------------------------------- benchmark: 9 tests --------------------------------------------------------------------------------------------------
Name (time in ms)                               Min                   Max                  Mean              StdDev                Median                 IQR            Outliers      OPS            Rounds  Iterations
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
test_file_io_performance                    23.3741 (1.0)        184.2200 (3.53)       138.2119 (2.66)      26.3403 (207.72)     136.8875 (2.64)      22.2443 (152.15)       14;1   7.2353 (0.38)         49           1
test_feature_extraction_performance         51.6512 (2.21)        52.1715 (1.0)         51.8900 (1.0)        0.1268 (1.0)         51.8934 (1.0)        0.1462 (1.0)           5;1  19.2715 (1.0)          16           1
test_data_processing_performance            61.4135 (2.63)       519.4663 (9.96)        89.7363 (1.73)     110.7428 (873.33)      62.8855 (1.21)       1.6989 (11.62)         1;1  11.1438 (0.58)         17           1
test_clustering_scalability                 89.2097 (3.82)       105.2928 (2.02)        97.0417 (1.87)       6.0213 (47.48)       96.0702 (1.85)      11.1579 (76.32)         5;0  10.3048 (0.53)         11           1
test_feature_scaling_performance           153.4808 (6.57)       157.3399 (3.02)       154.4519 (2.98)       1.6391 (12.93)      153.6958 (2.96)       1.4595 (9.98)          1;1   6.4745 (0.34)          5           1
test_parallel_processing_performance       176.7679 (7.56)       230.8540 (4.42)       202.5082 (3.90)      19.4923 (153.72)     198.5335 (3.83)      30.7716 (210.47)        2;0   4.9381 (0.26)          7           1
test_csv_io_performance                    331.5316 (14.18)      339.1681 (6.50)       333.9245 (6.44)       3.0857 (24.33)      333.3146 (6.42)       3.4024 (23.27)         1;0   2.9947 (0.16)          5           1
test_memory_usage_large_dataset            528.7350 (22.62)      731.1921 (14.02)      635.9911 (12.26)    101.3294 (799.09)     657.6920 (12.67)    200.5618 (>1000.0)       2;0   1.5723 (0.08)          5           1
test_random_forest_performance           8,072.3922 (345.36)   8,099.1279 (155.24)   8,085.9249 (155.83)    12.9721 (102.30)   8,087.4667 (155.85)    25.4350 (173.97)        3;0   0.1237 (0.01)          5           1
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Legend:
  Outliers: 1 Standard Deviation from Mean; 1.5 IQR (InterQuartile Range) from 1st Quartile and 3rd Quartile.
  OPS: Operations Per Second, computed as 1 / Mean
=========================== short test summary info ============================
FAILED plugins/reinforcement_learning/tests/test_reinforcement_learning.py::TestReinforcementLearningPlugin::test_environment_observation
FAILED pytest/test_app.py::TestUtilsModule::test_intelligent_vendor_lookup - ...
FAILED pytest/test_app.py::TestAnalysisModule::test_features_for_client_behavior
FAILED pytest/test_app.py::TestAnalysisModule::test_cluster_clients_runs - At...
FAILED pytest/test_app.py::TestAnalysisModule::test_profile_clusters - Attrib...
FAILED pytest/test_capture.py::TestPacketParsing::test_packet_to_event_probe_request
FAILED pytest/test_capture.py::TestPacketParsing::test_packet_to_event_data_frame
FAILED pytest/test_capture.py::TestPacketParsing::test_packet_to_event_with_dhcp
FAILED pytest/test_capture.py::TestChannelHopper::test_channel_hopper_command_failure
FAILED pytest/test_capture.py::TestIEExtraction::test_extract_seq - assert 0 ...
FAILED pytest/test_capture.py::TestErrorHandling::test_packet_to_event_encoding_error
FAILED pytest/test_controllers.py::TestCaptureController::test_select_interface_automatic
FAILED pytest/test_controllers.py::TestCaptureController::test_select_interface_no_interfaces
FAILED pytest/test_controllers.py::TestCaptureController::test_setup_monitor_mode_failure
FAILED pytest/test_controllers.py::TestAnalysisController::test_analysis_controller_initialization
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_inference
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_client_clustering
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_ap_clustering
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_graph_export
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_labeling_ui
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_client_labeling_ui
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_mac_correlation
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_analysis_no_actions
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_analysis_multiple_actions
FAILED pytest/test_controllers.py::TestControllerEdgeCases::test_analysis_controller_empty_state
FAILED pytest/test_controllers.py::TestControllerEdgeCases::test_analysis_controller_with_plugins
FAILED pytest/test_controllers.py::TestControllerIntegration::test_full_analysis_workflow
FAILED pytest/test_error_handling.py::TestLoggingSystem::test_setup_logging
FAILED pytest/test_error_handling.py::TestDatabaseErrorHandling::test_database_connection_error
FAILED pytest/test_error_handling.py::TestDatabaseErrorHandling::test_database_migration_error
FAILED pytest/test_error_handling.py::TestAnalysisErrorHandling::test_client_features_null_state
FAILED pytest/test_error_handling.py::TestAnalysisErrorHandling::test_client_features_invalid_type
FAILED pytest/test_error_handling.py::TestAnalysisErrorHandling::test_clustering_invalid_parameters
FAILED pytest/test_error_handling.py::TestFileSystemErrorHandling::test_csv_export_invalid_path
FAILED pytest/test_error_handling.py::TestFileSystemErrorHandling::test_csv_export_missing_db
FAILED pytest/test_error_handling.py::TestErrorHandlingEdgeCases::test_nested_error_contexts
FAILED pytest/test_integration.py::TestEndToEndWorkflow::test_database_integration
FAILED pytest/test_integration.py::TestEndToEndWorkflow::test_config_integration
FAILED pytest/test_integration.py::TestDataFlow::test_state_persistence - wla...
FAILED pytest/test_integration.py::TestLargeDataset::test_large_dataset_processing
FAILED pytest/test_integration.py::TestErrorRecovery::test_malformed_event_handling
FAILED pytest/test_integration.py::TestMemoryManagement::test_memory_usage_large_state
FAILED pytest/test_integration.py::TestMemoryManagement::test_state_pruning_memory_release
FAILED pytest/test_performance.py::TestAnalysisPerformance::test_clustering_performance
FAILED pytest/test_performance.py::TestAnalysisPerformance::test_inference_performance
FAILED pytest/test_performance.py::TestMemoryPerformance::test_memory_usage_large_state
FAILED pytest/test_performance.py::TestMemoryPerformance::test_memory_cleanup_after_pruning
FAILED pytest/test_performance.py::TestDatabasePerformance::test_database_write_performance
FAILED pytest/test_performance.py::TestDatabasePerformance::test_database_read_performance
FAILED pytest/test_performance.py::TestScalabilityPerformance::test_scalability_with_dataset_size
FAILED pytest/test_presentation.py::TestCLIModule::test_print_client_cluster_results
FAILED pytest/test_presentation.py::TestCLIEdgeCases::test_print_client_cluster_results_empty_data
FAILED pytest/test_presentation.py::TestPerformance::test_large_dataset_handling
FAILED pytest/test_storage.py::TestClientState::test_client_state_update_from_event
FAILED pytest/test_storage.py::TestAPState::test_ap_state_update_from_beacon
FAILED pytest/test_storage.py::TestWifiAnalysisState::test_state_pruning - As...
FAILED pytest/test_storage.py::TestWifiAnalysisState::test_state_ssid_mapping
FAILED pytest/test_storage.py::TestDatabaseModule::test_fetch_events - Attrib...
FAILED pytest/test_storage.py::TestDatabaseModule::test_add_label - Assertion...
FAILED pytest/test_utils.py::TestOUIFunctions::test_lookup_vendor_apple_mac
FAILED pytest/test_utils.py::TestOUIFunctions::test_lookup_vendor_unknown_mac
FAILED pytest/test_utils.py::TestIEParsing::test_parse_ies_vendor_specific - ...
FAILED pytest/test_utils.py::TestIEParsing::test_parse_ies_ht_capabilities - ...
FAILED pytest/test_utils.py::TestUtilityFunctions::test_is_local_admin_mac - ...
FAILED pytest/test_utils.py::TestUtilityFunctions::test_is_valid_bssid - Asse...
FAILED pytest/test_utils.py::TestUtilityFunctions::test_ie_fingerprint_hash
FAILED pytest/test_utils.py::TestUtilityFunctions::test_ie_fingerprint_hash_empty
FAILED pytest/test_utils.py::TestConfigFunctions::test_load_config_default - ...
FAILED pytest/test_utils.py::TestConfigFunctions::test_load_config_specific_profile
FAILED pytest/test_utils.py::TestConfigFunctions::test_load_config_missing_file
FAILED pytest/test_utils.py::TestEdgeCases::test_ie_fingerprint_hash_unicode
FAILED pytest/test_utils.py::TestEdgeCases::test_config_loading_with_invalid_yaml
FAILED tests/integration/test_end_to_end.py::TestEndToEndWorkflow::test_complete_wifi_analysis_workflow
FAILED tests/integration/test_end_to_end.py::TestEndToEndWorkflow::test_plugin_integration_workflow
FAILED tests/integration/test_end_to_end.py::TestEndToEndWorkflow::test_data_pipeline_with_file_io
FAILED tests/integration/test_end_to_end.py::TestEndToEndWorkflow::test_error_handling_and_recovery
FAILED tests/integration/test_end_to_end.py::TestEndToEndWorkflow::test_performance_under_load
FAILED tests/integration/test_end_to_end.py::TestEndToEndWorkflow::test_concurrent_processing
FAILED tests/performance/test_benchmarks.py::TestClusteringBenchmarks::test_kmeans_performance
FAILED tests/performance/test_benchmarks.py::TestClusteringBenchmarks::test_dbscan_performance
FAILED tests/performance/test_benchmarks.py::TestClusteringBenchmarks::test_hierarchical_performance
FAILED tests/performance/test_benchmarks.py::TestClusteringBenchmarks::test_clustering_scalability
FAILED tests/performance/test_benchmarks.py::TestDataProcessingBenchmarks::test_data_processing_performance
FAILED tests/performance/test_benchmarks.py::TestDataProcessingBenchmarks::test_feature_extraction_performance
FAILED tests/performance/test_benchmarks.py::TestDataProcessingBenchmarks::test_feature_scaling_performance
FAILED tests/performance/test_benchmarks.py::TestClassificationBenchmarks::test_random_forest_performance
FAILED tests/performance/test_benchmarks.py::TestClassificationBenchmarks::test_svm_performance
FAILED tests/performance/test_benchmarks.py::TestMemoryBenchmarks::test_memory_usage_clustering
FAILED tests/performance/test_benchmarks.py::TestMemoryBenchmarks::test_memory_usage_large_dataset
FAILED tests/performance/test_benchmarks.py::TestConcurrentBenchmarks::test_parallel_processing_performance
FAILED tests/performance/test_benchmarks.py::TestIOBenchmarks::test_file_io_performance
FAILED tests/performance/test_benchmarks.py::TestIOBenchmarks::test_csv_io_performance
FAILED tests/performance/test_memory_profiling.py::TestMemoryUsage::test_memory_usage_clustering
FAILED tests/performance/test_memory_profiling.py::TestMemoryProfiling::test_detailed_memory_profiling
FAILED tests/performance/test_memory_profiling.py::TestMemoryProfiling::test_memory_profiling_garbage_collection
FAILED tests/performance/test_memory_profiling.py::TestMemoryOptimization::test_memory_usage_data_types
FAILED tests/unit/test_data_processing.py::TestDataValidator::test_validate_valid_data
FAILED tests/unit/test_ml_models.py::TestClusteringModel::test_fit_kmeans - T...
FAILED tests/unit/test_ml_models.py::TestClusteringModel::test_predict_after_fit
FAILED tests/unit/test_ml_models.py::TestClusteringModel::test_get_cluster_centers
FAILED tests/unit/test_ml_models.py::TestClusteringModel::test_evaluate_clustering
FAILED tests/unit/test_ml_models.py::TestClusteringModel::test_invalid_algorithm
FAILED tests/unit/test_ml_models.py::TestClusteringModel::test_hyperparameter_validation
FAILED tests/unit/test_ml_models.py::TestClassificationModel::test_cross_validation
FAILED tests/unit/test_ml_models.py::TestEnsembleModel::test_fit_voting_classifier
FAILED tests/unit/test_ml_models.py::TestEnsembleModel::test_fit_bagging - Ty...
FAILED tests/unit/test_ml_models.py::TestEnsembleModel::test_fit_boosting - T...
FAILED tests/unit/test_ml_models.py::TestEnsembleModel::test_predict_ensemble
FAILED tests/unit/test_ml_models.py::TestEnsembleModel::test_evaluate_ensemble
FAILED tests/unit/test_ml_models.py::TestEnsembleModel::test_individual_estimator_performance
FAILED tests/unit/test_ml_models.py::TestEnsembleModel::test_invalid_algorithm
FAILED tests/unit/test_ml_models.py::TestEnsembleModel::test_empty_estimators
FAILED tests/unit/test_ml_models.py::TestModelPersistence::test_save_load_model
FAILED tests/unit/test_ml_models.py::TestModelPersistence::test_save_load_ensemble
========== 114 failed, 246 passed, 147 warnings in 962.97s (0:16:02) ===========
