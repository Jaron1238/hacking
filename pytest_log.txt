============================= test session starts ==============================
platform linux -- Python 3.11.9, pytest-8.2.0, pluggy-1.6.0
benchmark: 5.1.0 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)
rootdir: /home/pi/hacking
configfile: pytest.ini
plugins: xdist-3.8.0, hypothesis-6.142.1, cov-7.0.0, mock-3.12.0, html-4.1.1, benchmark-5.1.0, Faker-37.11.0, metadata-3.1.1, json-report-1.5.0
collected 360 items

plugins/clustering_advanced/tests/test_clustering_advanced.py ..FFF.F... [  2%]
.....                                                                    [  4%]
plugins/ensemble_models/tests/test_ensemble_models.py ...FFF..FF         [  6%]
plugins/example_plugin/tests/test_example_plugin.py ..                   [  7%]
plugins/reinforcement_learning/tests/test_reinforcement_learning.py .... [  8%]
.FFF...FFFFF.F                                                           [ 12%]
plugins/sankey/tests/test_sankey.py .F...F                               [ 14%]
plugins/umap_plot/tests/test_umap_plot.py FF.FF..F                       [ 16%]
pytest/test_analysis.py ........F.FF...F...FF..F.F                       [ 23%]
pytest/test_app.py ..F...FFF..                                           [ 26%]
pytest/test_capture.py .FF.FF....F....F.F.F.                             [ 32%]
pytest/test_controllers.py .FF..F...FFFFFFFFFF..FF.F                     [ 39%]
pytest/test_error_handling.py ...........F..........F..FFFFFFF..F...     [ 50%]
pytest/test_integration.py FFF.FF..F..FF                                 [ 53%]
pytest/test_performance.py ....FFFFFF.F                                  [ 56%]
pytest/test_presentation.py FF...........F....F.                         [ 62%]
pytest/test_storage.py .........F....FF..FF...                           [ 68%]
pytest/test_utils.py F.F......FF..FFFF.FFF.....F.F                       [ 76%]
tests/integration/test_end_to_end.py FFFFFF                              [ 78%]
tests/performance/test_benchmarks.py FFFFFFFFFFFFFF                      [ 82%]
tests/performance/test_memory_profiling.py ..F...F.F..F                  [ 85%]
tests/unit/test_data_processing.py ................F.....                [ 91%]
tests/unit/test_ml_models.py .F..FFFFF.......F..FFFFFFFFFF               [100%]

=================================== FAILURES ===================================
____________ TestAdvancedClusteringPlugin.test_spectral_clustering _____________

self = <plugins.clustering_advanced.tests.test_clustering_advanced.TestAdvancedClusteringPlugin object at 0x7f88f94710>
plugin = <plugins.clustering_advanced.plugin.Plugin object at 0x7f6f15f750>
mock_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f6f15f810>
mock_events = [{'client': 'aa:bb:cc:dd:ee:00', 'ts': 1000.0, 'type': 'probe_req'}, {'client': 'aa:bb:cc:dd:ee:01', 'ts': 1001.0, 'type': 'probe_req'}]

    def test_spectral_clustering(self, plugin, mock_state, mock_events):
        """Test Spectral Clustering."""
        features, client_macs = plugin._extract_features_for_clustering(mock_state, mock_events)
    
        labels, metrics = plugin._run_spectral_clustering(features, n_clusters=3)
    
        assert len(labels) == len(features)
>       assert "algorithm" in metrics
E       assert 'algorithm' in {'error': "name 'calinski_harabasz_score' is not defined"}

plugins/clustering_advanced/tests/test_clustering_advanced.py:88: AssertionError
------------------------------ Captured log call -------------------------------
ERROR    plugins.clustering_advanced.plugin:plugin.py:250 Fehler bei Spectral Clustering: name 'calinski_harabasz_score' is not defined
__________ TestAdvancedClusteringPlugin.test_hierarchical_clustering ___________

self = <plugins.clustering_advanced.tests.test_clustering_advanced.TestAdvancedClusteringPlugin object at 0x7f88f94d50>
plugin = <plugins.clustering_advanced.plugin.Plugin object at 0x7f6fe59710>
mock_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f6f0c6a10>
mock_events = [{'client': 'aa:bb:cc:dd:ee:00', 'ts': 1000.0, 'type': 'probe_req'}, {'client': 'aa:bb:cc:dd:ee:01', 'ts': 1001.0, 'type': 'probe_req'}]

    def test_hierarchical_clustering(self, plugin, mock_state, mock_events):
        """Test Hierarchical Clustering."""
        features, client_macs = plugin._extract_features_for_clustering(mock_state, mock_events)
    
        labels, metrics = plugin._run_hierarchical_clustering(features, n_clusters=3)
    
        assert len(labels) == len(features)
>       assert "algorithm" in metrics
E       assert 'algorithm' in {'error': "name 'calinski_harabasz_score' is not defined"}

plugins/clustering_advanced/tests/test_clustering_advanced.py:100: AssertionError
------------------------------ Captured log call -------------------------------
ERROR    plugins.clustering_advanced.plugin:plugin.py:288 Fehler bei Hierarchical Clustering: name 'calinski_harabasz_score' is not defined
______________ TestAdvancedClusteringPlugin.test_gaussian_mixture ______________

self = <plugins.clustering_advanced.tests.test_clustering_advanced.TestAdvancedClusteringPlugin object at 0x7f88f953d0>
plugin = <plugins.clustering_advanced.plugin.Plugin object at 0x7f6b02ce90>
mock_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f6b02db90>
mock_events = [{'client': 'aa:bb:cc:dd:ee:00', 'ts': 1000.0, 'type': 'probe_req'}, {'client': 'aa:bb:cc:dd:ee:01', 'ts': 1001.0, 'type': 'probe_req'}]

    def test_gaussian_mixture(self, plugin, mock_state, mock_events):
        """Test Gaussian Mixture Model."""
        features, client_macs = plugin._extract_features_for_clustering(mock_state, mock_events)
    
        labels, metrics = plugin._run_gaussian_mixture(features, n_clusters=3)
    
        assert len(labels) == len(features)
>       assert "algorithm" in metrics
E       assert 'algorithm' in {'error': "name 'calinski_harabasz_score' is not defined"}

plugins/clustering_advanced/tests/test_clustering_advanced.py:110: AssertionError
------------------------------ Captured log call -------------------------------
ERROR    plugins.clustering_advanced.plugin:plugin.py:333 Fehler bei Gaussian Mixture Model: name 'calinski_harabasz_score' is not defined
_____________ TestAdvancedClusteringPlugin.test_hdbscan_clustering _____________

self = <plugins.clustering_advanced.tests.test_clustering_advanced.TestAdvancedClusteringPlugin object at 0x7f88f960d0>
plugin = <plugins.clustering_advanced.plugin.Plugin object at 0x7f6afe7210>
mock_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f6afe7e10>
mock_events = [{'client': 'aa:bb:cc:dd:ee:00', 'ts': 1000.0, 'type': 'probe_req'}, {'client': 'aa:bb:cc:dd:ee:01', 'ts': 1001.0, 'type': 'probe_req'}]

    def test_hdbscan_clustering(self, plugin, mock_state, mock_events):
        """Test HDBSCAN Clustering."""
        features, client_macs = plugin._extract_features_for_clustering(mock_state, mock_events)
    
        labels, metrics = plugin._run_hdbscan_clustering(features)
    
        assert len(labels) == len(features)
>       assert "algorithm" in metrics
E       assert 'algorithm' in {'error': "name 'hdbscan' is not defined"}

plugins/clustering_advanced/tests/test_clustering_advanced.py:132: AssertionError
------------------------------ Captured log call -------------------------------
ERROR    plugins.clustering_advanced.plugin:plugin.py:408 Fehler bei HDBSCAN Clustering: name 'hdbscan' is not defined
________ TestEnsembleModelsPlugin.test_ensemble_model_builder_creation _________

self = <plugins.ensemble_models.tests.test_ensemble_models.TestEnsembleModelsPlugin object at 0x7f887228d0>
plugin = <plugins.ensemble_models.plugin.Plugin object at 0x7f6b049610>

    def test_ensemble_model_builder_creation(self, plugin):
        """Test Ensemble Model Builder."""
        builder = plugin._EnsembleModelBuilder()
    
        # Test Basis-Modelle
        base_models = builder.create_base_models()
        assert len(base_models) > 0
        assert 'random_forest' in base_models
        assert 'logistic_regression' in base_models
    
        # Test Voting Ensembles
        hard_voting, soft_voting = builder.create_voting_ensemble(base_models)
        assert hard_voting is not None
        assert soft_voting is not None
    
        # Test Bagging
>       bagging = builder.create_bagging_ensemble(base_models['random_forest'])

plugins/ensemble_models/tests/test_ensemble_models.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <plugins.ensemble_models.plugin.Plugin._EnsembleModelBuilder object at 0x7f6b04bb10>
base_estimator = RandomForestClassifier(max_depth=10, min_samples_split=5, random_state=42)

    def create_bagging_ensemble(self, base_estimator: Any) -> BaggingClassifier:
        """Erstellt ein Bagging-Ensemble."""
>       return BaggingClassifier(
            base_estimator=base_estimator,
            n_estimators=50,
            random_state=self.random_state,
            max_samples=0.8,
            max_features=0.8
        )
E       TypeError: BaggingClassifier.__init__() got an unexpected keyword argument 'base_estimator'

plugins/ensemble_models/plugin.py:537: TypeError
__________ TestEnsembleModelsPlugin.test_model_performance_evaluation __________

self = <plugins.ensemble_models.tests.test_ensemble_models.TestEnsembleModelsPlugin object at 0x7f88722f10>
plugin = <plugins.ensemble_models.plugin.Plugin object at 0x7f8b374650>
mock_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f6f8878d0>
mock_events = [{'client': 'aa:bb:cc:dd:ee:00', 'ts': 1000.0, 'type': 'probe_req'}, {'client': 'aa:bb:cc:dd:ee:01', 'ts': 1001.0, 'type': 'probe_req'}]

    def test_model_performance_evaluation(self, plugin, mock_state, mock_events):
        """Test Modell-Performance-Evaluation."""
        X, y, client_macs = plugin._extract_features_for_classification(mock_state, mock_events)
    
        # Erstelle ein einfaches Mock-Modell
        from sklearn.linear_model import LogisticRegression
        model = LogisticRegression(random_state=42)
    
        # Evaluiere Performance
>       perf = plugin._evaluate_model_performance(model, X, y, "test_model")

plugins/ensemble_models/tests/test_ensemble_models.py:138: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
plugins/ensemble_models/plugin.py:337: in _evaluate_model_performance
    cv_scores = cross_val_score(model, X, y, cv=cv_folds, scoring='accuracy')
.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213: in wrapper
    return func(*args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:714: in cross_val_score
    cv_results = cross_validate(
.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213: in wrapper
    return func(*args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:425: in cross_validate
    results = parallel(
.venv/lib/python3.11/site-packages/sklearn/utils/parallel.py:67: in __call__
    return super().__call__(iterable_with_config)
.venv/lib/python3.11/site-packages/joblib/parallel.py:1863: in __call__
    return output if self.return_generator else list(output)
.venv/lib/python3.11/site-packages/joblib/parallel.py:1789: in _get_sequential_output
    for func, args, kwargs in iterable:
.venv/lib/python3.11/site-packages/sklearn/utils/parallel.py:63: in <genexpr>
    iterable_with_config = (
.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:425: in <genexpr>
    results = parallel(
.venv/lib/python3.11/site-packages/sklearn/model_selection/_split.py:377: in split
    for train, test in super().split(X, y, groups):
.venv/lib/python3.11/site-packages/sklearn/model_selection/_split.py:108: in split
    for test_index in self._iter_test_masks(X, y, groups):
.venv/lib/python3.11/site-packages/sklearn/model_selection/_split.py:770: in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)
X = array([[ 1.00000000e+02,  2.00000000e-01,  2.00000000e+01,
         2.00000000e+01,  2.00000000e+01, -5.50000000e+01,
...         1.00000000e+00,  1.30000000e+01,  1.04363033e+03,
         6.53356228e+01,  8.11619517e-01,  5.63286297e-01]])
y = array([0, 0, 1, 3, 3, 3])

    def _make_test_folds(self, X, y=None):
        rng = check_random_state(self.random_state)
        y = np.asarray(y)
        type_of_target_y = type_of_target(y)
        allowed_target_types = ("binary", "multiclass")
        if type_of_target_y not in allowed_target_types:
            raise ValueError(
                "Supported target types are: {}. Got {!r} instead.".format(
                    allowed_target_types, type_of_target_y
                )
            )
    
        y = column_or_1d(y)
    
        _, y_idx, y_inv = np.unique(y, return_index=True, return_inverse=True)
        # y_inv encodes y according to lexicographic order. We invert y_idx to
        # map the classes so that they are encoded by order of appearance:
        # 0 represents the first label appearing in y, 1 the second, etc.
        _, class_perm = np.unique(y_idx, return_inverse=True)
        y_encoded = class_perm[y_inv]
    
        n_classes = len(y_idx)
        y_counts = np.bincount(y_encoded)
        min_groups = np.min(y_counts)
        if np.all(self.n_splits > y_counts):
>           raise ValueError(
                "n_splits=%d cannot be greater than the"
                " number of members in each class." % (self.n_splits)
            )
E           ValueError: n_splits=5 cannot be greater than the number of members in each class.

.venv/lib/python3.11/site-packages/sklearn/model_selection/_split.py:732: ValueError
________ TestEnsembleModelsPlugin.test_plugin_run_with_sufficient_data _________

self = <MagicMock name='dump' id='547324419920'>

    def assert_called(self):
        """assert that the mock was called at least once
        """
        if self.call_count == 0:
            msg = ("Expected '%s' to have been called." %
                   (self._mock_name or 'mock'))
>           raise AssertionError(msg)
E           AssertionError: Expected 'dump' to have been called.

../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:908: AssertionError

During handling of the above exception, another exception occurred:

self = <plugins.ensemble_models.tests.test_ensemble_models.TestEnsembleModelsPlugin object at 0x7f88723510>
plugin = <plugins.ensemble_models.plugin.Plugin object at 0x7f693cdc10>
mock_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f693cdf10>
mock_events = [{'client': 'aa:bb:cc:dd:ee:00', 'ts': 1000.0, 'type': 'probe_req'}, {'client': 'aa:bb:cc:dd:ee:01', 'ts': 1001.0, 'type': 'probe_req'}]
mock_console = <MagicMock id='547228860048'>
temp_outdir = PosixPath('/tmp/pytest-of-pi/pytest-0/test_plugin_run_with_sufficien1/output')

    def test_plugin_run_with_sufficient_data(self, plugin, mock_state, mock_events, mock_console, temp_outdir):
        """Test Plugin-Ausführung mit ausreichenden Daten."""
        temp_outdir.mkdir(exist_ok=True)
    
        with patch('joblib.dump') as mock_dump:
            with patch('builtins.open', create=True) as mock_open:
                plugin.run(mock_state, mock_events, mock_console, temp_outdir)
    
        # Überprüfe, dass Console-Ausgaben gemacht wurden
        assert mock_console.print.called
    
        # Überprüfe, dass Ergebnisse gespeichert wurden
>       mock_dump.assert_called()
E       AssertionError: Expected 'dump' to have been called.

plugins/ensemble_models/tests/test_ensemble_models.py:160: AssertionError
_______ TestEnsembleModelsPlugin.test_performance_visualization_creation _______

self = <plugins.ensemble_models.tests.test_ensemble_models.TestEnsembleModelsPlugin object at 0x7f8872c890>
plugin = <plugins.ensemble_models.plugin.Plugin object at 0x7f6afbb090>
temp_outdir = PosixPath('/tmp/pytest-of-pi/pytest-0/test_performance_visualization0/output')

    def test_performance_visualization_creation(self, plugin, temp_outdir):
        """Test Erstellung der Performance-Visualisierung."""
        temp_outdir.mkdir(exist_ok=True)
    
        # Mock Performance-Metriken
        from plugins.ensemble_models.plugin import ModelPerformance
        performance_metrics = [
            ModelPerformance("Model1", 0.8, 0.75, 0.8, 0.77, 0.78, 0.02, 1.0, 0.1),
            ModelPerformance("Model2", 0.85, 0.82, 0.85, 0.83, 0.84, 0.01, 1.5, 0.15),
        ]
    
>       with patch('plotly.graph_objects.go') as mock_go:

plugins/ensemble_models/tests/test_ensemble_models.py:223: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f6afd3210>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'plotly.graph_objects' from '/home/pi/hacking/.venv/lib/python3.11/site-packages/plotly/graph_objects/__init__.py'> does not have the attribute 'go'

../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1419: AttributeError
_______ TestEnsembleModelsPlugin.test_ensemble_model_builder_integration _______

self = <plugins.ensemble_models.tests.test_ensemble_models.TestEnsembleModelsPlugin object at 0x7f8872ced0>
plugin = <plugins.ensemble_models.plugin.Plugin object at 0x7f6b080650>
mock_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f6b0804d0>
mock_events = [{'client': 'aa:bb:cc:dd:ee:00', 'ts': 1000.0, 'type': 'probe_req'}, {'client': 'aa:bb:cc:dd:ee:01', 'ts': 1001.0, 'type': 'probe_req'}]

    def test_ensemble_model_builder_integration(self, plugin, mock_state, mock_events):
        """Test Integration des Ensemble Model Builders."""
        X, y, client_macs = plugin._extract_features_for_classification(mock_state, mock_events)
    
        # Erstelle Builder
        builder = plugin._EnsembleModelBuilder()
    
        # Test alle Builder-Funktionen
        base_models = builder.create_base_models()
        assert len(base_models) > 0
    
        hard_voting, soft_voting = builder.create_voting_ensemble(base_models)
        assert hard_voting is not None
        assert soft_voting is not None
    
        stacking = builder.create_stacking_ensemble(base_models)
        # Stacking kann None sein wenn sklearn.ensemble.StackingClassifier nicht verfügbar
    
>       bagging = builder.create_bagging_ensemble(list(base_models.values())[0])

plugins/ensemble_models/tests/test_ensemble_models.py:252: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <plugins.ensemble_models.plugin.Plugin._EnsembleModelBuilder object at 0x7f6b080290>
base_estimator = RandomForestClassifier(max_depth=10, min_samples_split=5, random_state=42)

    def create_bagging_ensemble(self, base_estimator: Any) -> BaggingClassifier:
        """Erstellt ein Bagging-Ensemble."""
>       return BaggingClassifier(
            base_estimator=base_estimator,
            n_estimators=50,
            random_state=self.random_state,
            max_samples=0.8,
            max_features=0.8
        )
E       TypeError: BaggingClassifier.__init__() got an unexpected keyword argument 'base_estimator'

plugins/ensemble_models/plugin.py:537: TypeError
_________ TestReinforcementLearningPlugin.test_environment_observation _________

self = <plugins.reinforcement_learning.tests.test_reinforcement_learning.TestReinforcementLearningPlugin object at 0x7f88756890>
plugin = <plugins.reinforcement_learning.plugin.Plugin object at 0x7f69356a10>
mock_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f69356e10>
mock_events = [{'client': 'aa:bb:cc:dd:ee:00', 'ts': 1000.0, 'type': 'probe_req'}, {'client': 'aa:bb:cc:dd:ee:01', 'ts': 1001.0, 'type': 'probe_req'}]

    def test_environment_observation(self, plugin, mock_state, mock_events):
        """Test Environment Observation."""
        env = plugin._WiFiScanningEnvironment(mock_state, mock_events)
        obs = env._get_observation()
    
        assert len(obs) == 10
        assert all(0 <= val <= 1 for val in obs)  # Normalisierte Werte
>       assert obs[0] == 1.0 / 48.0  # current_channel normalisiert
E       assert 0.020833334 == (1.0 / 48.0)

plugins/reinforcement_learning/tests/test_reinforcement_learning.py:139: AssertionError
____________ TestReinforcementLearningPlugin.test_environment_step _____________

self = <plugins.reinforcement_learning.tests.test_reinforcement_learning.TestReinforcementLearningPlugin object at 0x7f88756fd0>
plugin = <plugins.reinforcement_learning.plugin.Plugin object at 0x7f693574d0>
mock_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f69357a50>
mock_events = [{'client': 'aa:bb:cc:dd:ee:00', 'ts': 1000.0, 'type': 'probe_req'}, {'client': 'aa:bb:cc:dd:ee:01', 'ts': 1001.0, 'type': 'probe_req'}]

    def test_environment_step(self, plugin, mock_state, mock_events):
        """Test Environment Step."""
        env = plugin._WiFiScanningEnvironment(mock_state, mock_events)
        obs = env.reset()
    
        # Führe einen Schritt aus
        action = ActionType.SCAN_CHANNEL_6.value
>       next_obs, reward, done, info = env.step(action)

plugins/reinforcement_learning/tests/test_reinforcement_learning.py:150: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
plugins/reinforcement_learning/plugin.py:289: in step
    reward = self._execute_action(action)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <plugins.reinforcement_learning.plugin.Plugin._WiFiScanningEnvironment object at 0x7f69355190>
action = 1

    def _execute_action(self, action: int) -> float:
        """Führt die gegebene Aktion aus und gibt die Belohnung zurück."""
        action_type = ActionType(action)
        reward = 0.0
    
        if action_type in [ActionType.SCAN_CHANNEL_1, ActionType.SCAN_CHANNEL_6,
                          ActionType.SCAN_CHANNEL_11, ActionType.SCAN_CHANNEL_36,
                          ActionType.SCAN_CHANNEL_40, ActionType.SCAN_CHANNEL_44,
                          ActionType.SCAN_CHANNEL_48]:
            # Kanal scannen
            channel_map = {
                ActionType.SCAN_CHANNEL_1: 1,
                ActionType.SCAN_CHANNEL_6: 6,
                ActionType.SCAN_CHANNEL_11: 11,
                ActionType.SCAN_CHANNEL_36: 36,
                ActionType.SCAN_CHANNEL_40: 40,
                ActionType.SCAN_CHANNEL_44: 44,
                ActionType.SCAN_CHANNEL_48: 48
            }
    
            new_channel = channel_map[action_type]
            self.current_channel = new_channel
            self.scan_history.append(new_channel)
    
            # Simuliere Scan-Ergebnisse basierend auf echten Daten
            aps_found, clients_found = self._simulate_scan_results(new_channel)
    
            # Belohnung basierend auf gefundenen Geräten
            reward += aps_found * 0.1  # 0.1 Punkte pro AP
            reward += clients_found * 0.05  # 0.05 Punkte pro Client
    
            # Bonus für neue Kanäle
>           if new_channel not in [ch for ch in self.scan_history[:-1]]:
E           TypeError: sequence index must be integer, not 'slice'

plugins/reinforcement_learning/plugin.py:339: TypeError
______ TestReinforcementLearningPlugin.test_environment_action_execution _______

self = <plugins.reinforcement_learning.tests.test_reinforcement_learning.TestReinforcementLearningPlugin object at 0x7f88757710>
plugin = <plugins.reinforcement_learning.plugin.Plugin object at 0x7f6f12a790>
mock_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f6f12b4d0>
mock_events = [{'client': 'aa:bb:cc:dd:ee:00', 'ts': 1000.0, 'type': 'probe_req'}, {'client': 'aa:bb:cc:dd:ee:01', 'ts': 1001.0, 'type': 'probe_req'}]

    def test_environment_action_execution(self, plugin, mock_state, mock_events):
        """Test Action Execution."""
        env = plugin._WiFiScanningEnvironment(mock_state, mock_events)
    
        # Test Kanal-Scanning
>       reward = env._execute_action(ActionType.SCAN_CHANNEL_6.value)

plugins/reinforcement_learning/tests/test_reinforcement_learning.py:165: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <plugins.reinforcement_learning.plugin.Plugin._WiFiScanningEnvironment object at 0x7f6f12b890>
action = 1

    def _execute_action(self, action: int) -> float:
        """Führt die gegebene Aktion aus und gibt die Belohnung zurück."""
        action_type = ActionType(action)
        reward = 0.0
    
        if action_type in [ActionType.SCAN_CHANNEL_1, ActionType.SCAN_CHANNEL_6,
                          ActionType.SCAN_CHANNEL_11, ActionType.SCAN_CHANNEL_36,
                          ActionType.SCAN_CHANNEL_40, ActionType.SCAN_CHANNEL_44,
                          ActionType.SCAN_CHANNEL_48]:
            # Kanal scannen
            channel_map = {
                ActionType.SCAN_CHANNEL_1: 1,
                ActionType.SCAN_CHANNEL_6: 6,
                ActionType.SCAN_CHANNEL_11: 11,
                ActionType.SCAN_CHANNEL_36: 36,
                ActionType.SCAN_CHANNEL_40: 40,
                ActionType.SCAN_CHANNEL_44: 44,
                ActionType.SCAN_CHANNEL_48: 48
            }
    
            new_channel = channel_map[action_type]
            self.current_channel = new_channel
            self.scan_history.append(new_channel)
    
            # Simuliere Scan-Ergebnisse basierend auf echten Daten
            aps_found, clients_found = self._simulate_scan_results(new_channel)
    
            # Belohnung basierend auf gefundenen Geräten
            reward += aps_found * 0.1  # 0.1 Punkte pro AP
            reward += clients_found * 0.05  # 0.05 Punkte pro Client
    
            # Bonus für neue Kanäle
>           if new_channel not in [ch for ch in self.scan_history[:-1]]:
E           TypeError: sequence index must be integer, not 'slice'

plugins/reinforcement_learning/plugin.py:339: TypeError
______ TestReinforcementLearningPlugin.test_simple_rl_agent_epsilon_decay ______

self = <plugins.reinforcement_learning.tests.test_reinforcement_learning.TestReinforcementLearningPlugin object at 0x7f8875d410>
plugin = <plugins.reinforcement_learning.plugin.Plugin object at 0x7f6970e750>

    def test_simple_rl_agent_epsilon_decay(self, plugin):
        """Test Epsilon Decay."""
        agent = plugin._SimpleRLAgent(state_size=10, action_size=10)
    
        initial_epsilon = agent.epsilon
        assert initial_epsilon == 1.0
    
        # Simuliere viele Lernschritte
        for _ in range(1000):
            state = np.random.random(10)
            action = 0
            reward = 0.0
            next_state = np.random.random(10)
            done = False
            agent.learn(state, action, reward, next_state, done)
    
        # Epsilon sollte reduziert sein
        assert agent.epsilon < initial_epsilon
>       assert agent.epsilon >= agent.epsilon_min
E       assert 0.00998645168764533 >= 0.01
E        +  where 0.00998645168764533 = <plugins.reinforcement_learning.plugin.Plugin._SimpleRLAgent object at 0x7f6970df50>.epsilon
E        +  and   0.01 = <plugins.reinforcement_learning.plugin.Plugin._SimpleRLAgent object at 0x7f6970df50>.epsilon_min

plugins/reinforcement_learning/tests/test_reinforcement_learning.py:244: AssertionError
_____ TestReinforcementLearningPlugin.test_plugin_run_with_sufficient_data _____

self = <MagicMock name='dump' id='547256379920'>

    def assert_called(self):
        """assert that the mock was called at least once
        """
        if self.call_count == 0:
            msg = ("Expected '%s' to have been called." %
                   (self._mock_name or 'mock'))
>           raise AssertionError(msg)
E           AssertionError: Expected 'dump' to have been called.

../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:908: AssertionError

During handling of the above exception, another exception occurred:

self = <plugins.reinforcement_learning.tests.test_reinforcement_learning.TestReinforcementLearningPlugin object at 0x7f8875dad0>
plugin = <plugins.reinforcement_learning.plugin.Plugin object at 0x7f6afe6b50>
mock_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f6afe72d0>
mock_events = [{'client': 'aa:bb:cc:dd:ee:00', 'ts': 1000.0, 'type': 'probe_req'}, {'client': 'aa:bb:cc:dd:ee:01', 'ts': 1001.0, 'type': 'probe_req'}]
mock_console = <MagicMock id='547255900432'>
temp_outdir = PosixPath('/tmp/pytest-of-pi/pytest-0/test_plugin_run_with_sufficien2/output')

    def test_plugin_run_with_sufficient_data(self, plugin, mock_state, mock_events, mock_console, temp_outdir):
        """Test Plugin-Ausführung mit ausreichenden Daten."""
        temp_outdir.mkdir(exist_ok=True)
    
        with patch('joblib.dump') as mock_dump:
            with patch('builtins.open', create=True) as mock_open:
                plugin.run(mock_state, mock_events, mock_console, temp_outdir)
    
        # Überprüfe, dass Console-Ausgaben gemacht wurden
        assert mock_console.print.called
    
        # Überprüfe, dass Ergebnisse gespeichert wurden
>       mock_dump.assert_called()
E       AssertionError: Expected 'dump' to have been called.

plugins/reinforcement_learning/tests/test_reinforcement_learning.py:258: AssertionError
------------------------------ Captured log call -------------------------------
ERROR    plugins.reinforcement_learning.plugin:plugin.py:164 Fehler bei der RL-Optimierung: 'NoneType' object has no attribute 'shape'
Traceback (most recent call last):
  File "/home/pi/hacking/plugins/reinforcement_learning/plugin.py", line 93, in run
    raise ImportError("PyTorch nicht verfügbar")
ImportError: PyTorch nicht verfügbar

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/pi/hacking/plugins/reinforcement_learning/plugin.py", line 96, in run
    state_size=env.observation_space.shape[0],
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
_______ TestReinforcementLearningPlugin.test_plugin_run_without_pytorch ________

self = <plugins.reinforcement_learning.tests.test_reinforcement_learning.TestReinforcementLearningPlugin object at 0x7f8875e190>
plugin = <plugins.reinforcement_learning.plugin.Plugin object at 0x7f6b021810>
mock_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f6b021910>
mock_events = [{'client': 'aa:bb:cc:dd:ee:00', 'ts': 1000.0, 'type': 'probe_req'}, {'client': 'aa:bb:cc:dd:ee:01', 'ts': 1001.0, 'type': 'probe_req'}]
mock_console = <MagicMock id='547256594192'>
temp_outdir = PosixPath('/tmp/pytest-of-pi/pytest-0/test_plugin_run_without_pytorc0/output')

    def test_plugin_run_without_pytorch(self, plugin, mock_state, mock_events, mock_console, temp_outdir):
        """Test Plugin-Ausführung ohne PyTorch (Fallback zu Simple RL)."""
        temp_outdir.mkdir(exist_ok=True)
    
        with patch('plugins.reinforcement_learning.plugin.torch', None):
            with patch('joblib.dump') as mock_dump:
                with patch('builtins.open', create=True) as mock_open:
                    plugin.run(mock_state, mock_events, mock_console, temp_outdir)
    
        # Überprüfe, dass Console-Ausgaben gemacht wurden
        assert mock_console.print.called
    
        # Überprüfe, dass Simple RL Agent verwendet wurde
        console_calls = [str(call) for call in mock_console.print.call_args_list]
>       assert any("Q-Learning" in call for call in console_calls)
E       assert False
E        +  where False = any(<generator object TestReinforcementLearningPlugin.test_plugin_run_without_pytorch.<locals>.<genexpr> at 0x7f6b05d7d0>)

plugins/reinforcement_learning/tests/test_reinforcement_learning.py:275: AssertionError
------------------------------ Captured log call -------------------------------
ERROR    plugins.reinforcement_learning.plugin:plugin.py:164 Fehler bei der RL-Optimierung: 'NoneType' object has no attribute 'shape'
Traceback (most recent call last):
  File "/home/pi/hacking/plugins/reinforcement_learning/plugin.py", line 93, in run
    raise ImportError("PyTorch nicht verfügbar")
ImportError: PyTorch nicht verfügbar

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/pi/hacking/plugins/reinforcement_learning/plugin.py", line 96, in run
    state_size=env.observation_space.shape[0],
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'shape'
_______ TestReinforcementLearningPlugin.test_training_results_structure ________

self = <plugins.reinforcement_learning.tests.test_reinforcement_learning.TestReinforcementLearningPlugin object at 0x7f8875e8d0>
plugin = <plugins.reinforcement_learning.plugin.Plugin object at 0x7f6f10e750>
mock_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f6f10c950>
mock_events = [{'client': 'aa:bb:cc:dd:ee:00', 'ts': 1000.0, 'type': 'probe_req'}, {'client': 'aa:bb:cc:dd:ee:01', 'ts': 1001.0, 'type': 'probe_req'}]

    def test_training_results_structure(self, plugin, mock_state, mock_events):
        """Test Training Results Struktur."""
        env = plugin._WiFiScanningEnvironment(mock_state, mock_events)
        agent = plugin._SimpleRLAgent(state_size=10, action_size=10)
    
>       training_results = plugin._train_rl_agent(env, agent, episodes=5)

plugins/reinforcement_learning/tests/test_reinforcement_learning.py:282: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
plugins/reinforcement_learning/plugin.py:178: in _train_rl_agent
    next_state, reward, done, info = environment.step(action)
plugins/reinforcement_learning/plugin.py:289: in step
    reward = self._execute_action(action)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <plugins.reinforcement_learning.plugin.Plugin._WiFiScanningEnvironment object at 0x7f6f10d7d0>
action = 5

    def _execute_action(self, action: int) -> float:
        """Führt die gegebene Aktion aus und gibt die Belohnung zurück."""
        action_type = ActionType(action)
        reward = 0.0
    
        if action_type in [ActionType.SCAN_CHANNEL_1, ActionType.SCAN_CHANNEL_6,
                          ActionType.SCAN_CHANNEL_11, ActionType.SCAN_CHANNEL_36,
                          ActionType.SCAN_CHANNEL_40, ActionType.SCAN_CHANNEL_44,
                          ActionType.SCAN_CHANNEL_48]:
            # Kanal scannen
            channel_map = {
                ActionType.SCAN_CHANNEL_1: 1,
                ActionType.SCAN_CHANNEL_6: 6,
                ActionType.SCAN_CHANNEL_11: 11,
                ActionType.SCAN_CHANNEL_36: 36,
                ActionType.SCAN_CHANNEL_40: 40,
                ActionType.SCAN_CHANNEL_44: 44,
                ActionType.SCAN_CHANNEL_48: 48
            }
    
            new_channel = channel_map[action_type]
            self.current_channel = new_channel
            self.scan_history.append(new_channel)
    
            # Simuliere Scan-Ergebnisse basierend auf echten Daten
            aps_found, clients_found = self._simulate_scan_results(new_channel)
    
            # Belohnung basierend auf gefundenen Geräten
            reward += aps_found * 0.1  # 0.1 Punkte pro AP
            reward += clients_found * 0.05  # 0.05 Punkte pro Client
    
            # Bonus für neue Kanäle
>           if new_channel not in [ch for ch in self.scan_history[:-1]]:
E           TypeError: sequence index must be integer, not 'slice'

plugins/reinforcement_learning/plugin.py:339: TypeError
_____________ TestReinforcementLearningPlugin.test_agent_save_load _____________

self = <plugins.reinforcement_learning.tests.test_reinforcement_learning.TestReinforcementLearningPlugin object at 0x7f8875f010>
plugin = <plugins.reinforcement_learning.plugin.Plugin object at 0x7f691eded0>
temp_outdir = PosixPath('/tmp/pytest-of-pi/pytest-0/test_agent_save_load0/output')

    def test_agent_save_load(self, plugin, temp_outdir):
        """Test Agent Save/Load Funktionalität."""
        agent = plugin._SimpleRLAgent(state_size=10, action_size=10)
    
        # Simuliere einige Lernschritte
        for _ in range(10):
            state = np.random.random(10)
            action = 0
            reward = 1.0
            next_state = np.random.random(10)
            done = False
            agent.learn(state, action, reward, next_state, done)
    
        # Speichere Agent
        agent_file = temp_outdir / "test_agent.joblib"
>       agent.save(agent_file)

plugins/reinforcement_learning/tests/test_reinforcement_learning.py:306: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <plugins.reinforcement_learning.plugin.Plugin._SimpleRLAgent object at 0x7f691ed410>
filepath = PosixPath('/tmp/pytest-of-pi/pytest-0/test_agent_save_load0/output/test_agent.joblib')

    def save(self, filepath: Path):
        """Speichert das gelernte Modell."""
        model_data = {
            'q_table': dict(self.q_table),
            'epsilon': self.epsilon,
            'episode_rewards': self.episode_rewards,
            'episode_lengths': self.episode_lengths
        }
>       joblib.dump(model_data, filepath)
E       NameError: name 'joblib' is not defined

plugins/reinforcement_learning/plugin.py:446: NameError
_ TestReinforcementLearningPlugin.test_environment_performance_metrics_update __

self = <plugins.reinforcement_learning.tests.test_reinforcement_learning.TestReinforcementLearningPlugin object at 0x7f88756d10>
plugin = <plugins.reinforcement_learning.plugin.Plugin object at 0x7f695f8210>
mock_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f695fae10>
mock_events = [{'client': 'aa:bb:cc:dd:ee:00', 'ts': 1000.0, 'type': 'probe_req'}, {'client': 'aa:bb:cc:dd:ee:01', 'ts': 1001.0, 'type': 'probe_req'}]

    def test_environment_performance_metrics_update(self, plugin, mock_state, mock_events):
        """Test Performance Metrics Update."""
        env = plugin._WiFiScanningEnvironment(mock_state, mock_events)
    
        # Simuliere mehrere Scans
>       env._execute_action(ActionType.SCAN_CHANNEL_1.value)

plugins/reinforcement_learning/tests/test_reinforcement_learning.py:334: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <plugins.reinforcement_learning.plugin.Plugin._WiFiScanningEnvironment object at 0x7f695fa0d0>
action = 0

    def _execute_action(self, action: int) -> float:
        """Führt die gegebene Aktion aus und gibt die Belohnung zurück."""
        action_type = ActionType(action)
        reward = 0.0
    
        if action_type in [ActionType.SCAN_CHANNEL_1, ActionType.SCAN_CHANNEL_6,
                          ActionType.SCAN_CHANNEL_11, ActionType.SCAN_CHANNEL_36,
                          ActionType.SCAN_CHANNEL_40, ActionType.SCAN_CHANNEL_44,
                          ActionType.SCAN_CHANNEL_48]:
            # Kanal scannen
            channel_map = {
                ActionType.SCAN_CHANNEL_1: 1,
                ActionType.SCAN_CHANNEL_6: 6,
                ActionType.SCAN_CHANNEL_11: 11,
                ActionType.SCAN_CHANNEL_36: 36,
                ActionType.SCAN_CHANNEL_40: 40,
                ActionType.SCAN_CHANNEL_44: 44,
                ActionType.SCAN_CHANNEL_48: 48
            }
    
            new_channel = channel_map[action_type]
            self.current_channel = new_channel
            self.scan_history.append(new_channel)
    
            # Simuliere Scan-Ergebnisse basierend auf echten Daten
            aps_found, clients_found = self._simulate_scan_results(new_channel)
    
            # Belohnung basierend auf gefundenen Geräten
            reward += aps_found * 0.1  # 0.1 Punkte pro AP
            reward += clients_found * 0.05  # 0.05 Punkte pro Client
    
            # Bonus für neue Kanäle
>           if new_channel not in [ch for ch in self.scan_history[:-1]]:
E           TypeError: sequence index must be integer, not 'slice'

plugins/reinforcement_learning/plugin.py:339: TypeError
_____________ TestSankeyPlugin.test_plugin_run_with_roaming_events _____________

self = <plugins.sankey.tests.test_sankey.TestSankeyPlugin object at 0x7f88761e10>
plugin = <plugins.sankey.plugin.Plugin object at 0x7f6f11f9d0>
mock_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f6f11c810>
mock_events_with_roaming = [{'bssid': 'ap1', 'client': 'aa:bb:cc:dd:ee:00', 'ts': 1000.0, 'type': 'data'}, {'bssid': 'ap2', 'client': 'aa:bb:cc:d...d:ee:01', 'ts': 1002.0, 'type': 'data'}, {'bssid': 'ap3', 'client': 'aa:bb:cc:dd:ee:01', 'ts': 1003.0, 'type': 'data'}]
mock_console = <MagicMock id='547324291152'>
temp_outdir = PosixPath('/tmp/pytest-of-pi/pytest-0/test_plugin_run_with_roaming_e0/output')

    def test_plugin_run_with_roaming_events(self, plugin, mock_state, mock_events_with_roaming, mock_console, temp_outdir):
        """Test Plugin-Ausführung mit Roaming-Events."""
        temp_outdir.mkdir(exist_ok=True)
    
>       with patch('plotly.graph_objects.go') as mock_go:

plugins/sankey/tests/test_sankey.py:69: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f691ee3d0>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'plotly.graph_objects' from '/home/pi/hacking/.venv/lib/python3.11/site-packages/plotly/graph_objects/__init__.py'> does not have the attribute 'go'

../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1419: AttributeError
____________ TestSankeyPlugin.test_plugin_run_with_sufficient_data _____________

self = <plugins.sankey.tests.test_sankey.TestSankeyPlugin object at 0x7f88763390>
plugin = <plugins.sankey.plugin.Plugin object at 0x7f6b05b8d0>
mock_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f6b058690>
mock_events_with_roaming = [{'bssid': 'ap1', 'client': 'aa:bb:cc:dd:ee:00', 'ts': 1000.0, 'type': 'data'}, {'bssid': 'ap2', 'client': 'aa:bb:cc:d...d:ee:01', 'ts': 1002.0, 'type': 'data'}, {'bssid': 'ap3', 'client': 'aa:bb:cc:dd:ee:01', 'ts': 1003.0, 'type': 'data'}]
mock_console = <MagicMock id='547324222160'>
temp_outdir = PosixPath('/tmp/pytest-of-pi/pytest-0/test_plugin_run_with_sufficien3/output')

    def test_plugin_run_with_sufficient_data(self, plugin, mock_state, mock_events_with_roaming, mock_console, temp_outdir):
        """Test Plugin-Ausführung mit ausreichenden Daten."""
        temp_outdir.mkdir(exist_ok=True)
    
>       with patch('plotly.graph_objects.go') as mock_go:

plugins/sankey/tests/test_sankey.py:142: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f6f114450>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'plotly.graph_objects' from '/home/pi/hacking/.venv/lib/python3.11/site-packages/plotly/graph_objects/__init__.py'> does not have the attribute 'go'

../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1419: AttributeError
___________________ TestUMAPPlotPlugin.test_plugin_metadata ____________________

self = <plugins.umap_plot.tests.test_umap_plot.TestUMAPPlotPlugin object at 0x7f87cd2090>
plugin = <plugins.umap_plot.plugin.Plugin object at 0x7f6b08c7d0>

    def test_plugin_metadata(self, plugin):
        """Test Plugin-Metadaten."""
        metadata = plugin.get_metadata()
        assert metadata.name == "UMAP Plot"
        assert metadata.version == "1.0.0"
        assert "UMAP" in metadata.description
>       assert "umap-learn" in metadata.dependencies
E       AssertionError: assert 'umap-learn' in ['umap', 'plotly', 'pandas']
E        +  where ['umap', 'plotly', 'pandas'] = <plugins.PluginMetadata object at 0x7f6b08c110>.dependencies

plugins/umap_plot/tests/test_umap_plot.py:59: AssertionError
______________ TestUMAPPlotPlugin.test_plugin_run_with_valid_data ______________

self = <plugins.umap_plot.tests.test_umap_plot.TestUMAPPlotPlugin object at 0x7f87cd2750>
plugin = <plugins.umap_plot.plugin.Plugin object at 0x7f6966fd50>
mock_clustered_client_df =                  mac  cluster   vendor
0  aa:bb:cc:dd:ee:00        0    Apple
1  aa:bb:cc:dd:ee:01        1  Samsung
2  aa:bb:cc:dd:ee:02        0    Apple
mock_client_feature_df =    feature1  feature2  feature3      original_macs
0       1.0       4.0       7.0  aa:bb:cc:dd:ee:00
1       2.0       5.0       8.0  aa:bb:cc:dd:ee:01
2       3.0       6.0       9.0  aa:bb:cc:dd:ee:02
mock_console = <MagicMock id='547324388048'>
temp_outdir = PosixPath('/tmp/pytest-of-pi/pytest-0/test_plugin_run_with_valid_dat0/output')

    def test_plugin_run_with_valid_data(self, plugin, mock_clustered_client_df, mock_client_feature_df, mock_console, temp_outdir):
        """Test Plugin-Ausführung mit gültigen Daten."""
        temp_outdir.mkdir(exist_ok=True)
    
>       with patch('umap.UMAP') as mock_umap:

plugins/umap_plot/tests/test_umap_plot.py:66: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1430: in __enter__
    self.target = self.getter()
../.pyenv/versions/3.11.9/lib/python3.11/pkgutil.py:700: in resolve_name
    mod = importlib.import_module(modname)
../.pyenv/versions/3.11.9/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1204: in _gcd_import
    ???
<frozen importlib._bootstrap>:1176: in _find_and_load
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'umap', import_ = <function _gcd_import at 0x7fa9157d80>

>   ???
E   ModuleNotFoundError: No module named 'umap'

<frozen importlib._bootstrap>:1140: ModuleNotFoundError
__________ TestUMAPPlotPlugin.test_plugin_run_without_clustered_data ___________

self = <plugins.umap_plot.tests.test_umap_plot.TestUMAPPlotPlugin object at 0x7f87cd30d0>
plugin = <plugins.umap_plot.plugin.Plugin object at 0x7f695f8650>
mock_console = <MagicMock id='547228720144'>
temp_outdir = PosixPath('/tmp/pytest-of-pi/pytest-0/test_plugin_run_without_cluste0/output')

    def test_plugin_run_without_clustered_data(self, plugin, mock_console, temp_outdir):
        """Test Plugin-Ausführung ohne Cluster-Daten."""
        temp_outdir.mkdir(exist_ok=True)
    
        plugin.run(
            state=None,
            clustered_client_df=None,
            client_feature_df=None,
            outdir=temp_outdir,
            console=mock_console
        )
    
        # Überprüfe Warnung für fehlende Cluster-Daten
        warning_calls = [call for call in mock_console.print.call_args_list
                        if "Keine Cluster-Daten" in str(call)]
>       assert len(warning_calls) > 0
E       assert 0 > 0
E        +  where 0 = len([])

plugins/umap_plot/tests/test_umap_plot.py:129: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  plugins.umap_plot.plugin:plugin.py:38 UMAP/Plotly nicht installiert. Überspringe Client-Map-Visualisierung.
__________ TestUMAPPlotPlugin.test_plugin_run_with_empty_feature_data __________

self = <plugins.umap_plot.tests.test_umap_plot.TestUMAPPlotPlugin object at 0x7f87cd36d0>
plugin = <plugins.umap_plot.plugin.Plugin object at 0x7f88756910>
mock_clustered_client_df =                  mac  cluster   vendor
0  aa:bb:cc:dd:ee:00        0    Apple
1  aa:bb:cc:dd:ee:01        1  Samsung
2  aa:bb:cc:dd:ee:02        0    Apple
mock_console = <MagicMock id='547750072208'>
temp_outdir = PosixPath('/tmp/pytest-of-pi/pytest-0/test_plugin_run_with_empty_fea0/output')

    def test_plugin_run_with_empty_feature_data(self, plugin, mock_clustered_client_df, mock_console, temp_outdir):
        """Test Plugin-Ausführung mit leeren Feature-Daten."""
        temp_outdir.mkdir(exist_ok=True)
    
        empty_feature_df = pd.DataFrame()
    
        plugin.run(
            state=None,
            clustered_client_df=mock_clustered_client_df,
            client_feature_df=empty_feature_df,
            outdir=temp_outdir,
            console=mock_console
        )
    
        # Überprüfe Warnung für leere Feature-Daten
        warning_calls = [call for call in mock_console.print.call_args_list
                        if "Keine Cluster-Daten" in str(call)]
>       assert len(warning_calls) > 0
E       assert 0 > 0
E        +  where 0 = len([])

plugins/umap_plot/tests/test_umap_plot.py:148: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  plugins.umap_plot.plugin:plugin.py:38 UMAP/Plotly nicht installiert. Überspringe Client-Map-Visualisierung.
______________ TestUMAPPlotPlugin.test_plugin_run_with_exception _______________

self = <plugins.umap_plot.tests.test_umap_plot.TestUMAPPlotPlugin object at 0x7f87cdcc50>
plugin = <plugins.umap_plot.plugin.Plugin object at 0x7f6f13e690>
mock_clustered_client_df =                  mac  cluster   vendor
0  aa:bb:cc:dd:ee:00        0    Apple
1  aa:bb:cc:dd:ee:01        1  Samsung
2  aa:bb:cc:dd:ee:02        0    Apple
mock_client_feature_df =    feature1  feature2  feature3      original_macs
0       1.0       4.0       7.0  aa:bb:cc:dd:ee:00
1       2.0       5.0       8.0  aa:bb:cc:dd:ee:01
2       3.0       6.0       9.0  aa:bb:cc:dd:ee:02
mock_console = <MagicMock id='547224476816'>
temp_outdir = PosixPath('/tmp/pytest-of-pi/pytest-0/test_plugin_run_with_exception0/output')

    def test_plugin_run_with_exception(self, plugin, mock_clustered_client_df, mock_client_feature_df, mock_console, temp_outdir):
        """Test Plugin-Ausführung mit Exception."""
        temp_outdir.mkdir(exist_ok=True)
    
>       with patch('umap.UMAP') as mock_umap:

plugins/umap_plot/tests/test_umap_plot.py:192: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1430: in __enter__
    self.target = self.getter()
../.pyenv/versions/3.11.9/lib/python3.11/pkgutil.py:700: in resolve_name
    mod = importlib.import_module(modname)
../.pyenv/versions/3.11.9/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1204: in _gcd_import
    ???
<frozen importlib._bootstrap>:1176: in _find_and_load
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'umap', import_ = <function _gcd_import at 0x7fa9157d80>

>   ???
E   ModuleNotFoundError: No module named 'umap'

<frozen importlib._bootstrap>:1140: ModuleNotFoundError
___________________ TestAnalysisLogic.test_profile_clusters ____________________

self = <test_analysis.TestAnalysisLogic object at 0x7f706d5810>

    def test_profile_clusters(self):
        """Test Cluster-Profilierung."""
        feature_data = {
            'original_macs': ['mac1', 'mac2', 'mac3'],
            'feature1': [10, 20, 15],
            'feature2': [1, 2, 1.5]
        }
        feature_df = pd.DataFrame(feature_data)
    
        cluster_data = {
            'original_macs': ['mac1', 'mac2', 'mac3'],
            'cluster': [0, 0, 1]
        }
        clustered_df = pd.DataFrame(cluster_data)
    
>       profiles = analysis.profile_clusters(feature_df, clustered_df)

pytest/test_analysis.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/analysis/logic.py:666: in profile_clusters
    profiles["details"] = full_df.set_index("mac").to_dict(orient="index")
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self =   original_macs  feature1  feature2  cluster
0          mac1        10       1.0        0
1          mac2        20       2.0        0
2          mac3        15       1.5        1
keys = ['mac']

    def set_index(
        self,
        keys,
        *,
        drop: bool = True,
        append: bool = False,
        inplace: bool = False,
        verify_integrity: bool = False,
    ) -> DataFrame | None:
        """
        Set the DataFrame index using existing columns.
    
        Set the DataFrame index (row labels) using one or more existing
        columns or arrays (of the correct length). The index can replace the
        existing index or expand on it.
    
        Parameters
        ----------
        keys : label or array-like or list of labels/arrays
            This parameter can be either a single column key, a single array of
            the same length as the calling DataFrame, or a list containing an
            arbitrary combination of column keys and arrays. Here, "array"
            encompasses :class:`Series`, :class:`Index`, ``np.ndarray``, and
            instances of :class:`~collections.abc.Iterator`.
        drop : bool, default True
            Delete columns to be used as the new index.
        append : bool, default False
            Whether to append columns to existing index.
        inplace : bool, default False
            Whether to modify the DataFrame rather than creating a new one.
        verify_integrity : bool, default False
            Check the new index for duplicates. Otherwise defer the check until
            necessary. Setting to False will improve the performance of this
            method.
    
        Returns
        -------
        DataFrame or None
            Changed row labels or None if ``inplace=True``.
    
        See Also
        --------
        DataFrame.reset_index : Opposite of set_index.
        DataFrame.reindex : Change to new indices or expand indices.
        DataFrame.reindex_like : Change to same indices as other DataFrame.
    
        Examples
        --------
        >>> df = pd.DataFrame({'month': [1, 4, 7, 10],
        ...                    'year': [2012, 2014, 2013, 2014],
        ...                    'sale': [55, 40, 84, 31]})
        >>> df
           month  year  sale
        0      1  2012    55
        1      4  2014    40
        2      7  2013    84
        3     10  2014    31
    
        Set the index to become the 'month' column:
    
        >>> df.set_index('month')
               year  sale
        month
        1      2012    55
        4      2014    40
        7      2013    84
        10     2014    31
    
        Create a MultiIndex using columns 'year' and 'month':
    
        >>> df.set_index(['year', 'month'])
                    sale
        year  month
        2012  1     55
        2014  4     40
        2013  7     84
        2014  10    31
    
        Create a MultiIndex using an Index and a column:
    
        >>> df.set_index([pd.Index([1, 2, 3, 4]), 'year'])
                 month  sale
           year
        1  2012  1      55
        2  2014  4      40
        3  2013  7      84
        4  2014  10     31
    
        Create a MultiIndex using two Series:
    
        >>> s = pd.Series([1, 2, 3, 4])
        >>> df.set_index([s, s**2])
              month  year  sale
        1 1       1  2012    55
        2 4       4  2014    40
        3 9       7  2013    84
        4 16     10  2014    31
        """
        inplace = validate_bool_kwarg(inplace, "inplace")
        self._check_inplace_and_allows_duplicate_labels(inplace)
        if not isinstance(keys, list):
            keys = [keys]
    
        err_msg = (
            'The parameter "keys" may be a column key, one-dimensional '
            "array, or a list containing only valid column keys and "
            "one-dimensional arrays."
        )
    
        missing: list[Hashable] = []
        for col in keys:
            if isinstance(col, (Index, Series, np.ndarray, list, abc.Iterator)):
                # arrays are fine as long as they are one-dimensional
                # iterators get converted to list below
                if getattr(col, "ndim", 1) != 1:
                    raise ValueError(err_msg)
            else:
                # everything else gets tried as a key; see GH 24969
                try:
                    found = col in self.columns
                except TypeError as err:
                    raise TypeError(
                        f"{err_msg}. Received column of type {type(col)}"
                    ) from err
                else:
                    if not found:
                        missing.append(col)
    
        if missing:
>           raise KeyError(f"None of {missing} are in the columns")
E           KeyError: "None of ['mac'] are in the columns"

.venv/lib/python3.11/site-packages/pandas/core/frame.py:6106: KeyError
______________________ TestAnalysisLogic.test_cluster_aps ______________________

self = <test_analysis.TestAnalysisLogic object at 0x7f706d6650>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f6f107c10>

    def test_cluster_aps(self, populated_state):
        """Test AP-Clustering."""
>       clustered_df = analysis.cluster_aps(populated_state, n_clusters=2)

pytest/test_analysis.py:166: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/analysis/logic.py:736: in cluster_aps
    df["cluster"] = kmeans.fit_predict(X_scaled)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1071: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1351: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1490: in fit
    self._check_params_vs_input(X)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1431: in _check_params_vs_input
    super()._check_params_vs_input(X, default_n_init=10)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = KMeans(n_clusters=2, random_state=42)
X = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])
default_n_init = 10

    def _check_params_vs_input(self, X, default_n_init=None):
        # n_clusters
        if X.shape[0] < self.n_clusters:
>           raise ValueError(
                f"n_samples={X.shape[0]} should be >= n_clusters={self.n_clusters}."
            )
E           ValueError: n_samples=1 should be >= n_clusters=2.

.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:879: ValueError
__________________ TestAnalysisLogic.test_profile_ap_clusters __________________

self = Index(['bssid', 'ssid', 'vendor', 'cluster', 'supports_11k', 'supports_11v',
       'supports_11r'],
      dtype='object')
key = 'channel'

    def get_loc(self, key):
        """
        Get integer location, slice or boolean mask for requested label.
    
        Parameters
        ----------
        key : label
    
        Returns
        -------
        int if unique index, slice if monotonic index, else mask
    
        Examples
        --------
        >>> unique_index = pd.Index(list('abc'))
        >>> unique_index.get_loc('b')
        1
    
        >>> monotonic_index = pd.Index(list('abbc'))
        >>> monotonic_index.get_loc('b')
        slice(1, 3, None)
    
        >>> non_monotonic_index = pd.Index(list('abcb'))
        >>> non_monotonic_index.get_loc('b')
        array([False,  True, False,  True])
        """
        casted_key = self._maybe_cast_indexer(key)
        try:
>           return self._engine.get_loc(casted_key)

.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3802: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
index.pyx:153: in pandas._libs.index.IndexEngine.get_loc
    ???
index.pyx:182: in pandas._libs.index.IndexEngine.get_loc
    ???
pandas/_libs/hashtable_class_helper.pxi:7081: in pandas._libs.hashtable.PyObjectHashTable.get_item
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   KeyError: 'channel'

pandas/_libs/hashtable_class_helper.pxi:7089: KeyError

The above exception was the direct cause of the following exception:

self = <test_analysis.TestAnalysisLogic object at 0x7f706d6d10>

    def test_profile_ap_clusters(self):
        """Test AP-Cluster-Profilierung."""
        cluster_data = {
            'bssid': ['ap1', 'ap2'],
            'ssid': ['SSID1', 'SSID2'],
            'vendor': ['Vendor1', 'Vendor2'],
            'cluster': [0, 1],
            'supports_11k': [True, False],
            'supports_11v': [True, False],
            'supports_11r': [False, True]
        }
        clustered_df = pd.DataFrame(cluster_data)
    
>       profiles = analysis.profile_ap_clusters(clustered_df)

pytest/test_analysis.py:187: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/analysis/logic.py:766: in profile_ap_clusters
    "channels": cluster_data["channel"].value_counts().to_dict(),
.venv/lib/python3.11/site-packages/pandas/core/frame.py:4090: in __getitem__
    indexer = self.columns.get_loc(key)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Index(['bssid', 'ssid', 'vendor', 'cluster', 'supports_11k', 'supports_11v',
       'supports_11r'],
      dtype='object')
key = 'channel'

    def get_loc(self, key):
        """
        Get integer location, slice or boolean mask for requested label.
    
        Parameters
        ----------
        key : label
    
        Returns
        -------
        int if unique index, slice if monotonic index, else mask
    
        Examples
        --------
        >>> unique_index = pd.Index(list('abc'))
        >>> unique_index.get_loc('b')
        1
    
        >>> monotonic_index = pd.Index(list('abbc'))
        >>> monotonic_index.get_loc('b')
        slice(1, 3, None)
    
        >>> non_monotonic_index = pd.Index(list('abcb'))
        >>> non_monotonic_index.get_loc('b')
        array([False,  True, False,  True])
        """
        casted_key = self._maybe_cast_indexer(key)
        try:
            return self._engine.get_loc(casted_key)
        except KeyError as err:
            if isinstance(casted_key, slice) or (
                isinstance(casted_key, abc.Iterable)
                and any(isinstance(x, slice) for x in casted_key)
            ):
                raise InvalidIndexError(key)
>           raise KeyError(key) from err
E           KeyError: 'channel'

.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3809: KeyError
________ TestDeviceProfiler.test_create_device_fingerprint_empty_state _________

self = <test_analysis.TestDeviceProfiler object at 0x7f706e0b50>

    def test_create_device_fingerprint_empty_state(self):
        """Test Fingerprint mit leerem ClientState."""
        empty_client = ClientState(mac="aa:bb:cc:dd:ee:ff")
        fingerprint = create_device_fingerprint(empty_client)
    
>       assert fingerprint == ""  # Sollte leer sein für leeren State
E       AssertionError: assert 'd41d8cd98f00...00998ecf8427e' == ''
E         
E         + d41d8cd98f00b204e9800998ecf8427e

pytest/test_analysis.py:251: AssertionError
___________________ TestGraphExport.test_build_export_graph ____________________

self = <test_analysis.TestGraphExport object at 0x7f706e1310>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f6b05ae10>

    def test_build_export_graph(self, populated_state):
        """Test Graph-Aufbau für Export."""
        # Erstelle Test-Daten
        ap_data = {
            'bssid': ['08:96:d7:1a:21:1c'],
            'ssid': ['MyTestWLAN'],
            'vendor': ['TestVendor'],
            'cluster': [0],
            'channel': [6],
            'rssi_mean': [-50.0],
            'supports_11k': [False],
            'supports_11v': [False],
            'supports_11r': [False]
        }
        clustered_ap_df = pd.DataFrame(ap_data)
    
        aps_to_export = {'08:96:d7:1a:21:1c': populated_state.aps['08:96:d7:1a:21:1c']}
        clients_to_export = {}
    
        graph = analysis._build_export_graph(
            populated_state,
            clustered_ap_df,
            aps_to_export,
            clients_to_export,
            include_clients=False,
            clustered_client_df=None
        )
    
        assert graph is not None
        assert graph.number_of_nodes() > 0
>       assert 'start' in graph.graph
E       AssertionError: assert 'start' in {'mode': 'dynamic', 'timeformat': 'datetime'}
E        +  where {'mode': 'dynamic', 'timeformat': 'datetime'} = <networkx.classes.graph.Graph object at 0x7f6f503210>.graph

pytest/test_analysis.py:319: AssertionError
___________________ TestGraphExport.test_discover_attributes ___________________

self = <test_analysis.TestGraphExport object at 0x7f706e1410>

    def test_discover_attributes(self):
        """Test Attribut-Entdeckung für GEXF."""
        import networkx as nx
    
        G = nx.Graph()
        G.add_node("node1", type="AP", activity=10, vendor="Test")
        G.add_edge("node1", "node2", weight=1.5, kind="Association")
    
        node_attrs, edge_attrs = analysis._discover_attributes(G)
    
        assert isinstance(node_attrs, dict)
        assert isinstance(edge_attrs, dict)
        assert 'type' in node_attrs
        assert 'activity' in node_attrs
>       assert 'weight' in edge_attrs
E       AssertionError: assert 'weight' in {}

pytest/test_analysis.py:336: AssertionError
______________ TestAnalysisEdgeCases.test_single_client_analysis _______________

self = <test_analysis.TestAnalysisEdgeCases object at 0x7f706e29d0>

    def test_single_client_analysis(self):
        """Test Analyse mit nur einem Client."""
        state = WifiAnalysisState()
        client = ClientState(mac="aa:bb:cc:dd:ee:ff")
>       client.all_packet_ts = np.array([time.time(), time.time() + 1])
E       NameError: name 'time' is not defined

pytest/test_analysis.py:379: NameError
_____________ TestAnalysisEdgeCases.test_malformed_event_handling ______________

self = <test_analysis.TestAnalysisEdgeCases object at 0x7f706e34d0>

    def test_malformed_event_handling(self):
        """Test Behandlung von fehlerhaften Events."""
        state = WifiAnalysisState()
    
        # Teste mit unvollständigem Event
>       malformed_event = {'ts': time.time(), 'type': 'beacon'}  # Fehlt bssid
E       NameError: name 'time' is not defined

pytest/test_analysis.py:406: NameError
________________ TestUtilsModule.test_intelligent_vendor_lookup ________________

self = <test_app.TestUtilsModule object at 0x7f706ee890>

    def test_intelligent_vendor_lookup(self):
>       assert "Apple" in utils.lookup_vendor("a8:51:ab:0c:b9:e9")
E       TypeError: argument of type 'NoneType' is not iterable

pytest/test_app.py:71: TypeError
_____________ TestAnalysisModule.test_features_for_client_behavior _____________

self = <test_app.TestAnalysisModule object at 0x7f706eecd0>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f69104390>

    def test_features_for_client_behavior(self, populated_state):
        client = populated_state.clients['a8:51:ab:0c:b9:e9']
>       features = analysis.features_for_client_behavior(client)
E       AttributeError: module 'wlan_tool.analysis' has no attribute 'features_for_client_behavior'

pytest/test_app.py:108: AttributeError
_________________ TestAnalysisModule.test_cluster_clients_runs _________________

self = <test_app.TestAnalysisModule object at 0x7f706cea50>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f6f137a50>

    def test_cluster_clients_runs(self, populated_state):
>       clustered_df, feature_df = analysis.cluster_clients(populated_state, algo="kmeans", n_clusters=2)
E       AttributeError: module 'wlan_tool.analysis' has no attribute 'cluster_clients'

pytest/test_app.py:117: AttributeError
___________________ TestAnalysisModule.test_profile_clusters ___________________

self = <test_app.TestAnalysisModule object at 0x7f707009d0>

    def test_profile_clusters(self):
        feature_data = {'original_macs': ['mac1', 'mac2'], 'feature1': [10, 20], 'feature2': [1, 2]}
        feature_df = pd.DataFrame(feature_data)
        cluster_data = {'original_macs': ['mac1', 'mac2'], 'cluster': [0, 0]}
        clustered_df = pd.DataFrame(cluster_data)
>       profiles = analysis.profile_clusters(feature_df, clustered_df)
E       AttributeError: module 'wlan_tool.analysis' has no attribute 'profile_clusters'

pytest/test_app.py:128: AttributeError
_____________ TestPacketParsing.test_packet_to_event_probe_request _____________

self = <test_capture.TestPacketParsing object at 0x7f70704810>

    def test_packet_to_event_probe_request(self):
        """Test Probe-Request-Paket zu Event-Konvertierung."""
        rt_layer = RadioTap(
            present="Flags+Channel+dBm_AntSignal",
            Flags="",
            ChannelFrequency=2412,
            dBm_AntSignal=-60
        )
        dot11_layer = Dot11(
            type=0, subtype=4,
            addr1='ff:ff:ff:ff:ff:ff',  # Broadcast
            addr2='aa:bb:cc:dd:ee:ff'   # Client
        )
        ssid_ie = Dot11Elt(
            ID=0,
            info=b'TestSSID'
        )
    
        pkt = rt_layer / dot11_layer / ssid_ie
        pkt.time = time.time()
    
        event = capture.packet_to_event(pkt)
    
        assert event is not None
        assert event['type'] == 'probe_req'
        assert event['client'] == 'aa:bb:cc:dd:ee:ff'
        assert event['rssi'] == -60
>       assert 'TestSSID' in event['ies'][0]
E       AssertionError: assert 'TestSSID' in ['5465737453534944']

pytest/test_capture.py:62: AssertionError
______________ TestPacketParsing.test_packet_to_event_data_frame _______________

self = <test_capture.TestPacketParsing object at 0x7f70704e10>

    def test_packet_to_event_data_frame(self):
        """Test Data-Frame zu Event-Konvertierung."""
>       rt_layer = RadioTap(
            present="Flags+Channel+dBm_AntSignal+MCS_index",
            Flags="",
            ChannelFrequency=2412,
            dBm_AntSignal=-55,
            MCS_index=7
        )

pytest/test_capture.py:66: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.11/site-packages/scapy/base_classes.py:399: in __call__
    i.__init__(*args, **kargs)
.venv/lib/python3.11/site-packages/scapy/packet.py:178: in __init__
    self.get_field(fname).any2i(self, value)
.venv/lib/python3.11/site-packages/scapy/fields.py:3052: in any2i
    return self._fixup_val(super(FlagsField, self).any2i(pkt, x))
.venv/lib/python3.11/site-packages/scapy/fields.py:3048: in _fixup_val
    return FlagValue(x, self.names)
.venv/lib/python3.11/site-packages/scapy/fields.py:2835: in __init__
    self.value = self._fixvalue(value)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'FlagValue' object has no attribute 'value'") raised in repr()] FlagValue object at 0x7f6b05b6c0>
value = ['Flags', 'Channel', 'dBm_AntSignal', 'MCS_index']

    def _fixvalue(self, value):
        # type: (Any) -> int
        if not value:
            return 0
        if isinstance(value, six.string_types):
            value = value.split('+') if self.multi else list(value)
        if isinstance(value, list):
            y = 0
            for i in value:
>               y |= 1 << self.names.index(i)
E               ValueError: 'MCS_index' is not in list

.venv/lib/python3.11/site-packages/scapy/fields.py:2827: ValueError
____________ TestPacketParsing.test_packet_to_event_with_dns_query _____________

self = <test_capture.TestPacketParsing object at 0x7f70705a50>

    def test_packet_to_event_with_dns_query(self):
        """Test Paket mit DNS-Query."""
        from scapy.layers.dns import DNSQR
    
        rt_layer = RadioTap(
            present="Flags+Channel+dBm_AntSignal",
            Flags="",
            ChannelFrequency=2412,
            dBm_AntSignal=-50
        )
        dot11_layer = Dot11(
            type=2, subtype=0,
            addr1='aa:bb:cc:dd:ee:ff',
            addr2='11:22:33:44:55:66'
        )
        dns_layer = DNSQR(qname=b'example.com')
    
        pkt = rt_layer / dot11_layer / dns_layer
        pkt.time = time.time()
        pkt.dport = 53  # DNS-Port
    
        event = capture.packet_to_event(pkt)
    
        assert event is not None
        assert event['type'] == 'data'
>       assert event['dns_query'] == 'example.com'
E       AssertionError: assert 'example.com.' == 'example.com'
E         
E         - example.com
E         + example.com.
E         ?            +

pytest/test_capture.py:127: AssertionError
_______________ TestPacketParsing.test_packet_to_event_with_dhcp _______________

self = <test_capture.TestPacketParsing object at 0x7f70706050>

    def test_packet_to_event_with_dhcp(self):
        """Test Paket mit DHCP-Informationen."""
        from scapy.layers.dhcp import DHCP, BOOTP
    
        rt_layer = RadioTap(
            present="Flags+Channel+dBm_AntSignal",
            Flags="",
            ChannelFrequency=2412,
            dBm_AntSignal=-50
        )
        dot11_layer = Dot11(
            type=2, subtype=0,
            addr1='aa:bb:cc:dd:ee:ff',
            addr2='11:22:33:44:55:66'
        )
        bootp_layer = BOOTP(chaddr=b'\x11\x22\x33\x44\x55\x66')
        dhcp_layer = DHCP(options=[(53, 3), (12, b'TestHostname')])  # DHCP Request mit Hostname
    
        pkt = rt_layer / dot11_layer / bootp_layer / dhcp_layer
        pkt.time = time.time()
    
        event = capture.packet_to_event(pkt)
    
        assert event is not None
        assert event['type'] == 'data'
>       assert event['hostname'] == 'TestHostname'
E       KeyError: 'hostname'

pytest/test_capture.py:154: KeyError
____________ TestChannelHopper.test_channel_hopper_command_failure _____________

self = <test_capture.TestChannelHopper object at 0x7f70707410>
mock_run = <MagicMock name='run' id='547224058576'>

    @patch('subprocess.run')
    def test_channel_hopper_command_failure(self, mock_run):
        """Test ChannelHopper bei Kommando-Fehlern."""
>       mock_run.side_effect = subprocess.CalledProcessError(1, "iw")
E       NameError: name 'subprocess' is not defined

pytest/test_capture.py:234: NameError
__________________ TestIEExtraction.test_collect_ies_from_pkt __________________

self = <test_capture.TestIEExtraction object at 0x7f70709010>

    def test_collect_ies_from_pkt(self):
        """Test IE-Sammlung aus Paket."""
        # Erstelle Paket mit IEs
        rt_layer = RadioTap()
        dot11_layer = Dot11(type=0, subtype=8)
        beacon_layer = Dot11Beacon()
        ssid_ie = Dot11Elt(ID=0, info=b'TestSSID')
        vendor_ie = Dot11Elt(ID=221, info=b'\x00\x17\xf2\x0a\x01\x01')
    
        pkt = rt_layer / dot11_layer / beacon_layer / ssid_ie / vendor_ie
    
        ies, ie_order = capture._collect_ies_from_pkt(pkt)
    
        assert isinstance(ies, dict)
        assert isinstance(ie_order, list)
        assert 0 in ies  # SSID IE
        assert 221 in ies  # Vendor IE
>       assert 'TestSSID' in ies[0]
E       AssertionError: assert 'TestSSID' in ['5465737453534944']

pytest/test_capture.py:352: AssertionError
______________________ TestIEExtraction.test_extract_seq _______________________

self = <test_capture.TestIEExtraction object at 0x7f70709c10>

    def test_extract_seq(self):
        """Test Sequenznummer-Extraktion."""
        dot11 = Dot11(SC=0x1234)  # SC = 0x1234, >> 4 = 0x123
    
        seq = capture._extract_seq(dot11)
        assert seq == 0x123
    
        # Test mit None
        seq = capture._extract_seq(None)
>       assert seq is None
E       assert 0 is None

pytest/test_capture.py:377: AssertionError
____________ TestErrorHandling.test_packet_to_event_encoding_error _____________

self = <test_capture.TestErrorHandling object at 0x7f7070aa50>

    def test_packet_to_event_encoding_error(self):
        """Test mit Encoding-Fehlern."""
        rt_layer = RadioTap()
        dot11_layer = Dot11(type=0, subtype=8, addr3='aa:bb:cc:dd:ee:ff')
        beacon_layer = Dot11Beacon()
        # Erstelle IE mit ungültigem UTF-8
        ssid_ie = Dot11Elt(ID=0, info=b'\xff\xfe\xfd')
    
        pkt = rt_layer / dot11_layer / beacon_layer / ssid_ie
        pkt.time = time.time()
    
        # Sollte nicht crashen
        event = capture.packet_to_event(pkt)
        if event is not None:
>           assert event['ssid'] == "<binary>"  # Sollte als binary markiert werden
E           AssertionError: assert '<hidden>' == '<binary>'
E             
E             - <binary>
E             + <hidden>

pytest/test_capture.py:410: AssertionError
____________ TestCaptureController.test_select_interface_automatic _____________

self = <test_controllers.TestCaptureController object at 0x7f70726350>
mock_find_interfaces = <MagicMock name='find_wlan_interfaces' id='547149389584'>
mock_console = <MagicMock id='547338163856'>

    @patch('wlan_tool.pre_run_checks.find_wlan_interfaces')
    def test_select_interface_automatic(self, mock_find_interfaces, mock_console):
        """Test automatische Interface-Auswahl."""
        mock_find_interfaces.return_value = ["wlan0", "wlan1"]
    
        args = MagicMock()
        args.iface = None
        config_data = {}
    
        controller = CaptureController(args, config_data, mock_console)
    
        with patch('rich.prompt.Prompt.ask', return_value="wlan0"):
>           iface = controller._select_interface()

pytest/test_controllers.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.controllers.CaptureController object at 0x7f64a51fd0>

    def _select_interface(self) -> Optional[str]:
        """Wählt das zu verwendende physische WLAN-Interface aus."""
        iface = self.args.iface
        if not iface:
            self.console.print(
                "[bold cyan]Kein Interface angegeben. Suche nach geeigneten WLAN-Interfaces...[/bold cyan]"
            )
>           suitable_ifaces = pre_run_checks.find_wlan_interfaces()
E           NameError: name 'pre_run_checks' is not defined

wlan_tool/controllers.py:124: NameError
__________ TestCaptureController.test_select_interface_no_interfaces ___________

self = <test_controllers.TestCaptureController object at 0x7f70726710>
mock_find_interfaces = <MagicMock name='find_wlan_interfaces' id='547149080272'>
mock_console = <MagicMock id='547149330768'>

    @patch('wlan_tool.pre_run_checks.find_wlan_interfaces')
    def test_select_interface_no_interfaces(self, mock_find_interfaces, mock_console):
        """Test Interface-Auswahl ohne verfügbare Interfaces."""
        mock_find_interfaces.return_value = []
    
        args = MagicMock()
        args.iface = None
        config_data = {}
    
        controller = CaptureController(args, config_data, mock_console)
    
>       iface = controller._select_interface()

pytest/test_controllers.py:57: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.controllers.CaptureController object at 0x7f64a048d0>

    def _select_interface(self) -> Optional[str]:
        """Wählt das zu verwendende physische WLAN-Interface aus."""
        iface = self.args.iface
        if not iface:
            self.console.print(
                "[bold cyan]Kein Interface angegeben. Suche nach geeigneten WLAN-Interfaces...[/bold cyan]"
            )
>           suitable_ifaces = pre_run_checks.find_wlan_interfaces()
E           NameError: name 'pre_run_checks' is not defined

wlan_tool/controllers.py:124: NameError
____________ TestCaptureController.test_setup_monitor_mode_failure _____________

self = <test_controllers.TestCaptureController object at 0x7f70727850>
mock_run = <MagicMock name='run' id='547139427792'>
mock_console = <MagicMock id='547139380496'>

    @patch('subprocess.run')
    def test_setup_monitor_mode_failure(self, mock_run, mock_console):
        """Test Monitor-Mode-Setup (Fehler)."""
>       mock_run.side_effect = subprocess.CalledProcessError(1, "airmon-ng")
E       NameError: name 'subprocess' is not defined

pytest/test_controllers.py:89: NameError
________ TestAnalysisController.test_analysis_controller_initialization ________

self = <test_controllers.TestAnalysisController object at 0x7f707312d0>
mock_console = <MagicMock id='547139742096'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f640dfbd0>

    def test_analysis_controller_initialization(self, mock_console, populated_state):
        """Test AnalysisController-Initialisierung."""
        args = MagicMock()
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
        assert controller.args == args
        assert controller.config_data == config_data
        assert controller.console == mock_console
        assert controller.plugins == plugins
>       assert controller.state == populated_state
E       AttributeError: 'AnalysisController' object has no attribute 'state'

pytest/test_controllers.py:201: AttributeError
__________________ TestAnalysisController.test_run_inference ___________________

self = <test_controllers.TestAnalysisController object at 0x7f70731890>
mock_score = <MagicMock name='score_pairs_with_recency_and_matching' id='547139745040'>
mock_console = <MagicMock id='547139926288'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f6411fa50>

    @patch('wlan_tool.analysis.logic.score_pairs_with_recency_and_matching')
    def test_run_inference(self, mock_score, mock_console, populated_state):
        """Test Inferenz-Ausführung."""
        mock_score.return_value = []
    
        args = MagicMock()
        args.infer = True
        args.model = None
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       controller.run_inference()
E       AttributeError: 'AnalysisController' object has no attribute 'run_inference'

pytest/test_controllers.py:218: AttributeError
______________ TestAnalysisController.test_run_client_clustering _______________

self = <test_controllers.TestAnalysisController object at 0x7f70731e50>
mock_cluster = <MagicMock name='cluster_clients' id='547139708048'>
mock_console = <MagicMock id='547139521552'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f641176d0>

    @patch('wlan_tool.analysis.logic.cluster_clients')
    def test_run_client_clustering(self, mock_cluster, mock_console, populated_state):
        """Test Client-Clustering."""
        mock_cluster.return_value = (None, None)
    
        args = MagicMock()
        args.cluster_clients = 2
        args.cluster_algo = "kmeans"
        args.no_mac_correlation = False
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       controller.run_client_clustering()
E       AttributeError: 'AnalysisController' object has no attribute 'run_client_clustering'

pytest/test_controllers.py:237: AttributeError
________________ TestAnalysisController.test_run_ap_clustering _________________

self = <test_controllers.TestAnalysisController object at 0x7f70732450>
mock_cluster = <MagicMock name='cluster_aps' id='547149370576'>
mock_console = <MagicMock id='547139854864'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f64a4e710>

    @patch('wlan_tool.analysis.logic.cluster_aps')
    def test_run_ap_clustering(self, mock_cluster, mock_console, populated_state):
        """Test AP-Clustering."""
        mock_cluster.return_value = None
    
        args = MagicMock()
        args.cluster_aps = 2
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       controller.run_ap_clustering()
E       AttributeError: 'AnalysisController' object has no attribute 'run_ap_clustering'

pytest/test_controllers.py:254: AttributeError
_________________ TestAnalysisController.test_run_graph_export _________________

self = <test_controllers.TestAnalysisController object at 0x7f70732a10>
mock_export = <MagicMock name='export_ap_graph' id='547139291920'>
mock_console = <MagicMock id='547139863376'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f640b02d0>

    @patch('wlan_tool.analysis.logic.export_ap_graph')
    def test_run_graph_export(self, mock_export, mock_console, populated_state):
        """Test Graph-Export."""
        mock_export.return_value = True
    
        args = MagicMock()
        args.export_graph = "/tmp/test.gexf"
        args.cluster_aps = 2
        args.graph_include_clients = False
        args.graph_min_activity = 0
        args.graph_min_duration = 0
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       with patch.object(controller, 'run_ap_clustering', return_value=None):

pytest/test_controllers.py:275: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f640b1ad0>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <wlan_tool.controllers.AnalysisController object at 0x7f640b1b90> does not have the attribute 'run_ap_clustering'

../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1419: AttributeError
_________________ TestAnalysisController.test_run_labeling_ui __________________

self = <test_controllers.TestAnalysisController object at 0x7f70732fd0>
mock_label_ui = <MagicMock name='interactive_label_ui' id='547149210064'>
mock_console = <MagicMock id='547149219728'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f6411a710>

    @patch('wlan_tool.presentation.cli.interactive_label_ui')
    def test_run_labeling_ui(self, mock_label_ui, mock_console, populated_state):
        """Test Labeling-UI."""
        args = MagicMock()
        args.label_ui = True
        args.db = "test.db"
        args.label_db = "labels.db"
        args.model = "model.pkl"
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       controller.run_labeling_ui()
E       AttributeError: 'AnalysisController' object has no attribute 'run_labeling_ui'

pytest/test_controllers.py:294: AttributeError
______________ TestAnalysisController.test_run_client_labeling_ui ______________

self = <test_controllers.TestAnalysisController object at 0x7f70733590>
mock_client_label_ui = <MagicMock name='interactive_client_label_ui' id='547139051792'>
mock_console = <MagicMock id='547139379216'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f64075a10>

    @patch('wlan_tool.presentation.cli.interactive_client_label_ui')
    def test_run_client_labeling_ui(self, mock_client_label_ui, mock_console, populated_state):
        """Test Client-Labeling-UI."""
        args = MagicMock()
        args.label_clients = True
        args.label_db = "labels.db"
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       controller.run_client_labeling_ui()
E       AttributeError: 'AnalysisController' object has no attribute 'run_client_labeling_ui'

pytest/test_controllers.py:310: AttributeError
_______________ TestAnalysisController.test_run_mac_correlation ________________

self = <test_controllers.TestAnalysisController object at 0x7f70733c50>
mock_correlate = <MagicMock name='correlate_devices_by_fingerprint' id='546936316560'>
mock_console = <MagicMock id='547139283088'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f57f1c350>

    @patch('wlan_tool.analysis.device_profiler.correlate_devices_by_fingerprint')
    def test_run_mac_correlation(self, mock_correlate, mock_console, populated_state):
        """Test MAC-Korrelation."""
        mock_correlate.return_value = {}
    
        args = MagicMock()
        args.correlate_macs = True
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       controller.run_mac_correlation()
E       AttributeError: 'AnalysisController' object has no attribute 'run_mac_correlation'

pytest/test_controllers.py:327: AttributeError
_____________ TestAnalysisController.test_run_analysis_no_actions ______________

self = <test_controllers.TestAnalysisController object at 0x7f707383d0>
mock_console = <MagicMock id='547139541328'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f64141290>

    def test_run_analysis_no_actions(self, mock_console, populated_state):
        """Test Analyse ohne Aktionen."""
        args = MagicMock()
        args.infer = False
        args.cluster_clients = None
        args.cluster_aps = None
        args.export_graph = None
        args.label_ui = False
        args.label_clients = False
        args.correlate_macs = False
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
        # Sollte nicht crashen
>       controller.run_analysis()

pytest/test_controllers.py:348: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/controllers.py:339: in run_analysis
    self._run_profiling()  # Benötigt state, den es jetzt als self.state hat
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.controllers.AnalysisController object at 0x7f6f124150>

    def _run_profiling(self):
        self.console.print(
            "\n[bold cyan]Starte automatisches Geräte-Profiling...[/bold cyan]"
        )
        device_map = {}
    
        # --- NEU: Versuch 1: TR-064 (FRITZ!Box) ---
        self.console.print(
            "[cyan]Versuch 1: Identifizierung über FRITZ!Box TR-064...[/cyan]"
        )
        # Passwort aus Argumenten oder interaktiv abfragen
        fritz_password = self.args.fritzbox_password
        if FritzHosts and not fritz_password:
            if (
                self.console.input(
                    "Haben Sie ein Passwort für Ihre FRITZ!Box gesetzt? (y/n): "
                ).lower()
                == "y"
            ):
                fritz_password = self.console.input(
                    "Bitte FRITZ!Box-Passwort eingeben: ", password=True
                )
    
        device_map = (
>           device_profiler.get_devices_from_fritzbox_tr064(password=fritz_password)
            or {}
        )
E       NameError: name 'device_profiler' is not defined

wlan_tool/controllers.py:487: NameError
__________ TestAnalysisController.test_run_analysis_multiple_actions ___________

self = <test_controllers.TestAnalysisController object at 0x7f70738b10>
mock_console = <MagicMock id='547139366544'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f57c6be10>

    def test_run_analysis_multiple_actions(self, mock_console, populated_state):
        """Test Analyse mit mehreren Aktionen."""
        args = MagicMock()
        args.infer = True
        args.cluster_clients = 2
        args.cluster_aps = 2
        args.export_graph = "/tmp/test.gexf"
        args.label_ui = False
        args.label_clients = False
        args.correlate_macs = False
        args.model = None
        args.cluster_algo = "kmeans"
        args.no_mac_correlation = False
        args.graph_include_clients = False
        args.graph_min_activity = 0
        args.graph_min_duration = 0
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       with patch.object(controller, 'run_inference'):

pytest/test_controllers.py:372: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f88756950>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <wlan_tool.controllers.AnalysisController object at 0x7f6f1241d0> does not have the attribute 'run_inference'

../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1419: AttributeError
_________ TestControllerEdgeCases.test_analysis_controller_empty_state _________

self = <test_controllers.TestControllerEdgeCases object at 0x7f70731690>
mock_console = <MagicMock id='546933097872'>

    def test_analysis_controller_empty_state(self, mock_console):
        """Test AnalysisController mit leerem State."""
        args = MagicMock()
        args.infer = True
        args.model = None
        config_data = {}
        plugins = {}
        new_events = []
        empty_state = WifiAnalysisState()
    
        controller = AnalysisController(args, config_data, mock_console, plugins, empty_state, new_events)
    
        # Sollte nicht crashen
>       controller.run_inference()
E       AttributeError: 'AnalysisController' object has no attribute 'run_inference'

pytest/test_controllers.py:420: AttributeError
________ TestControllerEdgeCases.test_analysis_controller_with_plugins _________

self = <test_controllers.TestControllerEdgeCases object at 0x7f707265d0>
mock_console = <MagicMock id='547139055568'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f640ee890>

    def test_analysis_controller_with_plugins(self, mock_console, populated_state):
        """Test AnalysisController mit Plugins."""
        args = MagicMock()
        args.run_plugins = ["test_plugin"]
        config_data = {}
    
        mock_plugin = MagicMock()
        mock_plugin.run.return_value = None
        plugins = {"test_plugin": mock_plugin}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       controller.run_plugins()
E       AttributeError: 'AnalysisController' object has no attribute 'run_plugins'

pytest/test_controllers.py:435: AttributeError
____________ TestControllerIntegration.test_full_analysis_workflow _____________

self = <test_controllers.TestControllerIntegration object at 0x7f707393d0>
mock_console = <MagicMock id='547139288016'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f640ed410>

    def test_full_analysis_workflow(self, mock_console, populated_state):
        """Test vollständiger Analyse-Workflow."""
        args = MagicMock()
        args.infer = True
        args.cluster_clients = 2
        args.cluster_aps = 2
        args.export_graph = "/tmp/test.gexf"
        args.label_ui = False
        args.label_clients = False
        args.correlate_macs = False
        args.model = None
        args.cluster_algo = "kmeans"
        args.no_mac_correlation = False
        args.graph_include_clients = False
        args.graph_min_activity = 0
        args.graph_min_duration = 0
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
>       with patch.object(controller, 'run_inference'):

pytest/test_controllers.py:491: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f640ec7d0>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <wlan_tool.controllers.AnalysisController object at 0x7f640ea6d0> does not have the attribute 'run_inference'

../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1419: AttributeError
________________ TestErrorContext.test_error_context_exception _________________

self = <test_error_handling.TestErrorContext object at 0x7f7077fc90>

    def test_error_context_exception(self):
        """Test ErrorContext bei Exception."""
        with pytest.raises(WLANToolError) as exc_info:
            with ErrorContext("test_operation", "TEST_ERROR"):
                raise ValueError("Original error")
    
>       assert "Error in test_operation: Original error" in str(exc_info.value)
E       assert 'Error in test_operation: Original error' in "WLANToolError: Original error (Code: TEST_ERROR) | Details: {'operation': 'test_operation', 'original_type': 'ValueError'}"
E        +  where "WLANToolError: Original error (Code: TEST_ERROR) | Details: {'operation': 'test_operation', 'original_type': 'ValueError'}" = str(WLANToolError('Original error'))
E        +    where WLANToolError('Original error') = <ExceptionInfo WLANToolError('Original error') tblen=2>.value

pytest/test_error_handling.py:172: AssertionError
------------------------------ Captured log call -------------------------------
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in test_operation: Original error | Type: ValueError
_____________________ TestLoggingSystem.test_setup_logging _____________________

self = <test_error_handling.TestLoggingSystem object at 0x7f70590690>

    def test_setup_logging(self):
        """Test Logging-Setup."""
        logger = setup_logging(
            log_level="DEBUG",
            enable_console=True,
            enable_performance_logging=True,
            enable_error_tracking=True
        )
    
        assert logger is not None
        assert logger.name == "wlan_tool"
>       assert logger.level == logging.DEBUG
E       NameError: name 'logging' is not defined

pytest/test_error_handling.py:317: NameError
___________ TestDatabaseErrorHandling.test_database_connection_error ___________

self = <test_error_handling.TestDatabaseErrorHandling object at 0x7f70591ad0>

    def test_database_connection_error(self):
        """Test Datenbankverbindungs-Fehler."""
        with pytest.raises(DatabaseError) as exc_info:
            from wlan_tool.storage.database import db_conn_ctx
            with db_conn_ctx("/invalid/path/database.db"):
                pass
    
>       assert "Database operation failed" in str(exc_info.value)
E       assert 'Database operation failed' in 'WLANToolError: Unexpected database error: WLANToolError: Cannot create database directory: /invalid/path (Code: DB_DI...\\\'directory\\\': \\\'/invalid/path\\\', \\\'original_error\\\': "[Errno 13] Permission denied: \\\'/invalid\\\'"}\'}'
E        +  where 'WLANToolError: Unexpected database error: WLANToolError: Cannot create database directory: /invalid/path (Code: DB_DI...\\\'directory\\\': \\\'/invalid/path\\\', \\\'original_error\\\': "[Errno 13] Permission denied: \\\'/invalid\\\'"}\'}' = str(DatabaseError('Unexpected database error: WLANToolError: Cannot create database directory: /invalid/path (Code: DB_DIR...ILED) | Details: {\'directory\': \'/invalid/path\', \'original_error\': "[Errno 13] Permission denied: \'/invalid\'"}'))
E        +    where DatabaseError('Unexpected database error: WLANToolError: Cannot create database directory: /invalid/path (Code: DB_DIR...ILED) | Details: {\'directory\': \'/invalid/path\', \'original_error\': "[Errno 13] Permission denied: \'/invalid\'"}') = <ExceptionInfo DatabaseError('Unexpected database error: WLANToolError: Cannot create database directory: /invalid/pat...etails: {\'directory\': \'/invalid/path\', \'original_error\': "[Errno 13] Permission denied: \'/invalid\'"}') tblen=3>.value

pytest/test_error_handling.py:344: AssertionError
----------------------------- Captured stdout call -----------------------------
2025-10-19 09:19:38,818 | DEBUG    | Starting operation: database_connection
2025-10-19 09:19:38,819 | ERROR    | Error in database_connection: WLANToolError: Cannot create database directory: /invalid/path (Code: DB_DIR_CREATION_FAILED) | Details: {'directory': '/invalid/path', 'original_error': "[Errno 13] Permission denied: '/invalid'"} (Code: DB_DIR_CREATION_FAILED) | Details: {'directory': '/invalid/path', 'original_error': "[Errno 13] Permission denied: '/invalid'"}
2025-10-19 09:19:38,824 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/pathlib.py", line 1116, in mkdir
    os.mkdir(self, mode)
FileNotFoundError: [Errno 2] No such file or directory: '/invalid/path'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 81, in db_conn_ctx
    db_dir.mkdir(parents=True, exist_ok=True)
  File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/pathlib.py", line 1120, in mkdir
    self.parent.mkdir(parents=True, exist_ok=True)
  File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/pathlib.py", line 1116, in mkdir
    os.mkdir(self, mode)
PermissionError: [Errno 13] Permission denied: '/invalid'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 83, in db_conn_ctx
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Cannot create database directory: /invalid/path (Code: DB_DIR_CREATION_FAILED) | Details: {'directory': '/invalid/path', 'original_error': "[Errno 13] Permission denied: '/invalid'"}

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in database_connection: WLANToolError: Cannot create database directory: /invalid/path (Code: DB_DIR_CREATION_FAILED) | Details: {'directory': '/invalid/path', 'original_error': "[Errno 13] Permission denied: '/invalid'"} (Code: DB_DIR_CREATION_FAILED) | Details: {'directory': '/invalid/path', 'original_error': "[Errno 13] Permission denied: '/invalid'"}
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/pathlib.py", line 1116, in mkdir
    os.mkdir(self, mode)
FileNotFoundError: [Errno 2] No such file or directory: '/invalid/path'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 81, in db_conn_ctx
    db_dir.mkdir(parents=True, exist_ok=True)
  File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/pathlib.py", line 1120, in mkdir
    self.parent.mkdir(parents=True, exist_ok=True)
  File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/pathlib.py", line 1116, in mkdir
    os.mkdir(self, mode)
PermissionError: [Errno 13] Permission denied: '/invalid'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 83, in db_conn_ctx
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Cannot create database directory: /invalid/path (Code: DB_DIR_CREATION_FAILED) | Details: {'directory': '/invalid/path', 'original_error': "[Errno 13] Permission denied: '/invalid'"}
___________ TestDatabaseErrorHandling.test_database_migration_error ____________

self = <test_error_handling.TestDatabaseErrorHandling object at 0x7f7058a7d0>

    def test_database_migration_error(self):
        """Test Datenbankmigrations-Fehler."""
        with tempfile.NamedTemporaryFile(suffix='.db', delete=False) as f:
            db_path = f.name
    
        try:
            # Erstelle ungültige Migration
            migrations_dir = Path("wlan_tool/assets/sql_data/versions")
            migrations_dir.mkdir(parents=True, exist_ok=True)
    
            invalid_migration = migrations_dir / "999_invalid.sql"
            invalid_migration.write_text("INVALID SQL SYNTAX")
    
>           with pytest.raises(DatabaseError):
E           Failed: DID NOT RAISE <class 'wlan_tool.exceptions.DatabaseError'>

pytest/test_error_handling.py:360: Failed
----------------------------- Captured stdout call -----------------------------
2025-10-19 09:19:38,855 | DEBUG    | Starting operation: database_migration
2025-10-19 09:19:38,856 | DEBUG    | Starting operation: database_connection
2025-10-19 09:19:38,871 | INFO     | Current DB version: 0. Looking for migrations...
2025-10-19 09:19:38,871 | INFO     | Applying migration: 001_initial_schema.sql (Version 1)
2025-10-19 09:19:38,935 | INFO     | DB successfully migrated to version 1
2025-10-19 09:19:38,935 | INFO     | Applying migration: 002_add_dns_table.sql (Version 2)
2025-10-19 09:19:38,937 | INFO     | DB successfully migrated to version 2
2025-10-19 09:19:38,937 | INFO     | Applying migration: 003_add_network_info.sql (Version 3)
2025-10-19 09:19:38,939 | INFO     | DB successfully migrated to version 3
2025-10-19 09:19:38,940 | INFO     | Applying migration: 004_add_indexes.sql (Version 4)
2025-10-19 09:19:38,942 | INFO     | DB successfully migrated to version 4
2025-10-19 09:19:38,942 | INFO     | Applying migration: 999_invalid.sql (Version 999)
2025-10-19 09:19:38,943 | ERROR    | Unexpected error during migration 999_invalid.sql: WLANToolError: Migration failed: 999_invalid.sql (Code: MIGRATION_EXECUTION_FAILED) | Details: {'migration_file': '999_invalid.sql', 'version': 999, 'sqlite_error': 'near "INVALID": syntax error'}
2025-10-19 09:19:38,967 | INFO     | Database is up to date.
------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_migration
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
INFO     wlan_tool.storage.database:database.py:157 Current DB version: 0. Looking for migrations...
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 001_initial_schema.sql (Version 1)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 1
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 002_add_dns_table.sql (Version 2)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 2
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 003_add_network_info.sql (Version 3)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 3
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 004_add_indexes.sql (Version 4)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 4
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 999_invalid.sql (Version 999)
ERROR    wlan_tool.storage.database:database.py:199 Unexpected error during migration 999_invalid.sql: WLANToolError: Migration failed: 999_invalid.sql (Code: MIGRATION_EXECUTION_FAILED) | Details: {'migration_file': '999_invalid.sql', 'version': 999, 'sqlite_error': 'near "INVALID": syntax error'}
INFO     wlan_tool.storage.database:database.py:204 Database is up to date.
__________ TestAnalysisErrorHandling.test_client_features_null_state ___________

self = <test_error_handling.TestAnalysisErrorHandling object at 0x7f7077f850>

    def test_client_features_null_state(self):
        """Test Client-Features mit None-State."""
        from wlan_tool.analysis.logic import features_for_client
    
>       with pytest.raises(ValidationError) as exc_info:
E       Failed: DID NOT RAISE <class 'wlan_tool.exceptions.ValidationError'>

pytest/test_error_handling.py:377: Failed
----------------------------- Captured stdout call -----------------------------
2025-10-19 09:19:39,012 | DEBUG    | Starting operation: client_features_extraction
2025-10-19 09:19:39,012 | ERROR    | Error in client_features_extraction: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'} (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}
2025-10-19 09:19:39,013 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 229, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}

2025-10-19 09:19:39,013 | ERROR    | Unexpected error in features_for_client: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}
2025-10-19 09:19:39,014 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 229, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_features_extraction
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in client_features_extraction: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'} (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 229, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}

ERROR    wlan_tool.analysis.logic:exceptions.py:165 Unexpected error in features_for_client: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}
DEBUG    wlan_tool.analysis.logic:exceptions.py:166 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 229, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}
_________ TestAnalysisErrorHandling.test_client_features_invalid_type __________

self = <test_error_handling.TestAnalysisErrorHandling object at 0x7f70591410>

    def test_client_features_invalid_type(self):
        """Test Client-Features mit ungültigem Typ."""
        from wlan_tool.analysis.logic import features_for_client
    
>       with pytest.raises(ValidationError) as exc_info:
E       Failed: DID NOT RAISE <class 'wlan_tool.exceptions.ValidationError'>

pytest/test_error_handling.py:387: Failed
----------------------------- Captured stdout call -----------------------------
2025-10-19 09:19:39,050 | DEBUG    | Starting operation: client_features_extraction
2025-10-19 09:19:39,051 | ERROR    | Error in client_features_extraction: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"} (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}
2025-10-19 09:19:39,051 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 236, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}

2025-10-19 09:19:39,051 | ERROR    | Unexpected error in features_for_client: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}
2025-10-19 09:19:39,052 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 236, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_features_extraction
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in client_features_extraction: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"} (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 236, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}

ERROR    wlan_tool.analysis.logic:exceptions.py:165 Unexpected error in features_for_client: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}
DEBUG    wlan_tool.analysis.logic:exceptions.py:166 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 236, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}
_________ TestAnalysisErrorHandling.test_clustering_invalid_parameters _________

self = <test_error_handling.TestAnalysisErrorHandling object at 0x7f70591dd0>

    def test_clustering_invalid_parameters(self):
        """Test Clustering mit ungültigen Parametern."""
        from wlan_tool.analysis.logic import cluster_clients
        from wlan_tool.storage.state import WifiAnalysisState
    
        state = WifiAnalysisState()
    
        # Teste ungültige n_clusters
>       with pytest.raises(ValidationError) as exc_info:
E       Failed: DID NOT RAISE <class 'wlan_tool.exceptions.ValidationError'>

pytest/test_error_handling.py:401: Failed
----------------------------- Captured stdout call -----------------------------
2025-10-19 09:19:39,081 | DEBUG    | Starting operation: client_clustering
2025-10-19 09:19:39,081 | ERROR    | Error in client_clustering: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0} (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}
2025-10-19 09:19:39,082 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 495, in cluster_clients
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}

2025-10-19 09:19:39,082 | ERROR    | Unexpected error in cluster_clients: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}
2025-10-19 09:19:39,083 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 495, in cluster_clients
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_clustering
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in client_clustering: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0} (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 495, in cluster_clients
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}

ERROR    wlan_tool.analysis.logic:exceptions.py:165 Unexpected error in cluster_clients: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}
DEBUG    wlan_tool.analysis.logic:exceptions.py:166 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/analysis/logic.py", line 495, in cluster_clients
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}
___________ TestFileSystemErrorHandling.test_csv_export_invalid_path ___________

self = <test_error_handling.TestFileSystemErrorHandling object at 0x7f705908d0>

    def test_csv_export_invalid_path(self):
        """Test CSV-Export mit ungültigem Pfad."""
        from wlan_tool.storage.database import export_confirmed_to_csv
    
>       with pytest.raises(ValidationError) as exc_info:
E       Failed: DID NOT RAISE <class 'wlan_tool.exceptions.ValidationError'>

pytest/test_error_handling.py:422: Failed
----------------------------- Captured stdout call -----------------------------
2025-10-19 09:19:39,112 | DEBUG    | Starting operation: csv_export
2025-10-19 09:19:39,113 | ERROR    | Error in csv_export: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''} (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}
2025-10-19 09:19:39,114 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}

2025-10-19 09:19:39,114 | ERROR    | Error in export_confirmed_to_csv: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}
2025-10-19 09:19:39,114 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: csv_export
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in csv_export: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''} (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}

ERROR    wlan_tool.storage.database:exceptions.py:153 Error in export_confirmed_to_csv: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}
DEBUG    wlan_tool.storage.database:exceptions.py:154 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}
____________ TestFileSystemErrorHandling.test_csv_export_missing_db ____________

self = <test_error_handling.TestFileSystemErrorHandling object at 0x7f70591f10>

    def test_csv_export_missing_db(self):
        """Test CSV-Export mit fehlender Datenbank."""
        from wlan_tool.storage.database import export_confirmed_to_csv
    
>       with pytest.raises(FileSystemError) as exc_info:
E       Failed: DID NOT RAISE <class 'wlan_tool.exceptions.FileSystemError'>

pytest/test_error_handling.py:432: Failed
----------------------------- Captured stdout call -----------------------------
2025-10-19 09:19:39,143 | DEBUG    | Starting operation: csv_export
2025-10-19 09:19:39,144 | ERROR    | Error in csv_export: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'} (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}
2025-10-19 09:19:39,145 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}

2025-10-19 09:19:39,145 | ERROR    | Error in export_confirmed_to_csv: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}
2025-10-19 09:19:39,146 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: csv_export
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in csv_export: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'} (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}

ERROR    wlan_tool.storage.database:exceptions.py:153 Error in export_confirmed_to_csv: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}
DEBUG    wlan_tool.storage.database:exceptions.py:154 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}
____________ TestErrorHandlingEdgeCases.test_nested_error_contexts _____________

self = <test_error_handling.TestErrorHandlingEdgeCases object at 0x7f70593350>

    def test_nested_error_contexts(self):
        """Test verschachtelte Error-Contexts."""
        with ErrorContext("outer_operation", "OUTER_ERROR") as outer:
            with ErrorContext("inner_operation", "INNER_ERROR") as inner:
>               raise ValueError("Inner error")
E               ValueError: Inner error

pytest/test_error_handling.py:473: ValueError

The above exception was the direct cause of the following exception:

self = <test_error_handling.TestErrorHandlingEdgeCases object at 0x7f70593350>

    def test_nested_error_contexts(self):
        """Test verschachtelte Error-Contexts."""
        with ErrorContext("outer_operation", "OUTER_ERROR") as outer:
>           with ErrorContext("inner_operation", "INNER_ERROR") as inner:

pytest/test_error_handling.py:472: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.exceptions.ErrorContext object at 0x7f57c1d250>
exc_type = <class 'ValueError'>, exc_val = ValueError('Inner error')
exc_tb = <traceback object at 0x7f57c1eb00>

    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type is not None:
            error_msg = f"Error in {self.operation}: {exc_val}"
    
            if isinstance(exc_val, WLANToolError):
                error_msg += f" (Code: {exc_val.error_code})"
                if exc_val.details:
                    error_msg += f" | Details: {exc_val.details}"
            else:
                error_msg += f" | Type: {exc_type.__name__}"
    
            self.logger.log(self.log_level, error_msg)
            self.logger.debug(f"Traceback: {traceback.format_exc()}")
    
            # Konvertiere zu WLANToolError falls nötig
            if not isinstance(exc_val, WLANToolError):
                wlan_error = WLANToolError(
                    message=str(exc_val),
                    error_code=self.error_code or "CONTEXT_ERROR",
                    details={
                        "operation": self.operation,
                        "original_type": exc_type.__name__,
                    },
                )
>               raise wlan_error from exc_val
E               wlan_tool.exceptions.WLANToolError: WLANToolError: Inner error (Code: INNER_ERROR) | Details: {'operation': 'inner_operation', 'original_type': 'ValueError'}

wlan_tool/exceptions.py:313: WLANToolError
----------------------------- Captured stdout call -----------------------------
2025-10-19 09:19:40,183 | DEBUG    | Starting operation: outer_operation
2025-10-19 09:19:40,184 | DEBUG    | Starting operation: inner_operation
2025-10-19 09:19:40,184 | ERROR    | Error in inner_operation: Inner error | Type: ValueError
2025-10-19 09:19:40,184 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/pytest/test_error_handling.py", line 473, in test_nested_error_contexts
    raise ValueError("Inner error")
ValueError: Inner error

2025-10-19 09:19:40,185 | ERROR    | Error in outer_operation: WLANToolError: Inner error (Code: INNER_ERROR) | Details: {'operation': 'inner_operation', 'original_type': 'ValueError'} (Code: INNER_ERROR) | Details: {'operation': 'inner_operation', 'original_type': 'ValueError'}
2025-10-19 09:19:40,186 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/pytest/test_error_handling.py", line 473, in test_nested_error_contexts
    raise ValueError("Inner error")
ValueError: Inner error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/pi/hacking/pytest/test_error_handling.py", line 472, in test_nested_error_contexts
    with ErrorContext("inner_operation", "INNER_ERROR") as inner:
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 313, in __exit__
    raise wlan_error from exc_val
wlan_tool.exceptions.WLANToolError: WLANToolError: Inner error (Code: INNER_ERROR) | Details: {'operation': 'inner_operation', 'original_type': 'ValueError'}

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: outer_operation
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: inner_operation
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in inner_operation: Inner error | Type: ValueError
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/pytest/test_error_handling.py", line 473, in test_nested_error_contexts
    raise ValueError("Inner error")
ValueError: Inner error

ERROR    wlan_tool.exceptions:exceptions.py:300 Error in outer_operation: WLANToolError: Inner error (Code: INNER_ERROR) | Details: {'operation': 'inner_operation', 'original_type': 'ValueError'} (Code: INNER_ERROR) | Details: {'operation': 'inner_operation', 'original_type': 'ValueError'}
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/pytest/test_error_handling.py", line 473, in test_nested_error_contexts
    raise ValueError("Inner error")
ValueError: Inner error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/pi/hacking/pytest/test_error_handling.py", line 472, in test_nested_error_contexts
    with ErrorContext("inner_operation", "INNER_ERROR") as inner:
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 313, in __exit__
    raise wlan_error from exc_val
wlan_tool.exceptions.WLANToolError: WLANToolError: Inner error (Code: INNER_ERROR) | Details: {'operation': 'inner_operation', 'original_type': 'ValueError'}
_____________ TestEndToEndWorkflow.test_complete_analysis_pipeline _____________

self = <test_integration.TestEndToEndWorkflow object at 0x7f7059ef50>
sample_events = [{'beacon_interval': 102, 'bssid': '08:96:d7:1a:21:1c', 'cap': 17, 'channel': 6, ...}, {'client': 'a8:51:ab:0c:b9:e9',...-91, ...}, {'client': 'b2:87:23:15:7f:f2', 'ie_order_hash': 67890, 'ies': {0: ['MyOtherWLAN']}, 'rssi': -70, ...}, ...]
temp_db_file = '/tmp/tmpgnzzkpzr.db'

    def test_complete_analysis_pipeline(self, sample_events, temp_db_file):
        """Test kompletter Analyse-Pipeline."""
        # 1. Erstelle State aus Events
        state = WifiAnalysisState()
        state.build_from_events(sample_events)
    
        assert len(state.aps) > 0
        assert len(state.clients) > 0
    
        # 2. Führe Inferenz durch
        results = analysis.score_pairs_with_recency_and_matching(state)
        assert isinstance(results, list)
    
        # 3. Führe Client-Clustering durch
        clustered_df, feature_df = analysis.cluster_clients(state, n_clusters=2)
        if clustered_df is not None:
            assert len(clustered_df) > 0
    
        # 4. Führe AP-Clustering durch
>       ap_clustered_df = analysis.cluster_aps(state, n_clusters=2)

pytest/test_integration.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/analysis/logic.py:736: in cluster_aps
    df["cluster"] = kmeans.fit_predict(X_scaled)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1071: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1351: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1490: in fit
    self._check_params_vs_input(X)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1431: in _check_params_vs_input
    super()._check_params_vs_input(X, default_n_init=10)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = KMeans(n_clusters=2, random_state=42)
X = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])
default_n_init = 10

    def _check_params_vs_input(self, X, default_n_init=None):
        # n_clusters
        if X.shape[0] < self.n_clusters:
>           raise ValueError(
                f"n_samples={X.shape[0]} should be >= n_clusters={self.n_clusters}."
            )
E           ValueError: n_samples=1 should be >= n_clusters=2.

.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:879: ValueError
---------------------------- Captured stdout setup -----------------------------
2025-10-19 09:19:40,291 | DEBUG    | Starting operation: database_migration
2025-10-19 09:19:40,292 | DEBUG    | Starting operation: database_connection
2025-10-19 09:19:40,306 | INFO     | Current DB version: 0. Looking for migrations...
2025-10-19 09:19:40,306 | INFO     | Applying migration: 001_initial_schema.sql (Version 1)
2025-10-19 09:19:40,315 | INFO     | DB successfully migrated to version 1
2025-10-19 09:19:40,315 | INFO     | Applying migration: 002_add_dns_table.sql (Version 2)
2025-10-19 09:19:40,316 | INFO     | DB successfully migrated to version 2
2025-10-19 09:19:40,317 | INFO     | Applying migration: 003_add_network_info.sql (Version 3)
2025-10-19 09:19:40,318 | INFO     | DB successfully migrated to version 3
2025-10-19 09:19:40,318 | INFO     | Applying migration: 004_add_indexes.sql (Version 4)
2025-10-19 09:19:40,320 | INFO     | DB successfully migrated to version 4
2025-10-19 09:19:40,342 | INFO     | Database is up to date.
------------------------------ Captured log setup ------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_migration
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
INFO     wlan_tool.storage.database:database.py:157 Current DB version: 0. Looking for migrations...
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 001_initial_schema.sql (Version 1)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 1
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 002_add_dns_table.sql (Version 2)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 2
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 003_add_network_info.sql (Version 3)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 3
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 004_add_indexes.sql (Version 4)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 4
INFO     wlan_tool.storage.database:database.py:204 Database is up to date.
----------------------------- Captured stdout call -----------------------------
2025-10-19 09:19:40,343 | INFO     | Baue/Aktualisiere Zustand aus Event-Stream auf...
2025-10-19 09:19:40,344 | INFO     | Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
2025-10-19 09:19:40,354 | DEBUG    | Dynamische Normalisierungsfaktoren: {'beacon_count': 1.0, 'probe_resp_count': 1.0, 'supporting_clients': 1.0, 'seq_support': 1.0, 'rssi_std_max': 20.0}
2025-10-19 09:19:40,355 | DEBUG    | Starting operation: client_clustering
2025-10-19 09:19:40,355 | INFO     | Korreliere randomisierte MACs vor der Feature-Extraktion...
2025-10-19 09:19:40,355 | INFO     | Fand 0 Gruppen von potenziell zusammengehörigen randomisierten MACs.
2025-10-19 09:19:40,356 | DEBUG    | Starting operation: client_features_extraction
2025-10-19 09:19:40,356 | DEBUG    | Starting operation: client_features_extraction
2025-10-19 09:19:40,356 | DEBUG    | Starting operation: client_features_extraction
2025-10-19 09:19:40,370 | INFO     | Wende manuelle Feature-Gewichtungen für Standard-Clustering an...
2025-10-19 09:19:40,371 | DEBUG    | Gewichte Feature 'supports_11ax' mit Faktor 3.0.
2025-10-19 09:19:40,374 | DEBUG    | Gewichte Feature 'supports_11ac' mit Faktor 2.0.
2025-10-19 09:19:40,376 | DEBUG    | Gewichte Feature 'has_apple_ie' mit Faktor 2.5.
2025-10-19 09:19:40,379 | DEBUG    | Gewichte Feature 'has_ms_ie' mit Faktor 2.0.
2025-10-19 09:19:40,382 | DEBUG    | Gewichte Feature 'mimo_streams' mit Faktor 1.5.
2025-10-19 09:19:40,385 | DEBUG    | Gewichte Feature 'is_randomized_mac' mit Faktor 1.2.
2025-10-19 09:19:40,387 | DEBUG    | Gewichte Feature 'was_in_powersave' mit Faktor 1.2.
2025-10-19 09:19:40,390 | DEBUG    | Gewichte Feature 'probe_count' mit Faktor 1.0.
2025-10-19 09:19:40,393 | DEBUG    | Gewichte Feature 'seen_with_ap_count' mit Faktor 1.0.
2025-10-19 09:19:40,396 | INFO     | Verwende KMeans für das Clustering...
------------------------------ Captured log call -------------------------------
INFO     wlan_tool.storage.state:state.py:52 Baue/Aktualisiere Zustand aus Event-Stream auf...
INFO     wlan_tool.storage.state:state.py:57 Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
DEBUG    wlan_tool.analysis.logic:logic.py:148 Dynamische Normalisierungsfaktoren: {'beacon_count': 1.0, 'probe_resp_count': 1.0, 'supporting_clients': 1.0, 'seq_support': 1.0, 'rssi_std_max': 20.0}
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_clustering
INFO     wlan_tool.analysis.logic:logic.py:396 Korreliere randomisierte MACs vor der Feature-Extraktion...
INFO     wlan_tool.analysis.logic:logic.py:791 Fand 0 Gruppen von potenziell zusammengehörigen randomisierten MACs.
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_features_extraction
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_features_extraction
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_features_extraction
INFO     wlan_tool.analysis.logic:logic.py:584 Wende manuelle Feature-Gewichtungen für Standard-Clustering an...
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'supports_11ax' mit Faktor 3.0.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'supports_11ac' mit Faktor 2.0.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'has_apple_ie' mit Faktor 2.5.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'has_ms_ie' mit Faktor 2.0.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'mimo_streams' mit Faktor 1.5.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'is_randomized_mac' mit Faktor 1.2.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'was_in_powersave' mit Faktor 1.2.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'probe_count' mit Faktor 1.0.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'seen_with_ap_count' mit Faktor 1.0.
INFO     wlan_tool.analysis.logic:logic.py:609 Verwende KMeans für das Clustering...
________________ TestEndToEndWorkflow.test_database_integration ________________

self = <test_integration.TestEndToEndWorkflow object at 0x7f7059f5d0>
sample_events = [{'beacon_interval': 102, 'bssid': '08:96:d7:1a:21:1c', 'cap': 17, 'channel': 6, ...}, {'client': 'a8:51:ab:0c:b9:e9',...-91, ...}, {'client': 'b2:87:23:15:7f:f2', 'ie_order_hash': 67890, 'ies': {0: ['MyOtherWLAN']}, 'rssi': -70, ...}, ...]
temp_db_file = '/tmp/tmp1aevscgy.db'

    def test_database_integration(self, sample_events, temp_db_file):
        """Test Datenbank-Integration."""
        # Schreibe Events in Datenbank
        with database.db_conn_ctx(temp_db_file) as conn:
            for event in sample_events:
>               database.add_event(conn, event)
E               AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

pytest/test_integration.py:64: AttributeError

The above exception was the direct cause of the following exception:

path = '/tmp/tmp1aevscgy.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
>           with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):

wlan_tool/storage/database.py:68: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.exceptions.ErrorContext object at 0x7f640d3c10>
exc_type = <class 'AttributeError'>
exc_val = AttributeError("module 'wlan_tool.storage.database' has no attribute 'add_event'")
exc_tb = <traceback object at 0x7f640d0cc0>

    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type is not None:
            error_msg = f"Error in {self.operation}: {exc_val}"
    
            if isinstance(exc_val, WLANToolError):
                error_msg += f" (Code: {exc_val.error_code})"
                if exc_val.details:
                    error_msg += f" | Details: {exc_val.details}"
            else:
                error_msg += f" | Type: {exc_type.__name__}"
    
            self.logger.log(self.log_level, error_msg)
            self.logger.debug(f"Traceback: {traceback.format_exc()}")
    
            # Konvertiere zu WLANToolError falls nötig
            if not isinstance(exc_val, WLANToolError):
                wlan_error = WLANToolError(
                    message=str(exc_val),
                    error_code=self.error_code or "CONTEXT_ERROR",
                    details={
                        "operation": self.operation,
                        "original_type": exc_type.__name__,
                    },
                )
>               raise wlan_error from exc_val
E               wlan_tool.exceptions.WLANToolError: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}

wlan_tool/exceptions.py:313: WLANToolError

The above exception was the direct cause of the following exception:

self = <test_integration.TestEndToEndWorkflow object at 0x7f7059f5d0>
sample_events = [{'beacon_interval': 102, 'bssid': '08:96:d7:1a:21:1c', 'cap': 17, 'channel': 6, ...}, {'client': 'a8:51:ab:0c:b9:e9',...-91, ...}, {'client': 'b2:87:23:15:7f:f2', 'ie_order_hash': 67890, 'ies': {0: ['MyOtherWLAN']}, 'rssi': -70, ...}, ...]
temp_db_file = '/tmp/tmp1aevscgy.db'

    def test_database_integration(self, sample_events, temp_db_file):
        """Test Datenbank-Integration."""
        # Schreibe Events in Datenbank
>       with database.db_conn_ctx(temp_db_file) as conn:

pytest/test_integration.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/contextlib.py:158: in __exit__
    self.gen.throw(typ, value, traceback)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

path = '/tmp/tmp1aevscgy.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
            with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):
                # Validiere Datenbankpfad
                if not _validate_file_path(path):
                    raise ValidationError(
                        f"Invalid database path: {path}",
                        error_code="INVALID_DB_PATH",
                        details={"db_path": path},
                    )
    
                # Erstelle Verzeichnis falls nötig
                db_dir = Path(path).parent
                if not db_dir.exists():
                    try:
                        db_dir.mkdir(parents=True, exist_ok=True)
                    except OSError as e:
                        raise FileSystemError(
                            f"Cannot create database directory: {db_dir}",
                            error_code="DB_DIR_CREATION_FAILED",
                            details={"directory": str(db_dir), "original_error": str(e)},
                        ) from e
    
                # Verbinde zur Datenbank
                conn = sqlite3.connect(path, timeout=Constants.DB_CONNECTION_TIMEOUT)
                conn.row_factory = sqlite3.Row
    
                # Setze pragmas für bessere Performance und Fehlerbehandlung
                conn.execute("PRAGMA foreign_keys = ON")
                conn.execute("PRAGMA journal_mode = WAL")
                conn.execute("PRAGMA synchronous = NORMAL")
                conn.execute("PRAGMA cache_size = 10000")
                conn.execute("PRAGMA temp_store = MEMORY")
    
                yield conn
    
        except sqlite3.Error as e:
            if conn:
                conn.rollback()
            raise DatabaseError(
                get_error_message(ErrorCodes.DB_CONNECTION_FAILED, details=str(e)),
                error_code=ErrorCodes.DB_CONNECTION_FAILED.value,
                details={"db_path": path, "sqlite_error": str(e)},
            ) from e
        except Exception as e:
            if conn:
                conn.rollback()
>           raise DatabaseError(
                f"Unexpected database error: {e}",
                error_code="DB_UNEXPECTED_ERROR",
                details={"db_path": path, "original_error": str(e)},
            ) from e
E           wlan_tool.exceptions.DatabaseError: WLANToolError: Unexpected database error: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'} (Code: DB_UNEXPECTED_ERROR) | Details: {'db_path': '/tmp/tmp1aevscgy.db', 'original_error': "WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}"}

wlan_tool/storage/database.py:113: DatabaseError
---------------------------- Captured stdout setup -----------------------------
2025-10-19 09:19:40,681 | DEBUG    | Starting operation: database_migration
2025-10-19 09:19:40,681 | DEBUG    | Starting operation: database_connection
2025-10-19 09:19:40,696 | INFO     | Current DB version: 0. Looking for migrations...
2025-10-19 09:19:40,696 | INFO     | Applying migration: 001_initial_schema.sql (Version 1)
2025-10-19 09:19:40,706 | INFO     | DB successfully migrated to version 1
2025-10-19 09:19:40,707 | INFO     | Applying migration: 002_add_dns_table.sql (Version 2)
2025-10-19 09:19:40,708 | INFO     | DB successfully migrated to version 2
2025-10-19 09:19:40,708 | INFO     | Applying migration: 003_add_network_info.sql (Version 3)
2025-10-19 09:19:40,710 | INFO     | DB successfully migrated to version 3
2025-10-19 09:19:40,710 | INFO     | Applying migration: 004_add_indexes.sql (Version 4)
2025-10-19 09:19:40,711 | INFO     | DB successfully migrated to version 4
2025-10-19 09:19:40,733 | INFO     | Database is up to date.
------------------------------ Captured log setup ------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_migration
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
INFO     wlan_tool.storage.database:database.py:157 Current DB version: 0. Looking for migrations...
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 001_initial_schema.sql (Version 1)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 1
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 002_add_dns_table.sql (Version 2)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 2
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 003_add_network_info.sql (Version 3)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 3
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 004_add_indexes.sql (Version 4)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 4
INFO     wlan_tool.storage.database:database.py:204 Database is up to date.
----------------------------- Captured stdout call -----------------------------
2025-10-19 09:19:40,735 | DEBUG    | Starting operation: database_connection
2025-10-19 09:19:40,736 | ERROR    | Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
2025-10-19 09:19:40,737 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/hacking/pytest/test_integration.py", line 64, in test_database_integration
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/hacking/pytest/test_integration.py", line 64, in test_database_integration
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'
_________________ TestEndToEndWorkflow.test_config_integration _________________

self = <test_integration.TestEndToEndWorkflow object at 0x7f7059fbd0>

    def test_config_integration(self):
        """Test Konfigurations-Integration."""
        # Teste Konfigurations-Laden
>       config_data = utils.load_config()
E       TypeError: load_config() missing 1 required positional argument: 'profile'

pytest/test_integration.py:82: TypeError
_____________________ TestDataFlow.test_state_persistence ______________________

self = <test_integration.TestDataFlow object at 0x7f70592890>
sample_events = [{'beacon_interval': 102, 'bssid': '08:96:d7:1a:21:1c', 'cap': 17, 'channel': 6, ...}, {'client': 'a8:51:ab:0c:b9:e9',...-91, ...}, {'client': 'b2:87:23:15:7f:f2', 'ie_order_hash': 67890, 'ies': {0: ['MyOtherWLAN']}, 'rssi': -70, ...}, ...]
temp_db_file = '/tmp/tmpthk5j6xo.db'

    def test_state_persistence(self, sample_events, temp_db_file):
        """Test State-Persistierung."""
        # Erstelle State
        state1 = WifiAnalysisState()
        state1.build_from_events(sample_events)
    
        # Schreibe in Datenbank
        with database.db_conn_ctx(temp_db_file) as conn:
            for event in sample_events:
>               database.add_event(conn, event)
E               AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

pytest/test_integration.py:130: AttributeError

The above exception was the direct cause of the following exception:

path = '/tmp/tmpthk5j6xo.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
>           with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):

wlan_tool/storage/database.py:68: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.exceptions.ErrorContext object at 0x7f64a50c90>
exc_type = <class 'AttributeError'>
exc_val = AttributeError("module 'wlan_tool.storage.database' has no attribute 'add_event'")
exc_tb = <traceback object at 0x7f64a50600>

    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type is not None:
            error_msg = f"Error in {self.operation}: {exc_val}"
    
            if isinstance(exc_val, WLANToolError):
                error_msg += f" (Code: {exc_val.error_code})"
                if exc_val.details:
                    error_msg += f" | Details: {exc_val.details}"
            else:
                error_msg += f" | Type: {exc_type.__name__}"
    
            self.logger.log(self.log_level, error_msg)
            self.logger.debug(f"Traceback: {traceback.format_exc()}")
    
            # Konvertiere zu WLANToolError falls nötig
            if not isinstance(exc_val, WLANToolError):
                wlan_error = WLANToolError(
                    message=str(exc_val),
                    error_code=self.error_code or "CONTEXT_ERROR",
                    details={
                        "operation": self.operation,
                        "original_type": exc_type.__name__,
                    },
                )
>               raise wlan_error from exc_val
E               wlan_tool.exceptions.WLANToolError: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}

wlan_tool/exceptions.py:313: WLANToolError

The above exception was the direct cause of the following exception:

self = <test_integration.TestDataFlow object at 0x7f70592890>
sample_events = [{'beacon_interval': 102, 'bssid': '08:96:d7:1a:21:1c', 'cap': 17, 'channel': 6, ...}, {'client': 'a8:51:ab:0c:b9:e9',...-91, ...}, {'client': 'b2:87:23:15:7f:f2', 'ie_order_hash': 67890, 'ies': {0: ['MyOtherWLAN']}, 'rssi': -70, ...}, ...]
temp_db_file = '/tmp/tmpthk5j6xo.db'

    def test_state_persistence(self, sample_events, temp_db_file):
        """Test State-Persistierung."""
        # Erstelle State
        state1 = WifiAnalysisState()
        state1.build_from_events(sample_events)
    
        # Schreibe in Datenbank
>       with database.db_conn_ctx(temp_db_file) as conn:

pytest/test_integration.py:128: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/contextlib.py:158: in __exit__
    self.gen.throw(typ, value, traceback)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

path = '/tmp/tmpthk5j6xo.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
            with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):
                # Validiere Datenbankpfad
                if not _validate_file_path(path):
                    raise ValidationError(
                        f"Invalid database path: {path}",
                        error_code="INVALID_DB_PATH",
                        details={"db_path": path},
                    )
    
                # Erstelle Verzeichnis falls nötig
                db_dir = Path(path).parent
                if not db_dir.exists():
                    try:
                        db_dir.mkdir(parents=True, exist_ok=True)
                    except OSError as e:
                        raise FileSystemError(
                            f"Cannot create database directory: {db_dir}",
                            error_code="DB_DIR_CREATION_FAILED",
                            details={"directory": str(db_dir), "original_error": str(e)},
                        ) from e
    
                # Verbinde zur Datenbank
                conn = sqlite3.connect(path, timeout=Constants.DB_CONNECTION_TIMEOUT)
                conn.row_factory = sqlite3.Row
    
                # Setze pragmas für bessere Performance und Fehlerbehandlung
                conn.execute("PRAGMA foreign_keys = ON")
                conn.execute("PRAGMA journal_mode = WAL")
                conn.execute("PRAGMA synchronous = NORMAL")
                conn.execute("PRAGMA cache_size = 10000")
                conn.execute("PRAGMA temp_store = MEMORY")
    
                yield conn
    
        except sqlite3.Error as e:
            if conn:
                conn.rollback()
            raise DatabaseError(
                get_error_message(ErrorCodes.DB_CONNECTION_FAILED, details=str(e)),
                error_code=ErrorCodes.DB_CONNECTION_FAILED.value,
                details={"db_path": path, "sqlite_error": str(e)},
            ) from e
        except Exception as e:
            if conn:
                conn.rollback()
>           raise DatabaseError(
                f"Unexpected database error: {e}",
                error_code="DB_UNEXPECTED_ERROR",
                details={"db_path": path, "original_error": str(e)},
            ) from e
E           wlan_tool.exceptions.DatabaseError: WLANToolError: Unexpected database error: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'} (Code: DB_UNEXPECTED_ERROR) | Details: {'db_path': '/tmp/tmpthk5j6xo.db', 'original_error': "WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}"}

wlan_tool/storage/database.py:113: DatabaseError
---------------------------- Captured stdout setup -----------------------------
2025-10-19 09:19:40,972 | DEBUG    | Starting operation: database_migration
2025-10-19 09:19:40,973 | DEBUG    | Starting operation: database_connection
2025-10-19 09:19:40,990 | INFO     | Current DB version: 0. Looking for migrations...
2025-10-19 09:19:40,990 | INFO     | Applying migration: 001_initial_schema.sql (Version 1)
2025-10-19 09:19:41,001 | INFO     | DB successfully migrated to version 1
2025-10-19 09:19:41,001 | INFO     | Applying migration: 002_add_dns_table.sql (Version 2)
2025-10-19 09:19:41,002 | INFO     | DB successfully migrated to version 2
2025-10-19 09:19:41,003 | INFO     | Applying migration: 003_add_network_info.sql (Version 3)
2025-10-19 09:19:41,004 | INFO     | DB successfully migrated to version 3
2025-10-19 09:19:41,004 | INFO     | Applying migration: 004_add_indexes.sql (Version 4)
2025-10-19 09:19:41,006 | INFO     | DB successfully migrated to version 4
2025-10-19 09:19:41,028 | INFO     | Database is up to date.
------------------------------ Captured log setup ------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_migration
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
INFO     wlan_tool.storage.database:database.py:157 Current DB version: 0. Looking for migrations...
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 001_initial_schema.sql (Version 1)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 1
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 002_add_dns_table.sql (Version 2)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 2
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 003_add_network_info.sql (Version 3)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 3
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 004_add_indexes.sql (Version 4)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 4
INFO     wlan_tool.storage.database:database.py:204 Database is up to date.
----------------------------- Captured stdout call -----------------------------
2025-10-19 09:19:41,030 | INFO     | Baue/Aktualisiere Zustand aus Event-Stream auf...
2025-10-19 09:19:41,030 | INFO     | Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
2025-10-19 09:19:41,031 | DEBUG    | Starting operation: database_connection
2025-10-19 09:19:41,032 | ERROR    | Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
2025-10-19 09:19:41,033 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/hacking/pytest/test_integration.py", line 130, in test_state_persistence
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

------------------------------ Captured log call -------------------------------
INFO     wlan_tool.storage.state:state.py:52 Baue/Aktualisiere Zustand aus Event-Stream auf...
INFO     wlan_tool.storage.state:state.py:57 Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/hacking/pytest/test_integration.py", line 130, in test_state_persistence
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'
________________ TestLargeDataset.test_large_dataset_processing ________________

self = <test_integration.TestLargeDataset object at 0x7f70588350>

    def test_large_dataset_processing(self):
        """Test Verarbeitung großer Datensätze."""
        # Erstelle großen State
        state = WifiAnalysisState()
    
        # Erstelle 100 APs
        for i in range(100):
            bssid = f"08:96:d7:1a:21:{i:02x}"
>           ap = state.aps[bssid] = state.aps.get(bssid, type(state).__dict__['aps'].__class__())()
E           KeyError: 'aps'

pytest/test_integration.py:158: KeyError
_______________ TestErrorRecovery.test_malformed_event_handling ________________

self = <test_integration.TestErrorRecovery object at 0x7f705a50d0>

    def test_malformed_event_handling(self):
        """Test Behandlung fehlerhafter Events."""
        state = WifiAnalysisState()
    
        # Teste verschiedene fehlerhafte Events
        malformed_events = [
            {},  # Leeres Event
            {'ts': time.time()},  # Nur Zeitstempel
            {'ts': time.time(), 'type': 'invalid'},  # Ungültiger Typ
            {'ts': time.time(), 'type': 'beacon'},  # Beacon ohne BSSID
        ]
    
        for event in malformed_events:
            # Sollte nicht crashen
            try:
>               state.update_from_event(event)

pytest/test_integration.py:241: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f69372d10>
ev = {}, detailed_ies = False

    def update_from_event(self, ev: dict, detailed_ies: bool = False):
>       ts, ev_type = ev["ts"], ev.get("type")
E       KeyError: 'ts'

wlan_tool/storage/state.py:66: KeyError

During handling of the above exception, another exception occurred:

self = <test_integration.TestErrorRecovery object at 0x7f705a50d0>

    def test_malformed_event_handling(self):
        """Test Behandlung fehlerhafter Events."""
        state = WifiAnalysisState()
    
        # Teste verschiedene fehlerhafte Events
        malformed_events = [
            {},  # Leeres Event
            {'ts': time.time()},  # Nur Zeitstempel
            {'ts': time.time(), 'type': 'invalid'},  # Ungültiger Typ
            {'ts': time.time(), 'type': 'beacon'},  # Beacon ohne BSSID
        ]
    
        for event in malformed_events:
            # Sollte nicht crashen
            try:
                state.update_from_event(event)
            except Exception as e:
>               pytest.fail(f"Malformed event should be handled gracefully: {e}")
E               Failed: Malformed event should be handled gracefully: 'ts'

pytest/test_integration.py:243: Failed
______________ TestMemoryManagement.test_memory_usage_large_state ______________

self = <test_integration.TestMemoryManagement object at 0x7f705a6310>

    def test_memory_usage_large_state(self):
        """Test Speicherverbrauch mit großem State."""
        import psutil
        import os
    
        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss
    
        # Erstelle großen State
        state = WifiAnalysisState()
    
        for i in range(1000):
            mac = f"aa:bb:cc:dd:ee:{i:04x}"
>           client = state.clients[mac] = state.clients.get(mac, type(state).__dict__['clients'].__class__())()
E           KeyError: 'clients'

pytest/test_integration.py:295: KeyError
____________ TestMemoryManagement.test_state_pruning_memory_release ____________

self = <test_integration.TestMemoryManagement object at 0x7f705a6910>

    def test_state_pruning_memory_release(self):
        """Test Speicherfreigabe durch State-Pruning."""
        import psutil
        import os
    
        process = psutil.Process(os.getpid())
    
        # Erstelle State mit alten und neuen Daten
        state = WifiAnalysisState()
    
        # Alte Clients (werden gepruned)
        for i in range(100):
            mac = f"old:aa:bb:cc:dd:ee:{i:02x}"
>           client = state.clients[mac] = state.clients.get(mac, type(state).__dict__['clients'].__class__())()
E           KeyError: 'clients'

pytest/test_integration.py:321: KeyError
_____________ TestAnalysisPerformance.test_clustering_performance ______________

self = <test_performance.TestAnalysisPerformance object at 0x7f705aed10>

    def test_clustering_performance(self):
        """Test Clustering-Performance."""
        # Erstelle State mit vielen Clients
        state = WifiAnalysisState()
    
        for i in range(200):
            mac = f"aa:bb:cc:dd:ee:{i:02x}"
>           client = state.clients[mac] = state.clients.get(mac, type(state).__dict__['clients'].__class__())()
E           KeyError: 'clients'

pytest/test_performance.py:147: KeyError
______________ TestAnalysisPerformance.test_inference_performance ______________

self = <test_performance.TestAnalysisPerformance object at 0x7f705af310>

    def test_inference_performance(self):
        """Test Inferenz-Performance."""
        # Erstelle State mit APs und Clients
        state = WifiAnalysisState()
    
        # Erstelle 50 APs
        for i in range(50):
            bssid = f"08:96:d7:1a:21:{i:02x}"
>           ap = state.aps[bssid] = state.aps.get(bssid, type(state).__dict__['aps'].__class__())()
E           KeyError: 'aps'

pytest/test_performance.py:180: KeyError
_____________ TestMemoryPerformance.test_memory_usage_large_state ______________

self = <test_performance.TestMemoryPerformance object at 0x7f705a4e90>

    def test_memory_usage_large_state(self):
        """Test Speicherverbrauch mit großem State."""
        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss
    
        # Erstelle großen State
        state = WifiAnalysisState()
    
        # 1000 Clients
        for i in range(1000):
            mac = f"aa:bb:cc:dd:ee:{i:04x}"
>           client = state.clients[mac] = state.clients.get(mac, type(state).__dict__['clients'].__class__())()
E           KeyError: 'clients'

pytest/test_performance.py:228: KeyError
___________ TestMemoryPerformance.test_memory_cleanup_after_pruning ____________

self = <test_performance.TestMemoryPerformance object at 0x7f705af610>

    def test_memory_cleanup_after_pruning(self):
        """Test Speicherbereinigung nach Pruning."""
        process = psutil.Process(os.getpid())
    
        # Erstelle State mit alten und neuen Daten
        state = WifiAnalysisState()
    
        # 500 alte Clients (werden gepruned)
        for i in range(500):
            mac = f"old:aa:bb:cc:dd:ee:{i:03x}"
>           client = state.clients[mac] = state.clients.get(mac, type(state).__dict__['clients'].__class__())()
E           KeyError: 'clients'

pytest/test_performance.py:269: KeyError
___________ TestDatabasePerformance.test_database_write_performance ____________

self = <test_performance.TestDatabasePerformance object at 0x7f705adcd0>
temp_db_file = '/tmp/tmp_nhw6l5k.db'

    def test_database_write_performance(self, temp_db_file):
        """Test Datenbank-Schreib-Performance."""
        # Erstelle Test-Events
        events = []
        for i in range(1000):
            event = {
                'ts': time.time() + i,
                'type': 'beacon' if i % 2 == 0 else 'probe_req',
                'bssid': f'08:96:d7:1a:21:{i % 100:02x}',
                'ssid': f'SSID_{i % 50}',
                'rssi': -50 - (i % 50),
                'channel': (i % 13) + 1
            }
            events.append(event)
    
        start_time = time.time()
    
        with database.db_conn_ctx(temp_db_file) as conn:
            for event in events:
>               database.add_event(conn, event)
E               AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

pytest/test_performance.py:325: AttributeError

The above exception was the direct cause of the following exception:

path = '/tmp/tmp_nhw6l5k.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
>           with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):

wlan_tool/storage/database.py:68: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.exceptions.ErrorContext object at 0x7f57cd9d10>
exc_type = <class 'AttributeError'>
exc_val = AttributeError("module 'wlan_tool.storage.database' has no attribute 'add_event'")
exc_tb = <traceback object at 0x7f57cda180>

    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type is not None:
            error_msg = f"Error in {self.operation}: {exc_val}"
    
            if isinstance(exc_val, WLANToolError):
                error_msg += f" (Code: {exc_val.error_code})"
                if exc_val.details:
                    error_msg += f" | Details: {exc_val.details}"
            else:
                error_msg += f" | Type: {exc_type.__name__}"
    
            self.logger.log(self.log_level, error_msg)
            self.logger.debug(f"Traceback: {traceback.format_exc()}")
    
            # Konvertiere zu WLANToolError falls nötig
            if not isinstance(exc_val, WLANToolError):
                wlan_error = WLANToolError(
                    message=str(exc_val),
                    error_code=self.error_code or "CONTEXT_ERROR",
                    details={
                        "operation": self.operation,
                        "original_type": exc_type.__name__,
                    },
                )
>               raise wlan_error from exc_val
E               wlan_tool.exceptions.WLANToolError: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}

wlan_tool/exceptions.py:313: WLANToolError

The above exception was the direct cause of the following exception:

self = <test_performance.TestDatabasePerformance object at 0x7f705adcd0>
temp_db_file = '/tmp/tmp_nhw6l5k.db'

    def test_database_write_performance(self, temp_db_file):
        """Test Datenbank-Schreib-Performance."""
        # Erstelle Test-Events
        events = []
        for i in range(1000):
            event = {
                'ts': time.time() + i,
                'type': 'beacon' if i % 2 == 0 else 'probe_req',
                'bssid': f'08:96:d7:1a:21:{i % 100:02x}',
                'ssid': f'SSID_{i % 50}',
                'rssi': -50 - (i % 50),
                'channel': (i % 13) + 1
            }
            events.append(event)
    
        start_time = time.time()
    
>       with database.db_conn_ctx(temp_db_file) as conn:

pytest/test_performance.py:323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/contextlib.py:158: in __exit__
    self.gen.throw(typ, value, traceback)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

path = '/tmp/tmp_nhw6l5k.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
            with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):
                # Validiere Datenbankpfad
                if not _validate_file_path(path):
                    raise ValidationError(
                        f"Invalid database path: {path}",
                        error_code="INVALID_DB_PATH",
                        details={"db_path": path},
                    )
    
                # Erstelle Verzeichnis falls nötig
                db_dir = Path(path).parent
                if not db_dir.exists():
                    try:
                        db_dir.mkdir(parents=True, exist_ok=True)
                    except OSError as e:
                        raise FileSystemError(
                            f"Cannot create database directory: {db_dir}",
                            error_code="DB_DIR_CREATION_FAILED",
                            details={"directory": str(db_dir), "original_error": str(e)},
                        ) from e
    
                # Verbinde zur Datenbank
                conn = sqlite3.connect(path, timeout=Constants.DB_CONNECTION_TIMEOUT)
                conn.row_factory = sqlite3.Row
    
                # Setze pragmas für bessere Performance und Fehlerbehandlung
                conn.execute("PRAGMA foreign_keys = ON")
                conn.execute("PRAGMA journal_mode = WAL")
                conn.execute("PRAGMA synchronous = NORMAL")
                conn.execute("PRAGMA cache_size = 10000")
                conn.execute("PRAGMA temp_store = MEMORY")
    
                yield conn
    
        except sqlite3.Error as e:
            if conn:
                conn.rollback()
            raise DatabaseError(
                get_error_message(ErrorCodes.DB_CONNECTION_FAILED, details=str(e)),
                error_code=ErrorCodes.DB_CONNECTION_FAILED.value,
                details={"db_path": path, "sqlite_error": str(e)},
            ) from e
        except Exception as e:
            if conn:
                conn.rollback()
>           raise DatabaseError(
                f"Unexpected database error: {e}",
                error_code="DB_UNEXPECTED_ERROR",
                details={"db_path": path, "original_error": str(e)},
            ) from e
E           wlan_tool.exceptions.DatabaseError: WLANToolError: Unexpected database error: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'} (Code: DB_UNEXPECTED_ERROR) | Details: {'db_path': '/tmp/tmp_nhw6l5k.db', 'original_error': "WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}"}

wlan_tool/storage/database.py:113: DatabaseError
---------------------------- Captured stdout setup -----------------------------
2025-10-19 09:19:42,463 | DEBUG    | Starting operation: database_migration
2025-10-19 09:19:42,463 | DEBUG    | Starting operation: database_connection
2025-10-19 09:19:42,478 | INFO     | Current DB version: 0. Looking for migrations...
2025-10-19 09:19:42,478 | INFO     | Applying migration: 001_initial_schema.sql (Version 1)
2025-10-19 09:19:42,488 | INFO     | DB successfully migrated to version 1
2025-10-19 09:19:42,489 | INFO     | Applying migration: 002_add_dns_table.sql (Version 2)
2025-10-19 09:19:42,490 | INFO     | DB successfully migrated to version 2
2025-10-19 09:19:42,490 | INFO     | Applying migration: 003_add_network_info.sql (Version 3)
2025-10-19 09:19:42,492 | INFO     | DB successfully migrated to version 3
2025-10-19 09:19:42,492 | INFO     | Applying migration: 004_add_indexes.sql (Version 4)
2025-10-19 09:19:42,493 | INFO     | DB successfully migrated to version 4
2025-10-19 09:19:42,514 | INFO     | Database is up to date.
------------------------------ Captured log setup ------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_migration
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
INFO     wlan_tool.storage.database:database.py:157 Current DB version: 0. Looking for migrations...
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 001_initial_schema.sql (Version 1)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 1
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 002_add_dns_table.sql (Version 2)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 2
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 003_add_network_info.sql (Version 3)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 3
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 004_add_indexes.sql (Version 4)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 4
INFO     wlan_tool.storage.database:database.py:204 Database is up to date.
----------------------------- Captured stdout call -----------------------------
2025-10-19 09:19:42,520 | DEBUG    | Starting operation: database_connection
2025-10-19 09:19:42,523 | ERROR    | Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
2025-10-19 09:19:42,524 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/hacking/pytest/test_performance.py", line 325, in test_database_write_performance
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/hacking/pytest/test_performance.py", line 325, in test_database_write_performance
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'
____________ TestDatabasePerformance.test_database_read_performance ____________

self = <test_performance.TestDatabasePerformance object at 0x7f705afa90>
temp_db_file = '/tmp/tmp9sxwennd.db'

    def test_database_read_performance(self, temp_db_file):
        """Test Datenbank-Lese-Performance."""
        # Schreibe Test-Events
        events = []
        for i in range(1000):
            event = {
                'ts': time.time() + i,
                'type': 'beacon' if i % 2 == 0 else 'probe_req',
                'bssid': f'08:96:d7:1a:21:{i % 100:02x}',
                'ssid': f'SSID_{i % 50}',
                'rssi': -50 - (i % 50),
                'channel': (i % 13) + 1
            }
            events.append(event)
    
        with database.db_conn_ctx(temp_db_file) as conn:
            for event in events:
>               database.add_event(conn, event)
E               AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

pytest/test_performance.py:351: AttributeError

The above exception was the direct cause of the following exception:

path = '/tmp/tmp9sxwennd.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
>           with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):

wlan_tool/storage/database.py:68: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.exceptions.ErrorContext object at 0x7f6f124750>
exc_type = <class 'AttributeError'>
exc_val = AttributeError("module 'wlan_tool.storage.database' has no attribute 'add_event'")
exc_tb = <traceback object at 0x7f6f125a40>

    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type is not None:
            error_msg = f"Error in {self.operation}: {exc_val}"
    
            if isinstance(exc_val, WLANToolError):
                error_msg += f" (Code: {exc_val.error_code})"
                if exc_val.details:
                    error_msg += f" | Details: {exc_val.details}"
            else:
                error_msg += f" | Type: {exc_type.__name__}"
    
            self.logger.log(self.log_level, error_msg)
            self.logger.debug(f"Traceback: {traceback.format_exc()}")
    
            # Konvertiere zu WLANToolError falls nötig
            if not isinstance(exc_val, WLANToolError):
                wlan_error = WLANToolError(
                    message=str(exc_val),
                    error_code=self.error_code or "CONTEXT_ERROR",
                    details={
                        "operation": self.operation,
                        "original_type": exc_type.__name__,
                    },
                )
>               raise wlan_error from exc_val
E               wlan_tool.exceptions.WLANToolError: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}

wlan_tool/exceptions.py:313: WLANToolError

The above exception was the direct cause of the following exception:

self = <test_performance.TestDatabasePerformance object at 0x7f705afa90>
temp_db_file = '/tmp/tmp9sxwennd.db'

    def test_database_read_performance(self, temp_db_file):
        """Test Datenbank-Lese-Performance."""
        # Schreibe Test-Events
        events = []
        for i in range(1000):
            event = {
                'ts': time.time() + i,
                'type': 'beacon' if i % 2 == 0 else 'probe_req',
                'bssid': f'08:96:d7:1a:21:{i % 100:02x}',
                'ssid': f'SSID_{i % 50}',
                'rssi': -50 - (i % 50),
                'channel': (i % 13) + 1
            }
            events.append(event)
    
>       with database.db_conn_ctx(temp_db_file) as conn:

pytest/test_performance.py:349: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/contextlib.py:158: in __exit__
    self.gen.throw(typ, value, traceback)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

path = '/tmp/tmp9sxwennd.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
            with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):
                # Validiere Datenbankpfad
                if not _validate_file_path(path):
                    raise ValidationError(
                        f"Invalid database path: {path}",
                        error_code="INVALID_DB_PATH",
                        details={"db_path": path},
                    )
    
                # Erstelle Verzeichnis falls nötig
                db_dir = Path(path).parent
                if not db_dir.exists():
                    try:
                        db_dir.mkdir(parents=True, exist_ok=True)
                    except OSError as e:
                        raise FileSystemError(
                            f"Cannot create database directory: {db_dir}",
                            error_code="DB_DIR_CREATION_FAILED",
                            details={"directory": str(db_dir), "original_error": str(e)},
                        ) from e
    
                # Verbinde zur Datenbank
                conn = sqlite3.connect(path, timeout=Constants.DB_CONNECTION_TIMEOUT)
                conn.row_factory = sqlite3.Row
    
                # Setze pragmas für bessere Performance und Fehlerbehandlung
                conn.execute("PRAGMA foreign_keys = ON")
                conn.execute("PRAGMA journal_mode = WAL")
                conn.execute("PRAGMA synchronous = NORMAL")
                conn.execute("PRAGMA cache_size = 10000")
                conn.execute("PRAGMA temp_store = MEMORY")
    
                yield conn
    
        except sqlite3.Error as e:
            if conn:
                conn.rollback()
            raise DatabaseError(
                get_error_message(ErrorCodes.DB_CONNECTION_FAILED, details=str(e)),
                error_code=ErrorCodes.DB_CONNECTION_FAILED.value,
                details={"db_path": path, "sqlite_error": str(e)},
            ) from e
        except Exception as e:
            if conn:
                conn.rollback()
>           raise DatabaseError(
                f"Unexpected database error: {e}",
                error_code="DB_UNEXPECTED_ERROR",
                details={"db_path": path, "original_error": str(e)},
            ) from e
E           wlan_tool.exceptions.DatabaseError: WLANToolError: Unexpected database error: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'} (Code: DB_UNEXPECTED_ERROR) | Details: {'db_path': '/tmp/tmp9sxwennd.db', 'original_error': "WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}"}

wlan_tool/storage/database.py:113: DatabaseError
---------------------------- Captured stdout setup -----------------------------
2025-10-19 09:19:42,688 | DEBUG    | Starting operation: database_migration
2025-10-19 09:19:42,689 | DEBUG    | Starting operation: database_connection
2025-10-19 09:19:42,706 | INFO     | Current DB version: 0. Looking for migrations...
2025-10-19 09:19:42,706 | INFO     | Applying migration: 001_initial_schema.sql (Version 1)
2025-10-19 09:19:42,717 | INFO     | DB successfully migrated to version 1
2025-10-19 09:19:42,717 | INFO     | Applying migration: 002_add_dns_table.sql (Version 2)
2025-10-19 09:19:42,719 | INFO     | DB successfully migrated to version 2
2025-10-19 09:19:42,719 | INFO     | Applying migration: 003_add_network_info.sql (Version 3)
2025-10-19 09:19:42,720 | INFO     | DB successfully migrated to version 3
2025-10-19 09:19:42,721 | INFO     | Applying migration: 004_add_indexes.sql (Version 4)
2025-10-19 09:19:42,722 | INFO     | DB successfully migrated to version 4
2025-10-19 09:19:42,744 | INFO     | Database is up to date.
------------------------------ Captured log setup ------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_migration
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
INFO     wlan_tool.storage.database:database.py:157 Current DB version: 0. Looking for migrations...
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 001_initial_schema.sql (Version 1)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 1
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 002_add_dns_table.sql (Version 2)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 2
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 003_add_network_info.sql (Version 3)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 3
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 004_add_indexes.sql (Version 4)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 4
INFO     wlan_tool.storage.database:database.py:204 Database is up to date.
----------------------------- Captured stdout call -----------------------------
2025-10-19 09:19:42,750 | DEBUG    | Starting operation: database_connection
2025-10-19 09:19:42,752 | ERROR    | Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
2025-10-19 09:19:42,753 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/hacking/pytest/test_performance.py", line 351, in test_database_read_performance
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/hacking/pytest/test_performance.py", line 351, in test_database_read_performance
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'
________ TestScalabilityPerformance.test_scalability_with_dataset_size _________

self = <test_performance.TestScalabilityPerformance object at 0x7f705b4510>

    def test_scalability_with_dataset_size(self):
        """Test Skalierbarkeit mit Datensatz-Größe."""
        dataset_sizes = [100, 500, 1000]
        processing_times = []
    
        for size in dataset_sizes:
            # Erstelle State mit gegebener Größe
            state = WifiAnalysisState()
    
            for i in range(size):
                mac = f"aa:bb:cc:dd:ee:{i:04x}"
>               client = state.clients[mac] = state.clients.get(mac, type(state).__dict__['clients'].__class__())()
E               KeyError: 'clients'

pytest/test_performance.py:440: KeyError
_______________ TestCLIModule.test_print_client_cluster_results ________________

self = <test_presentation.TestCLIModule object at 0x7f705b6ad0>
mock_console = <MagicMock id='547256247504'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f6b02d150>

    def test_print_client_cluster_results(self, mock_console, populated_state):
        """Test Client-Cluster-Ergebnis-Ausgabe."""
        from wlan_tool.analysis import logic as analysis
    
        # Erstelle Test-Cluster-Daten
        clustered_df, feature_df = analysis.cluster_clients(populated_state, n_clusters=2)
    
        if clustered_df is not None and not clustered_df.empty:
            # Mock args
            args = MagicMock()
            args.cluster_clients = 2
            args.cluster_algo = "kmeans"
            args.no_mac_correlation = False
    
            # Sollte nicht crashen
>           cli.print_client_cluster_results(args, populated_state, mock_console)

pytest/test_presentation.py:38: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = <MagicMock id='547139745488'>
state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f6b02d150>
console = <MagicMock id='547256247504'>

    def print_client_cluster_results(args, state, console):
        """Führt das Client-Clustering aus und gibt die Ergebnisse formatiert aus."""
        clustered_df, feature_df = analysis.cluster_clients(
            state,
            n_clusters=args.cluster_clients,
            algo_name=args.cluster_algo,
            use_correlation=(not args.no_mac_correlation),
        )
        """Gibt die Ergebnisse des Client-Clusterings formatiert aus."""
        if clustered_df is not None and not clustered_df.empty:
            console.print(
                "[yellow]Keine Client-Daten für das Clustering gefunden.[/yellow]"
            )
            return
    
>       title_correlation_str = "& Korrelation" if use_correlation else "& ohne Korrelation"
E       NameError: name 'use_correlation' is not defined

wlan_tool/presentation/cli.py:34: NameError
---------------------------- Captured stdout setup -----------------------------
2025-10-19 09:19:43,006 | INFO     | Baue/Aktualisiere Zustand aus Event-Stream auf...
2025-10-19 09:19:43,007 | INFO     | Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
------------------------------ Captured log setup ------------------------------
INFO     wlan_tool.storage.state:state.py:52 Baue/Aktualisiere Zustand aus Event-Stream auf...
INFO     wlan_tool.storage.state:state.py:57 Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
----------------------------- Captured stdout call -----------------------------
2025-10-19 09:19:43,008 | DEBUG    | Starting operation: client_clustering
2025-10-19 09:19:43,008 | INFO     | Korreliere randomisierte MACs vor der Feature-Extraktion...
2025-10-19 09:19:43,009 | INFO     | Fand 0 Gruppen von potenziell zusammengehörigen randomisierten MACs.
2025-10-19 09:19:43,009 | DEBUG    | Starting operation: client_features_extraction
2025-10-19 09:19:43,009 | DEBUG    | Starting operation: client_features_extraction
2025-10-19 09:19:43,009 | DEBUG    | Starting operation: client_features_extraction
2025-10-19 09:19:43,022 | INFO     | Wende manuelle Feature-Gewichtungen für Standard-Clustering an...
2025-10-19 09:19:43,023 | DEBUG    | Gewichte Feature 'supports_11ax' mit Faktor 3.0.
2025-10-19 09:19:43,025 | DEBUG    | Gewichte Feature 'supports_11ac' mit Faktor 2.0.
2025-10-19 09:19:43,028 | DEBUG    | Gewichte Feature 'has_apple_ie' mit Faktor 2.5.
2025-10-19 09:19:43,031 | DEBUG    | Gewichte Feature 'has_ms_ie' mit Faktor 2.0.
2025-10-19 09:19:43,034 | DEBUG    | Gewichte Feature 'mimo_streams' mit Faktor 1.5.
2025-10-19 09:19:43,036 | DEBUG    | Gewichte Feature 'is_randomized_mac' mit Faktor 1.2.
2025-10-19 09:19:43,040 | DEBUG    | Gewichte Feature 'was_in_powersave' mit Faktor 1.2.
2025-10-19 09:19:43,043 | DEBUG    | Gewichte Feature 'probe_count' mit Faktor 1.0.
2025-10-19 09:19:43,045 | DEBUG    | Gewichte Feature 'seen_with_ap_count' mit Faktor 1.0.
2025-10-19 09:19:43,048 | INFO     | Verwende KMeans für das Clustering...
2025-10-19 09:19:43,055 | ERROR    | Unexpected error in cluster_clients: cluster_clients() got an unexpected keyword argument 'algo_name'
2025-10-19 09:19:43,056 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
TypeError: cluster_clients() got an unexpected keyword argument 'algo_name'

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_clustering
INFO     wlan_tool.analysis.logic:logic.py:396 Korreliere randomisierte MACs vor der Feature-Extraktion...
INFO     wlan_tool.analysis.logic:logic.py:791 Fand 0 Gruppen von potenziell zusammengehörigen randomisierten MACs.
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_features_extraction
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_features_extraction
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_features_extraction
INFO     wlan_tool.analysis.logic:logic.py:584 Wende manuelle Feature-Gewichtungen für Standard-Clustering an...
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'supports_11ax' mit Faktor 3.0.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'supports_11ac' mit Faktor 2.0.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'has_apple_ie' mit Faktor 2.5.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'has_ms_ie' mit Faktor 2.0.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'mimo_streams' mit Faktor 1.5.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'is_randomized_mac' mit Faktor 1.2.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'was_in_powersave' mit Faktor 1.2.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'probe_count' mit Faktor 1.0.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'seen_with_ap_count' mit Faktor 1.0.
INFO     wlan_tool.analysis.logic:logic.py:609 Verwende KMeans für das Clustering...
ERROR    wlan_tool.analysis.logic:exceptions.py:165 Unexpected error in cluster_clients: cluster_clients() got an unexpected keyword argument 'algo_name'
DEBUG    wlan_tool.analysis.logic:exceptions.py:166 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
TypeError: cluster_clients() got an unexpected keyword argument 'algo_name'
_________________ TestCLIModule.test_print_ap_cluster_results __________________

self = <test_presentation.TestCLIModule object at 0x7f705b7150>
mock_console = <MagicMock id='546933843472'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f6b05b210>

    def test_print_ap_cluster_results(self, mock_console, populated_state):
        """Test AP-Cluster-Ergebnis-Ausgabe."""
        from wlan_tool.analysis import logic as analysis
    
        # Erstelle Test-AP-Cluster-Daten
>       clustered_df = analysis.cluster_aps(populated_state, n_clusters=2)

pytest/test_presentation.py:48: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/analysis/logic.py:736: in cluster_aps
    df["cluster"] = kmeans.fit_predict(X_scaled)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1071: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1351: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1490: in fit
    self._check_params_vs_input(X)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1431: in _check_params_vs_input
    super()._check_params_vs_input(X, default_n_init=10)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = KMeans(n_clusters=2, random_state=42)
X = array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])
default_n_init = 10

    def _check_params_vs_input(self, X, default_n_init=None):
        # n_clusters
        if X.shape[0] < self.n_clusters:
>           raise ValueError(
                f"n_samples={X.shape[0]} should be >= n_clusters={self.n_clusters}."
            )
E           ValueError: n_samples=1 should be >= n_clusters=2.

.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:879: ValueError
---------------------------- Captured stdout setup -----------------------------
2025-10-19 09:19:43,101 | INFO     | Baue/Aktualisiere Zustand aus Event-Stream auf...
2025-10-19 09:19:43,101 | INFO     | Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
------------------------------ Captured log setup ------------------------------
INFO     wlan_tool.storage.state:state.py:52 Baue/Aktualisiere Zustand aus Event-Stream auf...
INFO     wlan_tool.storage.state:state.py:57 Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
________ TestCLIEdgeCases.test_print_client_cluster_results_empty_data _________

self = <test_presentation.TestCLIEdgeCases object at 0x7f705ceed0>
mock_console = <MagicMock id='546933489552'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f6408b710>

    def test_print_client_cluster_results_empty_data(self, mock_console, populated_state):
        """Test Client-Cluster-Ausgabe mit leeren Daten."""
        # Erstelle leeren State
        empty_state = WifiAnalysisState()
    
        args = MagicMock()
        args.cluster_clients = 2
        args.cluster_algo = "kmeans"
        args.no_mac_correlation = False
    
        # Sollte nicht crashen
>       cli.print_client_cluster_results(args, empty_state, mock_console)

pytest/test_presentation.py:281: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = <MagicMock id='547139036496'>
state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f64071b10>
console = <MagicMock id='546933489552'>

    def print_client_cluster_results(args, state, console):
        """Führt das Client-Clustering aus und gibt die Ergebnisse formatiert aus."""
        clustered_df, feature_df = analysis.cluster_clients(
            state,
            n_clusters=args.cluster_clients,
            algo_name=args.cluster_algo,
            use_correlation=(not args.no_mac_correlation),
        )
        """Gibt die Ergebnisse des Client-Clusterings formatiert aus."""
        if clustered_df is not None and not clustered_df.empty:
            console.print(
                "[yellow]Keine Client-Daten für das Clustering gefunden.[/yellow]"
            )
            return
    
>       title_correlation_str = "& Korrelation" if use_correlation else "& ohne Korrelation"
E       NameError: name 'use_correlation' is not defined

wlan_tool/presentation/cli.py:34: NameError
---------------------------- Captured stdout setup -----------------------------
2025-10-19 09:19:43,504 | INFO     | Baue/Aktualisiere Zustand aus Event-Stream auf...
2025-10-19 09:19:43,505 | INFO     | Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
------------------------------ Captured log setup ------------------------------
INFO     wlan_tool.storage.state:state.py:52 Baue/Aktualisiere Zustand aus Event-Stream auf...
INFO     wlan_tool.storage.state:state.py:57 Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
----------------------------- Captured stdout call -----------------------------
2025-10-19 09:19:43,507 | ERROR    | Unexpected error in cluster_clients: cluster_clients() got an unexpected keyword argument 'algo_name'
2025-10-19 09:19:43,507 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
TypeError: cluster_clients() got an unexpected keyword argument 'algo_name'

------------------------------ Captured log call -------------------------------
ERROR    wlan_tool.analysis.logic:exceptions.py:165 Unexpected error in cluster_clients: cluster_clients() got an unexpected keyword argument 'algo_name'
DEBUG    wlan_tool.analysis.logic:exceptions.py:166 Traceback: Traceback (most recent call last):
  File "/home/pi/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
TypeError: cluster_clients() got an unexpected keyword argument 'algo_name'
_________________ TestPerformance.test_large_dataset_handling __________________

self = <test_presentation.TestPerformance object at 0x7f705d0f10>
mock_console = <MagicMock id='547225830032'>

    def test_large_dataset_handling(self, mock_console):
        """Test mit großen Datensätzen."""
        # Erstelle State mit vielen Clients
        state = WifiAnalysisState()
    
        for i in range(100):
            client = ClientState(mac=f"aa:bb:cc:dd:ee:{i:02x}")
            client.probes = {f"SSID_{i}"}
            client.all_packet_ts = np.array([time.time() - 100, time.time()])
>           client.rssi_w = Welford()
E           NameError: name 'Welford' is not defined

pytest/test_presentation.py:366: NameError
_________________ TestAPState.test_ap_state_update_from_beacon _________________

self = <test_storage.TestAPState object at 0x7f705e1890>

    def test_ap_state_update_from_beacon(self):
        """Test APState-Update aus Beacon."""
        ap = APState(bssid="aa:bb:cc:dd:ee:ff", ssid="TestAP")
        event = {
            'ts': time.time(),
            'type': 'beacon',
            'bssid': 'aa:bb:cc:dd:ee:ff',
            'ssid': 'TestAP',
            'rssi': -50,
            'channel': 6,
            'beacon_interval': 102
        }
    
>       ap.update_from_event(event)
E       AttributeError: 'APState' object has no attribute 'update_from_event'

pytest/test_storage.py:141: AttributeError
___________________ TestWifiAnalysisState.test_state_pruning ___________________

self = <test_storage.TestWifiAnalysisState object at 0x7f705e3b50>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f69339910>

    def test_state_pruning(self, populated_state):
        """Test State-Pruning."""
        state = populated_state
        assert 'DE:AD:BE:EF:00:00' in state.clients
    
        pruned_count = state.prune_state(time.time(), threshold_s=7200)
    
        assert pruned_count > 0
        assert 'DE:AD:BE:EF:00:00' not in state.clients
>       assert 'a8:51:ab:0c:b9:e9' in state.clients  # Sollte bleiben
E       AssertionError: assert 'a8:51:ab:0c:b9:e9' in {}
E        +  where {} = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f69339910>.clients

pytest/test_storage.py:203: AssertionError
---------------------------- Captured stdout setup -----------------------------
2025-10-19 09:19:43,704 | INFO     | Baue/Aktualisiere Zustand aus Event-Stream auf...
2025-10-19 09:19:43,704 | INFO     | Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
------------------------------ Captured log setup ------------------------------
INFO     wlan_tool.storage.state:state.py:52 Baue/Aktualisiere Zustand aus Event-Stream auf...
INFO     wlan_tool.storage.state:state.py:57 Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
----------------------------- Captured stdout call -----------------------------
2025-10-19 09:19:43,706 | INFO     | Zustand bereinigt: 1 APs, 3 Clients, 0 Seq-Einträge und 1 SSIDs entfernt.
------------------------------ Captured log call -------------------------------
INFO     wlan_tool.storage.state:state.py:237 Zustand bereinigt: 1 APs, 3 Clients, 0 Seq-Einträge und 1 SSIDs entfernt.
________________ TestWifiAnalysisState.test_state_ssid_mapping _________________

self = <test_storage.TestWifiAnalysisState object at 0x7f705f0210>
sample_events = [{'beacon_interval': 102, 'bssid': '08:96:d7:1a:21:1c', 'cap': 17, 'channel': 6, ...}, {'client': 'a8:51:ab:0c:b9:e9',...-91, ...}, {'client': 'b2:87:23:15:7f:f2', 'ie_order_hash': 67890, 'ies': {0: ['MyOtherWLAN']}, 'rssi': -70, ...}, ...]

    def test_state_ssid_mapping(self, sample_events):
        """Test SSID-Mapping-Funktionalität."""
        state = WifiAnalysisState()
        state.build_from_events(sample_events)
    
        # Teste SSID-Map
        assert 'MyTestWLAN' in state.ssid_map
        ssid_info = state.ssid_map['MyTestWLAN']
        assert '08:96:d7:1a:21:1c' in ssid_info['bssids']
>       assert 'a8:51:ab:0c:b9:e9' in ssid_info['sources']['probe_req']
E       AssertionError: assert 'a8:51:ab:0c:b9:e9' in set()

pytest/test_storage.py:214: AssertionError
----------------------------- Captured stdout call -----------------------------
2025-10-19 09:19:43,729 | INFO     | Baue/Aktualisiere Zustand aus Event-Stream auf...
2025-10-19 09:19:43,730 | INFO     | Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
------------------------------ Captured log call -------------------------------
INFO     wlan_tool.storage.state:state.py:52 Baue/Aktualisiere Zustand aus Event-Stream auf...
INFO     wlan_tool.storage.state:state.py:57 Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
_____________________ TestDatabaseModule.test_fetch_events _____________________

self = <test_storage.TestDatabaseModule object at 0x7f705f17d0>
in_memory_db = <sqlite3.Connection object at 0x7f6afee980>
sample_events = [{'beacon_interval': 102, 'bssid': '08:96:d7:1a:21:1c', 'cap': 17, 'channel': 6, ...}, {'client': 'a8:51:ab:0c:b9:e9',...-91, ...}, {'client': 'b2:87:23:15:7f:f2', 'ie_order_hash': 67890, 'ies': {0: ['MyOtherWLAN']}, 'rssi': -70, ...}, ...]

    def test_fetch_events(self, in_memory_db, sample_events):
        """Test Event-Abruf."""
        conn = in_memory_db
    
        # Schreibe Test-Events
        for event in sample_events[:2]:
>           database.add_event(conn, event)
E           AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

pytest/test_storage.py:260: AttributeError
______________________ TestDatabaseModule.test_add_label _______________________

self = <test_storage.TestDatabaseModule object at 0x7f705f1e90>
in_memory_db = <sqlite3.Connection object at 0x7f6afefe20>

    def test_add_label(self, in_memory_db):
        """Test Label-Hinzufügung."""
        conn = in_memory_db
    
        database.add_label(conn, "TestSSID", "aa:bb:cc:dd:ee:ff", 1)
    
        cursor = conn.execute("SELECT * FROM labels WHERE ssid = ? AND bssid = ?",
                            ("TestSSID", "aa:bb:cc:dd:ee:ff"))
        result = cursor.fetchone()
        assert result is not None
>       assert result[2] == 1  # label = 1
E       AssertionError: assert 'aa:bb:cc:dd:ee:ff' == 1

pytest/test_storage.py:277: AssertionError
----------------------------- Captured stdout call -----------------------------
2025-10-19 09:19:44,427 | DEBUG    | Starting operation: add_label
2025-10-19 09:19:44,428 | DEBUG    | Added label: TestSSID -> aa:bb:cc:dd:ee:ff = 1 (source: ui)
------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: add_label
DEBUG    wlan_tool.storage.database:database.py:618 Added label: TestSSID -> aa:bb:cc:dd:ee:ff = 1 (source: ui)
________________ TestOUIFunctions.test_lookup_vendor_apple_mac _________________

self = <test_utils.TestOUIFunctions object at 0x7f70600050>

    def test_lookup_vendor_apple_mac(self):
        """Test Vendor-Lookup für Apple-MAC."""
        # Apple MAC-Adresse
        mac = "a8:51:ab:0c:b9:e9"
        vendor = utils.lookup_vendor(mac)
    
>       assert vendor is not None
E       assert None is not None

pytest/test_utils.py:26: AssertionError
_______________ TestOUIFunctions.test_lookup_vendor_unknown_mac ________________

self = <test_utils.TestOUIFunctions object at 0x7f706006d0>

    def test_lookup_vendor_unknown_mac(self):
        """Test Vendor-Lookup für unbekannte MAC."""
        # Unbekannte MAC-Adresse
        mac = "ff:ff:ff:ff:ff:ff"
        vendor = utils.lookup_vendor(mac)
    
        # Sollte None oder "Unknown" zurückgeben
>       assert vendor is None or vendor == "Unknown"
E       AssertionError: assert ('(Lokal / Randomisiert)' is None or '(Lokal / Randomisiert)' == 'Unknown'
E         
E         - Unknown
E         + (Lokal / Randomisiert))

pytest/test_utils.py:45: AssertionError
_________________ TestIEParsing.test_parse_ies_vendor_specific _________________

self = <test_utils.TestIEParsing object at 0x7f706032d0>

    def test_parse_ies_vendor_specific(self):
        """Test Vendor-spezifische IE-Parsing."""
        ies = {221: ['0017f20a010103040507080c']}  # Apple IE
        parsed = utils.parse_ies(ies, detailed=True)
    
        assert isinstance(parsed, dict)
        assert "vendor_specific" in parsed
>       assert "Apple" in parsed["vendor_specific"]
E       AssertionError: assert 'Apple' in {}

pytest/test_utils.py:131: AssertionError
_________________ TestIEParsing.test_parse_ies_ht_capabilities _________________

self = <test_utils.TestIEParsing object at 0x7f70603910>

    def test_parse_ies_ht_capabilities(self):
        """Test HT-Capabilities-Parsing."""
        ies = {45: ['1f']}  # HT Capabilities
        parsed = utils.parse_ies(ies, detailed=True)
    
        assert isinstance(parsed, dict)
        assert "ht_caps" in parsed
>       assert "streams" in parsed["ht_caps"]
E       AssertionError: assert 'streams' in {'40mhz_support': True}

pytest/test_utils.py:140: AssertionError
_________________ TestUtilityFunctions.test_is_local_admin_mac _________________

self = <test_utils.TestUtilityFunctions object at 0x7f70608d90>

    def test_is_local_admin_mac(self):
        """Test lokale Admin-MAC-Erkennung."""
        # Lokale Admin-MAC
        assert utils.is_local_admin_mac("02:00:00:00:00:00") is True
        assert utils.is_local_admin_mac("06:00:00:00:00:00") is True
    
        # Globale MAC
        assert utils.is_local_admin_mac("00:00:00:00:00:00") is False
>       assert utils.is_local_admin_mac("aa:bb:cc:dd:ee:ff") is False
E       AssertionError: assert True is False
E        +  where True = <function is_local_admin_mac at 0x7f88f73380>('aa:bb:cc:dd:ee:ff')
E        +    where <function is_local_admin_mac at 0x7f88f73380> = utils.is_local_admin_mac

pytest/test_utils.py:171: AssertionError
___________________ TestUtilityFunctions.test_is_valid_bssid ___________________

self = <test_utils.TestUtilityFunctions object at 0x7f70609390>

    def test_is_valid_bssid(self):
        """Test BSSID-Validierung."""
        # Gültige BSSID
        assert utils.is_valid_bssid("aa:bb:cc:dd:ee:ff") is True
        assert utils.is_valid_bssid("00:11:22:33:44:55") is True
    
        # Ungültige BSSID
        assert utils.is_valid_bssid("") is False
        assert utils.is_valid_bssid("invalid") is False
>       assert utils.is_valid_bssid("aa:bb:cc:dd:ee") is False  # Zu kurz
E       AssertionError: assert True is False
E        +  where True = <function is_valid_bssid at 0x7f88f73420>('aa:bb:cc:dd:ee')
E        +    where <function is_valid_bssid at 0x7f88f73420> = utils.is_valid_bssid

pytest/test_utils.py:182: AssertionError
________________ TestUtilityFunctions.test_ie_fingerprint_hash _________________

self = <test_utils.TestUtilityFunctions object at 0x7f70609990>

    def test_ie_fingerprint_hash(self):
        """Test IE-Fingerprint-Hash."""
        ies = {
            0: ['TestSSID'],
            1: ['82848b96'],
            48: ['0100000fac040100000fac020100000fac028c00']
        }
    
        hash_value = utils.ie_fingerprint_hash(ies)
    
        assert isinstance(hash_value, str)
>       assert len(hash_value) == 32  # MD5-Hash-Länge
E       AssertionError: assert 40 == 32
E        +  where 40 = len('fb3a54a0b7ca1a713fd927a194ff191b7de45566')

pytest/test_utils.py:196: AssertionError
_____________ TestUtilityFunctions.test_ie_fingerprint_hash_empty ______________

self = <test_utils.TestUtilityFunctions object at 0x7f706024d0>

    def test_ie_fingerprint_hash_empty(self):
        """Test IE-Fingerprint-Hash mit leeren IEs."""
        ies = {}
    
        hash_value = utils.ie_fingerprint_hash(ies)
    
>       assert hash_value is None or hash_value == ""
E       AssertionError: assert ('da39a3ee5e6b4b0d3255bfef95601890afd80709' is None or 'da39a3ee5e6b...01890afd80709' == ''
E         
E         + da39a3ee5e6b4b0d3255bfef95601890afd80709)

pytest/test_utils.py:205: AssertionError
_________________ TestConfigFunctions.test_load_config_default _________________

self = <test_utils.TestConfigFunctions object at 0x7f70608350>

    def test_load_config_default(self):
        """Test Konfigurations-Laden (Standard)."""
>       config_data = utils.load_config()
E       TypeError: load_config() missing 1 required positional argument: 'profile'

pytest/test_utils.py:226: TypeError
____________ TestConfigFunctions.test_load_config_specific_profile _____________

self = <test_utils.TestConfigFunctions object at 0x7f7060a010>

    def test_load_config_specific_profile(self):
        """Test Konfigurations-Laden (spezifisches Profil)."""
        # Erstelle temporäre Konfigurationsdatei
        test_config = {
            "capture": {"interface": "test0", "duration": 60},
            "database": {"path": "test.db"}
        }
    
        with tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False) as f:
            yaml.dump(test_config, f)
            config_path = f.name
    
        try:
>           with patch('wlan_tool.utils.CONFIG_PATH', config_path):

pytest/test_utils.py:245: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f64a52350>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'wlan_tool.utils' from '/home/pi/hacking/wlan_tool/utils.py'> does not have the attribute 'CONFIG_PATH'

../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1419: AttributeError
______________ TestConfigFunctions.test_load_config_missing_file _______________

self = <test_utils.TestConfigFunctions object at 0x7f7060a350>

    def test_load_config_missing_file(self):
        """Test Konfigurations-Laden (fehlende Datei)."""
>       with patch('wlan_tool.utils.CONFIG_PATH', Path("/nonexistent/config.yaml")):

pytest/test_utils.py:255: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f696b6990>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'wlan_tool.utils' from '/home/pi/hacking/wlan_tool/utils.py'> does not have the attribute 'CONFIG_PATH'

../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1419: AttributeError
________________ TestEdgeCases.test_ie_fingerprint_hash_unicode ________________

self = <test_utils.TestEdgeCases object at 0x7f7060c910>

    def test_ie_fingerprint_hash_unicode(self):
        """Test IE-Fingerprint-Hash mit Unicode-Daten."""
        ies = {0: ['TestSSID_äöü']}  # Unicode-Zeichen
    
        hash_value = utils.ie_fingerprint_hash(ies)
    
        assert isinstance(hash_value, str)
>       assert len(hash_value) == 32
E       AssertionError: assert 40 == 32
E        +  where 40 = len('758ed0819e647ff1683744b0bc9b1ff7470f6d37')

pytest/test_utils.py:356: AssertionError
_____________ TestEdgeCases.test_config_loading_with_invalid_yaml ______________

self = <test_utils.TestEdgeCases object at 0x7f7060d510>

    def test_config_loading_with_invalid_yaml(self):
        """Test Konfigurations-Laden mit ungültigem YAML."""
        invalid_yaml = "invalid: yaml: content: ["
    
        with tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False) as f:
            f.write(invalid_yaml)
            config_path = f.name
    
        try:
>           with patch('wlan_tool.utils.CONFIG_PATH', config_path):

pytest/test_utils.py:378: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f6973a850>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'wlan_tool.utils' from '/home/pi/hacking/wlan_tool/utils.py'> does not have the attribute 'CONFIG_PATH'

../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1419: AttributeError
__________ TestEndToEndWorkflow.test_complete_wifi_analysis_workflow ___________

self = <test_end_to_end.TestEndToEndWorkflow object at 0x7f6f79b710>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]
temp_dir = PosixPath('/tmp/tmpf30_dhj1')

    @pytest.mark.integration
    @pytest.mark.slow
    def test_complete_wifi_analysis_workflow(self, large_dataset, temp_dir):
        """Test des kompletten WLAN-Analyse-Workflows."""
        # 1. Datenverarbeitung
        processor = WiFiDataProcessor()
        processed_data = processor.process_data(large_dataset)
    
        assert len(processed_data) == len(large_dataset)
        assert "processed_timestamp" in processed_data.columns
    
        # 2. Feature-Extraktion
        extractor = FeatureExtractor()
        features = extractor.extract_features(processed_data)
    
        assert features.shape[0] == len(processed_data)
        assert features.shape[1] > 0
    
        # 3. Clustering-Analyse
        analyzer = ClusteringAnalyzer()
>       labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)

tests/integration/test_end_to_end.py:42: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1071: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1351: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1481: in fit
    X = self._validate_data(
.venv/lib/python3.11/site-packages/sklearn/base.py:633: in _validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1003: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:126: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[-1.15579349,  0.        ,  0.        , ...,  0.        ,
         0.15614176, -0.97725852],
       [-1.1557934...176, -0.97725852],
       [ 1.35680105,  0.        ,  0.        , ...,  0.        ,
         0.15614176,  1.02327069]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:175: ValueError
____________ TestEndToEndWorkflow.test_plugin_integration_workflow _____________

self = <test_end_to_end.TestEndToEndWorkflow object at 0x7f6f4a5d10>
sample_wifi_data =               timestamp device_id  ...  packet_count  bytes_transferred
0   2024-01-01 00:00:00  device_3  ...        ...15         206.754596
999 2024-01-01 16:39:00  device_1  ...           103         554.365485

[1000 rows x 11 columns]
temp_dir = PosixPath('/tmp/tmp_um2j_0g')

    @pytest.mark.integration
    def test_plugin_integration_workflow(self, sample_wifi_data, temp_dir):
        """Test der Plugin-Integration im Workflow."""
        from plugins import load_all_plugins
    
        # Plugins laden
        plugin_dir = Path("plugins")
        plugins = load_all_plugins(plugin_dir)
    
        assert len(plugins) > 0
    
        # Features extrahieren
        extractor = FeatureExtractor()
        features = extractor.extract_features(sample_wifi_data)
    
        # Jedes Plugin testen
        for plugin in plugins:
            # Plugin-Dependencies prüfen
>           if not plugin.validate_dependencies():
E           AttributeError: 'str' object has no attribute 'validate_dependencies'

tests/integration/test_end_to_end.py:101: AttributeError
----------------------------- Captured stdout call -----------------------------
2025-10-19 09:19:46,376 | WARNING  | Einige ML-Bibliotheken nicht verfügbar: No module named 'hdbscan'
2025-10-19 09:19:46,378 | WARNING  | Dependencies ['hdbscan'] für Plugin 'Advanced Clustering' nicht verfügbar
2025-10-19 09:19:46,378 | WARNING  | Plugin clustering_advanced hat fehlende Dependencies
2025-10-19 09:19:46,382 | INFO     | Plugin 'Ensemble Models' v1.0.0 geladen
2025-10-19 09:19:46,385 | WARNING  | Dependencies ['umap'] für Plugin 'UMAP Plot' nicht verfügbar
2025-10-19 09:19:46,385 | WARNING  | Plugin umap_plot hat fehlende Dependencies
2025-10-19 09:19:46,386 | INFO     | Plugin 'Sankey Diagram' v1.0.0 geladen
2025-10-19 09:19:46,388 | WARNING  | PyTorch oder Gym nicht verfügbar: No module named 'gym'
2025-10-19 09:19:46,392 | WARNING  | Dependencies ['gym'] für Plugin 'Reinforcement Learning' nicht verfügbar
2025-10-19 09:19:46,392 | WARNING  | Plugin reinforcement_learning hat fehlende Dependencies
2025-10-19 09:19:46,393 | INFO     | Plugin 'Example_Plugin' v1.0.0 geladen
------------------------------ Captured log call -------------------------------
WARNING  root:plugin.py:27 Einige ML-Bibliotheken nicht verfügbar: No module named 'hdbscan'
WARNING  plugins:__init__.py:68 Dependencies ['hdbscan'] für Plugin 'Advanced Clustering' nicht verfügbar
WARNING  plugins:__init__.py:97 Plugin clustering_advanced hat fehlende Dependencies
INFO     plugins:__init__.py:120 Plugin 'Ensemble Models' v1.0.0 geladen
WARNING  plugins:__init__.py:68 Dependencies ['umap'] für Plugin 'UMAP Plot' nicht verfügbar
WARNING  plugins:__init__.py:97 Plugin umap_plot hat fehlende Dependencies
INFO     plugins:__init__.py:120 Plugin 'Sankey Diagram' v1.0.0 geladen
WARNING  root:plugin.py:27 PyTorch oder Gym nicht verfügbar: No module named 'gym'
WARNING  plugins:__init__.py:68 Dependencies ['gym'] für Plugin 'Reinforcement Learning' nicht verfügbar
WARNING  plugins:__init__.py:97 Plugin reinforcement_learning hat fehlende Dependencies
INFO     plugins:__init__.py:120 Plugin 'Example_Plugin' v1.0.0 geladen
_____________ TestEndToEndWorkflow.test_data_pipeline_with_file_io _____________

self = <test_end_to_end.TestEndToEndWorkflow object at 0x7f6f4a6410>
temp_dir = PosixPath('/tmp/tmpex226up_')

    @pytest.mark.integration
    def test_data_pipeline_with_file_io(self, temp_dir):
        """Test der Datenpipeline mit Datei-I/O."""
        # Test-Daten generieren
        n_samples = 1000
        test_data = pd.DataFrame(
            {
                "timestamp": pd.date_range(
                    "2024-01-01", periods=n_samples, freq="1min"
                ),
                "device_id": np.random.choice(
                    ["device_1", "device_2", "device_3"], n_samples
                ),
                "signal_strength": np.random.normal(-50, 10, n_samples),
                "frequency": np.random.choice([2.4, 5.0], n_samples),
                "channel": np.random.randint(1, 14, n_samples),
                "mac_address": [f"00:11:22:33:44:{i:02x}" for i in range(n_samples)],
                "ssid": np.random.choice(
                    ["WiFi_Home", "WiFi_Office", "Public_WiFi"], n_samples
                ),
                "encryption": np.random.choice(["WPA2", "WPA3", "Open"], n_samples),
                "data_rate": np.random.normal(54, 10, n_samples),
                "packet_count": np.random.poisson(100, n_samples),
                "bytes_transferred": np.random.exponential(1000, n_samples),
            }
        )
    
        # 1. Daten in CSV speichern
        input_file = temp_dir / "input_data.csv"
        test_data.to_csv(input_file, index=False)
    
        # 2. Daten laden und verarbeiten
        loaded_data = pd.read_csv(input_file)
        processor = WiFiDataProcessor()
        processed_data = processor.process_data(loaded_data)
    
        # 3. Features extrahieren
        extractor = FeatureExtractor()
        features = extractor.extract_features(processed_data)
    
        # 4. Clustering
        analyzer = ClusteringAnalyzer()
>       labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=3)

tests/integration/test_end_to_end.py:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1071: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1351: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1481: in fit
    X = self._validate_data(
.venv/lib/python3.11/site-packages/sklearn/base.py:633: in _validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1003: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:126: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[-1.62859019,  0.        ,  0.        , ...,  0.        ,
         0.        , -0.9900495 ],
       [-1.6285901...   ,  1.0100505 ],
       [ 1.69506325,  0.        ,  0.        , ...,  0.        ,
         0.        ,  1.0100505 ]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:175: ValueError
____________ TestEndToEndWorkflow.test_error_handling_and_recovery _____________

self = <test_end_to_end.TestEndToEndWorkflow object at 0x7f6f4a6b50>
temp_dir = PosixPath('/tmp/tmpluasazwr')

    @pytest.mark.integration
    def test_error_handling_and_recovery(self, temp_dir):
        """Test der Fehlerbehandlung und Wiederherstellung."""
        processor = WiFiDataProcessor()
        extractor = FeatureExtractor()
        analyzer = ClusteringAnalyzer()
    
        # Test mit ungültigen Daten
        invalid_data = pd.DataFrame(
            {
                "timestamp": ["invalid_date", "2024-01-01", "2024-01-02"],
                "signal_strength": [np.nan, -50, -60],
                "frequency": [1.0, 2.4, 5.0],  # Ungültige Frequenz
                "device_id": ["device_1", "device_2", "device_3"],
                "mac_address": [
                    "00:11:22:33:44:01",
                    "00:11:22:33:44:02",
                    "00:11:22:33:44:03",
                ],
                "ssid": ["WiFi_Home", "WiFi_Office", "Public_WiFi"],
                "encryption": ["WPA2", "WPA3", "Open"],
                "channel": [1, 6, 11],
                "data_rate": [54, 100, 54],
                "packet_count": [100, 200, 150],
                "bytes_transferred": [1000, 2000, 1500],
            }
        )
    
        # Verarbeitung sollte Fehler behandeln
        try:
>           processed_data = processor.process_data(invalid_data)

tests/integration/test_end_to_end.py:203: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/data_processing/wifi_processor.py:45: in process_data
    processed_data['processed_timestamp'] = pd.to_datetime(processed_data['timestamp'])
.venv/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:1067: in to_datetime
    values = convert_listlike(arg._values, format)
.venv/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:435: in _convert_listlike_datetimes
    result, tz_parsed = objects_to_datetime64(
.venv/lib/python3.11/site-packages/pandas/core/arrays/datetimes.py:2398: in objects_to_datetime64
    result, tz_parsed = tslib.array_to_datetime(
tslib.pyx:414: in pandas._libs.tslib.array_to_datetime
    ???
tslib.pyx:596: in pandas._libs.tslib.array_to_datetime
    ???
tslib.pyx:553: in pandas._libs.tslib.array_to_datetime
    ???
conversion.pyx:641: in pandas._libs.tslibs.conversion.convert_str_to_tsobject
    ???
parsing.pyx:336: in pandas._libs.tslibs.parsing.parse_datetime_string
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   pandas._libs.tslibs.parsing.DateParseError: Unknown datetime string format, unable to parse: invalid_date, at position 0

parsing.pyx:666: DateParseError

During handling of the above exception, another exception occurred:

self = <test_end_to_end.TestEndToEndWorkflow object at 0x7f6f4a6b50>
temp_dir = PosixPath('/tmp/tmpluasazwr')

    @pytest.mark.integration
    def test_error_handling_and_recovery(self, temp_dir):
        """Test der Fehlerbehandlung und Wiederherstellung."""
        processor = WiFiDataProcessor()
        extractor = FeatureExtractor()
        analyzer = ClusteringAnalyzer()
    
        # Test mit ungültigen Daten
        invalid_data = pd.DataFrame(
            {
                "timestamp": ["invalid_date", "2024-01-01", "2024-01-02"],
                "signal_strength": [np.nan, -50, -60],
                "frequency": [1.0, 2.4, 5.0],  # Ungültige Frequenz
                "device_id": ["device_1", "device_2", "device_3"],
                "mac_address": [
                    "00:11:22:33:44:01",
                    "00:11:22:33:44:02",
                    "00:11:22:33:44:03",
                ],
                "ssid": ["WiFi_Home", "WiFi_Office", "Public_WiFi"],
                "encryption": ["WPA2", "WPA3", "Open"],
                "channel": [1, 6, 11],
                "data_rate": [54, 100, 54],
                "packet_count": [100, 200, 150],
                "bytes_transferred": [1000, 2000, 1500],
            }
        )
    
        # Verarbeitung sollte Fehler behandeln
        try:
            processed_data = processor.process_data(invalid_data)
            # Wenn erfolgreich, sollten ungültige Daten bereinigt sein
            assert len(processed_data) <= len(invalid_data)
        except Exception as e:
            # Fehler sollten informativ sein
>           assert "Invalid" in str(e) or "Missing" in str(e)
E           AssertionError: assert ('Invalid' in 'Unknown datetime string format, unable to parse: invalid_date, at position 0' or 'Missing' in 'Unknown datetime string format, unable to parse: invalid_date, at position 0')
E            +  where 'Unknown datetime string format, unable to parse: invalid_date, at position 0' = str(DateParseError('Unknown datetime string format, unable to parse: invalid_date, at position 0'))
E            +  and   'Unknown datetime string format, unable to parse: invalid_date, at position 0' = str(DateParseError('Unknown datetime string format, unable to parse: invalid_date, at position 0'))

tests/integration/test_end_to_end.py:208: AssertionError
_______________ TestEndToEndWorkflow.test_performance_under_load _______________

self = <test_end_to_end.TestEndToEndWorkflow object at 0x7f6f4a7210>
temp_dir = PosixPath('/tmp/tmpmv0g11t3')

    @pytest.mark.integration
    def test_performance_under_load(self, temp_dir):
        """Test der Performance unter Last."""
        import time
    
        # Große Datenmenge
        n_samples = 50000
        large_data = pd.DataFrame(
            {
                "timestamp": pd.date_range("2024-01-01", periods=n_samples, freq="1s"),
                "device_id": np.random.choice(
                    [f"device_{i}" for i in range(100)], n_samples
                ),
                "signal_strength": np.random.normal(-50, 10, n_samples),
                "frequency": np.random.choice([2.4, 5.0], n_samples),
                "channel": np.random.randint(1, 14, n_samples),
                "mac_address": [f"00:11:22:33:44:{i:02x}" for i in range(n_samples)],
                "ssid": np.random.choice(
                    ["WiFi_Home", "WiFi_Office", "Public_WiFi"], n_samples
                ),
                "encryption": np.random.choice(["WPA2", "WPA3", "Open"], n_samples),
                "data_rate": np.random.normal(54, 10, n_samples),
                "packet_count": np.random.poisson(100, n_samples),
                "bytes_transferred": np.random.exponential(1000, n_samples),
            }
        )
    
        processor = WiFiDataProcessor()
        extractor = FeatureExtractor()
        analyzer = ClusteringAnalyzer()
    
        # Performance-Messung
        start_time = time.time()
    
        # Verarbeitung
        processed_data = processor.process_data(large_data)
        features = extractor.extract_features(processed_data)
>       labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)

tests/integration/test_end_to_end.py:259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1071: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1351: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1481: in fit
    X = self._validate_data(
.venv/lib/python3.11/site-packages/sklearn/base.py:633: in _validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1003: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:126: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[-1.6100241 ,  0.        ,  0.        , ...,  0.        ,
         0.        , -1.00344594],
       [-1.6100241...   ,  0.9965659 ],
       [ 1.63599223,  0.        ,  0.        , ...,  0.        ,
         0.        , -1.00344594]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:175: ValueError
_______________ TestEndToEndWorkflow.test_concurrent_processing ________________

self = <test_end_to_end.TestEndToEndWorkflow object at 0x7f6f4a7910>
temp_dir = PosixPath('/tmp/tmpgq8czq8y')

    @pytest.mark.integration
    def test_concurrent_processing(self, temp_dir):
        """Test der parallelen Verarbeitung."""
        import threading
        from concurrent.futures import ThreadPoolExecutor
    
        def process_chunk(chunk_data):
            """Verarbeitet einen Daten-Chunk."""
            processor = WiFiDataProcessor()
            extractor = FeatureExtractor()
            analyzer = ClusteringAnalyzer()
    
            processed_data = processor.process_data(chunk_data)
            features = extractor.extract_features(processed_data)
            labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=3)
    
            return {
                "chunk_id": threading.current_thread().ident,
                "n_samples": len(chunk_data),
                "n_clusters": len(np.unique(labels)),
            }
    
        # Daten in Chunks aufteilen
        n_chunks = 4
        chunk_size = 1000
        n_samples = n_chunks * chunk_size
    
        test_data = pd.DataFrame(
            {
                "timestamp": pd.date_range(
                    "2024-01-01", periods=n_samples, freq="1min"
                ),
                "device_id": np.random.choice(
                    [f"device_{i}" for i in range(50)], n_samples
                ),
                "signal_strength": np.random.normal(-50, 10, n_samples),
                "frequency": np.random.choice([2.4, 5.0], n_samples),
                "channel": np.random.randint(1, 14, n_samples),
                "mac_address": [f"00:11:22:33:44:{i:02x}" for i in range(n_samples)],
                "ssid": np.random.choice(
                    ["WiFi_Home", "WiFi_Office", "Public_WiFi"], n_samples
                ),
                "encryption": np.random.choice(["WPA2", "WPA3", "Open"], n_samples),
                "data_rate": np.random.normal(54, 10, n_samples),
                "packet_count": np.random.poisson(100, n_samples),
                "bytes_transferred": np.random.exponential(1000, n_samples),
            }
        )
    
        chunks = [
            test_data.iloc[i * chunk_size : (i + 1) * chunk_size]
            for i in range(n_chunks)
        ]
    
        # Parallele Verarbeitung
        with ThreadPoolExecutor(max_workers=n_chunks) as executor:
            futures = [executor.submit(process_chunk, chunk) for chunk in chunks]
>           results = [future.result() for future in futures]

tests/integration/test_end_to_end.py:328: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/integration/test_end_to_end.py:328: in <listcomp>
    results = [future.result() for future in futures]
../.pyenv/versions/3.11.9/lib/python3.11/concurrent/futures/_base.py:456: in result
    return self.__get_result()
../.pyenv/versions/3.11.9/lib/python3.11/concurrent/futures/_base.py:401: in __get_result
    raise self._exception
../.pyenv/versions/3.11.9/lib/python3.11/concurrent/futures/thread.py:58: in run
    result = self.fn(*self.args, **self.kwargs)
tests/integration/test_end_to_end.py:285: in process_chunk
    labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=3)
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1071: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1351: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1481: in fit
    X = self._validate_data(
.venv/lib/python3.11/site-packages/sklearn/base.py:633: in _validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1003: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:126: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[-1.62859019,  0.        ,  0.        , ...,  0.11020775,
        -0.38663966, -1.06832936],
       [-1.6285901...14 ,  0.93604092],
       [ 1.69506325,  0.        ,  0.        , ...,  0.11020775,
         0.31126587,  0.93604092]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:175: ValueError
_______________ TestClusteringBenchmarks.test_kmeans_performance _______________

self = <test_benchmarks.TestClusteringBenchmarks object at 0x7f6f4bf850>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f68f64e90>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_kmeans_performance(self, benchmark, large_dataset):
        """Benchmark für K-Means Clustering."""
        analyzer = ClusteringAnalyzer()
    
        # Features extrahieren
        feature_extractor = FeatureExtractor()
        features = feature_extractor.extract_features(large_dataset)
    
        def clustering_func():
            return analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)
    
>       result = benchmark(clustering_func)

tests/performance/test_benchmarks.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:156: in __call__
    return self._raw(function_to_benchmark, *args, **kwargs)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:180: in _raw
    duration, iterations, loops_range = self._calibrate_timer(runner)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:318: in _calibrate_timer
    duration = runner(loops_range)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:109: in runner
    function_to_benchmark(*args, **kwargs)
tests/performance/test_benchmarks.py:29: in clustering_func
    return analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1071: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1351: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1481: in fit
    X = self._validate_data(
.venv/lib/python3.11/site-packages/sklearn/base.py:633: in _validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1003: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:126: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176, -0.97725852],
       [ 0.       ...176, -0.97725852],
       [ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176,  1.02327069]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:175: ValueError
_______________ TestClusteringBenchmarks.test_dbscan_performance _______________

self = <test_benchmarks.TestClusteringBenchmarks object at 0x7f6f4bfe50>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f6867b750>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_dbscan_performance(self, benchmark, large_dataset):
        """Benchmark für DBSCAN Clustering."""
        analyzer = ClusteringAnalyzer()
    
        feature_extractor = FeatureExtractor()
        features = feature_extractor.extract_features(large_dataset)
    
        def clustering_func():
            return analyzer.cluster_data(
                features, algorithm="dbscan", eps=0.5, min_samples=5
            )
    
>       result = benchmark(clustering_func)

tests/performance/test_benchmarks.py:51: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:156: in __call__
    return self._raw(function_to_benchmark, *args, **kwargs)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:180: in _raw
    duration, iterations, loops_range = self._calibrate_timer(runner)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:318: in _calibrate_timer
    duration = runner(loops_range)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:109: in runner
    function_to_benchmark(*args, **kwargs)
tests/performance/test_benchmarks.py:47: in clustering_func
    return analyzer.cluster_data(
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1071: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1351: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1481: in fit
    X = self._validate_data(
.venv/lib/python3.11/site-packages/sklearn/base.py:633: in _validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1003: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:126: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176, -0.97725852],
       [ 0.       ...176, -0.97725852],
       [ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176,  1.02327069]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:175: ValueError
____________ TestClusteringBenchmarks.test_hierarchical_performance ____________

self = <test_benchmarks.TestClusteringBenchmarks object at 0x7f6f4c0490>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f6915a890>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_hierarchical_performance(self, benchmark, large_dataset):
        """Benchmark für Hierarchical Clustering."""
        analyzer = ClusteringAnalyzer()
    
        feature_extractor = FeatureExtractor()
        features = feature_extractor.extract_features(large_dataset)
    
        def clustering_func():
            return analyzer.cluster_data(
                features, algorithm="hierarchical", n_clusters=5
            )
    
>       result = benchmark(clustering_func)

tests/performance/test_benchmarks.py:71: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:156: in __call__
    return self._raw(function_to_benchmark, *args, **kwargs)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:180: in _raw
    duration, iterations, loops_range = self._calibrate_timer(runner)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:318: in _calibrate_timer
    duration = runner(loops_range)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:109: in runner
    function_to_benchmark(*args, **kwargs)
tests/performance/test_benchmarks.py:67: in clustering_func
    return analyzer.cluster_data(
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1071: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1351: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1481: in fit
    X = self._validate_data(
.venv/lib/python3.11/site-packages/sklearn/base.py:633: in _validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1003: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:126: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176, -0.97725852],
       [ 0.       ...176, -0.97725852],
       [ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176,  1.02327069]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:175: ValueError
_____________ TestClusteringBenchmarks.test_clustering_scalability _____________

self = <test_benchmarks.TestClusteringBenchmarks object at 0x7f6f4c0b10>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f6926a890>

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_clustering_scalability(self, benchmark):
        """Test Skalierbarkeit mit verschiedenen Datengrößen."""
        sizes = [1000, 5000, 10000, 20000]
        times = []
    
        for size in sizes:
            # Generiere Test-Daten
            X = np.random.randn(size, 20)
            analyzer = ClusteringAnalyzer()
    
            def clustering_func():
                return analyzer.cluster_data(X, algorithm="kmeans", n_clusters=5)
    
            result = benchmark(clustering_func)
>           times.append(result.stats.mean)
E           AttributeError: 'numpy.ndarray' object has no attribute 'stats'

tests/performance/test_benchmarks.py:93: AttributeError
________ TestDataProcessingBenchmarks.test_data_processing_performance _________

self = <test_benchmarks.TestDataProcessingBenchmarks object at 0x7f6f4c1090>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f57c04090>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_data_processing_performance(self, benchmark, large_dataset):
        """Benchmark für Datenverarbeitung."""
        processor = WiFiDataProcessor()
    
        def processing_func():
            return processor.process_data(large_dataset)
    
        result = benchmark(processing_func)
    
        # Datenverarbeitung sollte schnell sein
>       assert result.stats.mean < 1.0

tests/performance/test_benchmarks.py:121: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self =                timestamp  device_id  ...  bytes_transferred  processed_timestamp
0    2024-01-01 00:00:00  device_51  ...01 02:46:38
9999 2024-01-01 02:46:39   device_7  ...         594.132395  2024-01-01 02:46:39

[10000 rows x 12 columns]
name = 'stats'

    @final
    def __getattr__(self, name: str):
        """
        After regular attribute access, try looking up the name
        This allows simpler access to columns for interactive use.
        """
        # Note: obj.x will always call obj.__getattribute__('x') prior to
        # calling obj.__getattr__('x').
        if (
            name not in self._internal_names_set
            and name not in self._metadata
            and name not in self._accessors
            and self._info_axis._can_hold_identifiers_and_holds_name(name)
        ):
            return self[name]
>       return object.__getattribute__(self, name)
E       AttributeError: 'DataFrame' object has no attribute 'stats'

.venv/lib/python3.11/site-packages/pandas/core/generic.py:6293: AttributeError
_______ TestDataProcessingBenchmarks.test_feature_extraction_performance _______

self = <test_benchmarks.TestDataProcessingBenchmarks object at 0x7f6f4c1690>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f6411ded0>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_feature_extraction_performance(self, benchmark, large_dataset):
        """Benchmark für Feature-Extraktion."""
        extractor = FeatureExtractor()
    
        def extraction_func():
            return extractor.extract_features(large_dataset)
    
        result = benchmark(extraction_func)
    
        # Feature-Extraktion sollte effizient sein
>       assert result.stats.mean < 2.0
E       AttributeError: 'numpy.ndarray' object has no attribute 'stats'

tests/performance/test_benchmarks.py:136: AttributeError
________ TestDataProcessingBenchmarks.test_feature_scaling_performance _________

self = <test_benchmarks.TestDataProcessingBenchmarks object at 0x7f6f4c1cd0>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f6901e550>

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_feature_scaling_performance(self, benchmark):
        """Benchmark für Feature-Skalierung."""
        extractor = FeatureExtractor()
    
        # Große Feature-Matrix
        features = np.random.randn(50000, 100)
    
        def scaling_func():
            return extractor.scale_features(features)
    
        result = benchmark(scaling_func)
    
        # Skalierung sollte sehr schnell sein
>       assert result.stats.mean < 0.5
E       AttributeError: 'numpy.ndarray' object has no attribute 'stats'

tests/performance/test_benchmarks.py:154: AttributeError
_________ TestClassificationBenchmarks.test_random_forest_performance __________

self = <test_benchmarks.TestClassificationBenchmarks object at 0x7f6f4c24d0>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f690f4e10>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_random_forest_performance(self, benchmark, large_dataset):
        """Benchmark für Random Forest Klassifikation."""
        classifier = DeviceClassifier()
    
        # Features und Labels generieren
        feature_extractor = FeatureExtractor()
        features = feature_extractor.extract_features(large_dataset)
        labels = np.random.randint(0, 5, len(features))
    
        def classification_func():
            classifier.train(features, labels)
            return classifier.predict(features)
    
        result = benchmark(classification_func)
    
        # Random Forest sollte effizient sein
>       assert result.stats.mean < 3.0
E       AttributeError: 'numpy.ndarray' object has no attribute 'stats'

tests/performance/test_benchmarks.py:179: AttributeError
______________ TestClassificationBenchmarks.test_svm_performance _______________

self = <test_benchmarks.TestClassificationBenchmarks object at 0x7f6f4c2ad0>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f6858f3d0>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_svm_performance(self, benchmark, large_dataset):
        """Benchmark für SVM Klassifikation."""
        classifier = DeviceClassifier(algorithm="svm")
    
        feature_extractor = FeatureExtractor()
        features = feature_extractor.extract_features(large_dataset)
        labels = np.random.randint(0, 5, len(features))
    
        def classification_func():
            classifier.train(features, labels)
            return classifier.predict(features)
    
>       result = benchmark(classification_func)

tests/performance/test_benchmarks.py:196: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:156: in __call__
    return self._raw(function_to_benchmark, *args, **kwargs)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:180: in _raw
    duration, iterations, loops_range = self._calibrate_timer(runner)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:318: in _calibrate_timer
    duration = runner(loops_range)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:109: in runner
    function_to_benchmark(*args, **kwargs)
tests/performance/test_benchmarks.py:193: in classification_func
    classifier.train(features, labels)
wlan_tool/analysis/device_classification.py:64: in train
    self.model.fit(X, y)
.venv/lib/python3.11/site-packages/sklearn/base.py:1351: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/svm/_base.py:190: in fit
    X, y = self._validate_data(
.venv/lib/python3.11/site-packages/sklearn/base.py:650: in _validate_data
    X, y = check_X_y(X, y, **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1192: in check_X_y
    X = check_array(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1003: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:126: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176, -0.97725852],
       [ 0.       ...176, -0.97725852],
       [ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176,  1.02327069]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           SVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:175: ValueError
______________ TestMemoryBenchmarks.test_memory_usage_clustering _______________

self = <test_benchmarks.TestMemoryBenchmarks object at 0x7f6f4c3250>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f68dc8410>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    @pytest.mark.memory
    def test_memory_usage_clustering(self, benchmark, large_dataset):
        """Benchmark für Speichernutzung beim Clustering."""
        analyzer = ClusteringAnalyzer()
        feature_extractor = FeatureExtractor()
    
        def memory_intensive_func():
            # Features extrahieren
            features = feature_extractor.extract_features(large_dataset)
    
            # Clustering durchführen
            labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)
    
            # Zusätzliche Berechnungen
            unique_labels = np.unique(labels)
            cluster_sizes = [np.sum(labels == label) for label in unique_labels]
    
            return {
                "n_clusters": len(unique_labels),
                "cluster_sizes": cluster_sizes,
                "features_shape": features.shape,
            }
    
>       result = benchmark(memory_intensive_func)

tests/performance/test_benchmarks.py:231: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:156: in __call__
    return self._raw(function_to_benchmark, *args, **kwargs)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:180: in _raw
    duration, iterations, loops_range = self._calibrate_timer(runner)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:318: in _calibrate_timer
    duration = runner(loops_range)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:109: in runner
    function_to_benchmark(*args, **kwargs)
tests/performance/test_benchmarks.py:219: in memory_intensive_func
    labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1071: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1351: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1481: in fit
    X = self._validate_data(
.venv/lib/python3.11/site-packages/sklearn/base.py:633: in _validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1003: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:126: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176, -0.97725852],
       [ 0.       ...176, -0.97725852],
       [ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176,  1.02327069]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:175: ValueError
_____________ TestMemoryBenchmarks.test_memory_usage_large_dataset _____________

self = <test_benchmarks.TestMemoryBenchmarks object at 0x7f6f4c3890>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f68e8c550>

    @pytest.mark.benchmark
    @pytest.mark.performance
    @pytest.mark.memory
    def test_memory_usage_large_dataset(self, benchmark):
        """Benchmark für Speichernutzung mit sehr großen Datensätzen."""
        # Sehr großer Datensatz
        n_samples = 100000
        n_features = 50
    
        def large_dataset_func():
            # Große Daten generieren
            X = np.random.randn(n_samples, n_features)
    
            # Clustering mit reduzierter Komplexität
            from sklearn.cluster import MiniBatchKMeans
    
            kmeans = MiniBatchKMeans(n_clusters=10, batch_size=1000)
            labels = kmeans.fit_predict(X)
    
            return {
                "n_samples": n_samples,
                "n_features": n_features,
                "n_clusters": len(np.unique(labels)),
            }
    
        result = benchmark(large_dataset_func)
    
        # Auch bei großen Datensätzen sollte es in angemessener Zeit laufen
>       assert result.stats.mean < 10.0
E       AttributeError: 'dict' object has no attribute 'stats'

tests/performance/test_benchmarks.py:265: AttributeError
________ TestConcurrentBenchmarks.test_parallel_processing_performance _________

self = <test_benchmarks.TestConcurrentBenchmarks object at 0x7f6f4d00d0>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f68e4bed0>

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_parallel_processing_performance(self, benchmark):
        """Benchmark für parallele Verarbeitung."""
        import threading
        from concurrent.futures import ThreadPoolExecutor
    
        def process_chunk(chunk_data):
            """Verarbeitet einen Daten-Chunk."""
            analyzer = ClusteringAnalyzer()
            return analyzer.cluster_data(chunk_data, algorithm="kmeans", n_clusters=3)
    
        def parallel_processing_func():
            # Daten in Chunks aufteilen
            n_chunks = 4
            chunk_size = 2500
            X = np.random.randn(n_chunks * chunk_size, 20)
            chunks = [X[i * chunk_size : (i + 1) * chunk_size] for i in range(n_chunks)]
    
            # Parallele Verarbeitung
            with ThreadPoolExecutor(max_workers=n_chunks) as executor:
                futures = [executor.submit(process_chunk, chunk) for chunk in chunks]
                results = [future.result() for future in futures]
    
            return results
    
        result = benchmark(parallel_processing_func)
    
        # Parallele Verarbeitung sollte effizienter sein
>       assert result.stats.mean < 3.0
E       AttributeError: 'list' object has no attribute 'stats'

tests/performance/test_benchmarks.py:301: AttributeError
__________________ TestIOBenchmarks.test_file_io_performance ___________________

self = <test_benchmarks.TestIOBenchmarks object at 0x7f6f4c1850>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f6f13b990>
temp_dir = PosixPath('/tmp/tmpn6wfbgey')

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_file_io_performance(self, benchmark, temp_dir):
        """Benchmark für Datei-I/O."""
        import pickle
    
        # Große Daten generieren
        large_data = np.random.randn(10000, 50)
        file_path = temp_dir / "test_data.pkl"
    
        def io_func():
            # Speichern
            with open(file_path, "wb") as f:
                pickle.dump(large_data, f)
    
            # Laden
            with open(file_path, "rb") as f:
                loaded_data = pickle.load(f)
    
            return loaded_data.shape
    
        result = benchmark(io_func)
    
        # I/O sollte schnell sein
>       assert result.stats.mean < 1.0
E       AttributeError: 'tuple' object has no attribute 'stats'

tests/performance/test_benchmarks.py:332: AttributeError
___________________ TestIOBenchmarks.test_csv_io_performance ___________________

self = <test_benchmarks.TestIOBenchmarks object at 0x7f6f4d0310>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f68dd05d0>
temp_dir = PosixPath('/tmp/tmpg0nd8fhy')
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_csv_io_performance(self, benchmark, temp_dir, large_dataset):
        """Benchmark für CSV-I/O."""
        csv_path = temp_dir / "test_data.csv"
    
        def csv_io_func():
            # Speichern
            large_dataset.to_csv(csv_path, index=False)
    
            # Laden
            loaded_data = pd.read_csv(csv_path)
    
            return loaded_data.shape
    
        result = benchmark(csv_io_func)
    
        # CSV-I/O kann langsamer sein
>       assert result.stats.mean < 2.0
E       AttributeError: 'tuple' object has no attribute 'stats'

tests/performance/test_benchmarks.py:353: AttributeError
_________________ TestMemoryUsage.test_memory_usage_clustering _________________

self = <test_memory_profiling.TestMemoryUsage object at 0x7f6f502210>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.memory
    @pytest.mark.performance
    def test_memory_usage_clustering(self, large_dataset):
        """Test Speichernutzung beim Clustering."""
        process = psutil.Process(os.getpid())
        memory_before = process.memory_info().rss / 1024 / 1024
    
        analyzer = ClusteringAnalyzer()
        feature_extractor = FeatureExtractor()
    
        # Features extrahieren
        features = feature_extractor.extract_features(large_dataset)
        memory_after_features = process.memory_info().rss / 1024 / 1024
    
        # Clustering durchführen
>       labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)

tests/performance/test_memory_profiling.py:77: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1071: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1351: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1481: in fit
    X = self._validate_data(
.venv/lib/python3.11/site-packages/sklearn/base.py:633: in _validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1003: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:126: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176, -0.97725852],
       [ 0.       ...176, -0.97725852],
       [ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176,  1.02327069]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:175: ValueError
______________ TestMemoryProfiling.test_detailed_memory_profiling ______________

self = <test_memory_profiling.TestMemoryProfiling object at 0x7f6f503c90>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.memory
    @pytest.mark.performance
    def test_detailed_memory_profiling(self, large_dataset):
        """Detailliertes Memory-Profiling der WLAN-Analyse."""
        from memory_profiler import memory_usage
    
        def analyze_wifi_data():
            """WLAN-Datenanalyse mit Memory-Tracking."""
            processor = WiFiDataProcessor()
            extractor = FeatureExtractor()
            analyzer = ClusteringAnalyzer()
    
            # 1. Daten verarbeiten
            processed_data = processor.process_data(large_dataset)
    
            # 2. Features extrahieren
            features = extractor.extract_features(processed_data)
    
            # 3. Clustering
            labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)
    
            # 4. Ergebnisse zusammenfassen
            unique_labels = np.unique(labels)
            cluster_sizes = [np.sum(labels == label) for label in unique_labels]
    
            return {
                "n_clusters": len(unique_labels),
                "cluster_sizes": cluster_sizes,
                "features_shape": features.shape,
            }
    
        # Memory-Usage während der Ausführung messen
>       mem_usage = memory_usage(analyze_wifi_data, interval=0.1)

tests/performance/test_memory_profiling.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.11/site-packages/memory_profiler.py:379: in memory_usage
    returned = f(*args, **kw)
tests/performance/test_memory_profiling.py:208: in analyze_wifi_data
    labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1071: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1351: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1481: in fit
    X = self._validate_data(
.venv/lib/python3.11/site-packages/sklearn/base.py:633: in _validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1003: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:126: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[-1.15579349,  0.        ,  0.        , ...,  0.        ,
         0.15614176, -0.97725852],
       [-1.1557934...176, -0.97725852],
       [ 1.35680105,  0.        ,  0.        , ...,  0.        ,
         0.15614176,  1.02327069]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:175: ValueError
_________ TestMemoryProfiling.test_memory_profiling_garbage_collection _________

self = <test_memory_profiling.TestMemoryProfiling object at 0x7f6f50c850>

    @pytest.mark.memory
    @pytest.mark.performance
    def test_memory_profiling_garbage_collection(self):
        """Test Memory-Profiling mit Garbage Collection."""
        import gc
    
        process = psutil.Process(os.getpid())
    
        def create_large_objects():
            """Erstellt große Objekte und führt Garbage Collection durch."""
            # Große Objekte erstellen
            large_arrays = [np.random.randn(1000, 100) for _ in range(10)]
    
            # Memory vor GC
            memory_before_gc = process.memory_info().rss / 1024 / 1024
    
            # Garbage Collection
            gc.collect()
    
            # Memory nach GC
            memory_after_gc = process.memory_info().rss / 1024 / 1024
    
            return memory_before_gc, memory_after_gc
    
        memory_before, memory_after = create_large_objects()
        memory_freed = memory_before - memory_after
    
        # Garbage Collection sollte Speicher freigeben
>       assert memory_freed > 0, "Garbage Collection hat keinen Speicher freigegeben"
E       AssertionError: Garbage Collection hat keinen Speicher freigegeben
E       assert 0.0 > 0

tests/performance/test_memory_profiling.py:302: AssertionError
_____________ TestMemoryOptimization.test_memory_usage_data_types ______________

self = <test_memory_profiling.TestMemoryOptimization object at 0x7f6f50dbd0>

    @pytest.mark.memory
    @pytest.mark.performance
    def test_memory_usage_data_types(self):
        """Test Speichernutzung verschiedener Datentypen."""
        process = psutil.Process(os.getpid())
    
        # Test verschiedene Datentypen
        data_types = [
            ("float32", np.float32),
            ("float64", np.float64),
            ("int32", np.int32),
            ("int64", np.int64),
        ]
    
        memory_usage = {}
    
        for dtype_name, dtype in data_types:
            memory_before = process.memory_info().rss / 1024 / 1024
    
            # Große Array mit spezifischem Datentyp
            array = np.random.randn(10000, 100).astype(dtype)
    
            memory_after = process.memory_info().rss / 1024 / 1024
            memory_usage[dtype_name] = memory_after - memory_before
    
        # float32 sollte weniger Speicher verwenden als float64
>       assert memory_usage["float32"] < memory_usage["float64"]
E       assert 0.0 < 0.0

tests/performance/test_memory_profiling.py:405: AssertionError
__________________ TestDataValidator.test_validate_valid_data __________________

self = <test_data_processing.TestDataValidator object at 0x7f6f518b90>
sample_wifi_data =               timestamp device_id  ...  packet_count  bytes_transferred
0   2024-01-01 00:00:00  device_3  ...        ...15         206.754596
999 2024-01-01 16:39:00  device_1  ...           103         554.365485

[1000 rows x 11 columns]

    def test_validate_valid_data(self, sample_wifi_data):
        """Test Validierung gültiger Daten."""
        validator = DataValidator()
        is_valid, errors = validator.validate(sample_wifi_data)
    
>       assert is_valid
E       assert False

tests/unit/test_data_processing.py:178: AssertionError
_____________________ TestClusteringModel.test_fit_kmeans ______________________

self = <test_ml_models.TestClusteringModel object at 0x7f6f3a5ad0>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])

    def test_fit_kmeans(self, sample_features):
        """Test K-Means Clustering."""
        model = ClusteringModel(algorithm="kmeans", n_clusters=3)
>       model.fit(sample_features)

tests/unit/test_ml_models.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/clustering_model.py:53: in fit
    self.model = self._create_model()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.clustering_model.ClusteringModel object at 0x7f57fb5510>
n_clusters = 3

    def _create_model(self, n_clusters: Optional[int] = None) -> Any:
        """Erstellt das Clustering-Modell."""
        if self.algorithm == 'kmeans':
            n_clusters = n_clusters or self.kwargs.get('n_clusters', 5)
>           return KMeans(n_clusters=n_clusters, random_state=42, **self.kwargs)
E           TypeError: sklearn.cluster._kmeans.KMeans() got multiple values for keyword argument 'n_clusters'

wlan_tool/ml_models/clustering_model.py:36: TypeError
__________________ TestClusteringModel.test_predict_after_fit __________________

self = <test_ml_models.TestClusteringModel object at 0x7f6f3a6d50>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])

    def test_predict_after_fit(self, sample_features):
        """Test Vorhersage nach Training."""
        model = ClusteringModel(algorithm="kmeans", n_clusters=3)
>       model.fit(sample_features)

tests/unit/test_ml_models.py:52: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/clustering_model.py:53: in fit
    self.model = self._create_model()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.clustering_model.ClusteringModel object at 0x7f68961450>
n_clusters = 3

    def _create_model(self, n_clusters: Optional[int] = None) -> Any:
        """Erstellt das Clustering-Modell."""
        if self.algorithm == 'kmeans':
            n_clusters = n_clusters or self.kwargs.get('n_clusters', 5)
>           return KMeans(n_clusters=n_clusters, random_state=42, **self.kwargs)
E           TypeError: sklearn.cluster._kmeans.KMeans() got multiple values for keyword argument 'n_clusters'

wlan_tool/ml_models/clustering_model.py:36: TypeError
_________________ TestClusteringModel.test_get_cluster_centers _________________

self = <test_ml_models.TestClusteringModel object at 0x7f6f3a6a90>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])

    def test_get_cluster_centers(self, sample_features):
        """Test Cluster-Zentren abrufen."""
        model = ClusteringModel(algorithm="kmeans", n_clusters=3)
>       model.fit(sample_features)

tests/unit/test_ml_models.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/clustering_model.py:53: in fit
    self.model = self._create_model()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.clustering_model.ClusteringModel object at 0x7f689f30d0>
n_clusters = 3

    def _create_model(self, n_clusters: Optional[int] = None) -> Any:
        """Erstellt das Clustering-Modell."""
        if self.algorithm == 'kmeans':
            n_clusters = n_clusters or self.kwargs.get('n_clusters', 5)
>           return KMeans(n_clusters=n_clusters, random_state=42, **self.kwargs)
E           TypeError: sklearn.cluster._kmeans.KMeans() got multiple values for keyword argument 'n_clusters'

wlan_tool/ml_models/clustering_model.py:36: TypeError
_________________ TestClusteringModel.test_evaluate_clustering _________________

self = <test_ml_models.TestClusteringModel object at 0x7f6f3a7490>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])

    def test_evaluate_clustering(self, sample_features):
        """Test Clustering-Evaluation."""
        model = ClusteringModel(algorithm="kmeans", n_clusters=3)
>       model.fit(sample_features)

tests/unit/test_ml_models.py:73: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/clustering_model.py:53: in fit
    self.model = self._create_model()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.clustering_model.ClusteringModel object at 0x7f68a18c10>
n_clusters = 3

    def _create_model(self, n_clusters: Optional[int] = None) -> Any:
        """Erstellt das Clustering-Modell."""
        if self.algorithm == 'kmeans':
            n_clusters = n_clusters or self.kwargs.get('n_clusters', 5)
>           return KMeans(n_clusters=n_clusters, random_state=42, **self.kwargs)
E           TypeError: sklearn.cluster._kmeans.KMeans() got multiple values for keyword argument 'n_clusters'

wlan_tool/ml_models/clustering_model.py:36: TypeError
__________________ TestClusteringModel.test_invalid_algorithm __________________

self = <test_ml_models.TestClusteringModel object at 0x7f6f3a77d0>

    def test_invalid_algorithm(self):
        """Test mit ungültigem Algorithmus."""
>       with pytest.raises(ValueError, match="Unsupported algorithm"):
E       Failed: DID NOT RAISE <class 'ValueError'>

tests/unit/test_ml_models.py:86: Failed
______________ TestClusteringModel.test_hyperparameter_validation ______________

self = <test_ml_models.TestClusteringModel object at 0x7f6f3a7d90>

    def test_hyperparameter_validation(self):
        """Test Hyperparameter-Validierung."""
        # Ungültige n_clusters
>       with pytest.raises(ValueError, match="n_clusters must be positive"):
E       Failed: DID NOT RAISE <class 'ValueError'>

tests/unit/test_ml_models.py:92: Failed
________________ TestClassificationModel.test_cross_validation _________________

self = <test_ml_models.TestClassificationModel object at 0x7f6f0bb690>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
sample_labels = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])

    def test_cross_validation(self, sample_features, sample_labels):
        """Test Cross-Validation."""
        model = ClassificationModel(algorithm="random_forest", n_estimators=10)
    
>       cv_scores = model.cross_validate(sample_features, sample_labels, cv=3)

tests/unit/test_ml_models.py:177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f68982cd0>
X = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
y = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])
cv = 3

    def cross_validate(self, X: np.ndarray, y: np.ndarray, cv: int = 5) -> Dict[str, List[float]]:
        """Führt Cross-Validation durch."""
        if not self.is_fitted:
>           raise ValueError("Model must be fitted first")
E           ValueError: Model must be fitted first

wlan_tool/ml_models/classification_model.py:103: ValueError
_________________ TestEnsembleModel.test_fit_voting_classifier _________________

self = <test_ml_models.TestEnsembleModel object at 0x7f6f0c4c10>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
sample_labels = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])

    def test_fit_voting_classifier(self, sample_features, sample_labels):
        """Test Voting Classifier Training."""
        model = EnsembleModel(
            algorithm="voting",
            estimators=[
                ("rf", ClassificationModel(algorithm="random_forest")),
                ("svm", ClassificationModel(algorithm="svm")),
            ],
        )
>       model.fit(sample_features, sample_labels)

tests/unit/test_ml_models.py:215: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/ensemble_model.py:62: in fit
    self.model = self._create_model(estimators=estimators)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.ensemble_model.EnsembleModel object at 0x7f68c823d0>
base_estimator = None
estimators = [('rf', <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f68c80510>), ('svm', <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f68c828d0>)]

    def _create_model(self, base_estimator=None, estimators=None) -> Any:
        """Erstellt das Ensemble-Modell."""
        if self.algorithm == 'voting':
            if estimators is None:
                raise ValueError("Voting requires estimators list")
>           return VotingClassifier(estimators=estimators, **self.kwargs)
E           TypeError: sklearn.ensemble._voting.VotingClassifier() got multiple values for keyword argument 'estimators'

wlan_tool/ml_models/ensemble_model.py:36: TypeError
______________________ TestEnsembleModel.test_fit_bagging ______________________

self = <test_ml_models.TestEnsembleModel object at 0x7f6f0c5310>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
sample_labels = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])

    def test_fit_bagging(self, sample_features, sample_labels):
        """Test Bagging Training."""
        model = EnsembleModel(
            algorithm="bagging",
            base_estimator=ClassificationModel(algorithm="random_forest"),
            n_estimators=5,
        )
>       model.fit(sample_features, sample_labels)

tests/unit/test_ml_models.py:227: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/ensemble_model.py:67: in fit
    self.model = self._create_model(base_estimator=base_estimator)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.ensemble_model.EnsembleModel object at 0x7f689f09d0>
base_estimator = <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f689f3290>
estimators = None

    def _create_model(self, base_estimator=None, estimators=None) -> Any:
        """Erstellt das Ensemble-Modell."""
        if self.algorithm == 'voting':
            if estimators is None:
                raise ValueError("Voting requires estimators list")
            return VotingClassifier(estimators=estimators, **self.kwargs)
        elif self.algorithm == 'bagging':
            if base_estimator is None:
                raise ValueError("Bagging requires base_estimator")
>           return BaggingClassifier(base_estimator=base_estimator, **self.kwargs)
E           TypeError: sklearn.ensemble._bagging.BaggingClassifier() got multiple values for keyword argument 'base_estimator'

wlan_tool/ml_models/ensemble_model.py:40: TypeError
_____________________ TestEnsembleModel.test_fit_boosting ______________________

self = <test_ml_models.TestEnsembleModel object at 0x7f6f0c5a50>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
sample_labels = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])

    def test_fit_boosting(self, sample_features, sample_labels):
        """Test Boosting Training."""
        model = EnsembleModel(
            algorithm="boosting",
            base_estimator=ClassificationModel(algorithm="random_forest"),
            n_estimators=5,
        )
>       model.fit(sample_features, sample_labels)

tests/unit/test_ml_models.py:239: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/ensemble_model.py:67: in fit
    self.model = self._create_model(base_estimator=base_estimator)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.ensemble_model.EnsembleModel object at 0x7f68a74d50>
base_estimator = <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f68a77290>
estimators = None

    def _create_model(self, base_estimator=None, estimators=None) -> Any:
        """Erstellt das Ensemble-Modell."""
        if self.algorithm == 'voting':
            if estimators is None:
                raise ValueError("Voting requires estimators list")
            return VotingClassifier(estimators=estimators, **self.kwargs)
        elif self.algorithm == 'bagging':
            if base_estimator is None:
                raise ValueError("Bagging requires base_estimator")
            return BaggingClassifier(base_estimator=base_estimator, **self.kwargs)
        elif self.algorithm == 'boosting':
            if base_estimator is None:
                raise ValueError("Boosting requires base_estimator")
>           return AdaBoostClassifier(base_estimator=base_estimator, **self.kwargs)
E           TypeError: sklearn.ensemble._weight_boosting.AdaBoostClassifier() got multiple values for keyword argument 'base_estimator'

wlan_tool/ml_models/ensemble_model.py:44: TypeError
___________________ TestEnsembleModel.test_predict_ensemble ____________________

self = <test_ml_models.TestEnsembleModel object at 0x7f6f0c6150>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
sample_labels = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])

    def test_predict_ensemble(self, sample_features, sample_labels):
        """Test Ensemble-Vorhersage."""
        model = EnsembleModel(
            algorithm="voting",
            estimators=[
                ("rf", ClassificationModel(algorithm="random_forest")),
                ("svm", ClassificationModel(algorithm="svm")),
            ],
        )
>       model.fit(sample_features, sample_labels)

tests/unit/test_ml_models.py:253: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/ensemble_model.py:62: in fit
    self.model = self._create_model(estimators=estimators)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.ensemble_model.EnsembleModel object at 0x7f68952710>
base_estimator = None
estimators = [('rf', <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f689523d0>), ('svm', <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f689510d0>)]

    def _create_model(self, base_estimator=None, estimators=None) -> Any:
        """Erstellt das Ensemble-Modell."""
        if self.algorithm == 'voting':
            if estimators is None:
                raise ValueError("Voting requires estimators list")
>           return VotingClassifier(estimators=estimators, **self.kwargs)
E           TypeError: sklearn.ensemble._voting.VotingClassifier() got multiple values for keyword argument 'estimators'

wlan_tool/ml_models/ensemble_model.py:36: TypeError
___________________ TestEnsembleModel.test_evaluate_ensemble ___________________

self = <test_ml_models.TestEnsembleModel object at 0x7f6f0c6850>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
sample_labels = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])

    def test_evaluate_ensemble(self, sample_features, sample_labels):
        """Test Ensemble-Evaluation."""
        model = EnsembleModel(
            algorithm="voting",
            estimators=[
                ("rf", ClassificationModel(algorithm="random_forest")),
                ("svm", ClassificationModel(algorithm="svm")),
            ],
        )
>       model.fit(sample_features, sample_labels)

tests/unit/test_ml_models.py:269: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/ensemble_model.py:62: in fit
    self.model = self._create_model(estimators=estimators)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.ensemble_model.EnsembleModel object at 0x7f68a1a390>
base_estimator = None
estimators = [('rf', <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f68a19210>), ('svm', <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f68a18b90>)]

    def _create_model(self, base_estimator=None, estimators=None) -> Any:
        """Erstellt das Ensemble-Modell."""
        if self.algorithm == 'voting':
            if estimators is None:
                raise ValueError("Voting requires estimators list")
>           return VotingClassifier(estimators=estimators, **self.kwargs)
E           TypeError: sklearn.ensemble._voting.VotingClassifier() got multiple values for keyword argument 'estimators'

wlan_tool/ml_models/ensemble_model.py:36: TypeError
___________ TestEnsembleModel.test_individual_estimator_performance ____________

self = <test_ml_models.TestEnsembleModel object at 0x7f6f0c6f50>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
sample_labels = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])

    def test_individual_estimator_performance(self, sample_features, sample_labels):
        """Test Performance einzelner Estimators."""
        model = EnsembleModel(
            algorithm="voting",
            estimators=[
                ("rf", ClassificationModel(algorithm="random_forest")),
                ("svm", ClassificationModel(algorithm="svm")),
            ],
        )
>       model.fit(sample_features, sample_labels)

tests/unit/test_ml_models.py:287: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/ensemble_model.py:62: in fit
    self.model = self._create_model(estimators=estimators)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.ensemble_model.EnsembleModel object at 0x7f68980750>
base_estimator = None
estimators = [('rf', <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f68980490>), ('svm', <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f68983610>)]

    def _create_model(self, base_estimator=None, estimators=None) -> Any:
        """Erstellt das Ensemble-Modell."""
        if self.algorithm == 'voting':
            if estimators is None:
                raise ValueError("Voting requires estimators list")
>           return VotingClassifier(estimators=estimators, **self.kwargs)
E           TypeError: sklearn.ensemble._voting.VotingClassifier() got multiple values for keyword argument 'estimators'

wlan_tool/ml_models/ensemble_model.py:36: TypeError
___________________ TestEnsembleModel.test_invalid_algorithm ___________________

self = <test_ml_models.TestEnsembleModel object at 0x7f6f0b9c50>

    def test_invalid_algorithm(self):
        """Test mit ungültigem Ensemble-Algorithmus."""
>       with pytest.raises(ValueError, match="Unsupported ensemble algorithm"):
E       Failed: DID NOT RAISE <class 'ValueError'>

tests/unit/test_ml_models.py:298: Failed
___________________ TestEnsembleModel.test_empty_estimators ____________________

self = <test_ml_models.TestEnsembleModel object at 0x7f6f3a6090>

    def test_empty_estimators(self):
        """Test mit leerer Estimator-Liste."""
>       with pytest.raises(ValueError, match="At least one estimator required"):
E       Failed: DID NOT RAISE <class 'ValueError'>

tests/unit/test_ml_models.py:303: Failed
__________________ TestModelPersistence.test_save_load_model ___________________

self = <test_ml_models.TestModelPersistence object at 0x7f6f0c65d0>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
sample_labels = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])
temp_dir = PosixPath('/tmp/tmp95y1fcqq')

    def test_save_load_model(self, sample_features, sample_labels, temp_dir):
        """Test Speichern und Laden von Modellen."""
        # Training
        model = ClassificationModel(algorithm="random_forest", n_estimators=10)
        model.fit(sample_features, sample_labels)
    
        # Speichern
        model_path = temp_dir / "test_model.pkl"
>       model.save(model_path)
E       AttributeError: 'ClassificationModel' object has no attribute 'save'

tests/unit/test_ml_models.py:318: AttributeError
_________________ TestModelPersistence.test_save_load_ensemble _________________

self = <test_ml_models.TestModelPersistence object at 0x7f6f0c5510>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
sample_labels = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])
temp_dir = PosixPath('/tmp/tmpatibalvd')

    def test_save_load_ensemble(self, sample_features, sample_labels, temp_dir):
        """Test Speichern und Laden von Ensemble-Modellen."""
        # Training
        model = EnsembleModel(
            algorithm="voting",
            estimators=[
                ("rf", ClassificationModel(algorithm="random_forest")),
                ("svm", ClassificationModel(algorithm="svm")),
            ],
        )
>       model.fit(sample_features, sample_labels)

tests/unit/test_ml_models.py:344: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/ensemble_model.py:62: in fit
    self.model = self._create_model(estimators=estimators)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.ensemble_model.EnsembleModel object at 0x7f68962690>
base_estimator = None
estimators = [('rf', <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f68960610>), ('svm', <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f68960550>)]

    def _create_model(self, base_estimator=None, estimators=None) -> Any:
        """Erstellt das Ensemble-Modell."""
        if self.algorithm == 'voting':
            if estimators is None:
                raise ValueError("Voting requires estimators list")
>           return VotingClassifier(estimators=estimators, **self.kwargs)
E           TypeError: sklearn.ensemble._voting.VotingClassifier() got multiple values for keyword argument 'estimators'

wlan_tool/ml_models/ensemble_model.py:36: TypeError
=============================== warnings summary ===============================
tests/conftest.py:12
  /home/pi/hacking/tests/conftest.py:12: DeprecationWarning: 
  Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),
  (to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)
  but was not found to be installed on your system.
  If this would cause problems for you,
  please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466
          
    import pandas as pd

pytest/test_integration.py:192
  /home/pi/hacking/pytest/test_integration.py:192: PytestUnknownMarkWarning: Unknown pytest.mark.network - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.network

plugins/clustering_advanced/tests/test_clustering_advanced.py::TestAdvancedClusteringPlugin::test_optics_clustering
plugins/clustering_advanced/tests/test_clustering_advanced.py::TestAdvancedClusteringPlugin::test_plugin_run_with_sufficient_data
  /home/pi/hacking/.venv/lib/python3.11/site-packages/sklearn/cluster/_optics.py:659: UserWarning: All reachability values are inf. Set a larger max_eps or all data will be considered outliers.
    warnings.warn(

pytest/test_capture.py::TestSniffingIntegration::test_sniff_with_writer_mock
  /home/pi/hacking/.venv/lib/python3.11/site-packages/_pytest/threadexception.py:77: PytestUnhandledThreadExceptionWarning: Exception in thread ChannelHopper
  
  Traceback (most recent call last):
    File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/threading.py", line 1045, in _bootstrap_inner
      self.run()
    File "/home/pi/hacking/wlan_tool/capture/sniffer.py", line 205, in run
      subprocess.run(command, check=True, capture_output=True, text=True)
    File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/subprocess.py", line 550, in run
      stdout, stderr = process.communicate(input, timeout=timeout)
      ^^^^^^^^^^^^^^
  ValueError: not enough values to unpack (expected 2, got 0)
  
    warnings.warn(pytest.PytestUnhandledThreadExceptionWarning(msg))

tests/integration/test_end_to_end.py::TestEndToEndWorkflow::test_error_handling_and_recovery
  /home/pi/hacking/wlan_tool/data_processing/wifi_processor.py:45: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
    processed_data['processed_timestamp'] = pd.to_datetime(processed_data['timestamp'])

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html

-------------------------------------------------------------------------------------------------- benchmark: 9 tests --------------------------------------------------------------------------------------------------
Name (time in ms)                               Min                   Max                  Mean              StdDev                Median                 IQR            Outliers      OPS            Rounds  Iterations
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
test_file_io_performance                    23.8574 (1.0)        197.3269 (3.74)       136.6777 (2.60)      25.5525 (187.51)     134.7665 (2.57)      18.1014 (103.54)        9;5   7.3165 (0.38)         55           1
test_feature_extraction_performance         52.3721 (2.20)        52.8167 (1.0)         52.5655 (1.0)        0.1363 (1.0)         52.5240 (1.0)        0.1748 (1.0)           5;0  19.0239 (1.0)          16           1
test_data_processing_performance            60.5139 (2.54)       399.0242 (7.55)        81.7029 (1.55)      81.7768 (600.10)      61.8474 (1.18)       1.8128 (10.37)         1;1  12.2395 (0.64)         17           1
test_clustering_scalability                 83.2225 (3.49)        94.6828 (1.79)        89.9342 (1.71)       3.1437 (23.07)       90.2790 (1.72)       3.7302 (21.34)         3;0  11.1192 (0.58)         11           1
test_feature_scaling_performance           152.2856 (6.38)       152.6441 (2.89)       152.4573 (2.90)       0.1383 (1.02)       152.4485 (2.90)       0.2060 (1.18)          2;0   6.5592 (0.34)          5           1
test_parallel_processing_performance       162.8323 (6.83)       215.2690 (4.08)       192.9771 (3.67)      17.9691 (131.86)     193.9426 (3.69)      25.3169 (144.82)        2;0   5.1820 (0.27)          7           1
test_csv_io_performance                    326.4694 (13.68)      365.3098 (6.92)       336.7504 (6.41)      16.0943 (118.11)     330.6912 (6.30)      11.6662 (66.73)         1;1   2.9696 (0.16)          5           1
test_memory_usage_large_dataset            526.1514 (22.05)      785.9911 (14.88)      666.7845 (12.68)    124.6410 (914.66)     725.2735 (13.81)    229.4335 (>1000.0)       2;0   1.4997 (0.08)          5           1
test_random_forest_performance           7,747.6451 (324.75)   7,895.2477 (149.48)   7,828.5756 (148.93)    69.3729 (509.08)   7,840.4354 (149.27)   132.4305 (757.51)        1;0   0.1277 (0.01)          5           1
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Legend:
  Outliers: 1 Standard Deviation from Mean; 1.5 IQR (InterQuartile Range) from 1st Quartile and 3rd Quartile.
  OPS: Operations Per Second, computed as 1 / Mean
=========================== short test summary info ============================
FAILED plugins/clustering_advanced/tests/test_clustering_advanced.py::TestAdvancedClusteringPlugin::test_spectral_clustering
FAILED plugins/clustering_advanced/tests/test_clustering_advanced.py::TestAdvancedClusteringPlugin::test_hierarchical_clustering
FAILED plugins/clustering_advanced/tests/test_clustering_advanced.py::TestAdvancedClusteringPlugin::test_gaussian_mixture
FAILED plugins/clustering_advanced/tests/test_clustering_advanced.py::TestAdvancedClusteringPlugin::test_hdbscan_clustering
FAILED plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_ensemble_model_builder_creation
FAILED plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_model_performance_evaluation
FAILED plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_plugin_run_with_sufficient_data
FAILED plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_performance_visualization_creation
FAILED plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_ensemble_model_builder_integration
FAILED plugins/reinforcement_learning/tests/test_reinforcement_learning.py::TestReinforcementLearningPlugin::test_environment_observation
FAILED plugins/reinforcement_learning/tests/test_reinforcement_learning.py::TestReinforcementLearningPlugin::test_environment_step
FAILED plugins/reinforcement_learning/tests/test_reinforcement_learning.py::TestReinforcementLearningPlugin::test_environment_action_execution
FAILED plugins/reinforcement_learning/tests/test_reinforcement_learning.py::TestReinforcementLearningPlugin::test_simple_rl_agent_epsilon_decay
FAILED plugins/reinforcement_learning/tests/test_reinforcement_learning.py::TestReinforcementLearningPlugin::test_plugin_run_with_sufficient_data
FAILED plugins/reinforcement_learning/tests/test_reinforcement_learning.py::TestReinforcementLearningPlugin::test_plugin_run_without_pytorch
FAILED plugins/reinforcement_learning/tests/test_reinforcement_learning.py::TestReinforcementLearningPlugin::test_training_results_structure
FAILED plugins/reinforcement_learning/tests/test_reinforcement_learning.py::TestReinforcementLearningPlugin::test_agent_save_load
FAILED plugins/reinforcement_learning/tests/test_reinforcement_learning.py::TestReinforcementLearningPlugin::test_environment_performance_metrics_update
FAILED plugins/sankey/tests/test_sankey.py::TestSankeyPlugin::test_plugin_run_with_roaming_events
FAILED plugins/sankey/tests/test_sankey.py::TestSankeyPlugin::test_plugin_run_with_sufficient_data
FAILED plugins/umap_plot/tests/test_umap_plot.py::TestUMAPPlotPlugin::test_plugin_metadata
FAILED plugins/umap_plot/tests/test_umap_plot.py::TestUMAPPlotPlugin::test_plugin_run_with_valid_data
FAILED plugins/umap_plot/tests/test_umap_plot.py::TestUMAPPlotPlugin::test_plugin_run_without_clustered_data
FAILED plugins/umap_plot/tests/test_umap_plot.py::TestUMAPPlotPlugin::test_plugin_run_with_empty_feature_data
FAILED plugins/umap_plot/tests/test_umap_plot.py::TestUMAPPlotPlugin::test_plugin_run_with_exception
FAILED pytest/test_analysis.py::TestAnalysisLogic::test_profile_clusters - Ke...
FAILED pytest/test_analysis.py::TestAnalysisLogic::test_cluster_aps - ValueEr...
FAILED pytest/test_analysis.py::TestAnalysisLogic::test_profile_ap_clusters
FAILED pytest/test_analysis.py::TestDeviceProfiler::test_create_device_fingerprint_empty_state
FAILED pytest/test_analysis.py::TestGraphExport::test_build_export_graph - As...
FAILED pytest/test_analysis.py::TestGraphExport::test_discover_attributes - A...
FAILED pytest/test_analysis.py::TestAnalysisEdgeCases::test_single_client_analysis
FAILED pytest/test_analysis.py::TestAnalysisEdgeCases::test_malformed_event_handling
FAILED pytest/test_app.py::TestUtilsModule::test_intelligent_vendor_lookup - ...
FAILED pytest/test_app.py::TestAnalysisModule::test_features_for_client_behavior
FAILED pytest/test_app.py::TestAnalysisModule::test_cluster_clients_runs - At...
FAILED pytest/test_app.py::TestAnalysisModule::test_profile_clusters - Attrib...
FAILED pytest/test_capture.py::TestPacketParsing::test_packet_to_event_probe_request
FAILED pytest/test_capture.py::TestPacketParsing::test_packet_to_event_data_frame
FAILED pytest/test_capture.py::TestPacketParsing::test_packet_to_event_with_dns_query
FAILED pytest/test_capture.py::TestPacketParsing::test_packet_to_event_with_dhcp
FAILED pytest/test_capture.py::TestChannelHopper::test_channel_hopper_command_failure
FAILED pytest/test_capture.py::TestIEExtraction::test_collect_ies_from_pkt - ...
FAILED pytest/test_capture.py::TestIEExtraction::test_extract_seq - assert 0 ...
FAILED pytest/test_capture.py::TestErrorHandling::test_packet_to_event_encoding_error
FAILED pytest/test_controllers.py::TestCaptureController::test_select_interface_automatic
FAILED pytest/test_controllers.py::TestCaptureController::test_select_interface_no_interfaces
FAILED pytest/test_controllers.py::TestCaptureController::test_setup_monitor_mode_failure
FAILED pytest/test_controllers.py::TestAnalysisController::test_analysis_controller_initialization
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_inference
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_client_clustering
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_ap_clustering
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_graph_export
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_labeling_ui
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_client_labeling_ui
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_mac_correlation
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_analysis_no_actions
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_analysis_multiple_actions
FAILED pytest/test_controllers.py::TestControllerEdgeCases::test_analysis_controller_empty_state
FAILED pytest/test_controllers.py::TestControllerEdgeCases::test_analysis_controller_with_plugins
FAILED pytest/test_controllers.py::TestControllerIntegration::test_full_analysis_workflow
FAILED pytest/test_error_handling.py::TestErrorContext::test_error_context_exception
FAILED pytest/test_error_handling.py::TestLoggingSystem::test_setup_logging
FAILED pytest/test_error_handling.py::TestDatabaseErrorHandling::test_database_connection_error
FAILED pytest/test_error_handling.py::TestDatabaseErrorHandling::test_database_migration_error
FAILED pytest/test_error_handling.py::TestAnalysisErrorHandling::test_client_features_null_state
FAILED pytest/test_error_handling.py::TestAnalysisErrorHandling::test_client_features_invalid_type
FAILED pytest/test_error_handling.py::TestAnalysisErrorHandling::test_clustering_invalid_parameters
FAILED pytest/test_error_handling.py::TestFileSystemErrorHandling::test_csv_export_invalid_path
FAILED pytest/test_error_handling.py::TestFileSystemErrorHandling::test_csv_export_missing_db
FAILED pytest/test_error_handling.py::TestErrorHandlingEdgeCases::test_nested_error_contexts
FAILED pytest/test_integration.py::TestEndToEndWorkflow::test_complete_analysis_pipeline
FAILED pytest/test_integration.py::TestEndToEndWorkflow::test_database_integration
FAILED pytest/test_integration.py::TestEndToEndWorkflow::test_config_integration
FAILED pytest/test_integration.py::TestDataFlow::test_state_persistence - wla...
FAILED pytest/test_integration.py::TestLargeDataset::test_large_dataset_processing
FAILED pytest/test_integration.py::TestErrorRecovery::test_malformed_event_handling
FAILED pytest/test_integration.py::TestMemoryManagement::test_memory_usage_large_state
FAILED pytest/test_integration.py::TestMemoryManagement::test_state_pruning_memory_release
FAILED pytest/test_performance.py::TestAnalysisPerformance::test_clustering_performance
FAILED pytest/test_performance.py::TestAnalysisPerformance::test_inference_performance
FAILED pytest/test_performance.py::TestMemoryPerformance::test_memory_usage_large_state
FAILED pytest/test_performance.py::TestMemoryPerformance::test_memory_cleanup_after_pruning
FAILED pytest/test_performance.py::TestDatabasePerformance::test_database_write_performance
FAILED pytest/test_performance.py::TestDatabasePerformance::test_database_read_performance
FAILED pytest/test_performance.py::TestScalabilityPerformance::test_scalability_with_dataset_size
FAILED pytest/test_presentation.py::TestCLIModule::test_print_client_cluster_results
FAILED pytest/test_presentation.py::TestCLIModule::test_print_ap_cluster_results
FAILED pytest/test_presentation.py::TestCLIEdgeCases::test_print_client_cluster_results_empty_data
FAILED pytest/test_presentation.py::TestPerformance::test_large_dataset_handling
FAILED pytest/test_storage.py::TestAPState::test_ap_state_update_from_beacon
FAILED pytest/test_storage.py::TestWifiAnalysisState::test_state_pruning - As...
FAILED pytest/test_storage.py::TestWifiAnalysisState::test_state_ssid_mapping
FAILED pytest/test_storage.py::TestDatabaseModule::test_fetch_events - Attrib...
FAILED pytest/test_storage.py::TestDatabaseModule::test_add_label - Assertion...
FAILED pytest/test_utils.py::TestOUIFunctions::test_lookup_vendor_apple_mac
FAILED pytest/test_utils.py::TestOUIFunctions::test_lookup_vendor_unknown_mac
FAILED pytest/test_utils.py::TestIEParsing::test_parse_ies_vendor_specific - ...
FAILED pytest/test_utils.py::TestIEParsing::test_parse_ies_ht_capabilities - ...
FAILED pytest/test_utils.py::TestUtilityFunctions::test_is_local_admin_mac - ...
FAILED pytest/test_utils.py::TestUtilityFunctions::test_is_valid_bssid - Asse...
FAILED pytest/test_utils.py::TestUtilityFunctions::test_ie_fingerprint_hash
FAILED pytest/test_utils.py::TestUtilityFunctions::test_ie_fingerprint_hash_empty
FAILED pytest/test_utils.py::TestConfigFunctions::test_load_config_default - ...
FAILED pytest/test_utils.py::TestConfigFunctions::test_load_config_specific_profile
FAILED pytest/test_utils.py::TestConfigFunctions::test_load_config_missing_file
FAILED pytest/test_utils.py::TestEdgeCases::test_ie_fingerprint_hash_unicode
FAILED pytest/test_utils.py::TestEdgeCases::test_config_loading_with_invalid_yaml
FAILED tests/integration/test_end_to_end.py::TestEndToEndWorkflow::test_complete_wifi_analysis_workflow
FAILED tests/integration/test_end_to_end.py::TestEndToEndWorkflow::test_plugin_integration_workflow
FAILED tests/integration/test_end_to_end.py::TestEndToEndWorkflow::test_data_pipeline_with_file_io
FAILED tests/integration/test_end_to_end.py::TestEndToEndWorkflow::test_error_handling_and_recovery
FAILED tests/integration/test_end_to_end.py::TestEndToEndWorkflow::test_performance_under_load
FAILED tests/integration/test_end_to_end.py::TestEndToEndWorkflow::test_concurrent_processing
FAILED tests/performance/test_benchmarks.py::TestClusteringBenchmarks::test_kmeans_performance
FAILED tests/performance/test_benchmarks.py::TestClusteringBenchmarks::test_dbscan_performance
FAILED tests/performance/test_benchmarks.py::TestClusteringBenchmarks::test_hierarchical_performance
FAILED tests/performance/test_benchmarks.py::TestClusteringBenchmarks::test_clustering_scalability
FAILED tests/performance/test_benchmarks.py::TestDataProcessingBenchmarks::test_data_processing_performance
FAILED tests/performance/test_benchmarks.py::TestDataProcessingBenchmarks::test_feature_extraction_performance
FAILED tests/performance/test_benchmarks.py::TestDataProcessingBenchmarks::test_feature_scaling_performance
FAILED tests/performance/test_benchmarks.py::TestClassificationBenchmarks::test_random_forest_performance
FAILED tests/performance/test_benchmarks.py::TestClassificationBenchmarks::test_svm_performance
FAILED tests/performance/test_benchmarks.py::TestMemoryBenchmarks::test_memory_usage_clustering
FAILED tests/performance/test_benchmarks.py::TestMemoryBenchmarks::test_memory_usage_large_dataset
FAILED tests/performance/test_benchmarks.py::TestConcurrentBenchmarks::test_parallel_processing_performance
FAILED tests/performance/test_benchmarks.py::TestIOBenchmarks::test_file_io_performance
FAILED tests/performance/test_benchmarks.py::TestIOBenchmarks::test_csv_io_performance
FAILED tests/performance/test_memory_profiling.py::TestMemoryUsage::test_memory_usage_clustering
FAILED tests/performance/test_memory_profiling.py::TestMemoryProfiling::test_detailed_memory_profiling
FAILED tests/performance/test_memory_profiling.py::TestMemoryProfiling::test_memory_profiling_garbage_collection
FAILED tests/performance/test_memory_profiling.py::TestMemoryOptimization::test_memory_usage_data_types
FAILED tests/unit/test_data_processing.py::TestDataValidator::test_validate_valid_data
FAILED tests/unit/test_ml_models.py::TestClusteringModel::test_fit_kmeans - T...
FAILED tests/unit/test_ml_models.py::TestClusteringModel::test_predict_after_fit
FAILED tests/unit/test_ml_models.py::TestClusteringModel::test_get_cluster_centers
FAILED tests/unit/test_ml_models.py::TestClusteringModel::test_evaluate_clustering
FAILED tests/unit/test_ml_models.py::TestClusteringModel::test_invalid_algorithm
FAILED tests/unit/test_ml_models.py::TestClusteringModel::test_hyperparameter_validation
FAILED tests/unit/test_ml_models.py::TestClassificationModel::test_cross_validation
FAILED tests/unit/test_ml_models.py::TestEnsembleModel::test_fit_voting_classifier
FAILED tests/unit/test_ml_models.py::TestEnsembleModel::test_fit_bagging - Ty...
FAILED tests/unit/test_ml_models.py::TestEnsembleModel::test_fit_boosting - T...
FAILED tests/unit/test_ml_models.py::TestEnsembleModel::test_predict_ensemble
FAILED tests/unit/test_ml_models.py::TestEnsembleModel::test_evaluate_ensemble
FAILED tests/unit/test_ml_models.py::TestEnsembleModel::test_individual_estimator_performance
FAILED tests/unit/test_ml_models.py::TestEnsembleModel::test_invalid_algorithm
FAILED tests/unit/test_ml_models.py::TestEnsembleModel::test_empty_estimators
FAILED tests/unit/test_ml_models.py::TestModelPersistence::test_save_load_model
FAILED tests/unit/test_ml_models.py::TestModelPersistence::test_save_load_ensemble
=========== 150 failed, 210 passed, 6 warnings in 139.26s (0:02:19) ============
