============================= test session starts ==============================
platform linux -- Python 3.11.9, pytest-8.2.0, pluggy-1.6.0
benchmark: 5.1.0 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)
rootdir: /home/pi/Ai_agent/hacking
configfile: pytest.ini
plugins: sugar-1.1.1, xdist-3.8.0, cov-7.0.0, hypothesis-6.142.3, mock-3.12.0, html-4.1.1, benchmark-5.1.0, Faker-37.11.0, testmon-2.1.3, metadata-3.1.1, json-report-1.5.0
collected 367 items

plugins/clustering_advanced/tests/test_clustering_advanced.py .......... [  2%]
.....                                                                    [  4%]
plugins/ensemble_models/tests/test_ensemble_models.py ..........         [  6%]
plugins/example_plugin/tests/test_example_plugin.py ..                   [  7%]
plugins/reinforcement_learning/tests/test_reinforcement_learning.py .... [  8%]
.F............                                                           [ 12%]
plugins/sankey/tests/test_sankey.py ......                               [ 13%]
plugins/umap_plot/tests/test_umap_plot.py ........                       [ 16%]
pytest/test_analysis.py ..........................                       [ 23%]
pytest/test_app.py ...........                                           [ 26%]
pytest/test_capture.py ..F..F....F......F.F.                             [ 31%]
pytest/test_controllers.py .FF..F....FFFFFFFFF...F.F                     [ 38%]
pytest/test_error_handling.py ......................F..FFFFFFF..F...     [ 49%]
pytest/test_integration.py .FF.FF..F..FF                                 [ 52%]
pytest/test_performance.py ....FFFFFF.F                                  [ 55%]
pytest/test_presentation.py F............F....F.                         [ 61%]
pytest/test_storage.py .........F.....F..FF...                           [ 67%]
pytest/test_utils.py F.F..........FFFF.FFF.....F.F                       [ 75%]
tests/integration/test_end_to_end.py FFFFFF                              [ 77%]
tests/performance/test_benchmarks.py FFFFFFFFFFFFFF                      [ 80%]
tests/performance/test_memory_profiling.py ..F...F.F..F                  [ 84%]
tests/unit/test_data_processing.py ................F.....                [ 90%]
tests/unit/test_ml_models.py .F..FFFFF.......F.FFFFFFFFFFF               [ 98%]
tests/unit/test_utils_failed.py EEEEEEE                                  [100%]

==================================== ERRORS ====================================
________________ ERROR at setup of test_lookup_vendor_apple_mac ________________
file /home/pi/Ai_agent/hacking/tests/unit/test_utils_failed.py, line 3
  def test_lookup_vendor_apple_mac(self):
E       fixture 'self' not found
>       available fixtures: _session_faker, benchmark, benchmark_weave, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, class_mocker, clustering_analyzer, cov, device_classifier, doctest_namespace, ensemble_model, extra, extras, faker, include_metadata_in_junit_xml, json_metadata, large_dataset, metadata, mock_logger, mock_pcap_file, mock_rich_console, mock_sklearn_model, mocker, module_mocker, monkeypatch, no_cover, package_mocker, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, sample_features, sample_labels, sample_wifi_data, session_mocker, temp_dir, testrun_uid, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, wifi_data_strategy, worker_id
>       use 'pytest --fixtures [testpath]' for help on them.

/home/pi/Ai_agent/hacking/tests/unit/test_utils_failed.py:3
_____________ ERROR at setup of test_lookup_vendor_randomized_mac ______________
file /home/pi/Ai_agent/hacking/tests/unit/test_utils_failed.py, line 12
  def test_lookup_vendor_randomized_mac(self):
E       fixture 'self' not found
>       available fixtures: _session_faker, benchmark, benchmark_weave, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, class_mocker, clustering_analyzer, cov, device_classifier, doctest_namespace, ensemble_model, extra, extras, faker, include_metadata_in_junit_xml, json_metadata, large_dataset, metadata, mock_logger, mock_pcap_file, mock_rich_console, mock_sklearn_model, mocker, module_mocker, monkeypatch, no_cover, package_mocker, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, sample_features, sample_labels, sample_wifi_data, session_mocker, temp_dir, testrun_uid, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, wifi_data_strategy, worker_id
>       use 'pytest --fixtures [testpath]' for help on them.

/home/pi/Ai_agent/hacking/tests/unit/test_utils_failed.py:12
_______________ ERROR at setup of test_lookup_vendor_unknown_mac _______________
file /home/pi/Ai_agent/hacking/tests/unit/test_utils_failed.py, line 21
  def test_lookup_vendor_unknown_mac(self):
E       fixture 'self' not found
>       available fixtures: _session_faker, benchmark, benchmark_weave, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, class_mocker, clustering_analyzer, cov, device_classifier, doctest_namespace, ensemble_model, extra, extras, faker, include_metadata_in_junit_xml, json_metadata, large_dataset, metadata, mock_logger, mock_pcap_file, mock_rich_console, mock_sklearn_model, mocker, module_mocker, monkeypatch, no_cover, package_mocker, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, sample_features, sample_labels, sample_wifi_data, session_mocker, temp_dir, testrun_uid, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, wifi_data_strategy, worker_id
>       use 'pytest --fixtures [testpath]' for help on them.

/home/pi/Ai_agent/hacking/tests/unit/test_utils_failed.py:21
_______________ ERROR at setup of test_intelligent_vendor_lookup _______________
file /home/pi/Ai_agent/hacking/tests/unit/test_utils_failed.py, line 30
  def test_intelligent_vendor_lookup(self, mock_client_state):
E       fixture 'self' not found
>       available fixtures: _session_faker, benchmark, benchmark_weave, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, class_mocker, clustering_analyzer, cov, device_classifier, doctest_namespace, ensemble_model, extra, extras, faker, include_metadata_in_junit_xml, json_metadata, large_dataset, metadata, mock_logger, mock_pcap_file, mock_rich_console, mock_sklearn_model, mocker, module_mocker, monkeypatch, no_cover, package_mocker, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, sample_features, sample_labels, sample_wifi_data, session_mocker, temp_dir, testrun_uid, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, wifi_data_strategy, worker_id
>       use 'pytest --fixtures [testpath]' for help on them.

/home/pi/Ai_agent/hacking/tests/unit/test_utils_failed.py:30
___________ ERROR at setup of test_intelligent_vendor_lookup_no_ies ____________
file /home/pi/Ai_agent/hacking/tests/unit/test_utils_failed.py, line 40
  def test_intelligent_vendor_lookup_no_ies(self, mock_client_state):
E       fixture 'self' not found
>       available fixtures: _session_faker, benchmark, benchmark_weave, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, class_mocker, clustering_analyzer, cov, device_classifier, doctest_namespace, ensemble_model, extra, extras, faker, include_metadata_in_junit_xml, json_metadata, large_dataset, metadata, mock_logger, mock_pcap_file, mock_rich_console, mock_sklearn_model, mocker, module_mocker, monkeypatch, no_cover, package_mocker, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, sample_features, sample_labels, sample_wifi_data, session_mocker, temp_dir, testrun_uid, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, wifi_data_strategy, worker_id
>       use 'pytest --fixtures [testpath]' for help on them.

/home/pi/Ai_agent/hacking/tests/unit/test_utils_failed.py:40
_______________ ERROR at setup of test_download_oui_file_success _______________
file /home/pi/Ai_agent/hacking/tests/unit/test_utils_failed.py, line 50
  def test_download_oui_file_success(self, mock_oui_path):
E       fixture 'self' not found
>       available fixtures: _session_faker, benchmark, benchmark_weave, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, class_mocker, clustering_analyzer, cov, device_classifier, doctest_namespace, ensemble_model, extra, extras, faker, include_metadata_in_junit_xml, json_metadata, large_dataset, metadata, mock_logger, mock_pcap_file, mock_rich_console, mock_sklearn_model, mocker, module_mocker, monkeypatch, no_cover, package_mocker, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, sample_features, sample_labels, sample_wifi_data, session_mocker, temp_dir, testrun_uid, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, wifi_data_strategy, worker_id
>       use 'pytest --fixtures [testpath]' for help on them.

/home/pi/Ai_agent/hacking/tests/unit/test_utils_failed.py:50
_______________ ERROR at setup of test_download_oui_file_failure _______________
file /home/pi/Ai_agent/hacking/tests/unit/test_utils_failed.py, line 71
  def test_download_oui_file_failure(self, mock_oui_path):
E       fixture 'self' not found
>       available fixtures: _session_faker, benchmark, benchmark_weave, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, class_mocker, clustering_analyzer, cov, device_classifier, doctest_namespace, ensemble_model, extra, extras, faker, include_metadata_in_junit_xml, json_metadata, large_dataset, metadata, mock_logger, mock_pcap_file, mock_rich_console, mock_sklearn_model, mocker, module_mocker, monkeypatch, no_cover, package_mocker, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, sample_features, sample_labels, sample_wifi_data, session_mocker, temp_dir, testrun_uid, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, wifi_data_strategy, worker_id
>       use 'pytest --fixtures [testpath]' for help on them.

/home/pi/Ai_agent/hacking/tests/unit/test_utils_failed.py:71
=================================== FAILURES ===================================
_________ TestReinforcementLearningPlugin.test_environment_observation _________

self = <plugins.reinforcement_learning.tests.test_reinforcement_learning.TestReinforcementLearningPlugin object at 0x7f868a2010>
plugin = <plugins.reinforcement_learning.plugin.Plugin object at 0x7f5d3f4950>
mock_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f5d3f6d90>
mock_events = [{'client': 'aa:bb:cc:dd:ee:00', 'ts': 1000.0, 'type': 'probe_req'}, {'client': 'aa:bb:cc:dd:ee:01', 'ts': 1001.0, 'type': 'probe_req'}]

    def test_environment_observation(self, plugin, mock_state, mock_events):
        """Test Environment Observation."""
        env = plugin._WiFiScanningEnvironment(mock_state, mock_events)
        obs = env._get_observation()
    
        assert len(obs) == 10
        assert all(0 <= val <= 1 for val in obs)  # Normalisierte Werte
>       assert obs[0] == 1.0 / 48.0  # current_channel normalisiert
E       assert 0.020833334 == (1.0 / 48.0)

plugins/reinforcement_learning/tests/test_reinforcement_learning.py:141: AssertionError
______________ TestPacketParsing.test_packet_to_event_data_frame _______________

self = <test_capture.TestPacketParsing object at 0x7f650d6bd0>

    def test_packet_to_event_data_frame(self):
        """Test Data-Frame zu Event-Konvertierung."""
        rt_layer = RadioTap(
            present="Flags+Channel+dBm_AntSignal",
            Flags=0,
            ChannelFrequency=2412,
            dBm_AntSignal=-55
        )
        dot11_layer = Dot11(
            type=2, subtype=0,
            addr1='aa:bb:cc:dd:ee:ff',  # BSSID
            addr2='11:22:33:44:55:66'   # Client
        )
    
        pkt = rt_layer / dot11_layer
        pkt.time = time.time()
    
        event = capture.packet_to_event(pkt)
    
        assert event is not None
        assert event['type'] == 'data'
        assert event['client'] == '11:22:33:44:55:66'
        assert event['bssid'] == 'aa:bb:cc:dd:ee:ff'
        assert event['rssi'] == -55
>       assert event['mcs_index'] == 7
E       KeyError: 'mcs_index'

pytest/test_capture.py:89: KeyError
_______________ TestPacketParsing.test_packet_to_event_with_dhcp _______________

self = <test_capture.TestPacketParsing object at 0x7f650d7e10>

    def test_packet_to_event_with_dhcp(self):
        """Test Paket mit DHCP-Informationen."""
        from scapy.layers.dhcp import DHCP, BOOTP
    
        rt_layer = RadioTap(
            present="Flags+Channel+dBm_AntSignal",
            Flags=0,
            ChannelFrequency=2412,
            dBm_AntSignal=-50
        )
        dot11_layer = Dot11(
            type=2, subtype=0,
            addr1='aa:bb:cc:dd:ee:ff',
            addr2='11:22:33:44:55:66'
        )
        bootp_layer = BOOTP(chaddr=b'\x11\x22\x33\x44\x55\x66')
        dhcp_layer = DHCP(options=[(53, 3), (12, b'TestHostname')])  # DHCP Request mit Hostname
    
        pkt = rt_layer / dot11_layer / bootp_layer / dhcp_layer
        pkt.time = time.time()
    
        event = capture.packet_to_event(pkt)
    
        assert event is not None
        assert event['type'] == 'data'
>       assert event['hostname'] == 'TestHostname'
E       KeyError: 'hostname'

pytest/test_capture.py:154: KeyError
____________ TestChannelHopper.test_channel_hopper_command_failure _____________

self = <test_capture.TestChannelHopper object at 0x7f650e08d0>
mock_run = <MagicMock name='run' id='547014180432'>

    @patch('subprocess.run')
    def test_channel_hopper_command_failure(self, mock_run):
        """Test ChannelHopper bei Kommando-Fehlern."""
>       mock_run.side_effect = subprocess.CalledProcessError(1, "iw")
E       NameError: name 'subprocess' is not defined

pytest/test_capture.py:234: NameError
______________________ TestIEExtraction.test_extract_seq _______________________

self = <test_capture.TestIEExtraction object at 0x7f650e39d0>

    def test_extract_seq(self):
        """Test Sequenznummer-Extraktion."""
        dot11 = Dot11(SC=0x1234)  # SC = 0x1234, >> 4 = 0x123
    
        seq = capture._extract_seq(dot11)
        assert seq == 0x123
    
        # Test mit None
        seq = capture._extract_seq(None)
>       assert seq is None
E       assert 0 is None

pytest/test_capture.py:381: AssertionError
____________ TestErrorHandling.test_packet_to_event_encoding_error _____________

self = <test_capture.TestErrorHandling object at 0x7f650e4850>

    def test_packet_to_event_encoding_error(self):
        """Test mit Encoding-Fehlern."""
        rt_layer = RadioTap()
        dot11_layer = Dot11(type=0, subtype=8, addr3='aa:bb:cc:dd:ee:ff')
        beacon_layer = Dot11Beacon()
        # Erstelle IE mit ungültigem UTF-8
        ssid_ie = Dot11Elt(ID=0, info=b'\xff\xfe\xfd')
    
        pkt = rt_layer / dot11_layer / beacon_layer / ssid_ie
        pkt.time = time.time()
    
        # Sollte nicht crashen - packet_to_event fängt Encoding-Fehler ab
        event = capture.packet_to_event(pkt)
        if event is not None:
>           assert event['ssid'] == "<binary>"  # Sollte als binary markiert werden
E           AssertionError: assert '<hidden>' == '<binary>'
E             
E             - <binary>
E             + <hidden>

pytest/test_capture.py:414: AssertionError
____________ TestCaptureController.test_select_interface_automatic _____________

self = <test_controllers.TestCaptureController object at 0x7f650f4610>
mock_find_interfaces = <MagicMock name='find_wlan_interfaces' id='546960501456'>
mock_console = <MagicMock id='546960360784'>

    @patch('wlan_tool.pre_run_checks.find_wlan_interfaces')
    def test_select_interface_automatic(self, mock_find_interfaces, mock_console):
        """Test automatische Interface-Auswahl."""
        mock_find_interfaces.return_value = ["wlan0", "wlan1"]
    
        args = MagicMock()
        args.iface = None
        config_data = {}
    
        controller = CaptureController(args, config_data, mock_console)
    
        with patch('rich.prompt.Prompt.ask', return_value="wlan0"):
>           iface = controller._select_interface()

pytest/test_controllers.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.controllers.CaptureController object at 0x7f5b6c9bd0>

    def _select_interface(self) -> Optional[str]:
        """Wählt das zu verwendende physische WLAN-Interface aus."""
        iface = self.args.iface
        if not iface:
            self.console.print(
                "[bold cyan]Kein Interface angegeben. Suche nach geeigneten WLAN-Interfaces...[/bold cyan]"
            )
>           suitable_ifaces = pre_run_checks.find_wlan_interfaces()
E           NameError: name 'pre_run_checks' is not defined

wlan_tool/controllers.py:124: NameError
__________ TestCaptureController.test_select_interface_no_interfaces ___________

self = <test_controllers.TestCaptureController object at 0x7f650f49d0>
mock_find_interfaces = <MagicMock name='find_wlan_interfaces' id='546960372944'>
mock_console = <MagicMock id='546994690384'>

    @patch('wlan_tool.pre_run_checks.find_wlan_interfaces')
    def test_select_interface_no_interfaces(self, mock_find_interfaces, mock_console):
        """Test Interface-Auswahl ohne verfügbare Interfaces."""
        mock_find_interfaces.return_value = []
    
        args = MagicMock()
        args.iface = None
        config_data = {}
    
        controller = CaptureController(args, config_data, mock_console)
    
>       iface = controller._select_interface()

pytest/test_controllers.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.controllers.CaptureController object at 0x7f5c8d1fd0>

    def _select_interface(self) -> Optional[str]:
        """Wählt das zu verwendende physische WLAN-Interface aus."""
        iface = self.args.iface
        if not iface:
            self.console.print(
                "[bold cyan]Kein Interface angegeben. Suche nach geeigneten WLAN-Interfaces...[/bold cyan]"
            )
>           suitable_ifaces = pre_run_checks.find_wlan_interfaces()
E           NameError: name 'pre_run_checks' is not defined

wlan_tool/controllers.py:124: NameError
____________ TestCaptureController.test_setup_monitor_mode_failure _____________

self = <wlan_tool.controllers.CaptureController object at 0x7f5b613f90>
physical_iface = 'wlan0'

    def _setup_monitor_mode(self, physical_iface: str) -> Optional[str]:
        """
        Erstellt ein dediziertes Monitor-Interface (mon0) aus einem physischen Interface (z.B. wlan0)
        und beendet störende Prozesse. Dies ist die empfohlene Methode für Nexmon.
        """
        monitor_iface = "mon0"
        logger.info(
            f"Erstelle dediziertes Monitor-Interface '{monitor_iface}' aus '{physical_iface}'..."
        )
    
        try:
            # --- Schritt 1: Störende Prozesse beenden, um den Chip freizugeben ---
            kill_commands = [
                "sudo systemctl stop wpa_supplicant",
                "sudo airmon-ng check kill",
            ]
            self.console.print(
                "[yellow]Beende potenziell störende Netzwerkdienste...[/yellow]"
            )
            for cmd in kill_commands:
>               subprocess.run(cmd, shell=True, capture_output=True, text=True)

wlan_tool/controllers.py:161: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1124: in __call__
    return self._mock_call(*args, **kwargs)
../../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1128: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock name='run' id='546993935952'>
args = ('sudo systemctl stop wpa_supplicant',)
kwargs = {'capture_output': True, 'shell': True, 'text': True}
effect = CalledProcessError(1, 'airmon-ng')

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
>               raise effect
E               subprocess.CalledProcessError: Command 'airmon-ng' returned non-zero exit status 1.

../../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1183: CalledProcessError

During handling of the above exception, another exception occurred:

self = <test_controllers.TestCaptureController object at 0x7f650f57d0>
mock_run = <MagicMock name='run' id='546993935952'>
mock_console = <MagicMock id='547014299408'>

    @patch('subprocess.run')
    def test_setup_monitor_mode_failure(self, mock_run, mock_console):
        """Test Monitor-Mode-Setup (Fehler)."""
        mock_run.side_effect = subprocess.CalledProcessError(1, "airmon-ng")
    
        args = MagicMock()
        config_data = {}
    
        controller = CaptureController(args, config_data, mock_console)
    
>       monitor_iface = controller._setup_monitor_mode("wlan0")

pytest/test_controllers.py:103: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.controllers.CaptureController object at 0x7f5b613f90>
physical_iface = 'wlan0'

    def _setup_monitor_mode(self, physical_iface: str) -> Optional[str]:
        """
        Erstellt ein dediziertes Monitor-Interface (mon0) aus einem physischen Interface (z.B. wlan0)
        und beendet störende Prozesse. Dies ist die empfohlene Methode für Nexmon.
        """
        monitor_iface = "mon0"
        logger.info(
            f"Erstelle dediziertes Monitor-Interface '{monitor_iface}' aus '{physical_iface}'..."
        )
    
        try:
            # --- Schritt 1: Störende Prozesse beenden, um den Chip freizugeben ---
            kill_commands = [
                "sudo systemctl stop wpa_supplicant",
                "sudo airmon-ng check kill",
            ]
            self.console.print(
                "[yellow]Beende potenziell störende Netzwerkdienste...[/yellow]"
            )
            for cmd in kill_commands:
                subprocess.run(cmd, shell=True, capture_output=True, text=True)
    
            # --- Schritt 2: Physisches Interface deaktivieren ---
            # Dies ist der entscheidende Schritt, um den "Operation not supported"-Fehler zu vermeiden.
            self.console.print(
                f"[cyan]Deaktiviere physisches Interface '{physical_iface}'...[/cyan]"
            )
            subprocess.run(
                f"sudo ip link set {physical_iface} down",
                shell=True,
                check=True,
                capture_output=True,
                text=True,
            )
    
            # --- Schritt 3: Phy-Namen ermitteln ---
            # Dies sollte jetzt auf dem 'down'-Interface funktionieren.
            phy_find_cmd = (
                f"iw dev {physical_iface} info | gawk '/wiphy/ {{printf \"phy\" $2}}'"
            )
            result = subprocess.run(
                phy_find_cmd, shell=True, check=True, capture_output=True, text=True
            )
            phy_name = result.stdout.strip()
            if not phy_name:
                logger.error(
                    f"Konnte den 'phy'-Namen für das Interface '{physical_iface}' nicht ermitteln."
                )
                return None
            logger.info(f"Physisches Gerät gefunden: {phy_name}")
    
            # --- Schritt 4: Monitor-Interface erstellen und aktivieren ---
            self.console.print(
                f"[cyan]Konfiguriere Interface '{monitor_iface}'...[/cyan]"
            )
            setup_commands = [
                f"sudo iw dev {monitor_iface} del",  # Fehler wird ignoriert
                f"sudo iw phy {phy_name} interface add {monitor_iface} type monitor",
                f"sudo ip link set {monitor_iface} up",
            ]
            for cmd in setup_commands:
                subprocess.run(cmd, shell=True, capture_output=True, text=True)
    
            logger.info(
                f"Monitor-Interface '{monitor_iface}' erfolgreich erstellt und aktiviert."
            )
            return monitor_iface
    
        except subprocess.CalledProcessError as e:
            logger.error(
                f"Ein Befehl zur Erstellung des Monitor-Interfaces ist fehlgeschlagen."
            )
            logger.error(f"Befehl: '{e.cmd}'")
>           logger.error(f"Fehlermeldung: {e.stderr.strip()}")
E           AttributeError: 'NoneType' object has no attribute 'strip'

wlan_tool/controllers.py:214: AttributeError
------------------------------ Captured log call -------------------------------
ERROR    wlan_tool.controllers:controllers.py:210 Ein Befehl zur Erstellung des Monitor-Interfaces ist fehlgeschlagen.
ERROR    wlan_tool.controllers:controllers.py:213 Befehl: 'airmon-ng'
__________________ TestAnalysisController.test_run_inference ___________________

self = <MagicMock name='score_pairs_with_recency_and_matching' id='547021645968'>

    def assert_called_once(self):
        """assert that the mock was called only once.
        """
        if not self.call_count == 1:
            msg = ("Expected '%s' to have been called once. Called %s times.%s"
                   % (self._mock_name or 'mock',
                      self.call_count,
                      self._calls_repr()))
>           raise AssertionError(msg)
E           AssertionError: Expected 'score_pairs_with_recency_and_matching' to have been called once. Called 0 times.

../../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:918: AssertionError

During handling of the above exception, another exception occurred:

self = <test_controllers.TestAnalysisController object at 0x7f650f7810>
mock_score = <MagicMock name='score_pairs_with_recency_and_matching' id='547021645968'>
mock_console = <MagicMock id='547013987280'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f5d07eb50>

    @patch('wlan_tool.analysis.logic.score_pairs_with_recency_and_matching')
    def test_run_inference(self, mock_score, mock_console, populated_state):
        """Test Inferenz-Ausführung."""
        mock_score.return_value = []
    
        args = MagicMock()
        args.infer = True
        args.model = None
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
        controller.run_inference()
    
>       mock_score.assert_called_once()
E       AssertionError: Expected 'score_pairs_with_recency_and_matching' to have been called once. Called 0 times.

pytest/test_controllers.py:234: AssertionError
______________ TestAnalysisController.test_run_client_clustering _______________

self = <MagicMock name='cluster_clients' id='547039420048'>

    def assert_called_once(self):
        """assert that the mock was called only once.
        """
        if not self.call_count == 1:
            msg = ("Expected '%s' to have been called once. Called %s times.%s"
                   % (self._mock_name or 'mock',
                      self.call_count,
                      self._calls_repr()))
>           raise AssertionError(msg)
E           AssertionError: Expected 'cluster_clients' to have been called once. Called 0 times.

../../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:918: AssertionError

During handling of the above exception, another exception occurred:

self = <test_controllers.TestAnalysisController object at 0x7f650f7dd0>
mock_cluster = <MagicMock name='cluster_clients' id='547039420048'>
mock_console = <MagicMock id='547738810192'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f5e24d710>

    @patch('wlan_tool.analysis.logic.cluster_clients')
    def test_run_client_clustering(self, mock_cluster, mock_console, populated_state):
        """Test Client-Clustering."""
        mock_cluster.return_value = (None, None)
    
        args = MagicMock()
        args.cluster_clients = 2
        args.cluster_algo = "kmeans"
        args.no_mac_correlation = False
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
        controller.run_client_clustering()
    
>       mock_cluster.assert_called_once()
E       AssertionError: Expected 'cluster_clients' to have been called once. Called 0 times.

pytest/test_controllers.py:253: AssertionError
________________ TestAnalysisController.test_run_ap_clustering _________________

self = <MagicMock name='cluster_aps' id='547018046672'>

    def assert_called_once(self):
        """assert that the mock was called only once.
        """
        if not self.call_count == 1:
            msg = ("Expected '%s' to have been called once. Called %s times.%s"
                   % (self._mock_name or 'mock',
                      self.call_count,
                      self._calls_repr()))
>           raise AssertionError(msg)
E           AssertionError: Expected 'cluster_aps' to have been called once. Called 0 times.

../../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:918: AssertionError

During handling of the above exception, another exception occurred:

self = <test_controllers.TestAnalysisController object at 0x7f65100410>
mock_cluster = <MagicMock name='cluster_aps' id='547018046672'>
mock_console = <MagicMock id='547019909776'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f5cd0e210>

    @patch('wlan_tool.analysis.logic.cluster_aps')
    def test_run_ap_clustering(self, mock_cluster, mock_console, populated_state):
        """Test AP-Clustering."""
        mock_cluster.return_value = None
    
        args = MagicMock()
        args.cluster_aps = 2
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
        controller.run_ap_clustering()
    
>       mock_cluster.assert_called_once()
E       AssertionError: Expected 'cluster_aps' to have been called once. Called 0 times.

pytest/test_controllers.py:270: AssertionError
_________________ TestAnalysisController.test_run_graph_export _________________

self = <test_controllers.TestAnalysisController object at 0x7f651009d0>
mock_export = <MagicMock name='export_ap_graph' id='547018969104'>
mock_console = <MagicMock id='547018944592'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f5cdf08d0>

    @patch('wlan_tool.analysis.logic.export_ap_graph')
    def test_run_graph_export(self, mock_export, mock_console, populated_state):
        """Test Graph-Export."""
        mock_export.return_value = True
    
        args = MagicMock()
        args.export_graph = "/tmp/test.gexf"
        args.cluster_aps = 2
        args.graph_include_clients = False
        args.graph_min_activity = 0
        args.graph_min_duration = 0
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
        with patch.object(controller, 'run_ap_clustering', return_value=None):
>           controller.run_graph_export()
E           AttributeError: 'AnalysisController' object has no attribute 'run_graph_export'

pytest/test_controllers.py:290: AttributeError
_________________ TestAnalysisController.test_run_labeling_ui __________________

self = <MagicMock name='interactive_label_ui' id='547024856080'>

    def assert_called_once(self):
        """assert that the mock was called only once.
        """
        if not self.call_count == 1:
            msg = ("Expected '%s' to have been called once. Called %s times.%s"
                   % (self._mock_name or 'mock',
                      self.call_count,
                      self._calls_repr()))
>           raise AssertionError(msg)
E           AssertionError: Expected 'interactive_label_ui' to have been called once. Called 0 times.

../../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:918: AssertionError

During handling of the above exception, another exception occurred:

self = <test_controllers.TestAnalysisController object at 0x7f65100f90>
mock_label_ui = <MagicMock name='interactive_label_ui' id='547024856080'>
mock_console = <MagicMock id='547022833360'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f5d38d190>

    @patch('wlan_tool.presentation.cli.interactive_label_ui')
    def test_run_labeling_ui(self, mock_label_ui, mock_console, populated_state):
        """Test Labeling-UI."""
        args = MagicMock()
        args.label_ui = True
        args.db = "test.db"
        args.label_db = "labels.db"
        args.model = "model.pkl"
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
        controller.run_labeling_ui()
    
>       mock_label_ui.assert_called_once()
E       AssertionError: Expected 'interactive_label_ui' to have been called once. Called 0 times.

pytest/test_controllers.py:310: AssertionError
______________ TestAnalysisController.test_run_client_labeling_ui ______________

self = <MagicMock name='interactive_client_label_ui' id='547021393296'>

    def assert_called_once(self):
        """assert that the mock was called only once.
        """
        if not self.call_count == 1:
            msg = ("Expected '%s' to have been called once. Called %s times.%s"
                   % (self._mock_name or 'mock',
                      self.call_count,
                      self._calls_repr()))
>           raise AssertionError(msg)
E           AssertionError: Expected 'interactive_client_label_ui' to have been called once. Called 0 times.

../../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:918: AssertionError

During handling of the above exception, another exception occurred:

self = <test_controllers.TestAnalysisController object at 0x7f651015d0>
mock_client_label_ui = <MagicMock name='interactive_client_label_ui' id='547021393296'>
mock_console = <MagicMock id='547016457616'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f5d041bd0>

    @patch('wlan_tool.presentation.cli.interactive_client_label_ui')
    def test_run_client_labeling_ui(self, mock_client_label_ui, mock_console, populated_state):
        """Test Client-Labeling-UI."""
        args = MagicMock()
        args.label_clients = True
        args.label_db = "labels.db"
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
        controller.run_client_labeling_ui()
    
>       mock_client_label_ui.assert_called_once()
E       AssertionError: Expected 'interactive_client_label_ui' to have been called once. Called 0 times.

pytest/test_controllers.py:326: AssertionError
_______________ TestAnalysisController.test_run_mac_correlation ________________

self = <MagicMock name='correlate_devices_by_fingerprint' id='547738704080'>

    def assert_called_once(self):
        """assert that the mock was called only once.
        """
        if not self.call_count == 1:
            msg = ("Expected '%s' to have been called once. Called %s times.%s"
                   % (self._mock_name or 'mock',
                      self.call_count,
                      self._calls_repr()))
>           raise AssertionError(msg)
E           AssertionError: Expected 'correlate_devices_by_fingerprint' to have been called once. Called 0 times.

../../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:918: AssertionError

During handling of the above exception, another exception occurred:

self = <test_controllers.TestAnalysisController object at 0x7f65101c90>
mock_correlate = <MagicMock name='correlate_devices_by_fingerprint' id='547738704080'>
mock_console = <MagicMock id='547018247696'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f87c562d0>

    @patch('wlan_tool.analysis.device_profiler.correlate_devices_by_fingerprint')
    def test_run_mac_correlation(self, mock_correlate, mock_console, populated_state):
        """Test MAC-Korrelation."""
        mock_correlate.return_value = {}
    
        args = MagicMock()
        args.correlate_macs = True
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
        controller.run_mac_correlation()
    
>       mock_correlate.assert_called_once()
E       AssertionError: Expected 'correlate_devices_by_fingerprint' to have been called once. Called 0 times.

pytest/test_controllers.py:343: AssertionError
_____________ TestAnalysisController.test_run_analysis_no_actions ______________

self = <test_controllers.TestAnalysisController object at 0x7f651023d0>
mock_console = <MagicMock id='547013175824'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f5ca11c90>

    def test_run_analysis_no_actions(self, mock_console, populated_state):
        """Test Analyse ohne Aktionen."""
        args = MagicMock()
        args.infer = False
        args.cluster_clients = None
        args.cluster_aps = None
        args.export_graph = None
        args.label_ui = False
        args.label_clients = False
        args.correlate_macs = False
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
        # Sollte nicht crashen
>       controller.run_analysis()

pytest/test_controllers.py:362: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/controllers.py:386: in run_analysis
    self._run_profiling()  # Benötigt state, den es jetzt als self.state hat
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.controllers.AnalysisController object at 0x7f5ca13b50>

    def _run_profiling(self):
        self.console.print(
            "\n[bold cyan]Starte automatisches Geräte-Profiling...[/bold cyan]"
        )
        device_map = {}
    
        # --- NEU: Versuch 1: TR-064 (FRITZ!Box) ---
        self.console.print(
            "[cyan]Versuch 1: Identifizierung über FRITZ!Box TR-064...[/cyan]"
        )
        # Passwort aus Argumenten oder interaktiv abfragen
        fritz_password = self.args.fritzbox_password
        if FritzHosts and not fritz_password:
            if (
                self.console.input(
                    "Haben Sie ein Passwort für Ihre FRITZ!Box gesetzt? (y/n): "
                ).lower()
                == "y"
            ):
                fritz_password = self.console.input(
                    "Bitte FRITZ!Box-Passwort eingeben: ", password=True
                )
    
        device_map = (
>           device_profiler.get_devices_from_fritzbox_tr064(password=fritz_password)
            or {}
        )
E       NameError: name 'device_profiler' is not defined

wlan_tool/controllers.py:534: NameError
__________ TestAnalysisController.test_run_analysis_multiple_actions ___________

self = <test_controllers.TestAnalysisController object at 0x7f65102b10>
mock_console = <MagicMock id='547017391888'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f5cc6dd10>

    def test_run_analysis_multiple_actions(self, mock_console, populated_state):
        """Test Analyse mit mehreren Aktionen."""
        args = MagicMock()
        args.infer = True
        args.cluster_clients = 2
        args.cluster_aps = 2
        args.export_graph = "/tmp/test.gexf"
        args.label_ui = False
        args.label_clients = False
        args.correlate_macs = False
        args.model = None
        args.cluster_algo = "kmeans"
        args.no_mac_correlation = False
        args.graph_include_clients = False
        args.graph_min_activity = 0
        args.graph_min_duration = 0
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
        with patch.object(controller, 'run_inference'):
            with patch.object(controller, 'run_client_clustering'):
                with patch.object(controller, 'run_ap_clustering'):
>                   with patch.object(controller, 'run_graph_export'):

pytest/test_controllers.py:389: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f5d324450>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <wlan_tool.controllers.AnalysisController object at 0x7f5c909c10> does not have the attribute 'run_graph_export'

../../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1419: AttributeError
________ TestControllerEdgeCases.test_analysis_controller_with_plugins _________

self = <MagicMock name='mock.run' id='546994677584'>

    def assert_called_once(self):
        """assert that the mock was called only once.
        """
        if not self.call_count == 1:
            msg = ("Expected '%s' to have been called once. Called %s times.%s"
                   % (self._mock_name or 'mock',
                      self.call_count,
                      self._calls_repr()))
>           raise AssertionError(msg)
E           AssertionError: Expected 'run' to have been called once. Called 0 times.

../../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:918: AssertionError

During handling of the above exception, another exception occurred:

self = <test_controllers.TestControllerEdgeCases object at 0x7f65101a10>
mock_console = <MagicMock id='547018970064'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f5cd8fc10>

    def test_analysis_controller_with_plugins(self, mock_console, populated_state):
        """Test AnalysisController mit Plugins."""
        args = MagicMock()
        args.run_plugins = ["test_plugin"]
        config_data = {}
    
        mock_plugin = MagicMock()
        mock_plugin.run.return_value = None
        plugins = {"test_plugin": mock_plugin}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
        controller.run_plugins()
    
>       mock_plugin.run.assert_called_once()
E       AssertionError: Expected 'run' to have been called once. Called 0 times.

pytest/test_controllers.py:451: AssertionError
____________ TestControllerIntegration.test_full_analysis_workflow _____________

self = <test_controllers.TestControllerIntegration object at 0x7f65103c10>
mock_console = <MagicMock id='547021873616'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f5cb31610>

    def test_full_analysis_workflow(self, mock_console, populated_state):
        """Test vollständiger Analyse-Workflow."""
        args = MagicMock()
        args.infer = True
        args.cluster_clients = 2
        args.cluster_aps = 2
        args.export_graph = "/tmp/test.gexf"
        args.label_ui = False
        args.label_clients = False
        args.correlate_macs = False
        args.model = None
        args.cluster_algo = "kmeans"
        args.no_mac_correlation = False
        args.graph_include_clients = False
        args.graph_min_activity = 0
        args.graph_min_duration = 0
        config_data = {}
        plugins = {}
        new_events = []
    
        controller = AnalysisController(args, config_data, mock_console, plugins, populated_state, new_events)
    
        with patch.object(controller, 'run_inference'):
            with patch.object(controller, 'run_client_clustering'):
                with patch.object(controller, 'run_ap_clustering'):
>                   with patch.object(controller, 'run_graph_export'):

pytest/test_controllers.py:512: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f5960ca50>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <wlan_tool.controllers.AnalysisController object at 0x7f5c976250> does not have the attribute 'run_graph_export'

../../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1419: AttributeError
_____________________ TestLoggingSystem.test_setup_logging _____________________

self = <test_error_handling.TestLoggingSystem object at 0x7f64f5ae10>

    def test_setup_logging(self):
        """Test Logging-Setup."""
        logger = setup_logging(
            log_level="DEBUG",
            enable_console=True,
            enable_performance_logging=True,
            enable_error_tracking=True
        )
    
        assert logger is not None
        assert logger.name == "wlan_tool"
>       assert logger.level == logging.DEBUG
E       NameError: name 'logging' is not defined

pytest/test_error_handling.py:317: NameError
___________ TestDatabaseErrorHandling.test_database_connection_error ___________

self = <test_error_handling.TestDatabaseErrorHandling object at 0x7f64f64290>

    def test_database_connection_error(self):
        """Test Datenbankverbindungs-Fehler."""
        with pytest.raises(DatabaseError) as exc_info:
            from wlan_tool.storage.database import db_conn_ctx
            with db_conn_ctx("/invalid/path/database.db"):
                pass
    
        assert "Cannot create database directory" in str(exc_info.value)
>       assert exc_info.value.error_code == "SQLITE_ERROR"
E       AssertionError: assert 'DB_UNEXPECTED_ERROR' == 'SQLITE_ERROR'
E         
E         - SQLITE_ERROR
E         + DB_UNEXPECTED_ERROR

pytest/test_error_handling.py:345: AssertionError
----------------------------- Captured stdout call -----------------------------
2025-11-28 14:45:23,439 | DEBUG    | Starting operation: database_connection
2025-11-28 14:45:23,440 | ERROR    | Error in database_connection: WLANToolError: Cannot create database directory: /invalid/path (Code: DB_DIR_CREATION_FAILED) | Details: {'directory': '/invalid/path', 'original_error': "[Errno 13] Permission denied: '/invalid'"} (Code: DB_DIR_CREATION_FAILED) | Details: {'directory': '/invalid/path', 'original_error': "[Errno 13] Permission denied: '/invalid'"}
2025-11-28 14:45:23,446 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/pathlib.py", line 1116, in mkdir
    os.mkdir(self, mode)
FileNotFoundError: [Errno 2] No such file or directory: '/invalid/path'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/pi/Ai_agent/hacking/wlan_tool/storage/database.py", line 81, in db_conn_ctx
    db_dir.mkdir(parents=True, exist_ok=True)
  File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/pathlib.py", line 1120, in mkdir
    self.parent.mkdir(parents=True, exist_ok=True)
  File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/pathlib.py", line 1116, in mkdir
    os.mkdir(self, mode)
PermissionError: [Errno 13] Permission denied: '/invalid'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/pi/Ai_agent/hacking/wlan_tool/storage/database.py", line 83, in db_conn_ctx
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Cannot create database directory: /invalid/path (Code: DB_DIR_CREATION_FAILED) | Details: {'directory': '/invalid/path', 'original_error': "[Errno 13] Permission denied: '/invalid'"}

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in database_connection: WLANToolError: Cannot create database directory: /invalid/path (Code: DB_DIR_CREATION_FAILED) | Details: {'directory': '/invalid/path', 'original_error': "[Errno 13] Permission denied: '/invalid'"} (Code: DB_DIR_CREATION_FAILED) | Details: {'directory': '/invalid/path', 'original_error': "[Errno 13] Permission denied: '/invalid'"}
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/pathlib.py", line 1116, in mkdir
    os.mkdir(self, mode)
FileNotFoundError: [Errno 2] No such file or directory: '/invalid/path'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/pi/Ai_agent/hacking/wlan_tool/storage/database.py", line 81, in db_conn_ctx
    db_dir.mkdir(parents=True, exist_ok=True)
  File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/pathlib.py", line 1120, in mkdir
    self.parent.mkdir(parents=True, exist_ok=True)
  File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/pathlib.py", line 1116, in mkdir
    os.mkdir(self, mode)
PermissionError: [Errno 13] Permission denied: '/invalid'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/pi/Ai_agent/hacking/wlan_tool/storage/database.py", line 83, in db_conn_ctx
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Cannot create database directory: /invalid/path (Code: DB_DIR_CREATION_FAILED) | Details: {'directory': '/invalid/path', 'original_error': "[Errno 13] Permission denied: '/invalid'"}
___________ TestDatabaseErrorHandling.test_database_migration_error ____________

self = <test_error_handling.TestDatabaseErrorHandling object at 0x7f64f5b850>

    def test_database_migration_error(self):
        """Test Datenbankmigrations-Fehler."""
        with tempfile.NamedTemporaryFile(suffix='.db', delete=False) as f:
            db_path = f.name
    
        try:
            # Erstelle ungültige Migration
            migrations_dir = Path("wlan_tool/assets/sql_data/versions")
            migrations_dir.mkdir(parents=True, exist_ok=True)
    
            invalid_migration = migrations_dir / "999_invalid.sql"
            invalid_migration.write_text("INVALID SQL SYNTAX")
    
>           with pytest.raises(DatabaseError):
E           Failed: DID NOT RAISE <class 'wlan_tool.exceptions.DatabaseError'>

pytest/test_error_handling.py:360: Failed
----------------------------- Captured stdout call -----------------------------
2025-11-28 14:45:23,481 | DEBUG    | Starting operation: database_migration
2025-11-28 14:45:23,482 | DEBUG    | Starting operation: database_connection
2025-11-28 14:45:23,504 | INFO     | Current DB version: 0. Looking for migrations...
2025-11-28 14:45:23,504 | INFO     | Applying migration: 001_initial_schema.sql (Version 1)
2025-11-28 14:45:23,513 | INFO     | DB successfully migrated to version 1
2025-11-28 14:45:23,513 | INFO     | Applying migration: 002_add_dns_table.sql (Version 2)
2025-11-28 14:45:23,514 | INFO     | DB successfully migrated to version 2
2025-11-28 14:45:23,515 | INFO     | Applying migration: 003_add_network_info.sql (Version 3)
2025-11-28 14:45:23,516 | INFO     | DB successfully migrated to version 3
2025-11-28 14:45:23,517 | INFO     | Applying migration: 004_add_indexes.sql (Version 4)
2025-11-28 14:45:23,518 | INFO     | DB successfully migrated to version 4
2025-11-28 14:45:23,518 | INFO     | Applying migration: 999_invalid.sql (Version 999)
2025-11-28 14:45:23,519 | ERROR    | Unexpected error during migration 999_invalid.sql: WLANToolError: Migration failed: 999_invalid.sql (Code: MIGRATION_EXECUTION_FAILED) | Details: {'migration_file': '999_invalid.sql', 'version': 999, 'sqlite_error': 'near "INVALID": syntax error'}
2025-11-28 14:45:23,541 | INFO     | Database is up to date.
------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_migration
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
INFO     wlan_tool.storage.database:database.py:157 Current DB version: 0. Looking for migrations...
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 001_initial_schema.sql (Version 1)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 1
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 002_add_dns_table.sql (Version 2)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 2
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 003_add_network_info.sql (Version 3)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 3
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 004_add_indexes.sql (Version 4)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 4
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 999_invalid.sql (Version 999)
ERROR    wlan_tool.storage.database:database.py:199 Unexpected error during migration 999_invalid.sql: WLANToolError: Migration failed: 999_invalid.sql (Code: MIGRATION_EXECUTION_FAILED) | Details: {'migration_file': '999_invalid.sql', 'version': 999, 'sqlite_error': 'near "INVALID": syntax error'}
INFO     wlan_tool.storage.database:database.py:204 Database is up to date.
__________ TestAnalysisErrorHandling.test_client_features_null_state ___________

self = <test_error_handling.TestAnalysisErrorHandling object at 0x7f64f5ac10>

    def test_client_features_null_state(self):
        """Test Client-Features mit None-State."""
        from wlan_tool.analysis.logic import features_for_client
    
>       with pytest.raises(ValidationError) as exc_info:
E       Failed: DID NOT RAISE <class 'wlan_tool.exceptions.ValidationError'>

pytest/test_error_handling.py:377: Failed
----------------------------- Captured stdout call -----------------------------
2025-11-28 14:45:23,570 | DEBUG    | Starting operation: client_features_extraction
2025-11-28 14:45:23,571 | ERROR    | Error in client_features_extraction: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'} (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}
2025-11-28 14:45:23,571 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/Ai_agent/hacking/wlan_tool/analysis/logic.py", line 229, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}

2025-11-28 14:45:23,572 | ERROR    | Unexpected error in features_for_client: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}
2025-11-28 14:45:23,572 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/Ai_agent/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/Ai_agent/hacking/wlan_tool/analysis/logic.py", line 229, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_features_extraction
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in client_features_extraction: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'} (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/Ai_agent/hacking/wlan_tool/analysis/logic.py", line 229, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}

ERROR    wlan_tool.analysis.logic:exceptions.py:165 Unexpected error in features_for_client: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}
DEBUG    wlan_tool.analysis.logic:exceptions.py:166 Traceback: Traceback (most recent call last):
  File "/home/pi/Ai_agent/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/Ai_agent/hacking/wlan_tool/analysis/logic.py", line 229, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Client state is None (Code: NULL_CLIENT_STATE) | Details: {'function': 'features_for_client'}
_________ TestAnalysisErrorHandling.test_client_features_invalid_type __________

self = <test_error_handling.TestAnalysisErrorHandling object at 0x7f64f591d0>

    def test_client_features_invalid_type(self):
        """Test Client-Features mit ungültigem Typ."""
        from wlan_tool.analysis.logic import features_for_client
    
>       with pytest.raises(ValidationError) as exc_info:
E       Failed: DID NOT RAISE <class 'wlan_tool.exceptions.ValidationError'>

pytest/test_error_handling.py:387: Failed
----------------------------- Captured stdout call -----------------------------
2025-11-28 14:45:23,602 | DEBUG    | Starting operation: client_features_extraction
2025-11-28 14:45:23,603 | ERROR    | Error in client_features_extraction: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"} (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}
2025-11-28 14:45:23,604 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/Ai_agent/hacking/wlan_tool/analysis/logic.py", line 236, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}

2025-11-28 14:45:23,604 | ERROR    | Unexpected error in features_for_client: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}
2025-11-28 14:45:23,604 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/Ai_agent/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/Ai_agent/hacking/wlan_tool/analysis/logic.py", line 236, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_features_extraction
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in client_features_extraction: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"} (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/Ai_agent/hacking/wlan_tool/analysis/logic.py", line 236, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}

ERROR    wlan_tool.analysis.logic:exceptions.py:165 Unexpected error in features_for_client: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}
DEBUG    wlan_tool.analysis.logic:exceptions.py:166 Traceback: Traceback (most recent call last):
  File "/home/pi/Ai_agent/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/Ai_agent/hacking/wlan_tool/analysis/logic.py", line 236, in features_for_client
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid client state type: <class 'str'> (Code: INVALID_CLIENT_STATE_TYPE) | Details: {'expected': 'ClientState', 'actual': "<class 'str'>"}
_________ TestAnalysisErrorHandling.test_clustering_invalid_parameters _________

self = <test_error_handling.TestAnalysisErrorHandling object at 0x7f64f52ad0>

    def test_clustering_invalid_parameters(self):
        """Test Clustering mit ungültigen Parametern."""
        from wlan_tool.analysis.logic import cluster_clients
        from wlan_tool.storage.state import WifiAnalysisState
    
        state = WifiAnalysisState()
    
        # Teste ungültige n_clusters
>       with pytest.raises(ValidationError) as exc_info:
E       Failed: DID NOT RAISE <class 'wlan_tool.exceptions.ValidationError'>

pytest/test_error_handling.py:401: Failed
----------------------------- Captured stdout call -----------------------------
2025-11-28 14:45:23,633 | DEBUG    | Starting operation: client_clustering
2025-11-28 14:45:23,634 | ERROR    | Error in client_clustering: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0} (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}
2025-11-28 14:45:23,634 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/Ai_agent/hacking/wlan_tool/analysis/logic.py", line 495, in cluster_clients
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}

2025-11-28 14:45:23,634 | ERROR    | Unexpected error in cluster_clients: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}
2025-11-28 14:45:23,635 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/Ai_agent/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/Ai_agent/hacking/wlan_tool/analysis/logic.py", line 495, in cluster_clients
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_clustering
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in client_clustering: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0} (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/Ai_agent/hacking/wlan_tool/analysis/logic.py", line 495, in cluster_clients
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}

ERROR    wlan_tool.analysis.logic:exceptions.py:165 Unexpected error in cluster_clients: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}
DEBUG    wlan_tool.analysis.logic:exceptions.py:166 Traceback: Traceback (most recent call last):
  File "/home/pi/Ai_agent/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/Ai_agent/hacking/wlan_tool/analysis/logic.py", line 495, in cluster_clients
    raise ValidationError(
wlan_tool.exceptions.ValidationError: WLANToolError: Invalid n_clusters: 0 (Code: INVALID_N_CLUSTERS) | Details: {'n_clusters': 0}
___________ TestFileSystemErrorHandling.test_csv_export_invalid_path ___________

self = <test_error_handling.TestFileSystemErrorHandling object at 0x7f64f64590>

    def test_csv_export_invalid_path(self):
        """Test CSV-Export mit ungültigem Pfad."""
        from wlan_tool.storage.database import export_confirmed_to_csv
    
>       with pytest.raises(ValidationError) as exc_info:
E       Failed: DID NOT RAISE <class 'wlan_tool.exceptions.ValidationError'>

pytest/test_error_handling.py:422: Failed
----------------------------- Captured stdout call -----------------------------
2025-11-28 14:45:23,664 | DEBUG    | Starting operation: csv_export
2025-11-28 14:45:23,665 | ERROR    | Error in csv_export: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''} (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}
2025-11-28 14:45:23,666 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/Ai_agent/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}

2025-11-28 14:45:23,666 | ERROR    | Error in export_confirmed_to_csv: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}
2025-11-28 14:45:23,666 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/Ai_agent/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/Ai_agent/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: csv_export
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in csv_export: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''} (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/Ai_agent/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}

ERROR    wlan_tool.storage.database:exceptions.py:153 Error in export_confirmed_to_csv: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}
DEBUG    wlan_tool.storage.database:exceptions.py:154 Traceback: Traceback (most recent call last):
  File "/home/pi/Ai_agent/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/Ai_agent/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found:  (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': ''}
____________ TestFileSystemErrorHandling.test_csv_export_missing_db ____________

self = <test_error_handling.TestFileSystemErrorHandling object at 0x7f64f64890>

    def test_csv_export_missing_db(self):
        """Test CSV-Export mit fehlender Datenbank."""
        from wlan_tool.storage.database import export_confirmed_to_csv
    
>       with pytest.raises(FileSystemError) as exc_info:
E       Failed: DID NOT RAISE <class 'wlan_tool.exceptions.FileSystemError'>

pytest/test_error_handling.py:432: Failed
----------------------------- Captured stdout call -----------------------------
2025-11-28 14:45:23,696 | DEBUG    | Starting operation: csv_export
2025-11-28 14:45:23,696 | ERROR    | Error in csv_export: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'} (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}
2025-11-28 14:45:23,697 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/Ai_agent/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}

2025-11-28 14:45:23,697 | ERROR    | Error in export_confirmed_to_csv: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}
2025-11-28 14:45:23,698 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/Ai_agent/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/Ai_agent/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: csv_export
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in csv_export: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'} (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/Ai_agent/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}

ERROR    wlan_tool.storage.database:exceptions.py:153 Error in export_confirmed_to_csv: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}
DEBUG    wlan_tool.storage.database:exceptions.py:154 Traceback: Traceback (most recent call last):
  File "/home/pi/Ai_agent/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/pi/Ai_agent/hacking/wlan_tool/storage/database.py", line 656, in export_confirmed_to_csv
    raise FileSystemError(
wlan_tool.exceptions.FileSystemError: WLANToolError: Label database not found: /nonexistent/database.db (Code: LABEL_DB_NOT_FOUND) | Details: {'label_db_path': '/nonexistent/database.db'}
____________ TestErrorHandlingEdgeCases.test_nested_error_contexts _____________

self = <test_error_handling.TestErrorHandlingEdgeCases object at 0x7f64f65d50>

    def test_nested_error_contexts(self):
        """Test verschachtelte Error-Contexts."""
        with ErrorContext("outer_operation", "OUTER_ERROR") as outer:
            with ErrorContext("inner_operation", "INNER_ERROR") as inner:
>               raise ValueError("Inner error")
E               ValueError: Inner error

pytest/test_error_handling.py:473: ValueError

The above exception was the direct cause of the following exception:

self = <test_error_handling.TestErrorHandlingEdgeCases object at 0x7f64f65d50>

    def test_nested_error_contexts(self):
        """Test verschachtelte Error-Contexts."""
        with ErrorContext("outer_operation", "OUTER_ERROR") as outer:
>           with ErrorContext("inner_operation", "INNER_ERROR") as inner:

pytest/test_error_handling.py:472: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.exceptions.ErrorContext object at 0x7f5b6102d0>
exc_type = <class 'ValueError'>, exc_val = ValueError('Inner error')
exc_tb = <traceback object at 0x7f5b610380>

    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type is not None:
            error_msg = f"Error in {self.operation}: {exc_val}"
    
            if isinstance(exc_val, WLANToolError):
                error_msg += f" (Code: {exc_val.error_code})"
                if exc_val.details:
                    error_msg += f" | Details: {exc_val.details}"
            else:
                error_msg += f" | Type: {exc_type.__name__}"
    
            self.logger.log(self.log_level, error_msg)
            self.logger.debug(f"Traceback: {traceback.format_exc()}")
    
            # Konvertiere zu WLANToolError falls nötig
            if not isinstance(exc_val, WLANToolError):
                wlan_error = WLANToolError(
                    message=str(exc_val),
                    error_code=self.error_code or "CONTEXT_ERROR",
                    details={
                        "operation": self.operation,
                        "original_type": exc_type.__name__,
                    },
                )
>               raise wlan_error from exc_val
E               wlan_tool.exceptions.WLANToolError: WLANToolError: Inner error (Code: INNER_ERROR) | Details: {'operation': 'inner_operation', 'original_type': 'ValueError'}

wlan_tool/exceptions.py:313: WLANToolError
----------------------------- Captured stdout call -----------------------------
2025-11-28 14:45:24,735 | DEBUG    | Starting operation: outer_operation
2025-11-28 14:45:24,735 | DEBUG    | Starting operation: inner_operation
2025-11-28 14:45:24,735 | ERROR    | Error in inner_operation: Inner error | Type: ValueError
2025-11-28 14:45:24,736 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/Ai_agent/hacking/pytest/test_error_handling.py", line 473, in test_nested_error_contexts
    raise ValueError("Inner error")
ValueError: Inner error

2025-11-28 14:45:24,736 | ERROR    | Error in outer_operation: WLANToolError: Inner error (Code: INNER_ERROR) | Details: {'operation': 'inner_operation', 'original_type': 'ValueError'} (Code: INNER_ERROR) | Details: {'operation': 'inner_operation', 'original_type': 'ValueError'}
2025-11-28 14:45:24,737 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/Ai_agent/hacking/pytest/test_error_handling.py", line 473, in test_nested_error_contexts
    raise ValueError("Inner error")
ValueError: Inner error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/pi/Ai_agent/hacking/pytest/test_error_handling.py", line 472, in test_nested_error_contexts
    with ErrorContext("inner_operation", "INNER_ERROR") as inner:
  File "/home/pi/Ai_agent/hacking/wlan_tool/exceptions.py", line 313, in __exit__
    raise wlan_error from exc_val
wlan_tool.exceptions.WLANToolError: WLANToolError: Inner error (Code: INNER_ERROR) | Details: {'operation': 'inner_operation', 'original_type': 'ValueError'}

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: outer_operation
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: inner_operation
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in inner_operation: Inner error | Type: ValueError
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/Ai_agent/hacking/pytest/test_error_handling.py", line 473, in test_nested_error_contexts
    raise ValueError("Inner error")
ValueError: Inner error

ERROR    wlan_tool.exceptions:exceptions.py:300 Error in outer_operation: WLANToolError: Inner error (Code: INNER_ERROR) | Details: {'operation': 'inner_operation', 'original_type': 'ValueError'} (Code: INNER_ERROR) | Details: {'operation': 'inner_operation', 'original_type': 'ValueError'}
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/Ai_agent/hacking/pytest/test_error_handling.py", line 473, in test_nested_error_contexts
    raise ValueError("Inner error")
ValueError: Inner error

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/pi/Ai_agent/hacking/pytest/test_error_handling.py", line 472, in test_nested_error_contexts
    with ErrorContext("inner_operation", "INNER_ERROR") as inner:
  File "/home/pi/Ai_agent/hacking/wlan_tool/exceptions.py", line 313, in __exit__
    raise wlan_error from exc_val
wlan_tool.exceptions.WLANToolError: WLANToolError: Inner error (Code: INNER_ERROR) | Details: {'operation': 'inner_operation', 'original_type': 'ValueError'}
________________ TestEndToEndWorkflow.test_database_integration ________________

self = <test_integration.TestEndToEndWorkflow object at 0x7f64f71fd0>
sample_events = [{'beacon_interval': 102, 'bssid': '08:96:d7:1a:21:1c', 'cap': 17, 'channel': 6, ...}, {'client': 'a8:51:ab:0c:b9:e9',...-91, ...}, {'client': 'b2:87:23:15:7f:f2', 'ie_order_hash': 67890, 'ies': {0: ['MyOtherWLAN']}, 'rssi': -70, ...}, ...]
temp_db_file = '/tmp/tmph0uvu3at.db'

    def test_database_integration(self, sample_events, temp_db_file):
        """Test Datenbank-Integration."""
        # Schreibe Events in Datenbank
        with database.db_conn_ctx(temp_db_file) as conn:
            for event in sample_events:
>               database.add_event(conn, event)
E               AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

pytest/test_integration.py:64: AttributeError

The above exception was the direct cause of the following exception:

path = '/tmp/tmph0uvu3at.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
>           with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):

wlan_tool/storage/database.py:68: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.exceptions.ErrorContext object at 0x7f5cdd7d90>
exc_type = <class 'AttributeError'>
exc_val = AttributeError("module 'wlan_tool.storage.database' has no attribute 'add_event'")
exc_tb = <traceback object at 0x7f5cdd7f00>

    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type is not None:
            error_msg = f"Error in {self.operation}: {exc_val}"
    
            if isinstance(exc_val, WLANToolError):
                error_msg += f" (Code: {exc_val.error_code})"
                if exc_val.details:
                    error_msg += f" | Details: {exc_val.details}"
            else:
                error_msg += f" | Type: {exc_type.__name__}"
    
            self.logger.log(self.log_level, error_msg)
            self.logger.debug(f"Traceback: {traceback.format_exc()}")
    
            # Konvertiere zu WLANToolError falls nötig
            if not isinstance(exc_val, WLANToolError):
                wlan_error = WLANToolError(
                    message=str(exc_val),
                    error_code=self.error_code or "CONTEXT_ERROR",
                    details={
                        "operation": self.operation,
                        "original_type": exc_type.__name__,
                    },
                )
>               raise wlan_error from exc_val
E               wlan_tool.exceptions.WLANToolError: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}

wlan_tool/exceptions.py:313: WLANToolError

The above exception was the direct cause of the following exception:

self = <test_integration.TestEndToEndWorkflow object at 0x7f64f71fd0>
sample_events = [{'beacon_interval': 102, 'bssid': '08:96:d7:1a:21:1c', 'cap': 17, 'channel': 6, ...}, {'client': 'a8:51:ab:0c:b9:e9',...-91, ...}, {'client': 'b2:87:23:15:7f:f2', 'ie_order_hash': 67890, 'ies': {0: ['MyOtherWLAN']}, 'rssi': -70, ...}, ...]
temp_db_file = '/tmp/tmph0uvu3at.db'

    def test_database_integration(self, sample_events, temp_db_file):
        """Test Datenbank-Integration."""
        # Schreibe Events in Datenbank
>       with database.db_conn_ctx(temp_db_file) as conn:

pytest/test_integration.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../.pyenv/versions/3.11.9/lib/python3.11/contextlib.py:158: in __exit__
    self.gen.throw(typ, value, traceback)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

path = '/tmp/tmph0uvu3at.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
            with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):
                # Validiere Datenbankpfad
                if not _validate_file_path(path):
                    raise ValidationError(
                        f"Invalid database path: {path}",
                        error_code="INVALID_DB_PATH",
                        details={"db_path": path},
                    )
    
                # Erstelle Verzeichnis falls nötig
                db_dir = Path(path).parent
                if not db_dir.exists():
                    try:
                        db_dir.mkdir(parents=True, exist_ok=True)
                    except OSError as e:
                        raise FileSystemError(
                            f"Cannot create database directory: {db_dir}",
                            error_code="DB_DIR_CREATION_FAILED",
                            details={"directory": str(db_dir), "original_error": str(e)},
                        ) from e
    
                # Verbinde zur Datenbank
                conn = sqlite3.connect(path, timeout=Constants.DB_CONNECTION_TIMEOUT)
                conn.row_factory = sqlite3.Row
    
                # Setze pragmas für bessere Performance und Fehlerbehandlung
                conn.execute("PRAGMA foreign_keys = ON")
                conn.execute("PRAGMA journal_mode = WAL")
                conn.execute("PRAGMA synchronous = NORMAL")
                conn.execute("PRAGMA cache_size = 10000")
                conn.execute("PRAGMA temp_store = MEMORY")
    
                yield conn
    
        except sqlite3.Error as e:
            if conn:
                conn.rollback()
            raise DatabaseError(
                get_error_message(ErrorCodes.DB_CONNECTION_FAILED, details=str(e)),
                error_code=ErrorCodes.DB_CONNECTION_FAILED.value,
                details={"db_path": path, "sqlite_error": str(e)},
            ) from e
        except Exception as e:
            if conn:
                conn.rollback()
>           raise DatabaseError(
                f"Unexpected database error: {e}",
                error_code="DB_UNEXPECTED_ERROR",
                details={"db_path": path, "original_error": str(e)},
            ) from e
E           wlan_tool.exceptions.DatabaseError: WLANToolError: Unexpected database error: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'} (Code: DB_UNEXPECTED_ERROR) | Details: {'db_path': '/tmp/tmph0uvu3at.db', 'original_error': "WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}"}

wlan_tool/storage/database.py:113: DatabaseError
---------------------------- Captured stdout setup -----------------------------
2025-11-28 14:45:24,986 | DEBUG    | Starting operation: database_migration
2025-11-28 14:45:24,987 | DEBUG    | Starting operation: database_connection
2025-11-28 14:45:25,012 | INFO     | Current DB version: 0. Looking for migrations...
2025-11-28 14:45:25,012 | INFO     | Applying migration: 001_initial_schema.sql (Version 1)
2025-11-28 14:45:25,020 | INFO     | DB successfully migrated to version 1
2025-11-28 14:45:25,021 | INFO     | Applying migration: 002_add_dns_table.sql (Version 2)
2025-11-28 14:45:25,022 | INFO     | DB successfully migrated to version 2
2025-11-28 14:45:25,022 | INFO     | Applying migration: 003_add_network_info.sql (Version 3)
2025-11-28 14:45:25,024 | INFO     | DB successfully migrated to version 3
2025-11-28 14:45:25,024 | INFO     | Applying migration: 004_add_indexes.sql (Version 4)
2025-11-28 14:45:25,025 | INFO     | DB successfully migrated to version 4
2025-11-28 14:45:25,047 | INFO     | Database is up to date.
------------------------------ Captured log setup ------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_migration
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
INFO     wlan_tool.storage.database:database.py:157 Current DB version: 0. Looking for migrations...
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 001_initial_schema.sql (Version 1)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 1
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 002_add_dns_table.sql (Version 2)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 2
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 003_add_network_info.sql (Version 3)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 3
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 004_add_indexes.sql (Version 4)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 4
INFO     wlan_tool.storage.database:database.py:204 Database is up to date.
----------------------------- Captured stdout call -----------------------------
2025-11-28 14:45:25,049 | DEBUG    | Starting operation: database_connection
2025-11-28 14:45:25,051 | ERROR    | Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
2025-11-28 14:45:25,052 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/Ai_agent/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/Ai_agent/hacking/pytest/test_integration.py", line 64, in test_database_integration
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/Ai_agent/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/Ai_agent/hacking/pytest/test_integration.py", line 64, in test_database_integration
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'
_________________ TestEndToEndWorkflow.test_config_integration _________________

self = <test_integration.TestEndToEndWorkflow object at 0x7f64f725d0>

    def test_config_integration(self):
        """Test Konfigurations-Integration."""
        # Teste Konfigurations-Laden
>       config_data = utils.load_config()
E       TypeError: load_config() missing 1 required positional argument: 'profile'

pytest/test_integration.py:82: TypeError
_____________________ TestDataFlow.test_state_persistence ______________________

self = <test_integration.TestDataFlow object at 0x7f64f5b650>
sample_events = [{'beacon_interval': 102, 'bssid': '08:96:d7:1a:21:1c', 'cap': 17, 'channel': 6, ...}, {'client': 'a8:51:ab:0c:b9:e9',...-91, ...}, {'client': 'b2:87:23:15:7f:f2', 'ie_order_hash': 67890, 'ies': {0: ['MyOtherWLAN']}, 'rssi': -70, ...}, ...]
temp_db_file = '/tmp/tmp80c1vvzc.db'

    def test_state_persistence(self, sample_events, temp_db_file):
        """Test State-Persistierung."""
        # Erstelle State
        state1 = WifiAnalysisState()
        state1.build_from_events(sample_events)
    
        # Schreibe in Datenbank
        with database.db_conn_ctx(temp_db_file) as conn:
            for event in sample_events:
>               database.add_event(conn, event)
E               AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

pytest/test_integration.py:130: AttributeError

The above exception was the direct cause of the following exception:

path = '/tmp/tmp80c1vvzc.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
>           with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):

wlan_tool/storage/database.py:68: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.exceptions.ErrorContext object at 0x7f5d077b50>
exc_type = <class 'AttributeError'>
exc_val = AttributeError("module 'wlan_tool.storage.database' has no attribute 'add_event'")
exc_tb = <traceback object at 0x7f5d0748c0>

    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type is not None:
            error_msg = f"Error in {self.operation}: {exc_val}"
    
            if isinstance(exc_val, WLANToolError):
                error_msg += f" (Code: {exc_val.error_code})"
                if exc_val.details:
                    error_msg += f" | Details: {exc_val.details}"
            else:
                error_msg += f" | Type: {exc_type.__name__}"
    
            self.logger.log(self.log_level, error_msg)
            self.logger.debug(f"Traceback: {traceback.format_exc()}")
    
            # Konvertiere zu WLANToolError falls nötig
            if not isinstance(exc_val, WLANToolError):
                wlan_error = WLANToolError(
                    message=str(exc_val),
                    error_code=self.error_code or "CONTEXT_ERROR",
                    details={
                        "operation": self.operation,
                        "original_type": exc_type.__name__,
                    },
                )
>               raise wlan_error from exc_val
E               wlan_tool.exceptions.WLANToolError: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}

wlan_tool/exceptions.py:313: WLANToolError

The above exception was the direct cause of the following exception:

self = <test_integration.TestDataFlow object at 0x7f64f5b650>
sample_events = [{'beacon_interval': 102, 'bssid': '08:96:d7:1a:21:1c', 'cap': 17, 'channel': 6, ...}, {'client': 'a8:51:ab:0c:b9:e9',...-91, ...}, {'client': 'b2:87:23:15:7f:f2', 'ie_order_hash': 67890, 'ies': {0: ['MyOtherWLAN']}, 'rssi': -70, ...}, ...]
temp_db_file = '/tmp/tmp80c1vvzc.db'

    def test_state_persistence(self, sample_events, temp_db_file):
        """Test State-Persistierung."""
        # Erstelle State
        state1 = WifiAnalysisState()
        state1.build_from_events(sample_events)
    
        # Schreibe in Datenbank
>       with database.db_conn_ctx(temp_db_file) as conn:

pytest/test_integration.py:128: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../.pyenv/versions/3.11.9/lib/python3.11/contextlib.py:158: in __exit__
    self.gen.throw(typ, value, traceback)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

path = '/tmp/tmp80c1vvzc.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
            with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):
                # Validiere Datenbankpfad
                if not _validate_file_path(path):
                    raise ValidationError(
                        f"Invalid database path: {path}",
                        error_code="INVALID_DB_PATH",
                        details={"db_path": path},
                    )
    
                # Erstelle Verzeichnis falls nötig
                db_dir = Path(path).parent
                if not db_dir.exists():
                    try:
                        db_dir.mkdir(parents=True, exist_ok=True)
                    except OSError as e:
                        raise FileSystemError(
                            f"Cannot create database directory: {db_dir}",
                            error_code="DB_DIR_CREATION_FAILED",
                            details={"directory": str(db_dir), "original_error": str(e)},
                        ) from e
    
                # Verbinde zur Datenbank
                conn = sqlite3.connect(path, timeout=Constants.DB_CONNECTION_TIMEOUT)
                conn.row_factory = sqlite3.Row
    
                # Setze pragmas für bessere Performance und Fehlerbehandlung
                conn.execute("PRAGMA foreign_keys = ON")
                conn.execute("PRAGMA journal_mode = WAL")
                conn.execute("PRAGMA synchronous = NORMAL")
                conn.execute("PRAGMA cache_size = 10000")
                conn.execute("PRAGMA temp_store = MEMORY")
    
                yield conn
    
        except sqlite3.Error as e:
            if conn:
                conn.rollback()
            raise DatabaseError(
                get_error_message(ErrorCodes.DB_CONNECTION_FAILED, details=str(e)),
                error_code=ErrorCodes.DB_CONNECTION_FAILED.value,
                details={"db_path": path, "sqlite_error": str(e)},
            ) from e
        except Exception as e:
            if conn:
                conn.rollback()
>           raise DatabaseError(
                f"Unexpected database error: {e}",
                error_code="DB_UNEXPECTED_ERROR",
                details={"db_path": path, "original_error": str(e)},
            ) from e
E           wlan_tool.exceptions.DatabaseError: WLANToolError: Unexpected database error: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'} (Code: DB_UNEXPECTED_ERROR) | Details: {'db_path': '/tmp/tmp80c1vvzc.db', 'original_error': "WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}"}

wlan_tool/storage/database.py:113: DatabaseError
---------------------------- Captured stdout setup -----------------------------
2025-11-28 14:45:25,287 | DEBUG    | Starting operation: database_migration
2025-11-28 14:45:25,288 | DEBUG    | Starting operation: database_connection
2025-11-28 14:45:25,301 | INFO     | Current DB version: 0. Looking for migrations...
2025-11-28 14:45:25,301 | INFO     | Applying migration: 001_initial_schema.sql (Version 1)
2025-11-28 14:45:25,311 | INFO     | DB successfully migrated to version 1
2025-11-28 14:45:25,312 | INFO     | Applying migration: 002_add_dns_table.sql (Version 2)
2025-11-28 14:45:25,313 | INFO     | DB successfully migrated to version 2
2025-11-28 14:45:25,313 | INFO     | Applying migration: 003_add_network_info.sql (Version 3)
2025-11-28 14:45:25,315 | INFO     | DB successfully migrated to version 3
2025-11-28 14:45:25,315 | INFO     | Applying migration: 004_add_indexes.sql (Version 4)
2025-11-28 14:45:25,317 | INFO     | DB successfully migrated to version 4
2025-11-28 14:45:25,337 | INFO     | Database is up to date.
------------------------------ Captured log setup ------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_migration
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
INFO     wlan_tool.storage.database:database.py:157 Current DB version: 0. Looking for migrations...
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 001_initial_schema.sql (Version 1)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 1
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 002_add_dns_table.sql (Version 2)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 2
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 003_add_network_info.sql (Version 3)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 3
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 004_add_indexes.sql (Version 4)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 4
INFO     wlan_tool.storage.database:database.py:204 Database is up to date.
----------------------------- Captured stdout call -----------------------------
2025-11-28 14:45:25,338 | INFO     | Baue/Aktualisiere Zustand aus Event-Stream auf...
2025-11-28 14:45:25,339 | INFO     | Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
2025-11-28 14:45:25,339 | DEBUG    | Starting operation: database_connection
2025-11-28 14:45:25,341 | ERROR    | Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
2025-11-28 14:45:25,342 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/Ai_agent/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/Ai_agent/hacking/pytest/test_integration.py", line 130, in test_state_persistence
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

------------------------------ Captured log call -------------------------------
INFO     wlan_tool.storage.state:state.py:52 Baue/Aktualisiere Zustand aus Event-Stream auf...
INFO     wlan_tool.storage.state:state.py:57 Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/Ai_agent/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/Ai_agent/hacking/pytest/test_integration.py", line 130, in test_state_persistence
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'
________________ TestLargeDataset.test_large_dataset_processing ________________

self = <test_integration.TestLargeDataset object at 0x7f64f72190>

    def test_large_dataset_processing(self):
        """Test Verarbeitung großer Datensätze."""
        # Erstelle großen State
        state = WifiAnalysisState()
    
        # Erstelle 100 APs
        for i in range(100):
            bssid = f"08:96:d7:1a:21:{i:02x}"
>           ap = state.aps[bssid] = state.aps.get(bssid, type(state).__dict__['aps'].__class__())()
E           KeyError: 'aps'

pytest/test_integration.py:158: KeyError
_______________ TestErrorRecovery.test_malformed_event_handling ________________

self = <test_integration.TestErrorRecovery object at 0x7f64f73a90>

    def test_malformed_event_handling(self):
        """Test Behandlung fehlerhafter Events."""
        state = WifiAnalysisState()
    
        # Teste verschiedene fehlerhafte Events
        malformed_events = [
            {},  # Leeres Event
            {'ts': time.time()},  # Nur Zeitstempel
            {'ts': time.time(), 'type': 'invalid'},  # Ungültiger Typ
            {'ts': time.time(), 'type': 'beacon'},  # Beacon ohne BSSID
        ]
    
        for event in malformed_events:
            # Sollte nicht crashen
            try:
>               state.update_from_event(event)

pytest/test_integration.py:241: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f5cd37e50>
ev = {}, detailed_ies = False

    def update_from_event(self, ev: dict, detailed_ies: bool = False):
>       ts, ev_type = ev["ts"], ev.get("type")
E       KeyError: 'ts'

wlan_tool/storage/state.py:66: KeyError

During handling of the above exception, another exception occurred:

self = <test_integration.TestErrorRecovery object at 0x7f64f73a90>

    def test_malformed_event_handling(self):
        """Test Behandlung fehlerhafter Events."""
        state = WifiAnalysisState()
    
        # Teste verschiedene fehlerhafte Events
        malformed_events = [
            {},  # Leeres Event
            {'ts': time.time()},  # Nur Zeitstempel
            {'ts': time.time(), 'type': 'invalid'},  # Ungültiger Typ
            {'ts': time.time(), 'type': 'beacon'},  # Beacon ohne BSSID
        ]
    
        for event in malformed_events:
            # Sollte nicht crashen
            try:
                state.update_from_event(event)
            except Exception as e:
>               pytest.fail(f"Malformed event should be handled gracefully: {e}")
E               Failed: Malformed event should be handled gracefully: 'ts'

pytest/test_integration.py:243: Failed
______________ TestMemoryManagement.test_memory_usage_large_state ______________

self = <test_integration.TestMemoryManagement object at 0x7f64f7cd10>

    def test_memory_usage_large_state(self):
        """Test Speicherverbrauch mit großem State."""
        import psutil
        import os
    
        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss
    
        # Erstelle großen State
        state = WifiAnalysisState()
    
        for i in range(1000):
            mac = f"aa:bb:cc:dd:ee:{i:04x}"
>           client = state.clients[mac] = state.clients.get(mac, type(state).__dict__['clients'].__class__())()
E           KeyError: 'clients'

pytest/test_integration.py:295: KeyError
____________ TestMemoryManagement.test_state_pruning_memory_release ____________

self = <test_integration.TestMemoryManagement object at 0x7f64f7d310>

    def test_state_pruning_memory_release(self):
        """Test Speicherfreigabe durch State-Pruning."""
        import psutil
        import os
    
        process = psutil.Process(os.getpid())
    
        # Erstelle State mit alten und neuen Daten
        state = WifiAnalysisState()
    
        # Alte Clients (werden gepruned)
        for i in range(100):
            mac = f"old:aa:bb:cc:dd:ee:{i:02x}"
>           client = state.clients[mac] = state.clients.get(mac, type(state).__dict__['clients'].__class__())()
E           KeyError: 'clients'

pytest/test_integration.py:321: KeyError
_____________ TestAnalysisPerformance.test_clustering_performance ______________

self = <test_performance.TestAnalysisPerformance object at 0x7f64f81750>

    def test_clustering_performance(self):
        """Test Clustering-Performance."""
        # Erstelle State mit vielen Clients
        state = WifiAnalysisState()
    
        for i in range(200):
            mac = f"aa:bb:cc:dd:ee:{i:02x}"
>           client = state.clients[mac] = state.clients.get(mac, type(state).__dict__['clients'].__class__())()
E           KeyError: 'clients'

pytest/test_performance.py:147: KeyError
______________ TestAnalysisPerformance.test_inference_performance ______________

self = <test_performance.TestAnalysisPerformance object at 0x7f64f81d50>

    def test_inference_performance(self):
        """Test Inferenz-Performance."""
        # Erstelle State mit APs und Clients
        state = WifiAnalysisState()
    
        # Erstelle 50 APs
        for i in range(50):
            bssid = f"08:96:d7:1a:21:{i:02x}"
>           ap = state.aps[bssid] = state.aps.get(bssid, type(state).__dict__['aps'].__class__())()
E           KeyError: 'aps'

pytest/test_performance.py:180: KeyError
_____________ TestMemoryPerformance.test_memory_usage_large_state ______________

self = <test_performance.TestMemoryPerformance object at 0x7f64f7ced0>

    def test_memory_usage_large_state(self):
        """Test Speicherverbrauch mit großem State."""
        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss
    
        # Erstelle großen State
        state = WifiAnalysisState()
    
        # 1000 Clients
        for i in range(1000):
            mac = f"aa:bb:cc:dd:ee:{i:04x}"
>           client = state.clients[mac] = state.clients.get(mac, type(state).__dict__['clients'].__class__())()
E           KeyError: 'clients'

pytest/test_performance.py:228: KeyError
___________ TestMemoryPerformance.test_memory_cleanup_after_pruning ____________

self = <test_performance.TestMemoryPerformance object at 0x7f64f72850>

    def test_memory_cleanup_after_pruning(self):
        """Test Speicherbereinigung nach Pruning."""
        process = psutil.Process(os.getpid())
    
        # Erstelle State mit alten und neuen Daten
        state = WifiAnalysisState()
    
        # 500 alte Clients (werden gepruned)
        for i in range(500):
            mac = f"old:aa:bb:cc:dd:ee:{i:03x}"
>           client = state.clients[mac] = state.clients.get(mac, type(state).__dict__['clients'].__class__())()
E           KeyError: 'clients'

pytest/test_performance.py:269: KeyError
___________ TestDatabasePerformance.test_database_write_performance ____________

self = <test_performance.TestDatabasePerformance object at 0x7f64f80cd0>
temp_db_file = '/tmp/tmplj6_zbtt.db'

    def test_database_write_performance(self, temp_db_file):
        """Test Datenbank-Schreib-Performance."""
        # Erstelle Test-Events
        events = []
        for i in range(1000):
            event = {
                'ts': time.time() + i,
                'type': 'beacon' if i % 2 == 0 else 'probe_req',
                'bssid': f'08:96:d7:1a:21:{i % 100:02x}',
                'ssid': f'SSID_{i % 50}',
                'rssi': -50 - (i % 50),
                'channel': (i % 13) + 1
            }
            events.append(event)
    
        start_time = time.time()
    
        with database.db_conn_ctx(temp_db_file) as conn:
            for event in events:
>               database.add_event(conn, event)
E               AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

pytest/test_performance.py:325: AttributeError

The above exception was the direct cause of the following exception:

path = '/tmp/tmplj6_zbtt.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
>           with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):

wlan_tool/storage/database.py:68: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.exceptions.ErrorContext object at 0x7f5b6929d0>
exc_type = <class 'AttributeError'>
exc_val = AttributeError("module 'wlan_tool.storage.database' has no attribute 'add_event'")
exc_tb = <traceback object at 0x7f5b692240>

    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type is not None:
            error_msg = f"Error in {self.operation}: {exc_val}"
    
            if isinstance(exc_val, WLANToolError):
                error_msg += f" (Code: {exc_val.error_code})"
                if exc_val.details:
                    error_msg += f" | Details: {exc_val.details}"
            else:
                error_msg += f" | Type: {exc_type.__name__}"
    
            self.logger.log(self.log_level, error_msg)
            self.logger.debug(f"Traceback: {traceback.format_exc()}")
    
            # Konvertiere zu WLANToolError falls nötig
            if not isinstance(exc_val, WLANToolError):
                wlan_error = WLANToolError(
                    message=str(exc_val),
                    error_code=self.error_code or "CONTEXT_ERROR",
                    details={
                        "operation": self.operation,
                        "original_type": exc_type.__name__,
                    },
                )
>               raise wlan_error from exc_val
E               wlan_tool.exceptions.WLANToolError: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}

wlan_tool/exceptions.py:313: WLANToolError

The above exception was the direct cause of the following exception:

self = <test_performance.TestDatabasePerformance object at 0x7f64f80cd0>
temp_db_file = '/tmp/tmplj6_zbtt.db'

    def test_database_write_performance(self, temp_db_file):
        """Test Datenbank-Schreib-Performance."""
        # Erstelle Test-Events
        events = []
        for i in range(1000):
            event = {
                'ts': time.time() + i,
                'type': 'beacon' if i % 2 == 0 else 'probe_req',
                'bssid': f'08:96:d7:1a:21:{i % 100:02x}',
                'ssid': f'SSID_{i % 50}',
                'rssi': -50 - (i % 50),
                'channel': (i % 13) + 1
            }
            events.append(event)
    
        start_time = time.time()
    
>       with database.db_conn_ctx(temp_db_file) as conn:

pytest/test_performance.py:323: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../.pyenv/versions/3.11.9/lib/python3.11/contextlib.py:158: in __exit__
    self.gen.throw(typ, value, traceback)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

path = '/tmp/tmplj6_zbtt.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
            with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):
                # Validiere Datenbankpfad
                if not _validate_file_path(path):
                    raise ValidationError(
                        f"Invalid database path: {path}",
                        error_code="INVALID_DB_PATH",
                        details={"db_path": path},
                    )
    
                # Erstelle Verzeichnis falls nötig
                db_dir = Path(path).parent
                if not db_dir.exists():
                    try:
                        db_dir.mkdir(parents=True, exist_ok=True)
                    except OSError as e:
                        raise FileSystemError(
                            f"Cannot create database directory: {db_dir}",
                            error_code="DB_DIR_CREATION_FAILED",
                            details={"directory": str(db_dir), "original_error": str(e)},
                        ) from e
    
                # Verbinde zur Datenbank
                conn = sqlite3.connect(path, timeout=Constants.DB_CONNECTION_TIMEOUT)
                conn.row_factory = sqlite3.Row
    
                # Setze pragmas für bessere Performance und Fehlerbehandlung
                conn.execute("PRAGMA foreign_keys = ON")
                conn.execute("PRAGMA journal_mode = WAL")
                conn.execute("PRAGMA synchronous = NORMAL")
                conn.execute("PRAGMA cache_size = 10000")
                conn.execute("PRAGMA temp_store = MEMORY")
    
                yield conn
    
        except sqlite3.Error as e:
            if conn:
                conn.rollback()
            raise DatabaseError(
                get_error_message(ErrorCodes.DB_CONNECTION_FAILED, details=str(e)),
                error_code=ErrorCodes.DB_CONNECTION_FAILED.value,
                details={"db_path": path, "sqlite_error": str(e)},
            ) from e
        except Exception as e:
            if conn:
                conn.rollback()
>           raise DatabaseError(
                f"Unexpected database error: {e}",
                error_code="DB_UNEXPECTED_ERROR",
                details={"db_path": path, "original_error": str(e)},
            ) from e
E           wlan_tool.exceptions.DatabaseError: WLANToolError: Unexpected database error: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'} (Code: DB_UNEXPECTED_ERROR) | Details: {'db_path': '/tmp/tmplj6_zbtt.db', 'original_error': "WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}"}

wlan_tool/storage/database.py:113: DatabaseError
---------------------------- Captured stdout setup -----------------------------
2025-11-28 14:45:26,447 | DEBUG    | Starting operation: database_migration
2025-11-28 14:45:26,448 | DEBUG    | Starting operation: database_connection
2025-11-28 14:45:26,469 | INFO     | Current DB version: 0. Looking for migrations...
2025-11-28 14:45:26,469 | INFO     | Applying migration: 001_initial_schema.sql (Version 1)
2025-11-28 14:45:26,478 | INFO     | DB successfully migrated to version 1
2025-11-28 14:45:26,478 | INFO     | Applying migration: 002_add_dns_table.sql (Version 2)
2025-11-28 14:45:26,479 | INFO     | DB successfully migrated to version 2
2025-11-28 14:45:26,479 | INFO     | Applying migration: 003_add_network_info.sql (Version 3)
2025-11-28 14:45:26,481 | INFO     | DB successfully migrated to version 3
2025-11-28 14:45:26,481 | INFO     | Applying migration: 004_add_indexes.sql (Version 4)
2025-11-28 14:45:26,483 | INFO     | DB successfully migrated to version 4
2025-11-28 14:45:26,505 | INFO     | Database is up to date.
------------------------------ Captured log setup ------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_migration
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
INFO     wlan_tool.storage.database:database.py:157 Current DB version: 0. Looking for migrations...
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 001_initial_schema.sql (Version 1)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 1
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 002_add_dns_table.sql (Version 2)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 2
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 003_add_network_info.sql (Version 3)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 3
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 004_add_indexes.sql (Version 4)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 4
INFO     wlan_tool.storage.database:database.py:204 Database is up to date.
----------------------------- Captured stdout call -----------------------------
2025-11-28 14:45:26,511 | DEBUG    | Starting operation: database_connection
2025-11-28 14:45:26,513 | ERROR    | Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
2025-11-28 14:45:26,514 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/Ai_agent/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/Ai_agent/hacking/pytest/test_performance.py", line 325, in test_database_write_performance
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/Ai_agent/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/Ai_agent/hacking/pytest/test_performance.py", line 325, in test_database_write_performance
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'
____________ TestDatabasePerformance.test_database_read_performance ____________

self = <test_performance.TestDatabasePerformance object at 0x7f64f824d0>
temp_db_file = '/tmp/tmpz7br_f05.db'

    def test_database_read_performance(self, temp_db_file):
        """Test Datenbank-Lese-Performance."""
        # Schreibe Test-Events
        events = []
        for i in range(1000):
            event = {
                'ts': time.time() + i,
                'type': 'beacon' if i % 2 == 0 else 'probe_req',
                'bssid': f'08:96:d7:1a:21:{i % 100:02x}',
                'ssid': f'SSID_{i % 50}',
                'rssi': -50 - (i % 50),
                'channel': (i % 13) + 1
            }
            events.append(event)
    
        with database.db_conn_ctx(temp_db_file) as conn:
            for event in events:
>               database.add_event(conn, event)
E               AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

pytest/test_performance.py:351: AttributeError

The above exception was the direct cause of the following exception:

path = '/tmp/tmpz7br_f05.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
>           with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):

wlan_tool/storage/database.py:68: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.exceptions.ErrorContext object at 0x7f5ccfe650>
exc_type = <class 'AttributeError'>
exc_val = AttributeError("module 'wlan_tool.storage.database' has no attribute 'add_event'")
exc_tb = <traceback object at 0x7f5ccfe5c0>

    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type is not None:
            error_msg = f"Error in {self.operation}: {exc_val}"
    
            if isinstance(exc_val, WLANToolError):
                error_msg += f" (Code: {exc_val.error_code})"
                if exc_val.details:
                    error_msg += f" | Details: {exc_val.details}"
            else:
                error_msg += f" | Type: {exc_type.__name__}"
    
            self.logger.log(self.log_level, error_msg)
            self.logger.debug(f"Traceback: {traceback.format_exc()}")
    
            # Konvertiere zu WLANToolError falls nötig
            if not isinstance(exc_val, WLANToolError):
                wlan_error = WLANToolError(
                    message=str(exc_val),
                    error_code=self.error_code or "CONTEXT_ERROR",
                    details={
                        "operation": self.operation,
                        "original_type": exc_type.__name__,
                    },
                )
>               raise wlan_error from exc_val
E               wlan_tool.exceptions.WLANToolError: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}

wlan_tool/exceptions.py:313: WLANToolError

The above exception was the direct cause of the following exception:

self = <test_performance.TestDatabasePerformance object at 0x7f64f824d0>
temp_db_file = '/tmp/tmpz7br_f05.db'

    def test_database_read_performance(self, temp_db_file):
        """Test Datenbank-Lese-Performance."""
        # Schreibe Test-Events
        events = []
        for i in range(1000):
            event = {
                'ts': time.time() + i,
                'type': 'beacon' if i % 2 == 0 else 'probe_req',
                'bssid': f'08:96:d7:1a:21:{i % 100:02x}',
                'ssid': f'SSID_{i % 50}',
                'rssi': -50 - (i % 50),
                'channel': (i % 13) + 1
            }
            events.append(event)
    
>       with database.db_conn_ctx(temp_db_file) as conn:

pytest/test_performance.py:349: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../.pyenv/versions/3.11.9/lib/python3.11/contextlib.py:158: in __exit__
    self.gen.throw(typ, value, traceback)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

path = '/tmp/tmpz7br_f05.db'

    @contextmanager
    def db_conn_ctx(path: str):
        """Context Manager für Datenbankverbindungen mit Fehlerbehandlung."""
        conn = None
        try:
            with ErrorContext("database_connection", "DB_CONNECTION_ERROR"):
                # Validiere Datenbankpfad
                if not _validate_file_path(path):
                    raise ValidationError(
                        f"Invalid database path: {path}",
                        error_code="INVALID_DB_PATH",
                        details={"db_path": path},
                    )
    
                # Erstelle Verzeichnis falls nötig
                db_dir = Path(path).parent
                if not db_dir.exists():
                    try:
                        db_dir.mkdir(parents=True, exist_ok=True)
                    except OSError as e:
                        raise FileSystemError(
                            f"Cannot create database directory: {db_dir}",
                            error_code="DB_DIR_CREATION_FAILED",
                            details={"directory": str(db_dir), "original_error": str(e)},
                        ) from e
    
                # Verbinde zur Datenbank
                conn = sqlite3.connect(path, timeout=Constants.DB_CONNECTION_TIMEOUT)
                conn.row_factory = sqlite3.Row
    
                # Setze pragmas für bessere Performance und Fehlerbehandlung
                conn.execute("PRAGMA foreign_keys = ON")
                conn.execute("PRAGMA journal_mode = WAL")
                conn.execute("PRAGMA synchronous = NORMAL")
                conn.execute("PRAGMA cache_size = 10000")
                conn.execute("PRAGMA temp_store = MEMORY")
    
                yield conn
    
        except sqlite3.Error as e:
            if conn:
                conn.rollback()
            raise DatabaseError(
                get_error_message(ErrorCodes.DB_CONNECTION_FAILED, details=str(e)),
                error_code=ErrorCodes.DB_CONNECTION_FAILED.value,
                details={"db_path": path, "sqlite_error": str(e)},
            ) from e
        except Exception as e:
            if conn:
                conn.rollback()
>           raise DatabaseError(
                f"Unexpected database error: {e}",
                error_code="DB_UNEXPECTED_ERROR",
                details={"db_path": path, "original_error": str(e)},
            ) from e
E           wlan_tool.exceptions.DatabaseError: WLANToolError: Unexpected database error: WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'} (Code: DB_UNEXPECTED_ERROR) | Details: {'db_path': '/tmp/tmpz7br_f05.db', 'original_error': "WLANToolError: module 'wlan_tool.storage.database' has no attribute 'add_event' (Code: DB_CONNECTION_ERROR) | Details: {'operation': 'database_connection', 'original_type': 'AttributeError'}"}

wlan_tool/storage/database.py:113: DatabaseError
---------------------------- Captured stdout setup -----------------------------
2025-11-28 14:45:27,133 | DEBUG    | Starting operation: database_migration
2025-11-28 14:45:27,134 | DEBUG    | Starting operation: database_connection
2025-11-28 14:45:27,148 | INFO     | Current DB version: 0. Looking for migrations...
2025-11-28 14:45:27,149 | INFO     | Applying migration: 001_initial_schema.sql (Version 1)
2025-11-28 14:45:27,159 | INFO     | DB successfully migrated to version 1
2025-11-28 14:45:27,159 | INFO     | Applying migration: 002_add_dns_table.sql (Version 2)
2025-11-28 14:45:27,160 | INFO     | DB successfully migrated to version 2
2025-11-28 14:45:27,161 | INFO     | Applying migration: 003_add_network_info.sql (Version 3)
2025-11-28 14:45:27,162 | INFO     | DB successfully migrated to version 3
2025-11-28 14:45:27,163 | INFO     | Applying migration: 004_add_indexes.sql (Version 4)
2025-11-28 14:45:27,164 | INFO     | DB successfully migrated to version 4
2025-11-28 14:45:27,186 | INFO     | Database is up to date.
------------------------------ Captured log setup ------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_migration
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
INFO     wlan_tool.storage.database:database.py:157 Current DB version: 0. Looking for migrations...
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 001_initial_schema.sql (Version 1)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 1
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 002_add_dns_table.sql (Version 2)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 2
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 003_add_network_info.sql (Version 3)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 3
INFO     wlan_tool.storage.database:database.py:165 Applying migration: 004_add_indexes.sql (Version 4)
INFO     wlan_tool.storage.database:database.py:176 DB successfully migrated to version 4
INFO     wlan_tool.storage.database:database.py:204 Database is up to date.
----------------------------- Captured stdout call -----------------------------
2025-11-28 14:45:27,192 | DEBUG    | Starting operation: database_connection
2025-11-28 14:45:27,194 | ERROR    | Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
2025-11-28 14:45:27,195 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/Ai_agent/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/Ai_agent/hacking/pytest/test_performance.py", line 351, in test_database_read_performance
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: database_connection
ERROR    wlan_tool.exceptions:exceptions.py:300 Error in database_connection: module 'wlan_tool.storage.database' has no attribute 'add_event' | Type: AttributeError
DEBUG    wlan_tool.exceptions:exceptions.py:301 Traceback: Traceback (most recent call last):
  File "/home/pi/Ai_agent/hacking/wlan_tool/storage/database.py", line 100, in db_conn_ctx
    yield conn
  File "/home/pi/Ai_agent/hacking/pytest/test_performance.py", line 351, in test_database_read_performance
    database.add_event(conn, event)
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'
________ TestScalabilityPerformance.test_scalability_with_dataset_size _________

self = <test_performance.TestScalabilityPerformance object at 0x7f64f82ed0>

    def test_scalability_with_dataset_size(self):
        """Test Skalierbarkeit mit Datensatz-Größe."""
        dataset_sizes = [100, 500, 1000]
        processing_times = []
    
        for size in dataset_sizes:
            # Erstelle State mit gegebener Größe
            state = WifiAnalysisState()
    
            for i in range(size):
                mac = f"aa:bb:cc:dd:ee:{i:04x}"
>               client = state.clients[mac] = state.clients.get(mac, type(state).__dict__['clients'].__class__())()
E               KeyError: 'clients'

pytest/test_performance.py:440: KeyError
_______________ TestCLIModule.test_print_client_cluster_results ________________

self = <test_presentation.TestCLIModule object at 0x7f64f95510>
mock_console = <MagicMock id='547014911632'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f5d25cf50>

    def test_print_client_cluster_results(self, mock_console, populated_state):
        """Test Client-Cluster-Ergebnis-Ausgabe."""
        from wlan_tool.analysis import logic as analysis
    
        # Erstelle Test-Cluster-Daten
        clustered_df, feature_df = analysis.cluster_clients(populated_state, n_clusters=2)
    
        if clustered_df is not None and not clustered_df.empty:
            # Mock args
            args = MagicMock()
            args.cluster_clients = 2
            args.cluster_algo = "kmeans"
            args.no_mac_correlation = False
    
            # Sollte nicht crashen
>           cli.print_client_cluster_results(args, populated_state, mock_console)

pytest/test_presentation.py:38: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = <MagicMock id='547034709456'>
state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f5d25cf50>
console = <MagicMock id='547014911632'>

    def print_client_cluster_results(args, state, console):
        """Führt das Client-Clustering aus und gibt die Ergebnisse formatiert aus."""
        clustered_df, feature_df = analysis.cluster_clients(
            state,
            n_clusters=args.cluster_clients,
            algo=args.cluster_algo,
            use_correlation=(not args.no_mac_correlation),
        )
        """Gibt die Ergebnisse des Client-Clusterings formatiert aus."""
        if clustered_df is not None and not clustered_df.empty:
            console.print(
                "[yellow]Keine Client-Daten für das Clustering gefunden.[/yellow]"
            )
            return
    
>       title_correlation_str = "& Korrelation" if use_correlation else "& ohne Korrelation"
E       NameError: name 'use_correlation' is not defined

wlan_tool/presentation/cli.py:34: NameError
---------------------------- Captured stdout setup -----------------------------
2025-11-28 14:45:27,444 | INFO     | Baue/Aktualisiere Zustand aus Event-Stream auf...
2025-11-28 14:45:27,445 | INFO     | Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
------------------------------ Captured log setup ------------------------------
INFO     wlan_tool.storage.state:state.py:52 Baue/Aktualisiere Zustand aus Event-Stream auf...
INFO     wlan_tool.storage.state:state.py:57 Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
----------------------------- Captured stdout call -----------------------------
2025-11-28 14:45:27,446 | DEBUG    | Starting operation: client_clustering
2025-11-28 14:45:27,447 | INFO     | Korreliere randomisierte MACs vor der Feature-Extraktion...
2025-11-28 14:45:27,447 | INFO     | Fand 0 Gruppen von potenziell zusammengehörigen randomisierten MACs.
2025-11-28 14:45:27,447 | DEBUG    | Starting operation: client_features_extraction
2025-11-28 14:45:27,447 | DEBUG    | Starting operation: client_features_extraction
2025-11-28 14:45:27,447 | DEBUG    | Starting operation: client_features_extraction
2025-11-28 14:45:27,460 | INFO     | Wende manuelle Feature-Gewichtungen für Standard-Clustering an...
2025-11-28 14:45:27,461 | DEBUG    | Gewichte Feature 'supports_11ax' mit Faktor 3.0.
2025-11-28 14:45:27,464 | DEBUG    | Gewichte Feature 'supports_11ac' mit Faktor 2.0.
2025-11-28 14:45:27,467 | DEBUG    | Gewichte Feature 'has_apple_ie' mit Faktor 2.5.
2025-11-28 14:45:27,470 | DEBUG    | Gewichte Feature 'has_ms_ie' mit Faktor 2.0.
2025-11-28 14:45:27,472 | DEBUG    | Gewichte Feature 'mimo_streams' mit Faktor 1.5.
2025-11-28 14:45:27,475 | DEBUG    | Gewichte Feature 'is_randomized_mac' mit Faktor 1.2.
2025-11-28 14:45:27,478 | DEBUG    | Gewichte Feature 'was_in_powersave' mit Faktor 1.2.
2025-11-28 14:45:27,481 | DEBUG    | Gewichte Feature 'probe_count' mit Faktor 1.0.
2025-11-28 14:45:27,484 | DEBUG    | Gewichte Feature 'seen_with_ap_count' mit Faktor 1.0.
2025-11-28 14:45:27,487 | INFO     | Verwende KMeans für das Clustering...
2025-11-28 14:45:27,494 | ERROR    | Unexpected error in cluster_clients: cluster_clients() got an unexpected keyword argument 'use_correlation'
2025-11-28 14:45:27,495 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/Ai_agent/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
TypeError: cluster_clients() got an unexpected keyword argument 'use_correlation'

------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_clustering
INFO     wlan_tool.analysis.logic:logic.py:396 Korreliere randomisierte MACs vor der Feature-Extraktion...
INFO     wlan_tool.analysis.logic:logic.py:807 Fand 0 Gruppen von potenziell zusammengehörigen randomisierten MACs.
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_features_extraction
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_features_extraction
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: client_features_extraction
INFO     wlan_tool.analysis.logic:logic.py:584 Wende manuelle Feature-Gewichtungen für Standard-Clustering an...
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'supports_11ax' mit Faktor 3.0.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'supports_11ac' mit Faktor 2.0.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'has_apple_ie' mit Faktor 2.5.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'has_ms_ie' mit Faktor 2.0.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'mimo_streams' mit Faktor 1.5.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'is_randomized_mac' mit Faktor 1.2.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'was_in_powersave' mit Faktor 1.2.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'probe_count' mit Faktor 1.0.
DEBUG    wlan_tool.analysis.logic:logic.py:594 Gewichte Feature 'seen_with_ap_count' mit Faktor 1.0.
INFO     wlan_tool.analysis.logic:logic.py:609 Verwende KMeans für das Clustering...
ERROR    wlan_tool.analysis.logic:exceptions.py:165 Unexpected error in cluster_clients: cluster_clients() got an unexpected keyword argument 'use_correlation'
DEBUG    wlan_tool.analysis.logic:exceptions.py:166 Traceback: Traceback (most recent call last):
  File "/home/pi/Ai_agent/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
TypeError: cluster_clients() got an unexpected keyword argument 'use_correlation'
________ TestCLIEdgeCases.test_print_client_cluster_results_empty_data _________

self = <test_presentation.TestCLIEdgeCases object at 0x7f64fa5910>
mock_console = <MagicMock id='547014186832'>
populated_state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f5cecc390>

    def test_print_client_cluster_results_empty_data(self, mock_console, populated_state):
        """Test Client-Cluster-Ausgabe mit leeren Daten."""
        # Erstelle leeren State
        empty_state = WifiAnalysisState()
    
        args = MagicMock()
        args.cluster_clients = 2
        args.cluster_algo = "kmeans"
        args.no_mac_correlation = False
    
        # Sollte nicht crashen
>       cli.print_client_cluster_results(args, empty_state, mock_console)

pytest/test_presentation.py:281: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = <MagicMock id='547014196176'>
state = <wlan_tool.storage.state.WifiAnalysisState object at 0x7f5cecca50>
console = <MagicMock id='547014186832'>

    def print_client_cluster_results(args, state, console):
        """Führt das Client-Clustering aus und gibt die Ergebnisse formatiert aus."""
        clustered_df, feature_df = analysis.cluster_clients(
            state,
            n_clusters=args.cluster_clients,
            algo=args.cluster_algo,
            use_correlation=(not args.no_mac_correlation),
        )
        """Gibt die Ergebnisse des Client-Clusterings formatiert aus."""
        if clustered_df is not None and not clustered_df.empty:
            console.print(
                "[yellow]Keine Client-Daten für das Clustering gefunden.[/yellow]"
            )
            return
    
>       title_correlation_str = "& Korrelation" if use_correlation else "& ohne Korrelation"
E       NameError: name 'use_correlation' is not defined

wlan_tool/presentation/cli.py:34: NameError
---------------------------- Captured stdout setup -----------------------------
2025-11-28 14:45:27,748 | INFO     | Baue/Aktualisiere Zustand aus Event-Stream auf...
2025-11-28 14:45:27,748 | INFO     | Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
------------------------------ Captured log setup ------------------------------
INFO     wlan_tool.storage.state:state.py:52 Baue/Aktualisiere Zustand aus Event-Stream auf...
INFO     wlan_tool.storage.state:state.py:57 Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
----------------------------- Captured stdout call -----------------------------
2025-11-28 14:45:27,751 | ERROR    | Unexpected error in cluster_clients: cluster_clients() got an unexpected keyword argument 'use_correlation'
2025-11-28 14:45:27,752 | DEBUG    | Traceback: Traceback (most recent call last):
  File "/home/pi/Ai_agent/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
TypeError: cluster_clients() got an unexpected keyword argument 'use_correlation'

------------------------------ Captured log call -------------------------------
ERROR    wlan_tool.analysis.logic:exceptions.py:165 Unexpected error in cluster_clients: cluster_clients() got an unexpected keyword argument 'use_correlation'
DEBUG    wlan_tool.analysis.logic:exceptions.py:166 Traceback: Traceback (most recent call last):
  File "/home/pi/Ai_agent/hacking/wlan_tool/exceptions.py", line 149, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
TypeError: cluster_clients() got an unexpected keyword argument 'use_correlation'
_________________ TestPerformance.test_large_dataset_handling __________________

self = <test_presentation.TestPerformance object at 0x7f64fa7950>
mock_console = <MagicMock id='547019565392'>

    def test_large_dataset_handling(self, mock_console):
        """Test mit großen Datensätzen."""
        # Erstelle State mit vielen Clients
        state = WifiAnalysisState()
    
        for i in range(100):
            client = ClientState(mac=f"aa:bb:cc:dd:ee:{i:02x}")
            client.probes = {f"SSID_{i}"}
            client.all_packet_ts = np.array([time.time() - 100, time.time()])
>           client.rssi_w = Welford()
E           NameError: name 'Welford' is not defined

pytest/test_presentation.py:366: NameError
_________________ TestAPState.test_ap_state_update_from_beacon _________________

self = <test_storage.TestAPState object at 0x7f64fb83d0>

    def test_ap_state_update_from_beacon(self):
        """Test APState-Update aus Beacon."""
        ap = APState(bssid="aa:bb:cc:dd:ee:ff", ssid="TestAP")
        event = {
            'ts': time.time(),
            'type': 'beacon',
            'bssid': 'aa:bb:cc:dd:ee:ff',
            'ssid': 'TestAP',
            'rssi': -50,
            'channel': 6,
            'beacon_interval': 102
        }
    
>       ap.update_from_event(event)
E       AttributeError: 'APState' object has no attribute 'update_from_event'

pytest/test_storage.py:141: AttributeError
________________ TestWifiAnalysisState.test_state_ssid_mapping _________________

self = <test_storage.TestWifiAnalysisState object at 0x7f64fbad10>
sample_events = [{'beacon_interval': 102, 'bssid': '08:96:d7:1a:21:1c', 'cap': 17, 'channel': 6, ...}, {'client': 'a8:51:ab:0c:b9:e9',...-91, ...}, {'client': 'b2:87:23:15:7f:f2', 'ie_order_hash': 67890, 'ies': {0: ['MyOtherWLAN']}, 'rssi': -70, ...}, ...]

    def test_state_ssid_mapping(self, sample_events):
        """Test SSID-Mapping-Funktionalität."""
        state = WifiAnalysisState()
        state.build_from_events(sample_events)
    
        # Teste SSID-Map
        assert 'MyTestWLAN' in state.ssid_map
        ssid_info = state.ssid_map['MyTestWLAN']
        assert '08:96:d7:1a:21:1c' in ssid_info['bssids']
>       assert 'a8:51:ab:0c:b9:e9' in ssid_info['sources']['probe_req']
E       AssertionError: assert 'a8:51:ab:0c:b9:e9' in set()

pytest/test_storage.py:217: AssertionError
----------------------------- Captured stdout call -----------------------------
2025-11-28 14:45:27,958 | INFO     | Baue/Aktualisiere Zustand aus Event-Stream auf...
2025-11-28 14:45:27,959 | INFO     | Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
------------------------------ Captured log call -------------------------------
INFO     wlan_tool.storage.state:state.py:52 Baue/Aktualisiere Zustand aus Event-Stream auf...
INFO     wlan_tool.storage.state:state.py:57 Zustand aus 7 Events aufgebaut/aktualisiert: APs=1, Clients=3, SSIDs=1
_____________________ TestDatabaseModule.test_fetch_events _____________________

self = <test_storage.TestDatabaseModule object at 0x7f64fc4310>
in_memory_db = <sqlite3.Connection object at 0x7f87c425c0>
sample_events = [{'beacon_interval': 102, 'bssid': '08:96:d7:1a:21:1c', 'cap': 17, 'channel': 6, ...}, {'client': 'a8:51:ab:0c:b9:e9',...-91, ...}, {'client': 'b2:87:23:15:7f:f2', 'ie_order_hash': 67890, 'ies': {0: ['MyOtherWLAN']}, 'rssi': -70, ...}, ...]

    def test_fetch_events(self, in_memory_db, sample_events):
        """Test Event-Abruf."""
        conn = in_memory_db
    
        # Schreibe Test-Events
        for event in sample_events[:2]:
>           database.add_event(conn, event)
E           AttributeError: module 'wlan_tool.storage.database' has no attribute 'add_event'

pytest/test_storage.py:263: AttributeError
______________________ TestDatabaseModule.test_add_label _______________________

self = <test_storage.TestDatabaseModule object at 0x7f64fc49d0>
in_memory_db = <sqlite3.Connection object at 0x7f87c418a0>

    def test_add_label(self, in_memory_db):
        """Test Label-Hinzufügung."""
        conn = in_memory_db
    
        database.add_label(conn, "TestSSID", "aa:bb:cc:dd:ee:ff", 1)
    
        cursor = conn.execute("SELECT * FROM labels WHERE ssid = ? AND bssid = ?",
                            ("TestSSID", "aa:bb:cc:dd:ee:ff"))
        result = cursor.fetchone()
        assert result is not None
>       assert result[2] == 1  # label = 1
E       AssertionError: assert 'aa:bb:cc:dd:ee:ff' == 1

pytest/test_storage.py:280: AssertionError
----------------------------- Captured stdout call -----------------------------
2025-11-28 14:45:28,669 | DEBUG    | Starting operation: add_label
2025-11-28 14:45:28,670 | DEBUG    | Added label: TestSSID -> aa:bb:cc:dd:ee:ff = 1 (source: ui)
------------------------------ Captured log call -------------------------------
DEBUG    wlan_tool.exceptions:exceptions.py:286 Starting operation: add_label
DEBUG    wlan_tool.storage.database:database.py:618 Added label: TestSSID -> aa:bb:cc:dd:ee:ff = 1 (source: ui)
________________ TestOUIFunctions.test_lookup_vendor_apple_mac _________________

self = <test_utils.TestOUIFunctions object at 0x7f64fc6b10>

    def test_lookup_vendor_apple_mac(self):
        """Test Vendor-Lookup für Apple-MAC."""
        # Apple MAC-Adresse
        mac = "a8:51:ab:0c:b9:e9"
        vendor = utils.lookup_vendor(mac)
    
>       assert vendor is not None
E       assert None is not None

pytest/test_utils.py:26: AssertionError
_______________ TestOUIFunctions.test_lookup_vendor_unknown_mac ________________

self = <test_utils.TestOUIFunctions object at 0x7f64fc7190>

    def test_lookup_vendor_unknown_mac(self):
        """Test Vendor-Lookup für unbekannte MAC."""
        # Unbekannte MAC-Adresse
        mac = "ff:ff:ff:ff:ff:ff"
        vendor = utils.lookup_vendor(mac)
    
        # Sollte None oder "Unknown" zurückgeben
>       assert vendor is None or vendor == "Unknown"
E       AssertionError: assert ('(Lokal / Randomisiert)' is None or '(Lokal / Randomisiert)' == 'Unknown'
E         
E         - Unknown
E         + (Lokal / Randomisiert))

pytest/test_utils.py:45: AssertionError
_________________ TestUtilityFunctions.test_is_local_admin_mac _________________

self = <test_utils.TestUtilityFunctions object at 0x7f64fd7850>

    def test_is_local_admin_mac(self):
        """Test lokale Admin-MAC-Erkennung."""
        # Lokale Admin-MAC
        assert utils.is_local_admin_mac("02:00:00:00:00:00") is True
        assert utils.is_local_admin_mac("06:00:00:00:00:00") is True
    
        # Globale MAC
        assert utils.is_local_admin_mac("00:00:00:00:00:00") is False
>       assert utils.is_local_admin_mac("aa:bb:cc:dd:ee:ff") is False
E       AssertionError: assert True is False
E        +  where True = <function is_local_admin_mac at 0x7f86ec2ca0>('aa:bb:cc:dd:ee:ff')
E        +    where <function is_local_admin_mac at 0x7f86ec2ca0> = utils.is_local_admin_mac

pytest/test_utils.py:172: AssertionError
___________________ TestUtilityFunctions.test_is_valid_bssid ___________________

self = <test_utils.TestUtilityFunctions object at 0x7f64fd7e50>

    def test_is_valid_bssid(self):
        """Test BSSID-Validierung."""
        # Gültige BSSID
        assert utils.is_valid_bssid("aa:bb:cc:dd:ee:ff") is True
        assert utils.is_valid_bssid("00:11:22:33:44:55") is True
    
        # Ungültige BSSID
        assert utils.is_valid_bssid("") is False
        assert utils.is_valid_bssid("invalid") is False
>       assert utils.is_valid_bssid("aa:bb:cc:dd:ee") is False  # Zu kurz
E       AssertionError: assert True is False
E        +  where True = <function is_valid_bssid at 0x7f86ec2d40>('aa:bb:cc:dd:ee')
E        +    where <function is_valid_bssid at 0x7f86ec2d40> = utils.is_valid_bssid

pytest/test_utils.py:183: AssertionError
________________ TestUtilityFunctions.test_ie_fingerprint_hash _________________

self = <test_utils.TestUtilityFunctions object at 0x7f64fe4490>

    def test_ie_fingerprint_hash(self):
        """Test IE-Fingerprint-Hash."""
        ies = {
            0: ['TestSSID'],
            1: ['82848b96'],
            48: ['0100000fac040100000fac020100000fac028c00']
        }
    
        hash_value = utils.ie_fingerprint_hash(ies)
    
        assert isinstance(hash_value, str)
>       assert len(hash_value) == 32  # MD5-Hash-Länge
E       AssertionError: assert 40 == 32
E        +  where 40 = len('fb3a54a0b7ca1a713fd927a194ff191b7de45566')

pytest/test_utils.py:197: AssertionError
_____________ TestUtilityFunctions.test_ie_fingerprint_hash_empty ______________

self = <test_utils.TestUtilityFunctions object at 0x7f64fd7b50>

    def test_ie_fingerprint_hash_empty(self):
        """Test IE-Fingerprint-Hash mit leeren IEs."""
        ies = {}
    
        hash_value = utils.ie_fingerprint_hash(ies)
    
>       assert hash_value is None or hash_value == ""
E       AssertionError: assert ('da39a3ee5e6b4b0d3255bfef95601890afd80709' is None or 'da39a3ee5e6b...01890afd80709' == ''
E         
E         + da39a3ee5e6b4b0d3255bfef95601890afd80709)

pytest/test_utils.py:206: AssertionError
_________________ TestConfigFunctions.test_load_config_default _________________

self = <test_utils.TestConfigFunctions object at 0x7f64fd6850>

    def test_load_config_default(self):
        """Test Konfigurations-Laden (Standard)."""
>       config_data = utils.load_config()
E       TypeError: load_config() missing 1 required positional argument: 'profile'

pytest/test_utils.py:227: TypeError
____________ TestConfigFunctions.test_load_config_specific_profile _____________

self = <test_utils.TestConfigFunctions object at 0x7f64fd5810>

    def test_load_config_specific_profile(self):
        """Test Konfigurations-Laden (spezifisches Profil)."""
        # Erstelle temporäre Konfigurationsdatei
        test_config = {
            "capture": {"interface": "test0", "duration": 60},
            "database": {"path": "test.db"}
        }
    
        with tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False) as f:
            yaml.dump(test_config, f)
            config_path = f.name
    
        try:
>           with patch('wlan_tool.utils.CONFIG_PATH', config_path):

pytest/test_utils.py:246: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f5c8a2fd0>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'wlan_tool.utils' from '/home/pi/Ai_agent/hacking/wlan_tool/utils.py'> does not have the attribute 'CONFIG_PATH'

../../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1419: AttributeError
______________ TestConfigFunctions.test_load_config_missing_file _______________

self = <test_utils.TestConfigFunctions object at 0x7f64fd54d0>

    def test_load_config_missing_file(self):
        """Test Konfigurations-Laden (fehlende Datei)."""
>       with patch('wlan_tool.utils.CONFIG_PATH', Path("/nonexistent/config.yaml")):

pytest/test_utils.py:256: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f5c990590>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'wlan_tool.utils' from '/home/pi/Ai_agent/hacking/wlan_tool/utils.py'> does not have the attribute 'CONFIG_PATH'

../../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1419: AttributeError
________________ TestEdgeCases.test_ie_fingerprint_hash_unicode ________________

self = <test_utils.TestEdgeCases object at 0x7f64fe5fd0>

    def test_ie_fingerprint_hash_unicode(self):
        """Test IE-Fingerprint-Hash mit Unicode-Daten."""
        ies = {0: ['TestSSID_äöü']}  # Unicode-Zeichen
    
        hash_value = utils.ie_fingerprint_hash(ies)
    
        assert isinstance(hash_value, str)
>       assert len(hash_value) == 32
E       AssertionError: assert 40 == 32
E        +  where 40 = len('758ed0819e647ff1683744b0bc9b1ff7470f6d37')

pytest/test_utils.py:357: AssertionError
_____________ TestEdgeCases.test_config_loading_with_invalid_yaml ______________

self = <test_utils.TestEdgeCases object at 0x7f64fe6bd0>

    def test_config_loading_with_invalid_yaml(self):
        """Test Konfigurations-Laden mit ungültigem YAML."""
        invalid_yaml = "invalid: yaml: content: ["
    
        with tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False) as f:
            f.write(invalid_yaml)
            config_path = f.name
    
        try:
>           with patch('wlan_tool.utils.CONFIG_PATH', config_path):

pytest/test_utils.py:379: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7f5c6fcc50>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'wlan_tool.utils' from '/home/pi/Ai_agent/hacking/wlan_tool/utils.py'> does not have the attribute 'CONFIG_PATH'

../../.pyenv/versions/3.11.9/lib/python3.11/unittest/mock.py:1419: AttributeError
__________ TestEndToEndWorkflow.test_complete_wifi_analysis_workflow ___________

self = <test_end_to_end.TestEndToEndWorkflow object at 0x7f644a3190>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]
temp_dir = PosixPath('/tmp/tmp251ncwfy')

    @pytest.mark.integration
    @pytest.mark.slow
    def test_complete_wifi_analysis_workflow(self, large_dataset, temp_dir):
        """Test des kompletten WLAN-Analyse-Workflows."""
        # 1. Datenverarbeitung
        processor = WiFiDataProcessor()
        processed_data = processor.process_data(large_dataset)
    
        assert len(processed_data) == len(large_dataset)
        assert "processed_timestamp" in processed_data.columns
    
        # 2. Feature-Extraktion
        extractor = FeatureExtractor()
        features = extractor.extract_features(processed_data)
    
        assert features.shape[0] == len(processed_data)
        assert features.shape[1] > 0
    
        # 3. Clustering-Analyse
        analyzer = ClusteringAnalyzer()
>       labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)

tests/integration/test_end_to_end.py:42: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1064: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1446: in fit
    X = validate_data(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2944: in validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1107: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:120: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[-1.15579349,  0.        ,  0.        , ...,  0.        ,
         0.15614176, -0.97725852],
       [-1.1557934...176, -0.97725852],
       [ 1.35680105,  0.        ,  0.        , ...,  0.        ,
         0.15614176,  1.02327069]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:169: ValueError
____________ TestEndToEndWorkflow.test_plugin_integration_workflow _____________

self = <test_end_to_end.TestEndToEndWorkflow object at 0x7f63f37390>
sample_wifi_data =               timestamp device_id  ...  packet_count  bytes_transferred
0   2024-01-01 00:00:00  device_3  ...        ...15         206.754596
999 2024-01-01 16:39:00  device_1  ...           103         554.365485

[1000 rows x 11 columns]
temp_dir = PosixPath('/tmp/tmp_6h1zavy')

    @pytest.mark.integration
    def test_plugin_integration_workflow(self, sample_wifi_data, temp_dir):
        """Test der Plugin-Integration im Workflow."""
        from plugins import load_all_plugins
    
        # Plugins laden
        plugin_dir = Path("plugins")
        plugins = load_all_plugins(plugin_dir)
    
        assert len(plugins) > 0
    
        # Features extrahieren
        extractor = FeatureExtractor()
        features = extractor.extract_features(sample_wifi_data)
    
        # Jedes Plugin testen
        for plugin in plugins:
            # Plugin-Dependencies prüfen
>           if not plugin.validate_dependencies():
E           AttributeError: 'str' object has no attribute 'validate_dependencies'

tests/integration/test_end_to_end.py:101: AttributeError
----------------------------- Captured stdout call -----------------------------
2025-11-28 14:45:30,790 | INFO     | Plugin 'Advanced Clustering' v1.0.0 geladen
2025-11-28 14:45:30,795 | INFO     | Plugin 'Ensemble Models' v1.0.0 geladen
2025-11-28 14:45:30,798 | WARNING  | Dependencies ["umap-learn (No module named 'umap-learn')"] für Plugin 'UMAP Plot' nicht verfügbar
2025-11-28 14:45:30,798 | WARNING  | Plugin umap_plot hat fehlende Dependencies - wird trotzdem geladen
2025-11-28 14:45:30,798 | INFO     | Plugin 'UMAP Plot' v1.0.0 geladen
2025-11-28 14:45:30,807 | INFO     | Plugin 'Sankey Diagram' v1.0.0 geladen
2025-11-28 14:45:30,810 | WARNING  | PyTorch oder Gym nicht verfügbar: No module named 'gym'
2025-11-28 14:45:30,814 | WARNING  | Dependencies ["gym (No module named 'gym')"] für Plugin 'Reinforcement Learning' nicht verfügbar
2025-11-28 14:45:30,815 | WARNING  | Plugin reinforcement_learning hat fehlende Dependencies - wird trotzdem geladen
2025-11-28 14:45:30,815 | INFO     | Plugin 'Reinforcement Learning' v1.0.0 geladen
2025-11-28 14:45:30,817 | INFO     | Plugin 'Example_Plugin' v1.0.0 geladen
------------------------------ Captured log call -------------------------------
INFO     plugins:__init__.py:133 Plugin 'Advanced Clustering' v1.0.0 geladen
INFO     plugins:__init__.py:133 Plugin 'Ensemble Models' v1.0.0 geladen
WARNING  plugins:__init__.py:79 Dependencies ["umap-learn (No module named 'umap-learn')"] für Plugin 'UMAP Plot' nicht verfügbar
WARNING  plugins:__init__.py:108 Plugin umap_plot hat fehlende Dependencies - wird trotzdem geladen
INFO     plugins:__init__.py:133 Plugin 'UMAP Plot' v1.0.0 geladen
INFO     plugins:__init__.py:133 Plugin 'Sankey Diagram' v1.0.0 geladen
WARNING  root:plugin.py:28 PyTorch oder Gym nicht verfügbar: No module named 'gym'
WARNING  plugins:__init__.py:79 Dependencies ["gym (No module named 'gym')"] für Plugin 'Reinforcement Learning' nicht verfügbar
WARNING  plugins:__init__.py:108 Plugin reinforcement_learning hat fehlende Dependencies - wird trotzdem geladen
INFO     plugins:__init__.py:133 Plugin 'Reinforcement Learning' v1.0.0 geladen
INFO     plugins:__init__.py:133 Plugin 'Example_Plugin' v1.0.0 geladen
_____________ TestEndToEndWorkflow.test_data_pipeline_with_file_io _____________

self = <test_end_to_end.TestEndToEndWorkflow object at 0x7f63f37a90>
temp_dir = PosixPath('/tmp/tmpx0s7j5fq')

    @pytest.mark.integration
    def test_data_pipeline_with_file_io(self, temp_dir):
        """Test der Datenpipeline mit Datei-I/O."""
        # Test-Daten generieren
        n_samples = 1000
        test_data = pd.DataFrame(
            {
                "timestamp": pd.date_range(
                    "2024-01-01", periods=n_samples, freq="1min"
                ),
                "device_id": np.random.choice(
                    ["device_1", "device_2", "device_3"], n_samples
                ),
                "signal_strength": np.random.normal(-50, 10, n_samples),
                "frequency": np.random.choice([2.4, 5.0], n_samples),
                "channel": np.random.randint(1, 14, n_samples),
                "mac_address": [f"00:11:22:33:44:{i:02x}" for i in range(n_samples)],
                "ssid": np.random.choice(
                    ["WiFi_Home", "WiFi_Office", "Public_WiFi"], n_samples
                ),
                "encryption": np.random.choice(["WPA2", "WPA3", "Open"], n_samples),
                "data_rate": np.random.normal(54, 10, n_samples),
                "packet_count": np.random.poisson(100, n_samples),
                "bytes_transferred": np.random.exponential(1000, n_samples),
            }
        )
    
        # 1. Daten in CSV speichern
        input_file = temp_dir / "input_data.csv"
        test_data.to_csv(input_file, index=False)
    
        # 2. Daten laden und verarbeiten
        loaded_data = pd.read_csv(input_file)
        processor = WiFiDataProcessor()
        processed_data = processor.process_data(loaded_data)
    
        # 3. Features extrahieren
        extractor = FeatureExtractor()
        features = extractor.extract_features(processed_data)
    
        # 4. Clustering
        analyzer = ClusteringAnalyzer()
>       labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=3)

tests/integration/test_end_to_end.py:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1064: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1446: in fit
    X = validate_data(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2944: in validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1107: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:120: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[-1.62859019,  0.        ,  0.        , ...,  0.        ,
         0.        , -0.9900495 ],
       [-1.6285901...   ,  1.0100505 ],
       [ 1.69506325,  0.        ,  0.        , ...,  0.        ,
         0.        ,  1.0100505 ]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:169: ValueError
____________ TestEndToEndWorkflow.test_error_handling_and_recovery _____________

self = <test_end_to_end.TestEndToEndWorkflow object at 0x7f63f44210>
temp_dir = PosixPath('/tmp/tmpfty3u59o')

    @pytest.mark.integration
    def test_error_handling_and_recovery(self, temp_dir):
        """Test der Fehlerbehandlung und Wiederherstellung."""
        processor = WiFiDataProcessor()
        extractor = FeatureExtractor()
        analyzer = ClusteringAnalyzer()
    
        # Test mit ungültigen Daten
        invalid_data = pd.DataFrame(
            {
                "timestamp": ["invalid_date", "2024-01-01", "2024-01-02"],
                "signal_strength": [np.nan, -50, -60],
                "frequency": [1.0, 2.4, 5.0],  # Ungültige Frequenz
                "device_id": ["device_1", "device_2", "device_3"],
                "mac_address": [
                    "00:11:22:33:44:01",
                    "00:11:22:33:44:02",
                    "00:11:22:33:44:03",
                ],
                "ssid": ["WiFi_Home", "WiFi_Office", "Public_WiFi"],
                "encryption": ["WPA2", "WPA3", "Open"],
                "channel": [1, 6, 11],
                "data_rate": [54, 100, 54],
                "packet_count": [100, 200, 150],
                "bytes_transferred": [1000, 2000, 1500],
            }
        )
    
        # Verarbeitung sollte Fehler behandeln
        try:
            processed_data = processor.process_data(invalid_data)
            # Wenn erfolgreich, sollten ungültige Daten bereinigt sein
            assert len(processed_data) <= len(invalid_data)
        except Exception as e:
            # Fehler sollten informativ sein
            assert "Invalid" in str(e) or "Missing" in str(e) or "Unknown datetime" in str(e)
    
        # Test mit leeren Daten
        empty_data = pd.DataFrame()
    
        with pytest.raises(ValueError, match="Empty dataset"):
            processor.process_data(empty_data)
    
        # Test mit zu wenigen Features für Clustering
        minimal_features = np.random.randn(2, 1)  # Nur 2 Samples, 1 Feature
    
        with pytest.raises(ValueError, match="Not enough samples"):
>           analyzer.cluster_data(minimal_features, algorithm="kmeans", n_clusters=3)

tests/integration/test_end_to_end.py:220: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1064: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1456: in fit
    self._check_params_vs_input(X)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1396: in _check_params_vs_input
    super()._check_params_vs_input(X, default_n_init=10)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = KMeans(n_clusters=3, random_state=42)
X = array([[-0.70823632],
       [ 0.40086101]]), default_n_init = 10

    def _check_params_vs_input(self, X, default_n_init=None):
        # n_clusters
        if X.shape[0] < self.n_clusters:
>           raise ValueError(
                f"n_samples={X.shape[0]} should be >= n_clusters={self.n_clusters}."
            )
E           ValueError: n_samples=2 should be >= n_clusters=3.

.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:871: ValueError

During handling of the above exception, another exception occurred:

self = <test_end_to_end.TestEndToEndWorkflow object at 0x7f63f44210>
temp_dir = PosixPath('/tmp/tmpfty3u59o')

    @pytest.mark.integration
    def test_error_handling_and_recovery(self, temp_dir):
        """Test der Fehlerbehandlung und Wiederherstellung."""
        processor = WiFiDataProcessor()
        extractor = FeatureExtractor()
        analyzer = ClusteringAnalyzer()
    
        # Test mit ungültigen Daten
        invalid_data = pd.DataFrame(
            {
                "timestamp": ["invalid_date", "2024-01-01", "2024-01-02"],
                "signal_strength": [np.nan, -50, -60],
                "frequency": [1.0, 2.4, 5.0],  # Ungültige Frequenz
                "device_id": ["device_1", "device_2", "device_3"],
                "mac_address": [
                    "00:11:22:33:44:01",
                    "00:11:22:33:44:02",
                    "00:11:22:33:44:03",
                ],
                "ssid": ["WiFi_Home", "WiFi_Office", "Public_WiFi"],
                "encryption": ["WPA2", "WPA3", "Open"],
                "channel": [1, 6, 11],
                "data_rate": [54, 100, 54],
                "packet_count": [100, 200, 150],
                "bytes_transferred": [1000, 2000, 1500],
            }
        )
    
        # Verarbeitung sollte Fehler behandeln
        try:
            processed_data = processor.process_data(invalid_data)
            # Wenn erfolgreich, sollten ungültige Daten bereinigt sein
            assert len(processed_data) <= len(invalid_data)
        except Exception as e:
            # Fehler sollten informativ sein
            assert "Invalid" in str(e) or "Missing" in str(e) or "Unknown datetime" in str(e)
    
        # Test mit leeren Daten
        empty_data = pd.DataFrame()
    
        with pytest.raises(ValueError, match="Empty dataset"):
            processor.process_data(empty_data)
    
        # Test mit zu wenigen Features für Clustering
        minimal_features = np.random.randn(2, 1)  # Nur 2 Samples, 1 Feature
    
>       with pytest.raises(ValueError, match="Not enough samples"):
E       AssertionError: Regex pattern did not match.
E        Regex: 'Not enough samples'
E        Input: 'n_samples=2 should be >= n_clusters=3.'

tests/integration/test_end_to_end.py:219: AssertionError
_______________ TestEndToEndWorkflow.test_performance_under_load _______________

self = <test_end_to_end.TestEndToEndWorkflow object at 0x7f63f44910>
temp_dir = PosixPath('/tmp/tmph4rbfqbr')

    @pytest.mark.integration
    def test_performance_under_load(self, temp_dir):
        """Test der Performance unter Last."""
        import time
    
        # Große Datenmenge
        n_samples = 50000
        large_data = pd.DataFrame(
            {
                "timestamp": pd.date_range("2024-01-01", periods=n_samples, freq="1s"),
                "device_id": np.random.choice(
                    [f"device_{i}" for i in range(100)], n_samples
                ),
                "signal_strength": np.random.normal(-50, 10, n_samples),
                "frequency": np.random.choice([2.4, 5.0], n_samples),
                "channel": np.random.randint(1, 14, n_samples),
                "mac_address": [f"00:11:22:33:44:{i:02x}" for i in range(n_samples)],
                "ssid": np.random.choice(
                    ["WiFi_Home", "WiFi_Office", "Public_WiFi"], n_samples
                ),
                "encryption": np.random.choice(["WPA2", "WPA3", "Open"], n_samples),
                "data_rate": np.random.normal(54, 10, n_samples),
                "packet_count": np.random.poisson(100, n_samples),
                "bytes_transferred": np.random.exponential(1000, n_samples),
            }
        )
    
        processor = WiFiDataProcessor()
        extractor = FeatureExtractor()
        analyzer = ClusteringAnalyzer()
    
        # Performance-Messung
        start_time = time.time()
    
        # Verarbeitung
        processed_data = processor.process_data(large_data)
        features = extractor.extract_features(processed_data)
>       labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)

tests/integration/test_end_to_end.py:259: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1064: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1446: in fit
    X = validate_data(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2944: in validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1107: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:120: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[-1.6100241 ,  0.        ,  0.        , ...,  0.        ,
         0.        , -1.00344594],
       [-1.6100241...   ,  0.9965659 ],
       [ 1.63599223,  0.        ,  0.        , ...,  0.        ,
         0.        ,  0.9965659 ]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:169: ValueError
_______________ TestEndToEndWorkflow.test_concurrent_processing ________________

self = <test_end_to_end.TestEndToEndWorkflow object at 0x7f63f45010>
temp_dir = PosixPath('/tmp/tmpwqa05yno')

    @pytest.mark.integration
    def test_concurrent_processing(self, temp_dir):
        """Test der parallelen Verarbeitung."""
        import threading
        from concurrent.futures import ThreadPoolExecutor
    
        def process_chunk(chunk_data):
            """Verarbeitet einen Daten-Chunk."""
            processor = WiFiDataProcessor()
            extractor = FeatureExtractor()
            analyzer = ClusteringAnalyzer()
    
            processed_data = processor.process_data(chunk_data)
            features = extractor.extract_features(processed_data)
            labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=3)
    
            return {
                "chunk_id": threading.current_thread().ident,
                "n_samples": len(chunk_data),
                "n_clusters": len(np.unique(labels)),
            }
    
        # Daten in Chunks aufteilen
        n_chunks = 4
        chunk_size = 1000
        n_samples = n_chunks * chunk_size
    
        test_data = pd.DataFrame(
            {
                "timestamp": pd.date_range(
                    "2024-01-01", periods=n_samples, freq="1min"
                ),
                "device_id": np.random.choice(
                    [f"device_{i}" for i in range(50)], n_samples
                ),
                "signal_strength": np.random.normal(-50, 10, n_samples),
                "frequency": np.random.choice([2.4, 5.0], n_samples),
                "channel": np.random.randint(1, 14, n_samples),
                "mac_address": [f"00:11:22:33:44:{i:02x}" for i in range(n_samples)],
                "ssid": np.random.choice(
                    ["WiFi_Home", "WiFi_Office", "Public_WiFi"], n_samples
                ),
                "encryption": np.random.choice(["WPA2", "WPA3", "Open"], n_samples),
                "data_rate": np.random.normal(54, 10, n_samples),
                "packet_count": np.random.poisson(100, n_samples),
                "bytes_transferred": np.random.exponential(1000, n_samples),
            }
        )
    
        chunks = [
            test_data.iloc[i * chunk_size : (i + 1) * chunk_size]
            for i in range(n_chunks)
        ]
    
        # Parallele Verarbeitung
        with ThreadPoolExecutor(max_workers=n_chunks) as executor:
            futures = [executor.submit(process_chunk, chunk) for chunk in chunks]
>           results = [future.result() for future in futures]

tests/integration/test_end_to_end.py:328: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/integration/test_end_to_end.py:328: in <listcomp>
    results = [future.result() for future in futures]
../../.pyenv/versions/3.11.9/lib/python3.11/concurrent/futures/_base.py:456: in result
    return self.__get_result()
../../.pyenv/versions/3.11.9/lib/python3.11/concurrent/futures/_base.py:401: in __get_result
    raise self._exception
../../.pyenv/versions/3.11.9/lib/python3.11/concurrent/futures/thread.py:58: in run
    result = self.fn(*self.args, **self.kwargs)
tests/integration/test_end_to_end.py:285: in process_chunk
    labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=3)
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1064: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1446: in fit
    X = validate_data(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2944: in validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1107: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:120: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[-1.62859019,  0.        ,  0.        , ...,  0.        ,
        -2.02980853,  1.02840321],
       [-1.6285901...581, -0.97238125],
       [ 1.69506325,  0.        ,  0.        , ...,  0.        ,
        -0.46480581,  1.02840321]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:169: ValueError
_______________ TestClusteringBenchmarks.test_kmeans_performance _______________

self = <test_benchmarks.TestClusteringBenchmarks object at 0x7f63f50f10>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f5b8c97d0>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_kmeans_performance(self, benchmark, large_dataset):
        """Benchmark für K-Means Clustering."""
        analyzer = ClusteringAnalyzer()
    
        # Features extrahieren
        feature_extractor = FeatureExtractor()
        features = feature_extractor.extract_features(large_dataset)
    
        def clustering_func():
            return analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)
    
>       result = benchmark(clustering_func)

tests/performance/test_benchmarks.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:156: in __call__
    return self._raw(function_to_benchmark, *args, **kwargs)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:180: in _raw
    duration, iterations, loops_range = self._calibrate_timer(runner)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:318: in _calibrate_timer
    duration = runner(loops_range)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:109: in runner
    function_to_benchmark(*args, **kwargs)
tests/performance/test_benchmarks.py:29: in clustering_func
    return analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1064: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1446: in fit
    X = validate_data(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2944: in validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1107: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:120: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176, -0.97725852],
       [ 0.       ...176, -0.97725852],
       [ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176,  1.02327069]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:169: ValueError
_______________ TestClusteringBenchmarks.test_dbscan_performance _______________

self = <test_benchmarks.TestClusteringBenchmarks object at 0x7f63f51510>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f64f80e50>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_dbscan_performance(self, benchmark, large_dataset):
        """Benchmark für DBSCAN Clustering."""
        analyzer = ClusteringAnalyzer()
    
        feature_extractor = FeatureExtractor()
        features = feature_extractor.extract_features(large_dataset)
    
        def clustering_func():
            return analyzer.cluster_data(
                features, algorithm="dbscan", eps=0.5, min_samples=5
            )
    
>       result = benchmark(clustering_func)

tests/performance/test_benchmarks.py:51: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:156: in __call__
    return self._raw(function_to_benchmark, *args, **kwargs)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:180: in _raw
    duration, iterations, loops_range = self._calibrate_timer(runner)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:318: in _calibrate_timer
    duration = runner(loops_range)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:109: in runner
    function_to_benchmark(*args, **kwargs)
tests/performance/test_benchmarks.py:47: in clustering_func
    return analyzer.cluster_data(
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1064: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1446: in fit
    X = validate_data(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2944: in validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1107: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:120: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176, -0.97725852],
       [ 0.       ...176, -0.97725852],
       [ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176,  1.02327069]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:169: ValueError
____________ TestClusteringBenchmarks.test_hierarchical_performance ____________

self = <test_benchmarks.TestClusteringBenchmarks object at 0x7f63f51b10>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f5b61e490>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_hierarchical_performance(self, benchmark, large_dataset):
        """Benchmark für Hierarchical Clustering."""
        analyzer = ClusteringAnalyzer()
    
        feature_extractor = FeatureExtractor()
        features = feature_extractor.extract_features(large_dataset)
    
        def clustering_func():
            return analyzer.cluster_data(
                features, algorithm="hierarchical", n_clusters=5
            )
    
>       result = benchmark(clustering_func)

tests/performance/test_benchmarks.py:71: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:156: in __call__
    return self._raw(function_to_benchmark, *args, **kwargs)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:180: in _raw
    duration, iterations, loops_range = self._calibrate_timer(runner)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:318: in _calibrate_timer
    duration = runner(loops_range)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:109: in runner
    function_to_benchmark(*args, **kwargs)
tests/performance/test_benchmarks.py:67: in clustering_func
    return analyzer.cluster_data(
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1064: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1446: in fit
    X = validate_data(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2944: in validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1107: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:120: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176, -0.97725852],
       [ 0.       ...176, -0.97725852],
       [ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176,  1.02327069]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:169: ValueError
_____________ TestClusteringBenchmarks.test_clustering_scalability _____________

self = <test_benchmarks.TestClusteringBenchmarks object at 0x7f63f52190>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f58e1b290>

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_clustering_scalability(self, benchmark):
        """Test Skalierbarkeit mit verschiedenen Datengrößen."""
        sizes = [1000, 5000, 10000, 20000]
        times = []
    
        for size in sizes:
            # Generiere Test-Daten
            X = np.random.randn(size, 20)
            analyzer = ClusteringAnalyzer()
    
            def clustering_func():
                return analyzer.cluster_data(X, algorithm="kmeans", n_clusters=5)
    
            result = benchmark(clustering_func)
>           times.append(result.stats.mean)
E           AttributeError: 'numpy.ndarray' object has no attribute 'stats'

tests/performance/test_benchmarks.py:93: AttributeError
________ TestDataProcessingBenchmarks.test_data_processing_performance _________

self = <test_benchmarks.TestDataProcessingBenchmarks object at 0x7f63f527d0>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f58e19590>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_data_processing_performance(self, benchmark, large_dataset):
        """Benchmark für Datenverarbeitung."""
        processor = WiFiDataProcessor()
    
        def processing_func():
            return processor.process_data(large_dataset)
    
        result = benchmark(processing_func)
    
        # Datenverarbeitung sollte schnell sein
>       assert result.stats.mean < 1.0

tests/performance/test_benchmarks.py:121: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self =                timestamp  device_id  ...  bytes_transferred  processed_timestamp
0    2024-01-01 00:00:00  device_51  ...01 02:46:38
9999 2024-01-01 02:46:39   device_7  ...         594.132395  2024-01-01 02:46:39

[10000 rows x 12 columns]
name = 'stats'

    @final
    def __getattr__(self, name: str):
        """
        After regular attribute access, try looking up the name
        This allows simpler access to columns for interactive use.
        """
        # Note: obj.x will always call obj.__getattribute__('x') prior to
        # calling obj.__getattr__('x').
        if (
            name not in self._internal_names_set
            and name not in self._metadata
            and name not in self._accessors
            and self._info_axis._can_hold_identifiers_and_holds_name(name)
        ):
            return self[name]
>       return object.__getattribute__(self, name)
E       AttributeError: 'DataFrame' object has no attribute 'stats'

.venv/lib/python3.11/site-packages/pandas/core/generic.py:6293: AttributeError
_______ TestDataProcessingBenchmarks.test_feature_extraction_performance _______

self = <test_benchmarks.TestDataProcessingBenchmarks object at 0x7f63f52dd0>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f5cf60dd0>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_feature_extraction_performance(self, benchmark, large_dataset):
        """Benchmark für Feature-Extraktion."""
        extractor = FeatureExtractor()
    
        def extraction_func():
            return extractor.extract_features(large_dataset)
    
        result = benchmark(extraction_func)
    
        # Feature-Extraktion sollte effizient sein
>       assert result.stats.mean < 2.0
E       AttributeError: 'numpy.ndarray' object has no attribute 'stats'

tests/performance/test_benchmarks.py:136: AttributeError
________ TestDataProcessingBenchmarks.test_feature_scaling_performance _________

self = <test_benchmarks.TestDataProcessingBenchmarks object at 0x7f63f53410>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f5c87d310>

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_feature_scaling_performance(self, benchmark):
        """Benchmark für Feature-Skalierung."""
        extractor = FeatureExtractor()
    
        # Große Feature-Matrix
        features = np.random.randn(50000, 100)
    
        def scaling_func():
            return extractor.scale_features(features)
    
        result = benchmark(scaling_func)
    
        # Skalierung sollte sehr schnell sein
>       assert result.stats.mean < 0.5
E       AttributeError: 'numpy.ndarray' object has no attribute 'stats'

tests/performance/test_benchmarks.py:154: AttributeError
_________ TestClassificationBenchmarks.test_random_forest_performance __________

self = <test_benchmarks.TestClassificationBenchmarks object at 0x7f63f53b10>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f5ce82bd0>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_random_forest_performance(self, benchmark, large_dataset):
        """Benchmark für Random Forest Klassifikation."""
        classifier = DeviceClassifier()
    
        # Features und Labels generieren
        feature_extractor = FeatureExtractor()
        features = feature_extractor.extract_features(large_dataset)
        labels = np.random.randint(0, 5, len(features))
    
        def classification_func():
            classifier.train(features, labels)
            return classifier.predict(features)
    
        result = benchmark(classification_func)
    
        # Random Forest sollte effizient sein
>       assert result.stats.mean < 3.0
E       AttributeError: 'numpy.ndarray' object has no attribute 'stats'

tests/performance/test_benchmarks.py:179: AttributeError
______________ TestClassificationBenchmarks.test_svm_performance _______________

self = <test_benchmarks.TestClassificationBenchmarks object at 0x7f63f5c150>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f64fd5050>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_svm_performance(self, benchmark, large_dataset):
        """Benchmark für SVM Klassifikation."""
        classifier = DeviceClassifier(algorithm="svm")
    
        feature_extractor = FeatureExtractor()
        features = feature_extractor.extract_features(large_dataset)
        labels = np.random.randint(0, 5, len(features))
    
        def classification_func():
            classifier.train(features, labels)
            return classifier.predict(features)
    
>       result = benchmark(classification_func)

tests/performance/test_benchmarks.py:196: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:156: in __call__
    return self._raw(function_to_benchmark, *args, **kwargs)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:180: in _raw
    duration, iterations, loops_range = self._calibrate_timer(runner)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:318: in _calibrate_timer
    duration = runner(loops_range)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:109: in runner
    function_to_benchmark(*args, **kwargs)
tests/performance/test_benchmarks.py:193: in classification_func
    classifier.train(features, labels)
wlan_tool/analysis/device_classification.py:64: in train
    self.model.fit(X, y)
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/svm/_base.py:196: in fit
    X, y = validate_data(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2961: in validate_data
    X, y = check_X_y(X, y, **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1370: in check_X_y
    X = check_array(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1107: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:120: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176, -0.97725852],
       [ 0.       ...176, -0.97725852],
       [ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176,  1.02327069]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           SVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:169: ValueError
______________ TestMemoryBenchmarks.test_memory_usage_clustering _______________

self = <test_benchmarks.TestMemoryBenchmarks object at 0x7f63f5c950>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f5b697890>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    @pytest.mark.memory
    def test_memory_usage_clustering(self, benchmark, large_dataset):
        """Benchmark für Speichernutzung beim Clustering."""
        analyzer = ClusteringAnalyzer()
        feature_extractor = FeatureExtractor()
    
        def memory_intensive_func():
            # Features extrahieren
            features = feature_extractor.extract_features(large_dataset)
    
            # Clustering durchführen
            labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)
    
            # Zusätzliche Berechnungen
            unique_labels = np.unique(labels)
            cluster_sizes = [np.sum(labels == label) for label in unique_labels]
    
            return {
                "n_clusters": len(unique_labels),
                "cluster_sizes": cluster_sizes,
                "features_shape": features.shape,
            }
    
>       result = benchmark(memory_intensive_func)

tests/performance/test_benchmarks.py:231: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:156: in __call__
    return self._raw(function_to_benchmark, *args, **kwargs)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:180: in _raw
    duration, iterations, loops_range = self._calibrate_timer(runner)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:318: in _calibrate_timer
    duration = runner(loops_range)
.venv/lib/python3.11/site-packages/pytest_benchmark/fixture.py:109: in runner
    function_to_benchmark(*args, **kwargs)
tests/performance/test_benchmarks.py:219: in memory_intensive_func
    labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1064: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1446: in fit
    X = validate_data(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2944: in validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1107: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:120: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176, -0.97725852],
       [ 0.       ...176, -0.97725852],
       [ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176,  1.02327069]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:169: ValueError
_____________ TestMemoryBenchmarks.test_memory_usage_large_dataset _____________

self = <test_benchmarks.TestMemoryBenchmarks object at 0x7f63f5cf90>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f5cf23410>

    @pytest.mark.benchmark
    @pytest.mark.performance
    @pytest.mark.memory
    def test_memory_usage_large_dataset(self, benchmark):
        """Benchmark für Speichernutzung mit sehr großen Datensätzen."""
        # Sehr großer Datensatz
        n_samples = 100000
        n_features = 50
    
        def large_dataset_func():
            # Große Daten generieren
            X = np.random.randn(n_samples, n_features)
    
            # Clustering mit reduzierter Komplexität
            from sklearn.cluster import MiniBatchKMeans
    
            kmeans = MiniBatchKMeans(n_clusters=10, batch_size=1000)
            labels = kmeans.fit_predict(X)
    
            return {
                "n_samples": n_samples,
                "n_features": n_features,
                "n_clusters": len(np.unique(labels)),
            }
    
        result = benchmark(large_dataset_func)
    
        # Auch bei großen Datensätzen sollte es in angemessener Zeit laufen
>       assert result.stats.mean < 10.0
E       AttributeError: 'dict' object has no attribute 'stats'

tests/performance/test_benchmarks.py:265: AttributeError
________ TestConcurrentBenchmarks.test_parallel_processing_performance _________

self = <test_benchmarks.TestConcurrentBenchmarks object at 0x7f63f5d750>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f5ca06a90>

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_parallel_processing_performance(self, benchmark):
        """Benchmark für parallele Verarbeitung."""
        import threading
        from concurrent.futures import ThreadPoolExecutor
    
        def process_chunk(chunk_data):
            """Verarbeitet einen Daten-Chunk."""
            analyzer = ClusteringAnalyzer()
            return analyzer.cluster_data(chunk_data, algorithm="kmeans", n_clusters=3)
    
        def parallel_processing_func():
            # Daten in Chunks aufteilen
            n_chunks = 4
            chunk_size = 2500
            X = np.random.randn(n_chunks * chunk_size, 20)
            chunks = [X[i * chunk_size : (i + 1) * chunk_size] for i in range(n_chunks)]
    
            # Parallele Verarbeitung
            with ThreadPoolExecutor(max_workers=n_chunks) as executor:
                futures = [executor.submit(process_chunk, chunk) for chunk in chunks]
                results = [future.result() for future in futures]
    
            return results
    
        result = benchmark(parallel_processing_func)
    
        # Parallele Verarbeitung sollte effizienter sein
>       assert result.stats.mean < 3.0
E       AttributeError: 'list' object has no attribute 'stats'

tests/performance/test_benchmarks.py:301: AttributeError
__________________ TestIOBenchmarks.test_file_io_performance ___________________

self = <test_benchmarks.TestIOBenchmarks object at 0x7f63f5de90>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f5b678910>
temp_dir = PosixPath('/tmp/tmpiebuag54')

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_file_io_performance(self, benchmark, temp_dir):
        """Benchmark für Datei-I/O."""
        import pickle
    
        # Große Daten generieren
        large_data = np.random.randn(10000, 50)
        file_path = temp_dir / "test_data.pkl"
    
        def io_func():
            # Speichern
            with open(file_path, "wb") as f:
                pickle.dump(large_data, f)
    
            # Laden
            with open(file_path, "rb") as f:
                loaded_data = pickle.load(f)
    
            return loaded_data.shape
    
        result = benchmark(io_func)
    
        # I/O sollte schnell sein
>       assert result.stats.mean < 1.0
E       AttributeError: 'tuple' object has no attribute 'stats'

tests/performance/test_benchmarks.py:332: AttributeError
___________________ TestIOBenchmarks.test_csv_io_performance ___________________

self = <test_benchmarks.TestIOBenchmarks object at 0x7f63f51d10>
benchmark = <pytest_benchmark.fixture.BenchmarkFixture object at 0x7f5b6f6a50>
temp_dir = PosixPath('/tmp/tmp_9044zil')
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.benchmark
    @pytest.mark.performance
    def test_csv_io_performance(self, benchmark, temp_dir, large_dataset):
        """Benchmark für CSV-I/O."""
        csv_path = temp_dir / "test_data.csv"
    
        def csv_io_func():
            # Speichern
            large_dataset.to_csv(csv_path, index=False)
    
            # Laden
            loaded_data = pd.read_csv(csv_path)
    
            return loaded_data.shape
    
        result = benchmark(csv_io_func)
    
        # CSV-I/O kann langsamer sein
>       assert result.stats.mean < 2.0
E       AttributeError: 'tuple' object has no attribute 'stats'

tests/performance/test_benchmarks.py:353: AttributeError
_________________ TestMemoryUsage.test_memory_usage_clustering _________________

self = <test_memory_profiling.TestMemoryUsage object at 0x7f63f97410>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.memory
    @pytest.mark.performance
    def test_memory_usage_clustering(self, large_dataset):
        """Test Speichernutzung beim Clustering."""
        process = psutil.Process(os.getpid())
        memory_before = process.memory_info().rss / 1024 / 1024
    
        analyzer = ClusteringAnalyzer()
        feature_extractor = FeatureExtractor()
    
        # Features extrahieren
        features = feature_extractor.extract_features(large_dataset)
        memory_after_features = process.memory_info().rss / 1024 / 1024
    
        # Clustering durchführen
>       labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)

tests/performance/test_memory_profiling.py:77: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1064: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1446: in fit
    X = validate_data(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2944: in validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1107: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:120: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176, -0.97725852],
       [ 0.       ...176, -0.97725852],
       [ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.15614176,  1.02327069]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:169: ValueError
______________ TestMemoryProfiling.test_detailed_memory_profiling ______________

self = <test_memory_profiling.TestMemoryProfiling object at 0x7f63f9cdd0>
large_dataset =                timestamp  device_id  ...  packet_count  bytes_transferred
0    2024-01-01 00:00:00  device_51  ...    ...       1993.643845
9999 2024-01-01 02:46:39   device_7  ...           103         594.132395

[10000 rows x 11 columns]

    @pytest.mark.memory
    @pytest.mark.performance
    def test_detailed_memory_profiling(self, large_dataset):
        """Detailliertes Memory-Profiling der WLAN-Analyse."""
        from memory_profiler import memory_usage
    
        def analyze_wifi_data():
            """WLAN-Datenanalyse mit Memory-Tracking."""
            processor = WiFiDataProcessor()
            extractor = FeatureExtractor()
            analyzer = ClusteringAnalyzer()
    
            # 1. Daten verarbeiten
            processed_data = processor.process_data(large_dataset)
    
            # 2. Features extrahieren
            features = extractor.extract_features(processed_data)
    
            # 3. Clustering
            labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)
    
            # 4. Ergebnisse zusammenfassen
            unique_labels = np.unique(labels)
            cluster_sizes = [np.sum(labels == label) for label in unique_labels]
    
            return {
                "n_clusters": len(unique_labels),
                "cluster_sizes": cluster_sizes,
                "features_shape": features.shape,
            }
    
        # Memory-Usage während der Ausführung messen
>       mem_usage = memory_usage(analyze_wifi_data, interval=0.1)

tests/performance/test_memory_profiling.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.venv/lib/python3.11/site-packages/memory_profiler.py:379: in memory_usage
    returned = f(*args, **kw)
tests/performance/test_memory_profiling.py:208: in analyze_wifi_data
    labels = analyzer.cluster_data(features, algorithm="kmeans", n_clusters=5)
wlan_tool/analysis/clustering.py:74: in cluster_data
    self.labels_ = self.model.fit_predict(data)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1064: in fit_predict
    return self.fit(X, sample_weight=sample_weight).labels_
.venv/lib/python3.11/site-packages/sklearn/base.py:1389: in wrapper
    return fit_method(estimator, *args, **kwargs)
.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1446: in fit
    X = validate_data(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2944: in validate_data
    out = check_array(X, input_name="X", **check_params)
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1107: in check_array
    _assert_all_finite(
.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:120: in _assert_all_finite
    _assert_all_finite_element_wise(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = array([[-1.15579349,  0.        ,  0.        , ...,  0.        ,
         0.15614176, -0.97725852],
       [-1.1557934...176, -0.97725852],
       [ 1.35680105,  0.        ,  0.        , ...,  0.        ,
         0.15614176,  1.02327069]])

    def _assert_all_finite_element_wise(
        X, *, xp, allow_nan, msg_dtype=None, estimator_name=None, input_name=""
    ):
        # Cython implementation doesn't support FP16 or complex numbers
        use_cython = (
            xp is np and X.data.contiguous and X.dtype.type in {np.float32, np.float64}
        )
        if use_cython:
            out = cy_isfinite(X.reshape(-1), allow_nan=allow_nan)
            has_nan_error = False if allow_nan else out == FiniteStatus.has_nan
            has_inf = out == FiniteStatus.has_infinite
        else:
            has_inf = xp.any(xp.isinf(X))
            has_nan_error = False if allow_nan else xp.any(xp.isnan(X))
        if has_inf or has_nan_error:
            if has_nan_error:
                type_err = "NaN"
            else:
                msg_dtype = msg_dtype if msg_dtype is not None else X.dtype
                type_err = f"infinity or a value too large for {msg_dtype!r}"
            padded_input_name = input_name + " " if input_name else ""
            msg_err = f"Input {padded_input_name}contains {type_err}."
            if estimator_name and input_name == "X" and has_nan_error:
                # Improve the error message on how to handle missing values in
                # scikit-learn.
                msg_err += (
                    f"\n{estimator_name} does not accept missing values"
                    " encoded as NaN natively. For supervised learning, you might want"
                    " to consider sklearn.ensemble.HistGradientBoostingClassifier and"
                    " Regressor which accept missing values encoded as NaNs natively."
                    " Alternatively, it is possible to preprocess the data, for"
                    " instance by using an imputer transformer in a pipeline or drop"
                    " samples with missing values. See"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    " You can find a list of all estimators that handle NaN values"
                    " at the following page:"
                    " https://scikit-learn.org/stable/modules/impute.html"
                    "#estimators-that-handle-nan-values"
                )
>           raise ValueError(msg_err)
E           ValueError: Input X contains NaN.
E           KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:169: ValueError
_________ TestMemoryProfiling.test_memory_profiling_garbage_collection _________

self = <test_memory_profiling.TestMemoryProfiling object at 0x7f63f9d950>

    @pytest.mark.memory
    @pytest.mark.performance
    def test_memory_profiling_garbage_collection(self):
        """Test Memory-Profiling mit Garbage Collection."""
        import gc
    
        process = psutil.Process(os.getpid())
    
        def create_large_objects():
            """Erstellt große Objekte und führt Garbage Collection durch."""
            # Große Objekte erstellen
            large_arrays = [np.random.randn(1000, 100) for _ in range(10)]
    
            # Memory vor GC
            memory_before_gc = process.memory_info().rss / 1024 / 1024
    
            # Garbage Collection
            gc.collect()
    
            # Memory nach GC
            memory_after_gc = process.memory_info().rss / 1024 / 1024
    
            return memory_before_gc, memory_after_gc
    
        memory_before, memory_after = create_large_objects()
        memory_freed = memory_before - memory_after
    
        # Garbage Collection sollte Speicher freigeben
>       assert memory_freed > 0, "Garbage Collection hat keinen Speicher freigegeben"
E       AssertionError: Garbage Collection hat keinen Speicher freigegeben
E       assert 0.0 > 0

tests/performance/test_memory_profiling.py:302: AssertionError
_____________ TestMemoryOptimization.test_memory_usage_data_types ______________

self = <test_memory_profiling.TestMemoryOptimization object at 0x7f63f9ec90>

    @pytest.mark.memory
    @pytest.mark.performance
    def test_memory_usage_data_types(self):
        """Test Speichernutzung verschiedener Datentypen."""
        process = psutil.Process(os.getpid())
    
        # Test verschiedene Datentypen
        data_types = [
            ("float32", np.float32),
            ("float64", np.float64),
            ("int32", np.int32),
            ("int64", np.int64),
        ]
    
        memory_usage = {}
    
        for dtype_name, dtype in data_types:
            memory_before = process.memory_info().rss / 1024 / 1024
    
            # Große Array mit spezifischem Datentyp
            array = np.random.randn(10000, 100).astype(dtype)
    
            memory_after = process.memory_info().rss / 1024 / 1024
            memory_usage[dtype_name] = memory_after - memory_before
    
        # float32 sollte weniger Speicher verwenden als float64
        assert memory_usage["float32"] < memory_usage["float64"]
    
        # int32 sollte weniger Speicher verwenden als int64
>       assert memory_usage["int32"] < memory_usage["int64"]
E       assert 0.0 < 0.0

tests/performance/test_memory_profiling.py:408: AssertionError
__________________ TestDataValidator.test_validate_valid_data __________________

self = <test_data_processing.TestDataValidator object at 0x7f63fc1dd0>
sample_wifi_data =               timestamp device_id  ...  packet_count  bytes_transferred
0   2024-01-01 00:00:00  device_3  ...        ...15         206.754596
999 2024-01-01 16:39:00  device_1  ...           103         554.365485

[1000 rows x 11 columns]

    def test_validate_valid_data(self, sample_wifi_data):
        """Test Validierung gültiger Daten."""
        validator = DataValidator()
        is_valid, errors = validator.validate(sample_wifi_data)
    
>       assert is_valid
E       assert False

tests/unit/test_data_processing.py:178: AssertionError
_____________________ TestClusteringModel.test_fit_kmeans ______________________

self = <test_ml_models.TestClusteringModel object at 0x7f63e3c150>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])

    def test_fit_kmeans(self, sample_features):
        """Test K-Means Clustering."""
        model = ClusteringModel(algorithm="kmeans", n_clusters=3)
>       model.fit(sample_features)

tests/unit/test_ml_models.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/clustering_model.py:53: in fit
    self.model = self._create_model()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.clustering_model.ClusteringModel object at 0x7f5cd02110>
n_clusters = 3

    def _create_model(self, n_clusters: Optional[int] = None) -> Any:
        """Erstellt das Clustering-Modell."""
        if self.algorithm == 'kmeans':
            n_clusters = n_clusters or self.kwargs.get('n_clusters', 5)
>           return KMeans(n_clusters=n_clusters, random_state=42, **self.kwargs)
E           TypeError: sklearn.cluster._kmeans.KMeans() got multiple values for keyword argument 'n_clusters'

wlan_tool/ml_models/clustering_model.py:36: TypeError
__________________ TestClusteringModel.test_predict_after_fit __________________

self = <test_ml_models.TestClusteringModel object at 0x7f63e3d390>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])

    def test_predict_after_fit(self, sample_features):
        """Test Vorhersage nach Training."""
        model = ClusteringModel(algorithm="kmeans", n_clusters=3)
>       model.fit(sample_features)

tests/unit/test_ml_models.py:52: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/clustering_model.py:53: in fit
    self.model = self._create_model()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.clustering_model.ClusteringModel object at 0x7f5cadae90>
n_clusters = 3

    def _create_model(self, n_clusters: Optional[int] = None) -> Any:
        """Erstellt das Clustering-Modell."""
        if self.algorithm == 'kmeans':
            n_clusters = n_clusters or self.kwargs.get('n_clusters', 5)
>           return KMeans(n_clusters=n_clusters, random_state=42, **self.kwargs)
E           TypeError: sklearn.cluster._kmeans.KMeans() got multiple values for keyword argument 'n_clusters'

wlan_tool/ml_models/clustering_model.py:36: TypeError
_________________ TestClusteringModel.test_get_cluster_centers _________________

self = <test_ml_models.TestClusteringModel object at 0x7f63e3c3d0>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])

    def test_get_cluster_centers(self, sample_features):
        """Test Cluster-Zentren abrufen."""
        model = ClusteringModel(algorithm="kmeans", n_clusters=3)
>       model.fit(sample_features)

tests/unit/test_ml_models.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/clustering_model.py:53: in fit
    self.model = self._create_model()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.clustering_model.ClusteringModel object at 0x7f5b806b90>
n_clusters = 3

    def _create_model(self, n_clusters: Optional[int] = None) -> Any:
        """Erstellt das Clustering-Modell."""
        if self.algorithm == 'kmeans':
            n_clusters = n_clusters or self.kwargs.get('n_clusters', 5)
>           return KMeans(n_clusters=n_clusters, random_state=42, **self.kwargs)
E           TypeError: sklearn.cluster._kmeans.KMeans() got multiple values for keyword argument 'n_clusters'

wlan_tool/ml_models/clustering_model.py:36: TypeError
_________________ TestClusteringModel.test_evaluate_clustering _________________

self = <test_ml_models.TestClusteringModel object at 0x7f63e3da90>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])

    def test_evaluate_clustering(self, sample_features):
        """Test Clustering-Evaluation."""
        model = ClusteringModel(algorithm="kmeans", n_clusters=3)
>       model.fit(sample_features)

tests/unit/test_ml_models.py:73: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
wlan_tool/ml_models/clustering_model.py:53: in fit
    self.model = self._create_model()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.clustering_model.ClusteringModel object at 0x7f5c9b8c50>
n_clusters = 3

    def _create_model(self, n_clusters: Optional[int] = None) -> Any:
        """Erstellt das Clustering-Modell."""
        if self.algorithm == 'kmeans':
            n_clusters = n_clusters or self.kwargs.get('n_clusters', 5)
>           return KMeans(n_clusters=n_clusters, random_state=42, **self.kwargs)
E           TypeError: sklearn.cluster._kmeans.KMeans() got multiple values for keyword argument 'n_clusters'

wlan_tool/ml_models/clustering_model.py:36: TypeError
__________________ TestClusteringModel.test_invalid_algorithm __________________

self = <test_ml_models.TestClusteringModel object at 0x7f63e3ddd0>

    def test_invalid_algorithm(self):
        """Test mit ungültigem Algorithmus."""
>       with pytest.raises(ValueError, match="Unsupported algorithm"):
E       Failed: DID NOT RAISE <class 'ValueError'>

tests/unit/test_ml_models.py:86: Failed
______________ TestClusteringModel.test_hyperparameter_validation ______________

self = <test_ml_models.TestClusteringModel object at 0x7f63e3e3d0>

    def test_hyperparameter_validation(self):
        """Test Hyperparameter-Validierung."""
        # Ungültige n_clusters
>       with pytest.raises(ValueError, match="n_clusters must be positive"):
E       Failed: DID NOT RAISE <class 'ValueError'>

tests/unit/test_ml_models.py:92: Failed
________________ TestClassificationModel.test_cross_validation _________________

self = <test_ml_models.TestClassificationModel object at 0x7f63e45bd0>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
sample_labels = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])

    def test_cross_validation(self, sample_features, sample_labels):
        """Test Cross-Validation."""
        model = ClassificationModel(algorithm="random_forest", n_estimators=10)
    
>       cv_scores = model.cross_validate(sample_features, sample_labels, cv=3)

tests/unit/test_ml_models.py:177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <wlan_tool.ml_models.classification_model.ClassificationModel object at 0x7f5cd01850>
X = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
y = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])
cv = 3

    def cross_validate(self, X: np.ndarray, y: np.ndarray, cv: int = 5) -> Dict[str, List[float]]:
        """Führt Cross-Validation durch."""
        if not self.is_fitted:
>           raise ValueError("Model must be fitted first")
E           ValueError: Model must be fitted first

wlan_tool/ml_models/classification_model.py:103: ValueError
_________________________ TestEnsembleModel.test_init __________________________

self = <test_ml_models.TestEnsembleModel object at 0x7f63e46ad0>

    def test_init(self):
        """Test Initialisierung."""
        model = EnsembleModel()
        assert model is not None
>       assert hasattr(model, "fit")
E       AssertionError: assert False
E        +  where False = hasattr(<wlan_tool.ml_models.ensemble_model.EnsembleModel object at 0x7f5cece610>, 'fit')

tests/unit/test_ml_models.py:203: AssertionError
_________________ TestEnsembleModel.test_fit_voting_classifier _________________

self = <test_ml_models.TestEnsembleModel object at 0x7f63e47190>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
sample_labels = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])

    def test_fit_voting_classifier(self, sample_features, sample_labels):
        """Test Voting Classifier Training."""
        model = EnsembleModel(
            algorithm="voting",
            estimators=[
                ("rf", ClassificationModel(algorithm="random_forest")),
                ("svm", ClassificationModel(algorithm="svm")),
            ],
        )
>       model.fit(sample_features, sample_labels)
E       AttributeError: 'EnsembleModel' object has no attribute 'fit'

tests/unit/test_ml_models.py:215: AttributeError
______________________ TestEnsembleModel.test_fit_bagging ______________________

self = <test_ml_models.TestEnsembleModel object at 0x7f63e47890>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
sample_labels = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])

    def test_fit_bagging(self, sample_features, sample_labels):
        """Test Bagging Training."""
        model = EnsembleModel(
            algorithm="bagging",
            base_estimator=ClassificationModel(algorithm="random_forest"),
            n_estimators=5,
        )
>       model.fit(sample_features, sample_labels)
E       AttributeError: 'EnsembleModel' object has no attribute 'fit'

tests/unit/test_ml_models.py:227: AttributeError
_____________________ TestEnsembleModel.test_fit_boosting ______________________

self = <test_ml_models.TestEnsembleModel object at 0x7f63e47fd0>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
sample_labels = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])

    def test_fit_boosting(self, sample_features, sample_labels):
        """Test Boosting Training."""
        model = EnsembleModel(
            algorithm="boosting",
            base_estimator=ClassificationModel(algorithm="random_forest"),
            n_estimators=5,
        )
>       model.fit(sample_features, sample_labels)
E       AttributeError: 'EnsembleModel' object has no attribute 'fit'

tests/unit/test_ml_models.py:239: AttributeError
___________________ TestEnsembleModel.test_predict_ensemble ____________________

self = <test_ml_models.TestEnsembleModel object at 0x7f63e54710>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
sample_labels = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])

    def test_predict_ensemble(self, sample_features, sample_labels):
        """Test Ensemble-Vorhersage."""
        model = EnsembleModel(
            algorithm="voting",
            estimators=[
                ("rf", ClassificationModel(algorithm="random_forest")),
                ("svm", ClassificationModel(algorithm="svm")),
            ],
        )
>       model.fit(sample_features, sample_labels)
E       AttributeError: 'EnsembleModel' object has no attribute 'fit'

tests/unit/test_ml_models.py:253: AttributeError
___________________ TestEnsembleModel.test_evaluate_ensemble ___________________

self = <test_ml_models.TestEnsembleModel object at 0x7f63e54e10>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
sample_labels = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])

    def test_evaluate_ensemble(self, sample_features, sample_labels):
        """Test Ensemble-Evaluation."""
        model = EnsembleModel(
            algorithm="voting",
            estimators=[
                ("rf", ClassificationModel(algorithm="random_forest")),
                ("svm", ClassificationModel(algorithm="svm")),
            ],
        )
>       model.fit(sample_features, sample_labels)
E       AttributeError: 'EnsembleModel' object has no attribute 'fit'

tests/unit/test_ml_models.py:269: AttributeError
___________ TestEnsembleModel.test_individual_estimator_performance ____________

self = <test_ml_models.TestEnsembleModel object at 0x7f63e55510>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
sample_labels = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])

    def test_individual_estimator_performance(self, sample_features, sample_labels):
        """Test Performance einzelner Estimators."""
        model = EnsembleModel(
            algorithm="voting",
            estimators=[
                ("rf", ClassificationModel(algorithm="random_forest")),
                ("svm", ClassificationModel(algorithm="svm")),
            ],
        )
>       model.fit(sample_features, sample_labels)
E       AttributeError: 'EnsembleModel' object has no attribute 'fit'

tests/unit/test_ml_models.py:287: AttributeError
___________________ TestEnsembleModel.test_invalid_algorithm ___________________

self = <test_ml_models.TestEnsembleModel object at 0x7f63e47610>

    def test_invalid_algorithm(self):
        """Test mit ungültigem Ensemble-Algorithmus."""
>       with pytest.raises(ValueError, match="Unsupported ensemble algorithm"):
E       Failed: DID NOT RAISE <class 'ValueError'>

tests/unit/test_ml_models.py:298: Failed
___________________ TestEnsembleModel.test_empty_estimators ____________________

self = <test_ml_models.TestEnsembleModel object at 0x7f63e45690>

    def test_empty_estimators(self):
        """Test mit leerer Estimator-Liste."""
>       with pytest.raises(ValueError, match="At least one estimator required"):
E       Failed: DID NOT RAISE <class 'ValueError'>

tests/unit/test_ml_models.py:303: Failed
__________________ TestModelPersistence.test_save_load_model ___________________

self = <test_ml_models.TestModelPersistence object at 0x7f63e3dc90>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
sample_labels = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])
temp_dir = PosixPath('/tmp/tmp0997h10_')

    def test_save_load_model(self, sample_features, sample_labels, temp_dir):
        """Test Speichern und Laden von Modellen."""
        # Training
        model = ClassificationModel(algorithm="random_forest", n_estimators=10)
        model.fit(sample_features, sample_labels)
    
        # Speichern
        model_path = temp_dir / "test_model.pkl"
>       model.save(model_path)
E       AttributeError: 'ClassificationModel' object has no attribute 'save'

tests/unit/test_ml_models.py:318: AttributeError
_________________ TestModelPersistence.test_save_load_ensemble _________________

self = <test_ml_models.TestModelPersistence object at 0x7f63e55290>
sample_features = array([[ 0.49671415, -0.1382643 ,  0.64768854, ...,  0.31424733,
        -0.90802408, -1.4123037 ],
       [ 1.4656487...522,  0.32797039],
       [ 0.96259198,  0.51259951, -0.75311158, ...,  0.37835397,
         1.71352973, -1.6199198 ]])
sample_labels = array([3, 4, 2, 4, 4, 1, 2, 2, 2, 4, 3, 2, 4, 1, 3, 1, 3, 4, 0, 3, 1, 4,
       3, 0, 0, 2, 2, 1, 3, 3, 2, 3, 3, 0, 2,...1, 0, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 4, 1, 2, 2, 2, 3, 3, 1, 2, 2, 4, 3, 2, 1,
       1, 2, 3, 1, 4, 1, 0, 0, 3, 2])
temp_dir = PosixPath('/tmp/tmpkt0dxp5b')

    def test_save_load_ensemble(self, sample_features, sample_labels, temp_dir):
        """Test Speichern und Laden von Ensemble-Modellen."""
        # Training
        model = EnsembleModel(
            algorithm="voting",
            estimators=[
                ("rf", ClassificationModel(algorithm="random_forest")),
                ("svm", ClassificationModel(algorithm="svm")),
            ],
        )
>       model.fit(sample_features, sample_labels)
E       AttributeError: 'EnsembleModel' object has no attribute 'fit'

tests/unit/test_ml_models.py:344: AttributeError
=============================== warnings summary ===============================
tests/conftest.py:12
  /home/pi/Ai_agent/hacking/tests/conftest.py:12: DeprecationWarning: 
  Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),
  (to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)
  but was not found to be installed on your system.
  If this would cause problems for you,
  please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466
          
    import pandas as pd

pytest/test_integration.py:192
  /home/pi/Ai_agent/hacking/pytest/test_integration.py:192: PytestUnknownMarkWarning: Unknown pytest.mark.network - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.network

plugins/clustering_advanced/tests/test_clustering_advanced.py::TestAdvancedClusteringPlugin::test_optics_clustering
  /home/pi/Ai_agent/hacking/.venv/lib/python3.11/site-packages/sklearn/cluster/_optics.py:664: UserWarning: All reachability values are inf. Set a larger max_eps or all data will be considered outliers.
    warnings.warn(

plugins/clustering_advanced/tests/test_clustering_advanced.py::TestAdvancedClusteringPlugin::test_hdbscan_clustering
plugins/clustering_advanced/tests/test_clustering_advanced.py::TestAdvancedClusteringPlugin::test_hdbscan_clustering
  /home/pi/Ai_agent/hacking/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.
    warnings.warn(

plugins/clustering_advanced/tests/test_clustering_advanced.py::TestAdvancedClusteringPlugin::test_plugin_run_with_sufficient_data
  /home/pi/Ai_agent/hacking/.venv/lib/python3.11/site-packages/sklearn/cluster/_optics.py:664: UserWarning:
  
  All reachability values are inf. Set a larger max_eps or all data will be considered outliers.

plugins/clustering_advanced/tests/test_clustering_advanced.py::TestAdvancedClusteringPlugin::test_plugin_run_with_sufficient_data
plugins/clustering_advanced/tests/test_clustering_advanced.py::TestAdvancedClusteringPlugin::test_plugin_run_with_sufficient_data
  /home/pi/Ai_agent/hacking/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:
  
  'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.

plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_model_performance_evaluation
  /home/pi/Ai_agent/hacking/.venv/lib/python3.11/site-packages/sklearn/model_selection/_split.py:805: UserWarning:
  
  The least populated class in y has only 4 members, which is less than n_splits=5.

plugins/ensemble_models/tests/test_ensemble_models.py: 66 warnings
  /home/pi/Ai_agent/hacking/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:451: DeprecationWarning:
  
  scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.

plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_model_performance_evaluation
plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_model_performance_evaluation
plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_model_performance_evaluation
plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_model_performance_evaluation
plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_model_performance_evaluation
plugins/ensemble_models/tests/test_ensemble_models.py::TestEnsembleModelsPlugin::test_model_performance_evaluation
  /home/pi/Ai_agent/hacking/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:
  
  lbfgs failed to converge (status=1):
  STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.
  
  Increase the number of iterations (max_iter) or scale the data as shown in:
      https://scikit-learn.org/stable/modules/preprocessing.html
  Please also refer to the documentation for alternative solver options:
      https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

plugins/ensemble_models/tests/test_ensemble_models.py: 40 warnings
  /home/pi/Ai_agent/hacking/.venv/lib/python3.11/site-packages/sklearn/model_selection/_split.py:805: UserWarning:
  
  The least populated class in y has only 3 members, which is less than n_splits=5.

plugins/ensemble_models/tests/test_ensemble_models.py: 24 warnings
  /home/pi/Ai_agent/hacking/.venv/lib/python3.11/site-packages/sklearn/model_selection/_split.py:805: UserWarning:
  
  The least populated class in y has only 2 members, which is less than n_splits=5.

pytest/test_capture.py::TestSniffingIntegration::test_sniff_with_writer_mock
  /home/pi/Ai_agent/hacking/.venv/lib/python3.11/site-packages/_pytest/threadexception.py:77: PytestUnhandledThreadExceptionWarning:
  
  Exception in thread ChannelHopper
  
  Traceback (most recent call last):
    File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/threading.py", line 1045, in _bootstrap_inner
      self.run()
    File "/home/pi/Ai_agent/hacking/wlan_tool/capture/sniffer.py", line 210, in run
      subprocess.run(command, check=True, capture_output=True, text=True)
    File "/home/pi/.pyenv/versions/3.11.9/lib/python3.11/subprocess.py", line 550, in run
      stdout, stderr = process.communicate(input, timeout=timeout)
      ^^^^^^^^^^^^^^
  ValueError: not enough values to unpack (expected 2, got 0)

tests/integration/test_end_to_end.py::TestEndToEndWorkflow::test_error_handling_and_recovery
  /home/pi/Ai_agent/hacking/wlan_tool/data_processing/wifi_processor.py:45: UserWarning:
  
  Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html

-------------------------------------------------------------------------------------------------- benchmark: 9 tests --------------------------------------------------------------------------------------------------
Name (time in ms)                               Min                   Max                  Mean              StdDev                Median                 IQR            Outliers      OPS            Rounds  Iterations
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
test_file_io_performance                    23.6699 (1.0)        179.5915 (3.37)       136.7698 (2.61)      20.4647 (85.91)      135.3752 (2.58)      10.5204 (79.17)         3;2   7.3116 (0.38)         42           1
test_feature_extraction_performance         52.2085 (2.21)        53.2930 (1.0)         52.4606 (1.0)        0.2382 (1.0)         52.4275 (1.0)        0.1329 (1.0)           2;1  19.0619 (1.0)          16           1
test_data_processing_performance            59.9481 (2.53)       514.3163 (9.65)        88.1458 (1.68)     109.8261 (461.07)      61.6109 (1.18)       1.8370 (13.82)         1;1  11.3448 (0.60)         17           1
test_clustering_scalability                 85.4247 (3.61)       105.5569 (1.98)        95.8837 (1.83)       7.2883 (30.60)       95.0152 (1.81)      13.7689 (103.62)        6;0  10.4293 (0.55)         12           1
test_feature_scaling_performance           154.1216 (6.51)       158.8576 (2.98)       155.2927 (2.96)       2.0009 (8.40)       154.5190 (2.95)       1.3454 (10.12)         1;1   6.4395 (0.34)          5           1
test_parallel_processing_performance       181.9603 (7.69)       226.4450 (4.25)       203.0436 (3.87)      18.6368 (78.24)      198.7636 (3.79)      35.7403 (268.96)        4;0   4.9251 (0.26)          7           1
test_csv_io_performance                    334.4366 (14.13)      379.5808 (7.12)       345.9431 (6.59)      18.9310 (79.48)      338.2515 (6.45)      13.9321 (104.84)        1;1   2.8906 (0.15)          5           1
test_memory_usage_large_dataset            579.1038 (24.47)      847.5319 (15.90)      709.8911 (13.53)    124.5400 (522.84)     743.9492 (14.19)    231.4024 (>1000.0)       3;0   1.4087 (0.07)          5           1
test_random_forest_performance           8,067.9917 (340.85)   8,107.4898 (152.13)   8,090.4225 (154.22)    16.6470 (69.89)    8,093.6941 (154.38)    28.2814 (212.83)        2;0   0.1236 (0.01)          5           1
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Legend:
  Outliers: 1 Standard Deviation from Mean; 1.5 IQR (InterQuartile Range) from 1st Quartile and 3rd Quartile.
  OPS: Operations Per Second, computed as 1 / Mean
=========================== short test summary info ============================
FAILED plugins/reinforcement_learning/tests/test_reinforcement_learning.py::TestReinforcementLearningPlugin::test_environment_observation
FAILED pytest/test_capture.py::TestPacketParsing::test_packet_to_event_data_frame
FAILED pytest/test_capture.py::TestPacketParsing::test_packet_to_event_with_dhcp
FAILED pytest/test_capture.py::TestChannelHopper::test_channel_hopper_command_failure
FAILED pytest/test_capture.py::TestIEExtraction::test_extract_seq - assert 0 ...
FAILED pytest/test_capture.py::TestErrorHandling::test_packet_to_event_encoding_error
FAILED pytest/test_controllers.py::TestCaptureController::test_select_interface_automatic
FAILED pytest/test_controllers.py::TestCaptureController::test_select_interface_no_interfaces
FAILED pytest/test_controllers.py::TestCaptureController::test_setup_monitor_mode_failure
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_inference
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_client_clustering
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_ap_clustering
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_graph_export
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_labeling_ui
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_client_labeling_ui
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_mac_correlation
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_analysis_no_actions
FAILED pytest/test_controllers.py::TestAnalysisController::test_run_analysis_multiple_actions
FAILED pytest/test_controllers.py::TestControllerEdgeCases::test_analysis_controller_with_plugins
FAILED pytest/test_controllers.py::TestControllerIntegration::test_full_analysis_workflow
FAILED pytest/test_error_handling.py::TestLoggingSystem::test_setup_logging
FAILED pytest/test_error_handling.py::TestDatabaseErrorHandling::test_database_connection_error
FAILED pytest/test_error_handling.py::TestDatabaseErrorHandling::test_database_migration_error
FAILED pytest/test_error_handling.py::TestAnalysisErrorHandling::test_client_features_null_state
FAILED pytest/test_error_handling.py::TestAnalysisErrorHandling::test_client_features_invalid_type
FAILED pytest/test_error_handling.py::TestAnalysisErrorHandling::test_clustering_invalid_parameters
FAILED pytest/test_error_handling.py::TestFileSystemErrorHandling::test_csv_export_invalid_path
FAILED pytest/test_error_handling.py::TestFileSystemErrorHandling::test_csv_export_missing_db
FAILED pytest/test_error_handling.py::TestErrorHandlingEdgeCases::test_nested_error_contexts
FAILED pytest/test_integration.py::TestEndToEndWorkflow::test_database_integration
FAILED pytest/test_integration.py::TestEndToEndWorkflow::test_config_integration
FAILED pytest/test_integration.py::TestDataFlow::test_state_persistence - wla...
FAILED pytest/test_integration.py::TestLargeDataset::test_large_dataset_processing
FAILED pytest/test_integration.py::TestErrorRecovery::test_malformed_event_handling
FAILED pytest/test_integration.py::TestMemoryManagement::test_memory_usage_large_state
FAILED pytest/test_integration.py::TestMemoryManagement::test_state_pruning_memory_release
FAILED pytest/test_performance.py::TestAnalysisPerformance::test_clustering_performance
FAILED pytest/test_performance.py::TestAnalysisPerformance::test_inference_performance
FAILED pytest/test_performance.py::TestMemoryPerformance::test_memory_usage_large_state
FAILED pytest/test_performance.py::TestMemoryPerformance::test_memory_cleanup_after_pruning
FAILED pytest/test_performance.py::TestDatabasePerformance::test_database_write_performance
FAILED pytest/test_performance.py::TestDatabasePerformance::test_database_read_performance
FAILED pytest/test_performance.py::TestScalabilityPerformance::test_scalability_with_dataset_size
FAILED pytest/test_presentation.py::TestCLIModule::test_print_client_cluster_results
FAILED pytest/test_presentation.py::TestCLIEdgeCases::test_print_client_cluster_results_empty_data
FAILED pytest/test_presentation.py::TestPerformance::test_large_dataset_handling
FAILED pytest/test_storage.py::TestAPState::test_ap_state_update_from_beacon
FAILED pytest/test_storage.py::TestWifiAnalysisState::test_state_ssid_mapping
FAILED pytest/test_storage.py::TestDatabaseModule::test_fetch_events - Attrib...
FAILED pytest/test_storage.py::TestDatabaseModule::test_add_label - Assertion...
FAILED pytest/test_utils.py::TestOUIFunctions::test_lookup_vendor_apple_mac
FAILED pytest/test_utils.py::TestOUIFunctions::test_lookup_vendor_unknown_mac
FAILED pytest/test_utils.py::TestUtilityFunctions::test_is_local_admin_mac - ...
FAILED pytest/test_utils.py::TestUtilityFunctions::test_is_valid_bssid - Asse...
FAILED pytest/test_utils.py::TestUtilityFunctions::test_ie_fingerprint_hash
FAILED pytest/test_utils.py::TestUtilityFunctions::test_ie_fingerprint_hash_empty
FAILED pytest/test_utils.py::TestConfigFunctions::test_load_config_default - ...
FAILED pytest/test_utils.py::TestConfigFunctions::test_load_config_specific_profile
FAILED pytest/test_utils.py::TestConfigFunctions::test_load_config_missing_file
FAILED pytest/test_utils.py::TestEdgeCases::test_ie_fingerprint_hash_unicode
FAILED pytest/test_utils.py::TestEdgeCases::test_config_loading_with_invalid_yaml
FAILED tests/integration/test_end_to_end.py::TestEndToEndWorkflow::test_complete_wifi_analysis_workflow
FAILED tests/integration/test_end_to_end.py::TestEndToEndWorkflow::test_plugin_integration_workflow
FAILED tests/integration/test_end_to_end.py::TestEndToEndWorkflow::test_data_pipeline_with_file_io
FAILED tests/integration/test_end_to_end.py::TestEndToEndWorkflow::test_error_handling_and_recovery
FAILED tests/integration/test_end_to_end.py::TestEndToEndWorkflow::test_performance_under_load
FAILED tests/integration/test_end_to_end.py::TestEndToEndWorkflow::test_concurrent_processing
FAILED tests/performance/test_benchmarks.py::TestClusteringBenchmarks::test_kmeans_performance
FAILED tests/performance/test_benchmarks.py::TestClusteringBenchmarks::test_dbscan_performance
FAILED tests/performance/test_benchmarks.py::TestClusteringBenchmarks::test_hierarchical_performance
FAILED tests/performance/test_benchmarks.py::TestClusteringBenchmarks::test_clustering_scalability
FAILED tests/performance/test_benchmarks.py::TestDataProcessingBenchmarks::test_data_processing_performance
FAILED tests/performance/test_benchmarks.py::TestDataProcessingBenchmarks::test_feature_extraction_performance
FAILED tests/performance/test_benchmarks.py::TestDataProcessingBenchmarks::test_feature_scaling_performance
FAILED tests/performance/test_benchmarks.py::TestClassificationBenchmarks::test_random_forest_performance
FAILED tests/performance/test_benchmarks.py::TestClassificationBenchmarks::test_svm_performance
FAILED tests/performance/test_benchmarks.py::TestMemoryBenchmarks::test_memory_usage_clustering
FAILED tests/performance/test_benchmarks.py::TestMemoryBenchmarks::test_memory_usage_large_dataset
FAILED tests/performance/test_benchmarks.py::TestConcurrentBenchmarks::test_parallel_processing_performance
FAILED tests/performance/test_benchmarks.py::TestIOBenchmarks::test_file_io_performance
FAILED tests/performance/test_benchmarks.py::TestIOBenchmarks::test_csv_io_performance
FAILED tests/performance/test_memory_profiling.py::TestMemoryUsage::test_memory_usage_clustering
FAILED tests/performance/test_memory_profiling.py::TestMemoryProfiling::test_detailed_memory_profiling
FAILED tests/performance/test_memory_profiling.py::TestMemoryProfiling::test_memory_profiling_garbage_collection
FAILED tests/performance/test_memory_profiling.py::TestMemoryOptimization::test_memory_usage_data_types
FAILED tests/unit/test_data_processing.py::TestDataValidator::test_validate_valid_data
FAILED tests/unit/test_ml_models.py::TestClusteringModel::test_fit_kmeans - T...
FAILED tests/unit/test_ml_models.py::TestClusteringModel::test_predict_after_fit
FAILED tests/unit/test_ml_models.py::TestClusteringModel::test_get_cluster_centers
FAILED tests/unit/test_ml_models.py::TestClusteringModel::test_evaluate_clustering
FAILED tests/unit/test_ml_models.py::TestClusteringModel::test_invalid_algorithm
FAILED tests/unit/test_ml_models.py::TestClusteringModel::test_hyperparameter_validation
FAILED tests/unit/test_ml_models.py::TestClassificationModel::test_cross_validation
FAILED tests/unit/test_ml_models.py::TestEnsembleModel::test_init - Assertion...
FAILED tests/unit/test_ml_models.py::TestEnsembleModel::test_fit_voting_classifier
FAILED tests/unit/test_ml_models.py::TestEnsembleModel::test_fit_bagging - At...
FAILED tests/unit/test_ml_models.py::TestEnsembleModel::test_fit_boosting - A...
FAILED tests/unit/test_ml_models.py::TestEnsembleModel::test_predict_ensemble
FAILED tests/unit/test_ml_models.py::TestEnsembleModel::test_evaluate_ensemble
FAILED tests/unit/test_ml_models.py::TestEnsembleModel::test_individual_estimator_performance
FAILED tests/unit/test_ml_models.py::TestEnsembleModel::test_invalid_algorithm
FAILED tests/unit/test_ml_models.py::TestEnsembleModel::test_empty_estimators
FAILED tests/unit/test_ml_models.py::TestModelPersistence::test_save_load_model
FAILED tests/unit/test_ml_models.py::TestModelPersistence::test_save_load_ensemble
ERROR tests/unit/test_utils_failed.py::test_lookup_vendor_apple_mac
ERROR tests/unit/test_utils_failed.py::test_lookup_vendor_randomized_mac
ERROR tests/unit/test_utils_failed.py::test_lookup_vendor_unknown_mac
ERROR tests/unit/test_utils_failed.py::test_intelligent_vendor_lookup
ERROR tests/unit/test_utils_failed.py::test_intelligent_vendor_lookup_no_ies
ERROR tests/unit/test_utils_failed.py::test_download_oui_file_success
ERROR tests/unit/test_utils_failed.py::test_download_oui_file_failure
===== 104 failed, 256 passed, 147 warnings, 7 errors in 931.01s (0:15:31) ======
